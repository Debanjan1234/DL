{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import impl.layer as l\n",
    "\n",
    "# Dataset preparation and pre-processing\n",
    "mnist = input_data.read_data_sets('data/MNIST_data/', one_hot=False)\n",
    "\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "# y_test.shape, y_val.shape, y_train.shape\n",
    "# X_train.shape, X_train.dtype, X_val.shape, X_val.dtype, X_test.shape, X_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-processing: normalizing\n",
    "def normalize(X):\n",
    "    # max scale for images 255= 2**8= 8 bit grayscale for each channel\n",
    "    return (X - X.mean(axis=0)) #/ X.std(axis=0)\n",
    "\n",
    "X_train, X_val, X_test = normalize(X=X_train), normalize(X=X_val), normalize(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l # or from impl.layer import *\n",
    "from impl.loss import * # import all functions from impl.loss file # import impl.loss as loss_func\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "class FFNN:\n",
    "\n",
    "    def __init__(self, D, C, H, L):\n",
    "        self.L = L # number of layers or depth\n",
    "        self.losses = {'train':[], 'valid':[], 'valid_acc':[]}\n",
    "        \n",
    "        # The adaptive/learnable/updatable random feedforward\n",
    "        self.model = []\n",
    "        self.W_fixed = []\n",
    "        self.grads = []\n",
    "        low, high = -1, 1\n",
    "        \n",
    "        # Input layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.), b=np.zeros((1, H)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Input layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[0].items()})\n",
    "\n",
    "        # Hidden layers: weights/ biases\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = dict(W=np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, H)))\n",
    "            m_L.append(m)\n",
    "        self.model.append(m_L)\n",
    "        # Fixed feedback weight\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.)\n",
    "            m_L.append(m)\n",
    "        self.W_fixed.append(m_L)\n",
    "        # Hidden layer: gradients\n",
    "        grad = []\n",
    "        for layer in range(L):\n",
    "            grad.append({key: np.zeros_like(val) for key, val in self.model[1][layer].items()})\n",
    "        self.grads.append(grad)\n",
    "        \n",
    "        # Output layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, C)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Outout layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[2].items()})\n",
    "        \n",
    "    def fc_forward(self, X, W, b):\n",
    "        out = (X @ W) + b\n",
    "        cache = (W, X)\n",
    "        return out, cache\n",
    "\n",
    "    def fc_backward(self, dout, cache, W_fixed):\n",
    "        W, X = cache\n",
    "\n",
    "        dW = X.T @ dout\n",
    "        db = np.sum(dout, axis=0).reshape(1, -1) # db_1xn\n",
    "        # dX = dout @ W.T # Backprop\n",
    "        dX = dout @ W_fixed.T # fb alignment\n",
    "\n",
    "        return dX, dW, db\n",
    "\n",
    "    def train_forward(self, X):\n",
    "        caches = []\n",
    "        \n",
    "        # Input layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[0]['W'], b=self.model[0]['b']) # X_1xD, y_1xc\n",
    "        y = l.sigmoid(X=y)\n",
    "        X = y.copy() # pass to the next layer\n",
    "        caches.append(fc_cache) # caches[0]\n",
    "        \n",
    "        # Hidden layers\n",
    "        fc_caches = []\n",
    "        for layer in range(self.L):\n",
    "            y, fc_cache = self.fc_forward(X=X, W=self.model[1][layer]['W'], b=self.model[1][layer]['b'])\n",
    "            y = l.sigmoid(X=y)\n",
    "            X = y.copy() # pass to next layer\n",
    "            fc_caches.append(fc_cache)\n",
    "        caches.append(fc_caches) # caches[1]\n",
    "        \n",
    "        # Output layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[2]['W'], b=self.model[2]['b'])\n",
    "        caches.append(fc_cache) # caches[2]\n",
    "\n",
    "        return y, caches\n",
    "\n",
    "    def loss_function(self, y, y_train):\n",
    "        \n",
    "        loss = cross_entropy(y, y_train) # softmax is included\n",
    "        dy = dcross_entropy(y, y_train) # dsoftmax is included\n",
    "        \n",
    "        return loss, dy\n",
    "    \n",
    "    def train_backward(self, dy, caches):\n",
    "        # Output layer\n",
    "        fc_cache = caches[2]\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[2])\n",
    "        dy = dX.copy() # pass to the previous layer\n",
    "        self.grads[2]['W'] = dW\n",
    "        self.grads[2]['b'] = db\n",
    "\n",
    "        # Hidden layer\n",
    "        fc_caches = caches[1]\n",
    "        for layer in reversed(range(self.L)):\n",
    "            dX, dW, db = self.fc_backward(dout=dy, cache=fc_caches[layer], W_fixed=self.W_fixed[1][layer])\n",
    "            dy = dX.copy()\n",
    "            self.grads[1][layer]['W'] = dW\n",
    "            self.grads[1][layer]['b'] = db\n",
    "        \n",
    "        # Input layer\n",
    "        fc_cache = caches[0]\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[0])\n",
    "        self.grads[0]['W'] = dW\n",
    "        self.grads[0]['b'] = db\n",
    "\n",
    "        return dX\n",
    "    \n",
    "    def test(self, X):\n",
    "        y_logit, _ = self.train_forward(X)\n",
    "        \n",
    "        # if self.mode == 'classification':\n",
    "        y_prob = l.softmax(y_logit) # for accuracy== acc\n",
    "        y_pred = np.argmax(y_prob, axis=1) # for loss==err\n",
    "        \n",
    "        return y_pred, y_logit\n",
    "        \n",
    "    def get_minibatch(self, X, y, minibatch_size, shuffle):\n",
    "        minibatches = []\n",
    "\n",
    "        if shuffle:\n",
    "            X, y = skshuffle(X, y)\n",
    "\n",
    "        for i in range(0, X.shape[0], minibatch_size):\n",
    "            X_mini = X[i:i + minibatch_size]\n",
    "            y_mini = y[i:i + minibatch_size]\n",
    "            minibatches.append((X_mini, y_mini))\n",
    "\n",
    "        return minibatches\n",
    "\n",
    "    def sgd(self, train_set, val_set, alpha, mb_size, n_iter, print_after):\n",
    "        X_train, y_train = train_set\n",
    "        X_val, y_val = val_set\n",
    "\n",
    "        # Epochs\n",
    "        for iter in range(1, n_iter + 1):\n",
    "\n",
    "            # Minibatches\n",
    "            minibatches = self.get_minibatch(X_train, y_train, mb_size, shuffle=True)\n",
    "            idx = np.random.randint(0, len(minibatches))\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            \n",
    "            # Train the model\n",
    "            y, caches = self.train_forward(X_mini)\n",
    "            loss, dy = self.loss_function(y, y_mini)\n",
    "            _ = self.train_backward(dy, caches)\n",
    "            self.losses['train'].append(loss)\n",
    "            \n",
    "            # Update the model for input layer\n",
    "            for key in self.grads[0].keys():\n",
    "                self.model[0][key] -= alpha * self.grads[0][key]\n",
    "\n",
    "            # Update the model for the hidden layers\n",
    "            for layer in range(self.L):\n",
    "                for key in self.grads[1][layer].keys():\n",
    "                    self.model[1][layer][key] -= alpha * self.grads[1][layer][key]\n",
    "\n",
    "            # Update the model for output layer\n",
    "            for key in self.grads[2].keys():\n",
    "                self.model[2][key] -= alpha * self.grads[2][key]\n",
    "                \n",
    "            # Validate the updated model\n",
    "            y_pred, y_logit = self.test(X_val)\n",
    "            valid_loss, _ = self.loss_function(y_logit, y_val) # softmax is included in entropy loss function\n",
    "            self.losses['valid'].append(valid_loss)\n",
    "            valid_acc = np.mean(y_pred == y_val)\n",
    "            self.losses['valid_acc'].append(valid_acc)\n",
    "            \n",
    "            # Print the model info: loss & accuracy or err & acc\n",
    "            if iter % print_after == 0:\n",
    "                print('Iter-{} train loss: {:.4f} valid loss: {:.4f}, valid accuracy: {:.4f}'.format(\n",
    "                    iter, loss, valid_loss, valid_acc))\n",
    "\n",
    "        # Test the final model\n",
    "        y_pred, y_logit = nn.test(X_test)\n",
    "        loss, _ = self.loss_function(y_logit, y_test) # softmax is included in entropy loss function\n",
    "        acc = np.mean(y_pred == y_test)\n",
    "        print('Last iteration - Test accuracy mean: {:.4f}, std: {:.4f}, loss: {:.4f}'.format(\n",
    "            acc.mean(), acc.std(), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-100 train loss: 2.4136 valid loss: 2.3602, valid accuracy: 0.0958\n",
      "Iter-200 train loss: 2.3442 valid loss: 2.3510, valid accuracy: 0.0958\n",
      "Iter-300 train loss: 2.3737 valid loss: 2.3428, valid accuracy: 0.0958\n",
      "Iter-400 train loss: 2.3175 valid loss: 2.3358, valid accuracy: 0.0958\n",
      "Iter-500 train loss: 2.3641 valid loss: 2.3303, valid accuracy: 0.0958\n",
      "Iter-600 train loss: 2.3110 valid loss: 2.3256, valid accuracy: 0.0958\n",
      "Iter-700 train loss: 2.3209 valid loss: 2.3214, valid accuracy: 0.0952\n",
      "Iter-800 train loss: 2.3063 valid loss: 2.3182, valid accuracy: 0.0928\n",
      "Iter-900 train loss: 2.3065 valid loss: 2.3154, valid accuracy: 0.0744\n",
      "Iter-1000 train loss: 2.2954 valid loss: 2.3132, valid accuracy: 0.0668\n",
      "Iter-1100 train loss: 2.3226 valid loss: 2.3111, valid accuracy: 0.0664\n",
      "Iter-1200 train loss: 2.2978 valid loss: 2.3096, valid accuracy: 0.0630\n",
      "Iter-1300 train loss: 2.3057 valid loss: 2.3083, valid accuracy: 0.0668\n",
      "Iter-1400 train loss: 2.3215 valid loss: 2.3071, valid accuracy: 0.0742\n",
      "Iter-1500 train loss: 2.3024 valid loss: 2.3061, valid accuracy: 0.0854\n",
      "Iter-1600 train loss: 2.2993 valid loss: 2.3054, valid accuracy: 0.0940\n",
      "Iter-1700 train loss: 2.2987 valid loss: 2.3047, valid accuracy: 0.1008\n",
      "Iter-1800 train loss: 2.3216 valid loss: 2.3041, valid accuracy: 0.1060\n",
      "Iter-1900 train loss: 2.2961 valid loss: 2.3037, valid accuracy: 0.1040\n",
      "Iter-2000 train loss: 2.2969 valid loss: 2.3034, valid accuracy: 0.0992\n",
      "Iter-2100 train loss: 2.3097 valid loss: 2.3030, valid accuracy: 0.0838\n",
      "Iter-2200 train loss: 2.2911 valid loss: 2.3026, valid accuracy: 0.0620\n",
      "Iter-2300 train loss: 2.3060 valid loss: 2.3023, valid accuracy: 0.0394\n",
      "Iter-2400 train loss: 2.3028 valid loss: 2.3021, valid accuracy: 0.0372\n",
      "Iter-2500 train loss: 2.3140 valid loss: 2.3019, valid accuracy: 0.0270\n",
      "Iter-2600 train loss: 2.2942 valid loss: 2.3015, valid accuracy: 0.0238\n",
      "Iter-2700 train loss: 2.3015 valid loss: 2.3013, valid accuracy: 0.0292\n",
      "Iter-2800 train loss: 2.2955 valid loss: 2.3011, valid accuracy: 0.0340\n",
      "Iter-2900 train loss: 2.2931 valid loss: 2.3008, valid accuracy: 0.0250\n",
      "Iter-3000 train loss: 2.3085 valid loss: 2.3007, valid accuracy: 0.0328\n",
      "Iter-3100 train loss: 2.3092 valid loss: 2.3004, valid accuracy: 0.0416\n",
      "Iter-3200 train loss: 2.2922 valid loss: 2.3001, valid accuracy: 0.0518\n",
      "Iter-3300 train loss: 2.3092 valid loss: 2.2998, valid accuracy: 0.0722\n",
      "Iter-3400 train loss: 2.3002 valid loss: 2.2996, valid accuracy: 0.0964\n",
      "Iter-3500 train loss: 2.2926 valid loss: 2.2993, valid accuracy: 0.1110\n",
      "Iter-3600 train loss: 2.3032 valid loss: 2.2992, valid accuracy: 0.1096\n",
      "Iter-3700 train loss: 2.2996 valid loss: 2.2989, valid accuracy: 0.1116\n",
      "Iter-3800 train loss: 2.2987 valid loss: 2.2985, valid accuracy: 0.1122\n",
      "Iter-3900 train loss: 2.3004 valid loss: 2.2981, valid accuracy: 0.1086\n",
      "Iter-4000 train loss: 2.2918 valid loss: 2.2977, valid accuracy: 0.1044\n",
      "Iter-4100 train loss: 2.3001 valid loss: 2.2973, valid accuracy: 0.1052\n",
      "Iter-4200 train loss: 2.2873 valid loss: 2.2970, valid accuracy: 0.0954\n",
      "Iter-4300 train loss: 2.3015 valid loss: 2.2966, valid accuracy: 0.0990\n",
      "Iter-4400 train loss: 2.2942 valid loss: 2.2962, valid accuracy: 0.1004\n",
      "Iter-4500 train loss: 2.2865 valid loss: 2.2957, valid accuracy: 0.1010\n",
      "Iter-4600 train loss: 2.2969 valid loss: 2.2953, valid accuracy: 0.1122\n",
      "Iter-4700 train loss: 2.2902 valid loss: 2.2948, valid accuracy: 0.1050\n",
      "Iter-4800 train loss: 2.2985 valid loss: 2.2942, valid accuracy: 0.1080\n",
      "Iter-4900 train loss: 2.2877 valid loss: 2.2936, valid accuracy: 0.1076\n",
      "Iter-5000 train loss: 2.2878 valid loss: 2.2929, valid accuracy: 0.1116\n",
      "Iter-5100 train loss: 2.2938 valid loss: 2.2924, valid accuracy: 0.1140\n",
      "Iter-5200 train loss: 2.2852 valid loss: 2.2918, valid accuracy: 0.1204\n",
      "Iter-5300 train loss: 2.2798 valid loss: 2.2912, valid accuracy: 0.1288\n",
      "Iter-5400 train loss: 2.2862 valid loss: 2.2905, valid accuracy: 0.1336\n",
      "Iter-5500 train loss: 2.2996 valid loss: 2.2898, valid accuracy: 0.1420\n",
      "Iter-5600 train loss: 2.2985 valid loss: 2.2889, valid accuracy: 0.1462\n",
      "Iter-5700 train loss: 2.2890 valid loss: 2.2881, valid accuracy: 0.1546\n",
      "Iter-5800 train loss: 2.2902 valid loss: 2.2872, valid accuracy: 0.1472\n",
      "Iter-5900 train loss: 2.2910 valid loss: 2.2863, valid accuracy: 0.1500\n",
      "Iter-6000 train loss: 2.2831 valid loss: 2.2855, valid accuracy: 0.1566\n",
      "Iter-6100 train loss: 2.2757 valid loss: 2.2846, valid accuracy: 0.1542\n",
      "Iter-6200 train loss: 2.2807 valid loss: 2.2834, valid accuracy: 0.1564\n",
      "Iter-6300 train loss: 2.2958 valid loss: 2.2824, valid accuracy: 0.1572\n",
      "Iter-6400 train loss: 2.2899 valid loss: 2.2813, valid accuracy: 0.1642\n",
      "Iter-6500 train loss: 2.2829 valid loss: 2.2802, valid accuracy: 0.1716\n",
      "Iter-6600 train loss: 2.2809 valid loss: 2.2790, valid accuracy: 0.1700\n",
      "Iter-6700 train loss: 2.2748 valid loss: 2.2778, valid accuracy: 0.1722\n",
      "Iter-6800 train loss: 2.2935 valid loss: 2.2766, valid accuracy: 0.1734\n",
      "Iter-6900 train loss: 2.2720 valid loss: 2.2754, valid accuracy: 0.1812\n",
      "Iter-7000 train loss: 2.2610 valid loss: 2.2739, valid accuracy: 0.1838\n",
      "Iter-7100 train loss: 2.2624 valid loss: 2.2726, valid accuracy: 0.1866\n",
      "Iter-7200 train loss: 2.2719 valid loss: 2.2713, valid accuracy: 0.1872\n",
      "Iter-7300 train loss: 2.2688 valid loss: 2.2697, valid accuracy: 0.1902\n",
      "Iter-7400 train loss: 2.2624 valid loss: 2.2681, valid accuracy: 0.1920\n",
      "Iter-7500 train loss: 2.2734 valid loss: 2.2665, valid accuracy: 0.1942\n",
      "Iter-7600 train loss: 2.2668 valid loss: 2.2648, valid accuracy: 0.1960\n",
      "Iter-7700 train loss: 2.2594 valid loss: 2.2630, valid accuracy: 0.1980\n",
      "Iter-7800 train loss: 2.2750 valid loss: 2.2613, valid accuracy: 0.1986\n",
      "Iter-7900 train loss: 2.2561 valid loss: 2.2593, valid accuracy: 0.2006\n",
      "Iter-8000 train loss: 2.2643 valid loss: 2.2574, valid accuracy: 0.2050\n",
      "Iter-8100 train loss: 2.2541 valid loss: 2.2553, valid accuracy: 0.2052\n",
      "Iter-8200 train loss: 2.2526 valid loss: 2.2533, valid accuracy: 0.2090\n",
      "Iter-8300 train loss: 2.2442 valid loss: 2.2512, valid accuracy: 0.2106\n",
      "Iter-8400 train loss: 2.2528 valid loss: 2.2490, valid accuracy: 0.2152\n",
      "Iter-8500 train loss: 2.2482 valid loss: 2.2468, valid accuracy: 0.2186\n",
      "Iter-8600 train loss: 2.2469 valid loss: 2.2446, valid accuracy: 0.2184\n",
      "Iter-8700 train loss: 2.2448 valid loss: 2.2423, valid accuracy: 0.2166\n",
      "Iter-8800 train loss: 2.2158 valid loss: 2.2399, valid accuracy: 0.2202\n",
      "Iter-8900 train loss: 2.2419 valid loss: 2.2374, valid accuracy: 0.2232\n",
      "Iter-9000 train loss: 2.2518 valid loss: 2.2348, valid accuracy: 0.2264\n",
      "Iter-9100 train loss: 2.2208 valid loss: 2.2321, valid accuracy: 0.2324\n",
      "Iter-9200 train loss: 2.2295 valid loss: 2.2295, valid accuracy: 0.2336\n",
      "Iter-9300 train loss: 2.2120 valid loss: 2.2268, valid accuracy: 0.2370\n",
      "Iter-9400 train loss: 2.2376 valid loss: 2.2241, valid accuracy: 0.2452\n",
      "Iter-9500 train loss: 2.2301 valid loss: 2.2212, valid accuracy: 0.2498\n",
      "Iter-9600 train loss: 2.2310 valid loss: 2.2183, valid accuracy: 0.2496\n",
      "Iter-9700 train loss: 2.2220 valid loss: 2.2152, valid accuracy: 0.2524\n",
      "Iter-9800 train loss: 2.2128 valid loss: 2.2122, valid accuracy: 0.2568\n",
      "Iter-9900 train loss: 2.2373 valid loss: 2.2090, valid accuracy: 0.2616\n",
      "Iter-10000 train loss: 2.1965 valid loss: 2.2058, valid accuracy: 0.2630\n",
      "Iter-10100 train loss: 2.1720 valid loss: 2.2024, valid accuracy: 0.2642\n",
      "Iter-10200 train loss: 2.1854 valid loss: 2.1991, valid accuracy: 0.2684\n",
      "Iter-10300 train loss: 2.2025 valid loss: 2.1955, valid accuracy: 0.2728\n",
      "Iter-10400 train loss: 2.2070 valid loss: 2.1921, valid accuracy: 0.2784\n",
      "Iter-10500 train loss: 2.1962 valid loss: 2.1886, valid accuracy: 0.2834\n",
      "Iter-10600 train loss: 2.1945 valid loss: 2.1849, valid accuracy: 0.2872\n",
      "Iter-10700 train loss: 2.2065 valid loss: 2.1812, valid accuracy: 0.2902\n",
      "Iter-10800 train loss: 2.2001 valid loss: 2.1773, valid accuracy: 0.2918\n",
      "Iter-10900 train loss: 2.1936 valid loss: 2.1735, valid accuracy: 0.2958\n",
      "Iter-11000 train loss: 2.1819 valid loss: 2.1695, valid accuracy: 0.2986\n",
      "Iter-11100 train loss: 2.1515 valid loss: 2.1655, valid accuracy: 0.2996\n",
      "Iter-11200 train loss: 2.1881 valid loss: 2.1615, valid accuracy: 0.3014\n",
      "Iter-11300 train loss: 2.1459 valid loss: 2.1573, valid accuracy: 0.3036\n",
      "Iter-11400 train loss: 2.1370 valid loss: 2.1532, valid accuracy: 0.3062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-11500 train loss: 2.1584 valid loss: 2.1490, valid accuracy: 0.3098\n",
      "Iter-11600 train loss: 2.1528 valid loss: 2.1447, valid accuracy: 0.3138\n",
      "Iter-11700 train loss: 2.1360 valid loss: 2.1405, valid accuracy: 0.3176\n",
      "Iter-11800 train loss: 2.1195 valid loss: 2.1362, valid accuracy: 0.3166\n",
      "Iter-11900 train loss: 2.1144 valid loss: 2.1319, valid accuracy: 0.3212\n",
      "Iter-12000 train loss: 2.0980 valid loss: 2.1276, valid accuracy: 0.3302\n",
      "Iter-12100 train loss: 2.1328 valid loss: 2.1232, valid accuracy: 0.3294\n",
      "Iter-12200 train loss: 2.1125 valid loss: 2.1187, valid accuracy: 0.3290\n",
      "Iter-12300 train loss: 2.1266 valid loss: 2.1141, valid accuracy: 0.3336\n",
      "Iter-12400 train loss: 2.1171 valid loss: 2.1096, valid accuracy: 0.3340\n",
      "Iter-12500 train loss: 2.1131 valid loss: 2.1049, valid accuracy: 0.3368\n",
      "Iter-12600 train loss: 2.0990 valid loss: 2.1002, valid accuracy: 0.3388\n",
      "Iter-12700 train loss: 2.0853 valid loss: 2.0955, valid accuracy: 0.3398\n",
      "Iter-12800 train loss: 2.1008 valid loss: 2.0907, valid accuracy: 0.3412\n",
      "Iter-12900 train loss: 2.0528 valid loss: 2.0860, valid accuracy: 0.3432\n",
      "Iter-13000 train loss: 2.0862 valid loss: 2.0812, valid accuracy: 0.3414\n",
      "Iter-13100 train loss: 2.1362 valid loss: 2.0764, valid accuracy: 0.3426\n",
      "Iter-13200 train loss: 2.0810 valid loss: 2.0715, valid accuracy: 0.3442\n",
      "Iter-13300 train loss: 2.1470 valid loss: 2.0665, valid accuracy: 0.3440\n",
      "Iter-13400 train loss: 2.0712 valid loss: 2.0617, valid accuracy: 0.3438\n",
      "Iter-13500 train loss: 2.0748 valid loss: 2.0568, valid accuracy: 0.3452\n",
      "Iter-13600 train loss: 2.0708 valid loss: 2.0519, valid accuracy: 0.3476\n",
      "Iter-13700 train loss: 2.0084 valid loss: 2.0470, valid accuracy: 0.3490\n",
      "Iter-13800 train loss: 2.0502 valid loss: 2.0420, valid accuracy: 0.3484\n",
      "Iter-13900 train loss: 2.0101 valid loss: 2.0370, valid accuracy: 0.3472\n",
      "Iter-14000 train loss: 2.0000 valid loss: 2.0319, valid accuracy: 0.3480\n",
      "Iter-14100 train loss: 2.0350 valid loss: 2.0268, valid accuracy: 0.3504\n",
      "Iter-14200 train loss: 2.0324 valid loss: 2.0218, valid accuracy: 0.3520\n",
      "Iter-14300 train loss: 1.9857 valid loss: 2.0168, valid accuracy: 0.3528\n",
      "Iter-14400 train loss: 2.0117 valid loss: 2.0120, valid accuracy: 0.3532\n",
      "Iter-14500 train loss: 2.0651 valid loss: 2.0069, valid accuracy: 0.3526\n",
      "Iter-14600 train loss: 2.0124 valid loss: 2.0020, valid accuracy: 0.3550\n",
      "Iter-14700 train loss: 1.9658 valid loss: 1.9970, valid accuracy: 0.3556\n",
      "Iter-14800 train loss: 1.9515 valid loss: 1.9921, valid accuracy: 0.3574\n",
      "Iter-14900 train loss: 1.9617 valid loss: 1.9871, valid accuracy: 0.3582\n",
      "Iter-15000 train loss: 1.9914 valid loss: 1.9820, valid accuracy: 0.3596\n",
      "Iter-15100 train loss: 1.9673 valid loss: 1.9770, valid accuracy: 0.3590\n",
      "Iter-15200 train loss: 2.0039 valid loss: 1.9720, valid accuracy: 0.3618\n",
      "Iter-15300 train loss: 1.9054 valid loss: 1.9671, valid accuracy: 0.3634\n",
      "Iter-15400 train loss: 1.8775 valid loss: 1.9622, valid accuracy: 0.3656\n",
      "Iter-15500 train loss: 1.9474 valid loss: 1.9572, valid accuracy: 0.3666\n",
      "Iter-15600 train loss: 1.9950 valid loss: 1.9524, valid accuracy: 0.3676\n",
      "Iter-15700 train loss: 1.9557 valid loss: 1.9475, valid accuracy: 0.3686\n",
      "Iter-15800 train loss: 2.0302 valid loss: 1.9425, valid accuracy: 0.3696\n",
      "Iter-15900 train loss: 2.0201 valid loss: 1.9378, valid accuracy: 0.3714\n",
      "Iter-16000 train loss: 1.8610 valid loss: 1.9329, valid accuracy: 0.3700\n",
      "Iter-16100 train loss: 1.9166 valid loss: 1.9281, valid accuracy: 0.3718\n",
      "Iter-16200 train loss: 1.9569 valid loss: 1.9234, valid accuracy: 0.3742\n",
      "Iter-16300 train loss: 1.9471 valid loss: 1.9185, valid accuracy: 0.3746\n",
      "Iter-16400 train loss: 1.8232 valid loss: 1.9137, valid accuracy: 0.3742\n",
      "Iter-16500 train loss: 1.8393 valid loss: 1.9090, valid accuracy: 0.3782\n",
      "Iter-16600 train loss: 1.8759 valid loss: 1.9043, valid accuracy: 0.3778\n",
      "Iter-16700 train loss: 1.8500 valid loss: 1.8996, valid accuracy: 0.3794\n",
      "Iter-16800 train loss: 1.8346 valid loss: 1.8948, valid accuracy: 0.3796\n",
      "Iter-16900 train loss: 1.9494 valid loss: 1.8901, valid accuracy: 0.3788\n",
      "Iter-17000 train loss: 1.8959 valid loss: 1.8854, valid accuracy: 0.3796\n",
      "Iter-17100 train loss: 1.9370 valid loss: 1.8807, valid accuracy: 0.3822\n",
      "Iter-17200 train loss: 1.8646 valid loss: 1.8763, valid accuracy: 0.3826\n",
      "Iter-17300 train loss: 1.8331 valid loss: 1.8717, valid accuracy: 0.3826\n",
      "Iter-17400 train loss: 1.8844 valid loss: 1.8674, valid accuracy: 0.3818\n",
      "Iter-17500 train loss: 1.8671 valid loss: 1.8630, valid accuracy: 0.3808\n",
      "Iter-17600 train loss: 1.8420 valid loss: 1.8583, valid accuracy: 0.3810\n",
      "Iter-17700 train loss: 1.8236 valid loss: 1.8539, valid accuracy: 0.3818\n",
      "Iter-17800 train loss: 1.8302 valid loss: 1.8494, valid accuracy: 0.3830\n",
      "Iter-17900 train loss: 1.8277 valid loss: 1.8450, valid accuracy: 0.3848\n",
      "Iter-18000 train loss: 1.8260 valid loss: 1.8406, valid accuracy: 0.3856\n",
      "Iter-18100 train loss: 1.8652 valid loss: 1.8362, valid accuracy: 0.3856\n",
      "Iter-18200 train loss: 1.8939 valid loss: 1.8319, valid accuracy: 0.3860\n",
      "Iter-18300 train loss: 1.7648 valid loss: 1.8276, valid accuracy: 0.3882\n",
      "Iter-18400 train loss: 1.8279 valid loss: 1.8233, valid accuracy: 0.3886\n",
      "Iter-18500 train loss: 1.8715 valid loss: 1.8191, valid accuracy: 0.3886\n",
      "Iter-18600 train loss: 1.8616 valid loss: 1.8148, valid accuracy: 0.3878\n",
      "Iter-18700 train loss: 1.7999 valid loss: 1.8106, valid accuracy: 0.3888\n",
      "Iter-18800 train loss: 1.8426 valid loss: 1.8065, valid accuracy: 0.3888\n",
      "Iter-18900 train loss: 1.9232 valid loss: 1.8024, valid accuracy: 0.3896\n",
      "Iter-19000 train loss: 1.8209 valid loss: 1.7981, valid accuracy: 0.3906\n",
      "Iter-19100 train loss: 1.8216 valid loss: 1.7939, valid accuracy: 0.3908\n",
      "Iter-19200 train loss: 1.7504 valid loss: 1.7897, valid accuracy: 0.3912\n",
      "Iter-19300 train loss: 1.7557 valid loss: 1.7857, valid accuracy: 0.3922\n",
      "Iter-19400 train loss: 1.7419 valid loss: 1.7817, valid accuracy: 0.3930\n",
      "Iter-19500 train loss: 1.8290 valid loss: 1.7777, valid accuracy: 0.3942\n",
      "Iter-19600 train loss: 1.7697 valid loss: 1.7738, valid accuracy: 0.3958\n",
      "Iter-19700 train loss: 1.6798 valid loss: 1.7699, valid accuracy: 0.3970\n",
      "Iter-19800 train loss: 1.7002 valid loss: 1.7660, valid accuracy: 0.3972\n",
      "Iter-19900 train loss: 1.8505 valid loss: 1.7622, valid accuracy: 0.3978\n",
      "Iter-20000 train loss: 1.7806 valid loss: 1.7584, valid accuracy: 0.3982\n",
      "Last iteration - Test accuracy mean: 0.4004, std: 0.0000, loss: 1.7537\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "n_iter = 20000 # number of epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "mb_size = 64 # 2**10==1024 # width, timestep for sequential data or minibatch size\n",
    "print_after = 100 # n_iter//10 # print loss for train, valid, and test\n",
    "num_hidden_units = 32 # number of kernels/ filters in each layer\n",
    "num_input_units = X_train.shape[1] # noise added at the input lavel as input noise we can use dX or for more improvement\n",
    "num_output_units = y_train.max() + 1 # number of classes in this classification problem\n",
    "num_layers = 1 # depth \n",
    "\n",
    "# Build the model/NN and learn it: running session.\n",
    "nn = FFNN(C=num_output_units, D=num_input_units, H=num_hidden_units, L=num_layers)\n",
    "\n",
    "nn.sgd(train_set=(X_train, y_train), val_set=(X_val, y_val), mb_size=mb_size, alpha=alpha, \n",
    "           n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAkIIkYtJEBBCiFxMgoAQQuRi/w9DSGaP/fMKLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119127550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(nn.losses['train'], label='Train loss')\n",
    "# plt.plot(nn.losses['smooth train'], label='Train smooth loss')\n",
    "plt.plot(nn.losses['valid'], label='Valid loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118ef9278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn.losses['valid_acc'], label='Valid accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
