{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('data/text_data/japan.txt', 'r') as f:\n",
    "    txt = f.read()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    char_to_idx = {char: i for i, char in enumerate(set(txt))}\n",
    "    idx_to_char = {i: char for i, char in enumerate(set(txt))}\n",
    "\n",
    "    X = np.array([char_to_idx[x] for x in txt])\n",
    "    y = [char_to_idx[x] for x in txt[1:]]\n",
    "    y.append(char_to_idx['.'])\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import impl.layer as l\n",
    "\n",
    "class GRU2:\n",
    "\n",
    "    def __init__(self, D, H, L, char2idx, idx2char, p_dropout):\n",
    "        self.D = D\n",
    "        self.H = H\n",
    "        self.L = L\n",
    "        self.char2idx = char2idx\n",
    "        self.idx2char = idx2char\n",
    "        self.vocab_size = len(char2idx)\n",
    "        self.losses = {'train':[], 'smooth train':[]}\n",
    "        self.p_dropout = p_dropout\n",
    "        \n",
    "        # Model parameters\n",
    "        Z = H + D\n",
    "        m = dict(\n",
    "            Wz=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wh=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wy=np.random.randn(H, D) / np.sqrt(H / 2.),\n",
    "            bz=np.zeros((1, H)),\n",
    "            bh=np.zeros((1, H)),\n",
    "            by=np.zeros((1, D))\n",
    "        )\n",
    "        \n",
    "        self.model = []\n",
    "        for _ in range(self.L):\n",
    "            self.model.append(m)\n",
    "            \n",
    "    def initial_state(self):\n",
    "        return np.zeros((1, self.H))\n",
    "\n",
    "    # p_dropout == keep_prob in this case!\n",
    "    # p = p_dropout and q = keep_prob => q = 1-q??\n",
    "    def dropout_forward(self, X, p_dropout):\n",
    "        u = np.random.binomial(1, p_dropout, size=X.shape) / p_dropout\n",
    "        #         q = 1-p_dropout\n",
    "        #         u = np.random.binomial(1, q, size=X.shape)\n",
    "        out = X * u\n",
    "        cache = u\n",
    "        return out, cache\n",
    "\n",
    "    def dropout_backward(self, dout, cache):\n",
    "        dX = dout * cache\n",
    "        return dX\n",
    "    \n",
    "    def forward(self, X, h, m, train):\n",
    "        Wz, Wh, Wy = m['Wz'], m['Wh'], m['Wy']\n",
    "        bz, bh, by = m['bz'], m['bh'], m['by']\n",
    "\n",
    "        X_one_hot = X.copy()\n",
    "        h_old = h.copy()\n",
    "\n",
    "        X = np.column_stack((h_old, X_one_hot))\n",
    "\n",
    "        hz, hz_cache = l.fc_forward(X, Wz, bz)\n",
    "        hz, hz_sigm_cache = l.sigmoid_forward(hz)\n",
    "\n",
    "        hh, hh_cache = l.fc_forward(X, Wh, bh)\n",
    "        hh, hh_tanh_cache = l.tanh_forward(hh)\n",
    "\n",
    "        h = h_old + (hz * (hh - h_old))\n",
    "        y, y_cache = l.fc_forward(h, Wy, by)\n",
    "\n",
    "        if train:\n",
    "            y, do_cache = self.dropout_forward(X=y, p_dropout=self.p_dropout)\n",
    "            cache = (h_old, X_one_hot, hz, hz_cache, hz_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache, do_cache)\n",
    "        else:\n",
    "            cache = h_old, X_one_hot, hz, hz_cache, hz_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache\n",
    "\n",
    "        return y, h, cache\n",
    "\n",
    "    def backward(self, dy, dh, cache, train):\n",
    "        if train:\n",
    "            h_old, X_one_hot, hz, hz_cache, hz_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache, do_cache = cache\n",
    "            dy = self.dropout_backward(dout=dy, cache=do_cache)\n",
    "        else:\n",
    "            h_old, X_one_hot, hz, hz_cache, hz_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache = cache\n",
    "        \n",
    "        dh_next = dh.copy()\n",
    "\n",
    "        dh, dWy, dby = l.fc_backward(dy, y_cache)\n",
    "        dh += dh_next\n",
    "        dh_old1 = (1. - hz) * dh\n",
    "\n",
    "        dhh = hz * dh\n",
    "        dhh = l.tanh_backward(dhh, hh_tanh_cache)\n",
    "        dX, dWh, dbh = l.fc_backward(dhh, hh_cache)\n",
    "        \n",
    "        dh_old2 = dX[:, :self.H]\n",
    "        dX1 = dX[:, self.H:]\n",
    "\n",
    "        dhz = (hh - h_old) * dh\n",
    "        dhz = l.sigmoid_backward(dhz, hz_sigm_cache)\n",
    "        dX, dWz, dbz = l.fc_backward(dhz, hz_cache)\n",
    "        \n",
    "        dh_old3 = dX[:, :self.H]\n",
    "        dX2 = dX[:, self.H:]\n",
    "\n",
    "        dh = dh_old1 + dh_old2 + dh_old3\n",
    "        dX = dX1 + dX2\n",
    "\n",
    "        grad = dict(Wz=dWz, Wh=dWh, Wy=dWy, bz=dbz, bh=dbh, by=dby)\n",
    "        \n",
    "        return dX, dh, grad\n",
    "    \n",
    "    def train_forward(self, X_train, h):\n",
    "        ys, caches = [], []\n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "            caches.append([])\n",
    "            \n",
    "        for X in X_train:\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], cache = self.forward(y, h[layer], self.model[layer], train=True)\n",
    "                caches[layer].append(cache)\n",
    "                \n",
    "            ys.append(y)\n",
    "            \n",
    "        return ys, caches\n",
    "\n",
    "    def cross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(prob[range(m), y_train])\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        grad_y = l.softmax(y_pred)\n",
    "        grad_y[range(m), y_train] -= 1.0\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "    \n",
    "    def loss_function(self, y_train, ys):\n",
    "        loss, dys = 0.0, []\n",
    "\n",
    "        for y_pred, y in zip(ys, y_train):\n",
    "            loss += self.cross_entropy(y_pred, y)\n",
    "            dy = self.dcross_entropy(y_pred, y)\n",
    "            dys.append(dy)\n",
    "            \n",
    "        return loss, dys\n",
    "\n",
    "    def train_backward(self, dys, caches):\n",
    "        dh, grad, grads = [], [], []\n",
    "        for layer in range(self.L):\n",
    "            dh.append(np.zeros((1, self.H)))\n",
    "            grad.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            grads.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            \n",
    "        for t in reversed(range(len(dys))):\n",
    "            dX = dys[t]\n",
    "            for layer in reversed(range(self.L)):\n",
    "                dX, dh[layer], grad[layer] = self.backward(dX, dh[layer], caches[layer][t], train=True)\n",
    "                for key in grad[layer].keys():\n",
    "                    grads[layer][key] += grad[layer][key]\n",
    "                \n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X_seed, h, size):\n",
    "        chars = [self.idx2char[X_seed]]\n",
    "        idx_list = list(range(self.vocab_size))\n",
    "        X = X_seed\n",
    "        \n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for layer in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "\n",
    "        for _ in range(size):\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], _ = self.forward(y, h[layer], self.model[layer], train=False)\n",
    "                \n",
    "            prob = l.softmax(y)\n",
    "            idx = np.random.choice(idx_list, p=prob.ravel())\n",
    "            chars.append(self.idx2char[idx])\n",
    "            X = idx\n",
    "\n",
    "        return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "def get_minibatch(X, y, minibatch_size, shuffle):\n",
    "    minibatches = []\n",
    "\n",
    "    if shuffle:\n",
    "        X, y = skshuffle(X, y)\n",
    "\n",
    "    #     for i in range(0, X.shape[0], minibatch_size):\n",
    "    for i in range(0, X.shape[0] - minibatch_size + 1, 1):\n",
    "        X_mini = X[i:i + minibatch_size]\n",
    "        y_mini = y[i:i + minibatch_size]\n",
    "        minibatches.append((X_mini, y_mini))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "def adam_rnn(nn, X_train, y_train, alpha, mb_size, n_iter, print_after):\n",
    "    M, R = [], []\n",
    "    for layer in range(nn.L):\n",
    "        M.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        R.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        \n",
    "    beta1 = .99\n",
    "    beta2 = .999\n",
    "    state = nn.initial_state()\n",
    "    smooth_loss = 1.0\n",
    "    eps = 1e-8\n",
    "    minibatches = get_minibatch(X_train, y_train, mb_size, shuffle=False)\n",
    "\n",
    "    # Epochs\n",
    "    for iter in range(1, n_iter + 1):\n",
    "\n",
    "        # Minibatches\n",
    "        for idx in range(len(minibatches)):\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            ys, caches = nn.train_forward(X_mini, state)\n",
    "            loss, dys = nn.loss_function(y_mini, ys)\n",
    "            _, grads = nn.train_backward(dys, caches)\n",
    "            nn.losses['train'].append(loss)\n",
    "            smooth_loss = (0.999 * smooth_loss) + (0.001 * loss)\n",
    "            nn.losses['smooth train'].append(smooth_loss)\n",
    "\n",
    "            for layer in range(nn.L):\n",
    "                for key in grads[layer].keys(): #key, value: items\n",
    "                    M[layer][key] = l.exp_running_avg(M[layer][key], grads[layer][key], beta1)\n",
    "                    R[layer][key] = l.exp_running_avg(R[layer][key], grads[layer][key]**2, beta2)\n",
    "\n",
    "                    m_k_hat = M[layer][key] / (1. - (beta1**(iter)))\n",
    "                    r_k_hat = R[layer][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                    nn.model[layer][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + eps)\n",
    "\n",
    "        # Print loss and test sample\n",
    "        if iter % print_after == 0:\n",
    "            print('Iter-{} loss: {:.4f}'.format(iter, loss))\n",
    "            sample = nn.test(X_mini[0], state, size=100)\n",
    "            print(sample)\n",
    "            \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-13 loss: 40.3817\n",
      "iteIkyxtoJi tt, Inhax iivdexpubht aAciAint a.onard 2akht 1shch2sis soUub ntbhhtdimsexG2nelhty fic hg \n",
      "Iter-26 loss: 42.8164\n",
      "it  unhond Jirenan Ilasonh0 ar, toni xIs.', naftaG 2Cnbrru1pded onabeteetiamd satiotrinke0 paaary hy \n",
      "Iter-39 loss: 35.4492\n",
      "iskhaor rooduiIr-in ly lh. cohatted Indt Ghe GRapawapaiss phapCtehiapiph pan anes paaaaoad an, papoaw\n",
      "Iter-52 loss: 40.6266\n",
      "inlhe taran, sortUtachans tinruGnitutinthun totoxen notes con on wiraphe loGr on homh ripoinn ph8 moa\n",
      "Iter-65 loss: 37.9168\n",
      "irss net yy uAfy intoth sonty tiiuunt rpidt puthess noEowegsgttoph whess mhhrshghss in Ct tinE Gprpop\n",
      "Iter-78 loss: 48.2132\n",
      "ind. AJoky rinaneshiwpwhethiir popon whirhiwwwhiwiwhiwh widh windiwhewhiwhiwowiwowowon howhiwiwhhthha\n",
      "Iter-91 loss: 33.3388\n",
      "ich Comaci4g nohh daranian riadawinias anadininan natadiancadinttaadd inanadesn tininiin titinian and\n",
      "Iter-104 loss: 43.7282\n",
      "iJapan, has wawiwithiwh, wht, wiwhotiwthwwwhhht wiwht whhtth wth whawheshhthithisth whh whe ar tapant\n",
      "Iter-117 loss: 31.3770\n",
      "intrefindiperind usariwint aniAnoind As iniis oporolitirhh ideniCoti ttint onii de triin pii nioetoit\n",
      "Iter-130 loss: 33.5091\n",
      "iSnesandke lyfaslesototitef in ss he in ditr. insd ug dud uns ins bg un hisosoin duos nuuu ndof in ou\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.GRU2 at 0x7fc274e51f98>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "time_step = 10 # width, minibatch size and test sample size as well\n",
    "num_layers = 2 # depth\n",
    "n_iter = 130 # epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "p_dropout = 0.95 # q=1-p, q=keep_prob and p=dropout.\n",
    "print_after = n_iter//10 # print training loss, valid, and test\n",
    "num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "num_input_units = len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "\n",
    "# Build the network and learning it or optimizing it using SGD\n",
    "net = GRU2(D=num_input_units, H=num_hidden_units, L=num_layers, char2idx=char_to_idx, idx2char=idx_to_char, \n",
    "          p_dropout=p_dropout)\n",
    "\n",
    "# Start learning using BP-SGD-ADAM\n",
    "adam_rnn(nn=net, X_train=X, y_train=y, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEtCFEKKKkIAuhBBVhAR0IYSoIv4f0io76HxmZf8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc274758e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(net.losses['train'], label='Train loss')\n",
    "plt.plot(net.losses['smooth train'], label='Train smooth loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
