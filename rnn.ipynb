{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import impl.RNN as rnn\n",
    "import impl.solver as solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "with open('data/text_data/japan.txt', 'r') as f:\n",
    "    txt = f.read()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    char_to_idx = {char: i for i, char in enumerate(set(txt))}\n",
    "    idx_to_char = {i: char for i, char in enumerate(set(txt))}\n",
    "\n",
    "    X = np.array([char_to_idx[x] for x in txt])\n",
    "    y = [char_to_idx[x] for x in txt[1:]]\n",
    "    y.append(char_to_idx['.'])\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import impl.loss as loss_fun\n",
    "import impl.layer as l\n",
    "import impl.regularization as reg\n",
    "import impl.utils as util\n",
    "import impl.RNN as rnn\n",
    "\n",
    "class GRU(rnn.RNN):\n",
    "\n",
    "    def __init__(self, D, H, char2idx, idx2char):\n",
    "        super().__init__(D, H, char2idx, idx2char)\n",
    "\n",
    "    def forward(self, X, h_old, train=True):\n",
    "        m = self.model\n",
    "        Wz, Wh, Wy = m['Wz'], m['Wh'], m['Wy']\n",
    "        bz, bh, by = m['bz'], m['bh'], m['by']\n",
    "\n",
    "        X_one_hot = np.zeros(self.D)\n",
    "        X_one_hot[X] = 1.\n",
    "        X_one_hot = X_one_hot.reshape(1, -1)\n",
    "\n",
    "        # concat: [h, x]\n",
    "        X = np.column_stack((h_old, X_one_hot))\n",
    "\n",
    "        # gate: h_prob\n",
    "        hz, hz_cache = l.fc_forward(X, Wz, bz)\n",
    "        hz, hz_sigm_cache = l.sigmoid_forward(hz)\n",
    "\n",
    "        # signal: h_pred\n",
    "        hh, hh_cache = l.fc_forward(X, Wh, bh)\n",
    "        hh, hh_tanh_cache = l.tanh_forward(hh)\n",
    "\n",
    "        # h_next and y_pred\n",
    "        h = (1. - hz) * h_old + hz * hh\n",
    "        # h = h_old + hz * (hh - h_old)\n",
    "        y, y_cache = l.fc_forward(h, Wy, by)\n",
    "\n",
    "        cache = h_old, X, hz, hz_cache, hz_sigm_cache, hh, hh_cache, hh_tanh_cache, h, y_cache\n",
    "\n",
    "        if not train:\n",
    "            y = util.softmax(y)\n",
    "\n",
    "        return y, h, cache\n",
    "\n",
    "    def backward(self, y_pred, y_train, dh_next, cache):\n",
    "        h_old, X, hz, hz_cache, hz_sigm_cache, hh, hh_cache, hh_tanh_cache, h, y_cache = cache\n",
    "\n",
    "        dy = loss_fun.dcross_entropy(y_pred, y_train)\n",
    "\n",
    "        dh, dWy, dby = l.fc_backward(dy, y_cache)\n",
    "        dh += dh_next\n",
    "        dh_old1 = (1. - hz) * dh\n",
    "\n",
    "        dhh = hz * dh\n",
    "        dhh = l.tanh_backward(dhh, hh_tanh_cache)\n",
    "        dX, dWh, dbh = l.fc_backward(dhh, hh_cache)\n",
    "        dh_old2 = dX[:, :self.H]\n",
    "\n",
    "        dhz = hh * dh - h_old * dh\n",
    "        dhz = l.sigmoid_backward(dhz, hz_sigm_cache)\n",
    "        dX, dWz, dbz = l.fc_backward(dhz, hz_cache)\n",
    "        dh_old3 = dX[:, :self.H]\n",
    "\n",
    "        dh_next = dh_old1 + dh_old2 + dh_old3\n",
    "\n",
    "        grad = dict(Wz=dWz, Wh=dWh, Wy=dWy, bz=dbz, bh=dbh, by=dby)\n",
    "\n",
    "        return grad, dh_next\n",
    "\n",
    "    def _init_model(self, D, C, H):\n",
    "        Z = H + D\n",
    "\n",
    "        self.model = dict(\n",
    "            Wz=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wh=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wy=np.random.randn(H, D) / np.sqrt(D / 2.),\n",
    "            bz=np.zeros((1, H)),\n",
    "            bh=np.zeros((1, H)),\n",
    "            by=np.zeros((1, D))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(char_to_idx)\n",
    "\n",
    "# hyper parameters\n",
    "time_step = 10\n",
    "n_iter = 100000 * 3 # epochs\n",
    "alpha = 1e-3\n",
    "print_after = 1000\n",
    "H = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import impl.LSTM as lstm\n",
    "import impl.GRU as gru\n",
    "import impl.RNN as rnn\n",
    "\n",
    "# net = nn.LSTM(vocab_size, H=H, char2idx=char_to_idx, idx2char=idx_to_char)\n",
    "# net = nn.RNN(vocab_size, H=H, char2idx=char_to_idx, idx2char=idx_to_char)\n",
    "net = GRU(D=vocab_size, H=H, char2idx=char_to_idx, idx2char=idx_to_char)\n",
    "# net = nn.GRU(vocab_size, H=H, char2idx=char_to_idx, idx2char=idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================\n",
      "Iter-1000 loss: 3.3942\n",
      "=========================================================================\n",
      " tS af anl zre Sp, oat tha hTto impin rodo welear cxei me the clitioldd J2lpesr Fialgd salapls Ja  n\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-2000 loss: 2.7366\n",
      "=========================================================================\n",
      "ol pureof lht mite  riwrwh- initilalackournbc octtoul's moal 6Oponcerom is ha. on lurarer ao coruily\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-3000 loss: 2.3062\n",
      "=========================================================================\n",
      "rcory r in6 firl whp thil th e coollly god of ming Japcorat milloipmret thce 1xpf ag Covcit, rsith o\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-4000 loss: 2.0115\n",
      "=========================================================================\n",
      "ury. it ricitas ore slomed Indsis mies, porett-and the ffeat war1. R1s\"isg ut ofdy fonted pwous lyve\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-5000 loss: 1.7911\n",
      "=========================================================================\n",
      "ctaniWes the atatinof Sentiveled beitargiss 197tho. The cauled y wos cnof us ofd fofith and Horly. w\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-6000 loss: 1.6151\n",
      "=========================================================================\n",
      "ourtr in1 1uthish in Aary the Eutho firodeco smredecthe mar ionld's inttory tsr Puofes ofthind ih th\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-7000 loss: 1.4476\n",
      "=========================================================================\n",
      "a is a gopas If acean\n",
      ". The Sinok%o Kant filltoving ang the pag thil ioulimamip ane iticy 3m ala , p\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-8000 loss: 1.3180\n",
      "=========================================================================\n",
      "in E3par ort tuobaly Nith lnofured, Chinat is abund Worst-boreas. N2i5s in tyr P and country ic ofpe\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-9000 loss: 1.2095\n",
      "=========================================================================\n",
      "st  intherpao fopkagary winan, valled foryd the G9iJ peJapan'onzOa.-Karlaid chanangy s firghed is 19\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-10000 loss: 1.1294\n",
      "=========================================================================\n",
      " maea. Is rinttientJ pan extomnwatur. zilothon frof fountr. zrat mferea, was ivtopeit. Apithe chistr\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-11000 loss: 1.0565\n",
      "=========================================================================\n",
      "rnes an Emb ponio unomy in the Olob char opllame thind Shanec.. Fbunthe fouth coke. Japan is cint of\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-12000 loss: 0.9982\n",
      "=========================================================================\n",
      " Fitpting, whi ghs first Nihotar es the umaty of the warud, hasto late the o-Pileaint iritorea and I\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-13000 loss: 0.9537\n",
      "=========================================================================\n",
      " flom cobrl in byigino-gokAthictaecturinCiing itsoru, Horno turin tury, the anic aristurlaid chiss e\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-14000 loss: 0.9042\n",
      "=========================================================================\n",
      "sur7ost mper an es wopury bo fory ssraited wo thechusen myintaig se bempored 68. Chemas thi ntatoke \n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-15000 loss: 0.8503\n",
      "=========================================================================\n",
      "iol eatk in the etom tillicluris meint in the , Chinan Efrems Sinodids or and. The Okea nalitatiog o\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-16000 loss: 0.8209\n",
      "=========================================================================\n",
      " lountor oothisal the Sintery bo ald inturces of the world'sy wowta darallod reanuD-op in 185 oo ala\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-17000 loss: 0.7969\n",
      "=========================================================================\n",
      "the Sia octecpat of Japan was const tro sorsedtal G86a isse tas  hittercd Sha, whic urinl. The count\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-18000 loss: 0.7591\n",
      "=========================================================================\n",
      "ry ter wether the jigets fedtented Emper an es teenea liof is the gith of 1868, whith licolet on enr\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-19000 loss: 0.7196\n",
      "=========================================================================\n",
      "ihalerdal Deade in maintokard with a Kirghinaniky. Tokoo lichay stating ppeesttoush. Japanesechingh \n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-20000 loss: 0.6986\n",
      "=========================================================================\n",
      " puloter as id assered chinse Warld ifpor and houstein dorlded ane dar founts livithe tory corol. Ar\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-21000 loss: 0.6798\n",
      "=========================================================================\n",
      "nd sichesiod is the world's lichndextle Emperorting its fowt. The alat 2ericand percing In the -oped\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-22000 loss: 0.6547\n",
      "=========================================================================\n",
      "Worl Chicinal mekiored as hegither. Ahatercand sed of incleave opeaity Irobal of itrl darly Emporea \n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-23000 loss: 0.6302\n",
      "=========================================================================\n",
      " Paleowethoma Imation of engllareectre the the firrting pughon fsurts. Ni15–2016 and io th toked its\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-24000 loss: 0.6027\n",
      "=========================================================================\n",
      "aiglt8 Frea, Japanest efplled ty 19s sevint imperea a Asin lesturen, pounloy. Tokokec and Hountry in\n",
      "=========================================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================\n",
      "Iter-25000 loss: 0.6007\n",
      "=========================================================================\n",
      "riKywClurth 1oth the Immilaries reateres. The courlly. Aithe EOping surled In 1545 Koreation in the \n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-26000 loss: 0.5780\n",
      "=========================================================================\n",
      " anconercind enjch-lare with oper pountry in Emperor docake op bolaley or hiUllorala destorexth-rake\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-27000 loss: 0.5670\n",
      "=========================================================================\n",
      "hesicedes larsed is and is is meforold imper counsl iepor. Japan is a developmentr Area. The cise em\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-28000 loss: 0.5397\n",
      "=========================================================================\n",
      "vola, wish inxnd in Ebea of ingh Japan cons if the G7, the G8, and the G20 and is the oplltery vetns\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-29000 loss: 0.5255\n",
      "=========================================================================\n",
      "igloxsen fountry 1inh. Japan was calopes and With any. maliol revirea, Asta cary sudged dinthe a ani\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-30000 loss: 0.5008\n",
      "=========================================================================\n",
      "f the Nanicrurte: iunsre fioth largest meity-int wolowed of 19to and In ty the Russo Japan in isto w\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-31000 loss: 0.4909\n",
      "=========================================================================\n",
      "arand inntiy stured Japanea es inctikecily, Appardexth lariestury high tha world'Tasy constraltores \n",
      "=========================================================================\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "Iter-32000 loss: 0.4704\n",
      "=========================================================================\n",
      "kcales imet int the world's fourth-largest. Japan was Toundei loglod ith roved found ifl, tolloChita\n",
      "=========================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solver.adam_rnn(\n",
    "    net, X, y,\n",
    "    alpha=alpha,\n",
    "    mb_size=time_step,\n",
    "    n_iter=n_iter,\n",
    "    print_after=print_after\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "=========================================================================\n",
    "Iter-198000 loss: 0.1331\n",
    "=========================================================================\n",
    "tary shoguns who ruled in the nainty n mainterd Taiwat lors latulaty und Sunarend thia dudg oonaly r\n",
    "=========================================================================\n",
    "\n",
    "\n",
    "=========================================================================\n",
    "Iter-199000 loss: 0.1386\n",
    "=========================================================================\n",
    "th largest imf in the korlation mainlatI un the eipan endand of the Rising Sun\". Japan is a stratovo\n",
    "=========================================================================\n",
    "\n",
    "\n",
    "=========================================================================\n",
    "Iter-200000 loss: 0.0987\n",
    "=========================================================================\n",
    "hest-ranked Asian countrord with the Since caly towertor Jaty in the country in East Asia. Located i\n",
    "=========================================================================\n",
    "\n",
    "\n",
    "Out[11]:\n",
    "<__main__.GRU at 0x10d053f98>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "=========================================================================\n",
    "Iter-99000 loss: 0.1890\n",
    "=========================================================================\n",
    " of No20th bex, mfen eped consic th led the fourth leading globan in the name of the Emperor. Japan \n",
    "=========================================================================\n",
    "\n",
    "\n",
    "=========================================================================\n",
    "Iter-100000 loss: 0.1673\n",
    "=========================================================================\n",
    "the early 1shthicaped and the forchest urerlate 19th and the world's fourth-largest economy by purch\n",
    "=========================================================================\n",
    "\n",
    "\n",
    "Out[24]:\n",
    "<__main__.GRU at 0x10d1f7b00>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "=========================================================================\n",
    "Iter-100000 loss: 0.3913\n",
    "=========================================================================\n",
    "the 1pman a inusy rotory surrowho tOkike upporter wor peven des The easty porterized itivecend perce\n",
    "=========================================================================\n",
    "\n",
    "\n",
    "Out[7]:\n",
    "<hipsternet.neuralnet.RNN at 0x7fc2f5182e80>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "=========================================================================\n",
    "Iter-100000 loss: 0.1615\n",
    "=========================================================================\n",
    "the name of the 12th century until 1868, Japan was ruled by successime Wer of 1941, which country is\n",
    "=========================================================================\n",
    "\n",
    "\n",
    "Out[16]:\n",
    "<hipsternet.neuralnet.LSTM at 0x7f67fe0c9978>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "=========================================================================\n",
    "Iter-100000 loss: 0.1333\n",
    "=========================================================================\n",
    "the Coun resilate a in the population. Russided in the OECD and the world's fourth-largest econompic\n",
    "=========================================================================\n",
    "\n",
    "\n",
    "Out[10]:\n",
    "<hipsternet.neuralnet.GRU at 0x7fc2cec1e1d0>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
