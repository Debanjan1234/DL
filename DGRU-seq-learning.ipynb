{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "\n",
    "with open('data/text_data/japan.txt', 'r') as f:\n",
    "# with open('data/text_data/anna.txt', 'r') as f:\n",
    "\n",
    "    txt = f.read()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    char_to_idx = {char: i for i, char in enumerate(set(txt))}\n",
    "    idx_to_char = {i: char for i, char in enumerate(set(txt))}\n",
    "\n",
    "    X = np.array([char_to_idx[x] for x in txt])\n",
    "    y = [char_to_idx[x] for x in txt[1:]]\n",
    "    y.append(char_to_idx['.'])\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model or Network\n",
    "import impl.layer as l\n",
    "from impl.loss import *\n",
    "\n",
    "class GRU:\n",
    "    def __init__(self, D, H, L, char2idx, idx2char):\n",
    "        self.D = D\n",
    "        self.H = H\n",
    "        self.L = L\n",
    "        self.char2idx = char2idx\n",
    "        self.idx2char = idx2char\n",
    "        self.vocab_size = len(char2idx)\n",
    "        self.losses = {'train':[], 'smooth train':[]}\n",
    "        \n",
    "        # Model params: output and input sequence\n",
    "        Z = H + D\n",
    "        m = dict(\n",
    "            Wz=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wr=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wh=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wy=np.random.randn(H, D) / np.sqrt(H / 2.),\n",
    "            bz=np.zeros((1, H)),\n",
    "            br=np.zeros((1, H)),\n",
    "            bh=np.zeros((1, H)),\n",
    "            by=np.zeros((1, D))\n",
    "        )\n",
    "\n",
    "        self.model = []        \n",
    "        self.model.append([])\n",
    "        for _ in range(0, self.L - 1, 1):\n",
    "            self.model[0].append(m)\n",
    "\n",
    "        self.model.append([])\n",
    "        for _ in range(self.L):\n",
    "            self.model[1].append(m)\n",
    "\n",
    "        # Input sequence - last layer\n",
    "        m = dict(\n",
    "            Wz=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wr=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wh=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            bz=np.zeros((1, H)),\n",
    "            br=np.zeros((1, H)),\n",
    "            bh=np.zeros((1, H)),\n",
    "        )\n",
    "        for _ in range(self.L - 1, self.L, 1):\n",
    "            self.model[0].append(m)\n",
    "\n",
    "    def initial_state(self):\n",
    "        return np.zeros((1, self.H))\n",
    "\n",
    "    def forward(self, X, h, m):\n",
    "        Wz, Wr, Wh, Wy = m['Wz'], m['Wr'], m['Wh'], m['Wy']\n",
    "        bz, br, bh, by = m['bz'], m['br'], m['bh'], m['by']\n",
    "\n",
    "        X_in = X.copy()\n",
    "        h_in = h.copy()\n",
    "\n",
    "        X = np.column_stack((h_in, X_in))\n",
    "\n",
    "        hz, hz_cache = l.fc_forward(X, Wz, bz)\n",
    "        hz, hz_sigm_cache = l.sigmoid_forward(hz)\n",
    "\n",
    "        hr, hr_cache = l.fc_forward(X, Wr, br)\n",
    "        hr, hr_sigm_cache = l.sigmoid_forward(hr)\n",
    "\n",
    "        X = np.column_stack((hr * h_in, X_in))\n",
    "        \n",
    "        hh, hh_cache = l.fc_forward(X, Wh, bh)\n",
    "        hh, hh_tanh_cache = l.tanh_forward(hh)\n",
    "\n",
    "        # h = (1. - hz) * h_old + hz * hh\n",
    "        # or\n",
    "        h = ((1. - hz) * h_in) + (hz * hh)\n",
    "        # or\n",
    "        # h = h_in + hz (hh - h_in)\n",
    "\n",
    "        y, y_cache = l.fc_forward(h, Wy, by)\n",
    "\n",
    "        cache = (h_in, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache)\n",
    "\n",
    "        return y, h, cache\n",
    "\n",
    "    def backward(self, dy, dh, cache):\n",
    "        h_in, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache = cache\n",
    "        \n",
    "        dh_out = dh.copy()\n",
    "\n",
    "        dh, dWy, dby = l.fc_backward(dy, y_cache)\n",
    "        dh += dh_out\n",
    "\n",
    "        dh_in1 = (1. - hz) * dh\n",
    "        dhh = hz * dh\n",
    "        dhz = (hh * dh) - (h_in * dh)\n",
    "        # or\n",
    "        # dhz = (hh - h_in) * dh\n",
    "\n",
    "        dhh = l.tanh_backward(dhh, hh_tanh_cache)\n",
    "        dXh, dWh, dbh = l.fc_backward(dhh, hh_cache)\n",
    "\n",
    "        dh = dXh[:, :self.H]\n",
    "        dX_in2 = dXh[:, self.H:]\n",
    "        dh_in2 = hr * dh\n",
    "\n",
    "        dhr = h_in * dh\n",
    "        dhr = l.sigmoid_backward(dhr, hr_sigm_cache)\n",
    "        dXr, dWr, dbr = l.fc_backward(dhr, hr_cache)\n",
    "\n",
    "        dhz = l.sigmoid_backward(dhz, hz_sigm_cache)\n",
    "        dXz, dWz, dbz = l.fc_backward(dhz, hz_cache)\n",
    "\n",
    "        dX = dXr + dXz\n",
    "        dh_in3 = dX[:, :self.H]\n",
    "        dX_in1 = dX[:, self.H:]\n",
    "\n",
    "        dh = dh_in1 + dh_in2 + dh_in3\n",
    "        dX = dX_in1 + dX_in2\n",
    "\n",
    "        grad = dict(Wz=dWz, Wr=dWr, Wh=dWh, Wy=dWy, bz=dbz, br=dbr, bh=dbh, by=dby)\n",
    "        \n",
    "        return dX, dh, grad\n",
    "\n",
    "    def forward_(self, X, h, m):\n",
    "        Wz, Wr, Wh = m['Wz'], m['Wr'], m['Wh']\n",
    "        bz, br, bh = m['bz'], m['br'], m['bh']\n",
    "\n",
    "        X_in = X.copy()\n",
    "        h_in = h.copy()\n",
    "\n",
    "        X = np.column_stack((h_in, X_in))\n",
    "\n",
    "        hz, hz_cache = l.fc_forward(X, Wz, bz)\n",
    "        hz, hz_sigm_cache = l.sigmoid_forward(hz)\n",
    "\n",
    "        hr, hr_cache = l.fc_forward(X, Wr, br)\n",
    "        hr, hr_sigm_cache = l.sigmoid_forward(hr)\n",
    "\n",
    "        X = np.column_stack((hr * h_in, X_in))\n",
    "        \n",
    "        hh, hh_cache = l.fc_forward(X, Wh, bh)\n",
    "        hh, hh_tanh_cache = l.tanh_forward(hh)\n",
    "\n",
    "        # h = (1. - hz) * h_old + hz * hh\n",
    "        # or\n",
    "        h = ((1. - hz) * h_in) + (hz * hh)\n",
    "        # or\n",
    "        # h = h_in + hz (hh - h_in)\n",
    "\n",
    "        cache = (h_in, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache)\n",
    "\n",
    "        return h, cache\n",
    "\n",
    "    def backward_(self, dh, cache):\n",
    "        h_in, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache = cache\n",
    "        \n",
    "        dh_in1 = (1. - hz) * dh\n",
    "        dhh = hz * dh\n",
    "        dhz = (hh * dh) - (h_in * dh)\n",
    "        # or\n",
    "        # dhz = (hh - h_in) * dh\n",
    "\n",
    "        dhh = l.tanh_backward(dhh, hh_tanh_cache)\n",
    "        dXh, dWh, dbh = l.fc_backward(dhh, hh_cache)\n",
    "\n",
    "        dh = dXh[:, :self.H]\n",
    "        dX_in2 = dXh[:, self.H:]\n",
    "        dh_in2 = hr * dh\n",
    "\n",
    "        dhr = h_in * dh\n",
    "        dhr = l.sigmoid_backward(dhr, hr_sigm_cache)\n",
    "        dXr, dWr, dbr = l.fc_backward(dhr, hr_cache)\n",
    "\n",
    "        dhz = l.sigmoid_backward(dhz, hz_sigm_cache)\n",
    "        dXz, dWz, dbz = l.fc_backward(dhz, hz_cache)\n",
    "\n",
    "        dX = dXr + dXz\n",
    "        dh_in3 = dX[:, :self.H]\n",
    "        dX_in1 = dX[:, self.H:]\n",
    "\n",
    "        dh = dh_in1 + dh_in2 + dh_in3\n",
    "        dX = dX_in1 + dX_in2\n",
    "\n",
    "        grad = dict(Wz=dWz, Wr=dWr, Wh=dWh, bz=dbz, br=dbr, bh=dbh)\n",
    "        \n",
    "        return dX, dh, grad\n",
    "    \n",
    "    def train_forward(self, XY_train, h):\n",
    "        ys, caches = [], []\n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "\n",
    "        # number of sequences: in & out\n",
    "        for _ in range(2):\n",
    "            caches.append([])\n",
    "        \n",
    "        # number of layers\n",
    "        for _ in range(self.L):\n",
    "            caches[0].append([])\n",
    "            caches[1].append([])\n",
    "            \n",
    "        # in and out sequences\n",
    "        X_train, Y_train = XY_train\n",
    "\n",
    "        # Input sequence\n",
    "        for X in X_train:\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            X = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                if layer is not self.L-1:\n",
    "                    y, h[layer], cache = self.forward(X, h[layer], self.model[0][layer])\n",
    "                    X = y.copy()\n",
    "                else:\n",
    "                    h[layer], cache = self.forward_(X, h[layer], self.model[0][layer])\n",
    "                caches[0][layer].append(cache)\n",
    "\n",
    "        # Output sequence\n",
    "        for X in Y_train:\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            X = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], cache = self.forward(X, h[layer], self.model[1][layer])\n",
    "                caches[1][layer].append(cache)\n",
    "                X = y.copy()\n",
    "            ys.append(y)\n",
    "            \n",
    "        return ys, caches\n",
    "    \n",
    "    def loss_function(self, y_train, ys):\n",
    "        loss, dys = 0.0, []\n",
    "\n",
    "        for y_pred, y in zip(ys, y_train):\n",
    "            loss += cross_entropy(y_pred, y)\n",
    "            dy = dcross_entropy(y_pred, y)\n",
    "            dys.append(dy)\n",
    "            \n",
    "        return loss, dys\n",
    "    \n",
    "    def train_backward(self, dys, caches):\n",
    "        dh, grad, grads = [], [], []\n",
    "        \n",
    "        for _ in range(self.L):\n",
    "            dh.append(np.zeros((1, self.H)))\n",
    "        \n",
    "        for _ in range(2):\n",
    "            grad.append([])\n",
    "            grads.append([])\n",
    "\n",
    "        for mode in range(2):\n",
    "            for layer in range(self.L):\n",
    "                grad[mode].append({key: np.zeros_like(val) for key, val in self.model[mode][layer].items()})\n",
    "                grads[mode].append({key: np.zeros_like(val) for key, val in self.model[mode][layer].items()})\n",
    "\n",
    "        # Output seq\n",
    "        for t in reversed(range(len(dys))):\n",
    "            dy = dys[t]\n",
    "            for layer in reversed(range(self.L)):\n",
    "                dX, dh[layer], grad[1][layer] = self.backward(dy, dh[layer], caches[1][layer][t])\n",
    "                for k in grad[1][layer].keys():\n",
    "                    grads[1][layer][k] += grad[1][layer][k]\n",
    "                dy = dX.copy()\n",
    "                \n",
    "        # Input seq\n",
    "        for t in reversed(range(len(dys))):\n",
    "            for layer in reversed(range(self.L)):\n",
    "                if layer is self.L-1:\n",
    "                    dX, dh[layer], grad[0][layer] = self.backward_(dh[layer], caches[0][layer][t])\n",
    "                else:\n",
    "                    dX, dh[layer], grad[0][layer] = self.backward(dy, dh[layer], caches[0][layer][t])\n",
    "                for k in grad[0][layer].keys():\n",
    "                    grads[0][layer][k] += grad[0][layer][k]\n",
    "                dy = dX.copy()\n",
    "\n",
    "        return grads\n",
    "    \n",
    "    def test(self, Xs, h, size):        \n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "            \n",
    "        # Input sequence or the historical/previous/background sequence\n",
    "        for t in range(len(Xs)//2):\n",
    "            X = Xs[t]\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            X = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(0, self.L - 1):\n",
    "                y, h[layer], _ = self.forward(X, h[layer], self.model[0][layer])\n",
    "                X = y.copy()\n",
    "            # last layer\n",
    "            for layer in range(self.L - 1, self.L):\n",
    "                h[layer], _ = self.forward_(X, h[layer], self.model[0][layer])\n",
    "\n",
    "        # The starting point of the prediction or <GO>\n",
    "        X_seed = Xs[(len(Xs)//2)+1]\n",
    "        chars = [self.idx2char[X_seed]]\n",
    "        idx_list = list(range(self.vocab_size))\n",
    "        X = X_seed\n",
    "\n",
    "        # Output sequence or predicted or reconstructed sequence\n",
    "        for _ in range(size):\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            X = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], _ = self.forward(X, h[layer], self.model[1][layer])\n",
    "                X = y.copy()\n",
    "                \n",
    "            prob = l.softmax(y)\n",
    "            idx = np.random.choice(idx_list, p=prob.ravel())\n",
    "            chars.append(self.idx2char[idx])\n",
    "            X = idx\n",
    "\n",
    "        return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minibatch(X, y, minibatch_size, shuffle):\n",
    "    minibatches = []\n",
    "\n",
    "    # for i in range(0, X.shape[0], minibatch_size):\n",
    "    for i in range(0, X.shape[0] - minibatch_size + 1, 1):\n",
    "        X_mini = X[i:i + minibatch_size]\n",
    "        y_mini = y[i:i + minibatch_size]\n",
    "        minibatches.append((X_mini, y_mini))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "def adam_rnn(nn, X_train, y_train, alpha, mb_size, n_iter, print_after):\n",
    "    M, R = [], []\n",
    "    for _ in range(2):\n",
    "        M.append([])\n",
    "        R.append([])\n",
    "        \n",
    "    for mode in range(2):\n",
    "        for layer in range(nn.L):\n",
    "            M[mode].append({key: np.zeros_like(val) for key, val in nn.model[mode][layer].items()})\n",
    "            R[mode].append({key: np.zeros_like(val) for key, val in nn.model[mode][layer].items()})\n",
    "        \n",
    "    beta1 = .99\n",
    "    beta2 = .999\n",
    "    state = nn.initial_state()\n",
    "    smooth_loss = 1.\n",
    "    minibatches = get_minibatch(X_train, y_train, mb_size, shuffle=False)\n",
    "    \n",
    "    for iter in range(1, n_iter + 1):\n",
    "        for idx in range(len(minibatches)):\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            X_train = X_mini[: mb_size//2]\n",
    "            Y_train_in = X_mini[mb_size//2: ]\n",
    "            Y_train_out = y_mini[mb_size//2: ]\n",
    "            XY_train = (X_train, Y_train_in)\n",
    "            \n",
    "            ys, caches = nn.train_forward(XY_train, state)\n",
    "            loss, dys = nn.loss_function(Y_train_out, ys)\n",
    "            grads = nn.train_backward(dys, caches)\n",
    "            \n",
    "            nn.losses['train'].append(loss)\n",
    "            smooth_loss = (0.999 * smooth_loss) + (0.001 * loss)\n",
    "            nn.losses['smooth train'].append(smooth_loss)\n",
    "\n",
    "            for mode in range(2):\n",
    "                for layer in range(nn.L):\n",
    "                    for key in grads[mode][layer].keys(): # key, value: items, dict{}, tuple(), array[]\n",
    "                        M[mode][layer][key] = l.exp_running_avg(M[mode][layer][key], grads[mode][layer][key], beta1)\n",
    "                        R[mode][layer][key] = l.exp_running_avg(R[mode][layer][key], grads[mode][layer][key]**2, beta2)\n",
    "\n",
    "                        m_k_hat = M[mode][layer][key] / (1. - (beta1**(iter)))\n",
    "                        r_k_hat = R[mode][layer][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                        nn.model[mode][layer][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + l.eps)\n",
    "\n",
    "        # Print loss and test/valid/verifying sample\n",
    "        if iter % print_after == 0:\n",
    "            print('Iter-{} loss: {:.4f}'.format(iter, loss))\n",
    "            sample = nn.test(X_mini, state, size=100)\n",
    "            print(sample)\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1 loss: 21.7121\n",
      "esicst Japansd mian-th exthe G899jPL7t it2deJEIn chesrengmselinger ond in ranany 8, evcide baas, San \n",
      "Iter-2 loss: 21.5081\n",
      "es aan rivissc5 Ryuest in coudity pouf 9GUped Cobes chaugunes in fe'n of seurt be8 an, chy coufty his\n",
      "Iter-3 loss: 20.8859\n",
      "es t'ins-1日 9umthy wort's in suxth andcilody biJapaveireigest of bourano, in ounty byuuns of sefoleg \n",
      "Iter-4 loss: 19.9460\n",
      "en Japany , samonmly sovtorchon 916, in beigerty Me;usty Anfounter Thind Asitar wist to fro, in vonut\n",
      "Iter-5 loss: 18.9368\n",
      "e of Japan, eapargal counoper hakes-zikor. The chimed ofd Japan, latise O1935M Amulary in HoC. In oxt\n",
      "Iter-6 loss: 17.7929\n",
      "est unm\"ptan werlad to the ond is the EDuntion2, higass and revensed il 1947Nan worat ranked werch-9F\n",
      "Iter-7 loss: 16.6628\n",
      "e eactateen bomter cofo mins te sinthr world, Ind to the 5eund seroxcthbes the ranst inaal in gintery\n",
      "Iter-8 loss: 15.7008\n",
      "es. Japan in the Wurld ened of fovreaclangest expbrenomybbuns is fourtt ny-Ingiter, and Colarled rans\n",
      "Iter-9 loss: 14.9485\n",
      "en.uncend in the Sunluin military: 2x p7rea, the kourth of the country in fobist in the U0nso percory\n",
      "Iter-10 loss: 14.2809\n",
      "e and in the Emperor of ineth largest GronstbAreacenst in livintargiont cunntur DmLbpor anx colfterbh\n",
      "Iter-11 loss: 13.6091\n",
      "est, millie of of Japanl edeving akie the Natolates erhorkass efvon of Japan is to huse lyuster and 1\n",
      "Iter-12 loss: 12.8958\n",
      "es. Japan is a devtes forlon5 Im, th the hast in the Suromest to omtorith. 1teticates. Japan a, sulit\n",
      "Iter-13 loss: 12.1934\n",
      "e contoring mlentied an gopen, to profercad of an it Immic.. Itiory mentexIn exppboumbe of chonm. Ind\n",
      "Iter-14 loss: 11.5726\n",
      "es., Japan is a gved and in the pericey moroper and peroust Gfb%llowed counjinst inopulitary by wost \n",
      "Iter-15 loss: 11.0648\n",
      "est in the 47ted fom thons oftvfinef ron. Japan in the Global 'ss puchluper ora and Nupnution conutir\n",
      "Iter-16 loss: 10.6567\n",
      "es., undy-which and Wro loungrst inotJppniecess echoped highest erfder and to the higountry in the wo\n",
      "Iter-17 loss: 10.3151\n",
      "es. Japanese War of and Ristopfen to the worldvoI an Divelargest eppoptiter in the numterin to folloJ\n",
      "Iter-18 loss: 10.0178\n",
      "es. Japan is the Empiot to mpention confiat in the world, Sed World. Frem. revorghca conomerchesed, t\n",
      "Iter-19 loss: 9.7284\n",
      "es, rasiding allower Hrchighest ronko. Japan is the world本, the forlo-make by 2 inty In the tan empir\n",
      "Iter-20 loss: 9.3908\n",
      "es. Japan is a dfeeunty renound, 19, prore courth lation., the the worldofet conithy it liviny intr-t\n",
      "Iter-21 loss: 8.9693\n",
      "es. Japan is cotid-tokkyo of Japand to and in the courtarly urthes to the world. Arthu and hiat in th\n",
      "Iter-22 loss: 8.4435\n",
      "es. Arcoveare chal porcharides-dali's thard liget to the G0, the G本iper. 1ven peree and first. Thrfer\n",
      "Iter-23 loss: 7.8080\n",
      "es, firto untery with the historpest rned ino11 Hirth is the number of an highest-rasing Suna, barghe\n",
      "Iter-24 loss: 7.0919\n",
      "es. The latiter porth the Country in the Gled bou the world's difes ofte nangcalitery of aon the Glob\n",
      "Iter-25 loss: 6.3613\n",
      "estered vidol pomperer country tad Peaced livigest ofo9lad country mellowed an host the Number of Elj\n",
      "Iter-26 loss: 5.6848\n",
      "es. Japan is the militar I0th hiald-gantionates of ended reaing prlion merchon end ifolational DoNiat\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "time_step = 10 # width, minibatch size and test sample size as well\n",
    "num_layers = 2 # depth\n",
    "n_iter = 300 # epochs\n",
    "alpha = 1e-4 # learning_rate\n",
    "print_after = 1 # n_iter//10 # print training loss, valid, and test\n",
    "num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "num_input_units = len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "\n",
    "# Build the network and learning it or optimizing it using SGD\n",
    "net = GRU(D=num_input_units, H=num_hidden_units, L=num_layers, char2idx=char_to_idx, idx2char=idx_to_char)\n",
    "\n",
    "# Start learning using BP-SGD-ADAM\n",
    "adam_rnn(nn=net, X_train=X, y_train=y, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)\n",
    "\n",
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(net.losses['train'], label='Train loss')\n",
    "plt.plot(net.losses['smooth train'], label='Train smooth loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1 loss: 23.4348\n",
      "\n",
      "ne NRd fithesd Denites iph tanT 1onR tsd Uld lhite Thend thoatn hnsGRJrmry vi, Ga tars Sngisig the J\n",
      "Iter-2 loss: 23.6945\n",
      "\n",
      "h rat cary L-smme1ewo. EM eveit byepislan thiag gnkc mand iisarn si. thedy-rs wtia inlt bar, the In.\n",
      "Iter-3 loss: 23.5648\n",
      "\n",
      "Japan eat  i1nd Himr1-'s thist unth tlentn courany n2trdecome pan moutinCar oegteris cumist is tuoeg\n",
      "Iter-4 loss: 23.4410\n",
      "\n",
      "5un0ward bopvese 2ide nd an 1fin. Ef uemte, Sulaty D87ked Efperedisuad Ps ripana eal wal whe wof auy\n",
      "Iter-5 loss: 23.3706\n",
      "\n",
      "nith th seystrend Japan , unolhe Wh omed Japan in eataon, and ind eant of hinan WeaE pirgoang tres m\n",
      "Iter-6 loss: 23.2680\n",
      "\n",
      "restithis terthy ss a8ded Oows istary torld dghhy- insta the 3h, frutel wh, emportoyided rots ind an\n",
      "Iter-7 loss: 23.1007\n",
      "\n",
      "rlan. Japan ivglathe thoropucces liland Japar Dimplegumith chind ofcintorinocy perncoulomkek, fovert\n",
      "Iter-8 loss: 22.8740\n",
      "\n",
      "Aitila. Thear wa angest Ises furok sica Seanit east wat the Ruithinthi est eanesithe the tay ests ch\n",
      "Iter-9 loss: 22.5994\n",
      "\n",
      "id topan ist-ihat wis the Rfrat ef ind-CAntre:, hectar is ald. Thinh-lanas the wy the wopnd of handn\n",
      "Iter-10 loss: 22.2844\n",
      "\n",
      "5ulary IMutirg the G7, Napan P iakowas am, wmentirn of Japan \"r homatenise toung me reihid in eiped \n",
      "Iter-11 loss: 21.9326\n",
      "\n",
      "Japan, arla7g and f comytr hal es ioplowist in latieg of Japan is lanito inthiss hake the 2heckeande\n",
      "Iter-12 loss: 21.5464\n",
      "\n",
      "Japanes in lioklRed cintorcetat ef Worlalin\"aka ca iso arledtith on worgh and with in lareR., ixport\n",
      "Iter-13 loss: 21.1300\n",
      "\n",
      "\"Asincry Nagkrea of Japan ind wirs wecero, the hoprtaty boun ty bys courthe World's canse war Dame t\n",
      "Iter-14 loss: 20.6897\n",
      "\n",
      "Japan as and asl anest uruhe thid en, calo5in; Worlapery iss miled rand, tal the 123 suntme feurld's\n",
      "Iter-15 loss: 20.2317\n",
      "\n",
      "riatd frets. Ifu% calddialalinatesd voflled lerthe wor1d is thighist AhexGptro, pareh and pareat mor\n",
      "Iter-16 loss: 19.7621\n",
      "\n",
      "bid 204n angest ortatowict Siunty whest Nillecanke meally the the Kard pergoflymBs merean is the 28r\n",
      "Iter-17 loss: 19.2867\n",
      "\n",
      "-Japan cally count, of framlly-ofturghed mallyjg tion uroKustho Empertar, 37 inang estate taitaclitu\n",
      "Iter-18 loss: 18.8107\n",
      "\n",
      "ming os and malloby ptromityy und inst and iz the Empere tae worgedse the Glo:y of cinlowed the \"okg\n",
      "Iter-19 loss: 18.3381\n",
      "\n",
      "'s a dextest ceand ling in to the Gboul the sONiconary of Japan \"furobal In an, Chinam on mhenticite\n",
      "Iter-20 loss: 17.8710\n",
      "\n",
      "-Japan larended of Japan a the Siode-nasuriese and world. Japan hivent Chint porlatiogegsuleta. Trer\n",
      "Iter-21 loss: 17.4099\n",
      "\n",
      "Japanges eopal Inder eadte te in the Inatarny the surhe for perth the G20 mantrend with OO420 Sea an\n",
      "Iter-22 loss: 16.9549\n",
      "\n",
      "cigs and errghisanky prextarly.r15kith century ce menth in lighs fiful denh sent lion of Japan Phand\n",
      "Iter-23 loss: 16.5056\n",
      "\n",
      "Japanese G245 wat on amded war, th is phe persed of in 85\"inst ares. The world's 1ushas rurth-of rit\n",
      "Iter-24 loss: 16.0613\n",
      "\n",
      "–ruth councsina ar, dichea, Japan is and uxth atist the sornd countodeg ppristar. Chith anhed purth \n",
      "Iter-25 loss: 15.6218\n",
      "\n",
      "Tain, Siand lapenge pentwerl in ceowal eipen un wot ded as ceaner 196 Gp5% a grot-lang rereargenty p\n",
      "Iter-26 loss: 15.1871\n",
      "\n",
      "Japan wfroplbulitd in Asia. 20168 Afiod Naked ase mowestrry city ririo, inkeuurod the Dforithe nasit\n",
      "Iter-27 loss: 14.7579\n",
      "\n",
      "Japan sturmpat om wits and \"fclorell mer oflledex lertae stof comsorchang serrop.-Japan Ky, the four\n",
      "Iter-28 loss: 14.3355\n",
      "\n",
      "20ivel ofkecountry lerg sided G83U, fiuto and the Srows d9kea is and Chins-fant Indent of enomided t\n",
      "Iter-29 loss: 13.9214\n",
      "\n",
      "Japan is the of Japan the 's the papureh-largesc frestaing tombor eslardevin\", Chenfcendest into io \n",
      "Iter-30 loss: 13.5173\n",
      "\n",
      "Japan Emptread pecitar -Japaneso ardes. Thican, milly pfoinld's hesothe a andudec andsmanist meand c\n",
      "Iter-31 loss: 13.1252\n",
      "\n",
      "Tkit in the vintofiSearas has owrand the Sununost thi world the censed it the Gxpaid of ithor and Ch\n",
      "Iter-32 loss: 12.7468\n",
      "\n",
      " Suriogd sifir teP bsuthe U–p1Gs ic lomye centirgh icstor and the ward istanven world larenkadec ath\n",
      "Iter-33 loss: 12.3834\n",
      "\n",
      "Japan, of ufres and khe borlldry mprrollcodmy-largest ith ceanis the worlatiry. 37 prexes purcan\") t\n",
      "Iter-34 loss: 12.0358\n",
      "\n",
      ", who fest cenouden's rege tamy or Nihelat-6erneal wos and ofo19l1's largest in 19455's fourth-largI\n",
      "Iter-35 loss: 11.7040\n",
      "\n",
      "Japan was mound, a dexse Empont-liwat im Japan hagest-lymbre rom3 Epreaily of Japan in the couril pi\n",
      "Iter-36 loss: 11.3878\n",
      "\n",
      "inked migint of hthed's lardest-ranes. The worlodamitiry of Japan enjist mienterea, Cha colsto3udand\n",
      "Iter-37 loss: 11.0867\n",
      "\n",
      " itr 20kakiof Gee of ereal Elelecenclumins. Japan, easinges ant ih Restanje witg preet powent of the\n",
      "Iter-38 loss: 10.8000\n",
      "\n",
      "Apictdenjer Winsed and as aed piutlomf inds, whiche: :xpreac to ean. Ilmainco-lerne's owariods, ath \n",
      "Iter-39 loss: 10.5268\n",
      "\n",
      "-Japan Os ofnd Nipppeo anded Somestuthe dexpeard is onfecolaticy of Japan, wath the G8Pfakuchu gicte\n",
      "Iter-40 loss: 10.2662\n",
      "\n",
      "-laggmporiapeon ts lates rrestariest of thilardest periolld's festo nomy, is the Sigity by peeslatwe\n",
      "Iter-41 loss: 10.0173\n",
      "\n",
      ", vintory churoped popet pomberom to its urth cemsirges. The warl potunery mbintankek and fist centi\n",
      "Iter-42 loss: 9.7792\n",
      "\n",
      "icon-restiin at of Japan has sxThe historusing ropeo-Japan's tended in the to Nanaldy furntat. Chinh\n",
      "Iter-43 loss: 9.5511\n",
      "\n",
      "To hents is is hand conllyP in sive pured ciced inting polFigstang sout popent-lagese:u 本8xthe nombi\n",
      "Iter-44 loss: 9.3324\n",
      "\n",
      "Brencencomy hin\", comeladgs a decodoled 6 efrumoninded the 186, and vegsolecidasided Wor ;astite en \n",
      "Iter-45 loss: 9.1222\n",
      "\n",
      "inoded is thith-largiss a wert 2018 furmo teally Dral tolldenMe populathe Ficto-Oarle Toky of Japan \n",
      "Iter-46 loss: 8.9199\n",
      "\n",
      ") of Japan hase the fourth-large tary with ontored thildtomoledkbac uculereadur, conaidaliodilaleced\n",
      "Iter-47 loss: 8.7249\n",
      "\n",
      "irsd eallodt bed comerioge to ane eofllitg of if intion porutary wich omulati n as ofertes fent rank\n",
      "Iter-48 loss: 8.5366\n",
      "\n",
      "Lowar coprlaresd rand forstanked cinsured, athe meanlry. Astarest ropect-renodicicotunig porlcoun. I\n",
      "Iter-49 loss: 8.3546\n",
      "\n",
      "Se forld's enfliof cigsto-largest-ranked Tokea Tas the dedlodillicluitar eapes promlly. int1 the Hur\n",
      "Iter-50 loss: 8.1783\n",
      "\n",
      "Japan The farl ag mare 1535 and ral obed Napentur Nean\"y Index 2lato eard of 1orbard War cobnse fifi\n",
      "Iter-51 loss: 8.0074\n",
      "\n",
      "-minin efpirt rily, is lich the from the wat courthing scrupal twion. Japan inges antho and country \n",
      "Iter-52 loss: 7.8415\n",
      "\n",
      "-Japan's lares alded mint Iteet ofrly4js 19thiven to and and whind War historcality surar-has thith-\n",
      "Iter-53 loss: 7.6801\n",
      "\n",
      ". which ADighoc., Korse War O3kigan\"), which a midste-make a devintky by simhic perite exppart cones\n",
      "Iter-54 loss: 7.5230\n",
      "\n",
      ". Thiced Japan hast hith-largss the SercoundeN, 20th comulation of intinca nomyobd liest Japan of Ja\n",
      "Iter-55 loss: 7.3700\n",
      "\n",
      "inct its ofolomain Eymat enculita om intor wistaneade a giman in live th ren. The eaodld fis thising\n",
      "Iter-56 loss: 7.2206\n",
      "\n",
      "-20th in the seud byCctuncinst uprobal ecpae popeorighte of livol ateo and and is pevis. Ayth Suncce\n",
      "Iter-57 loss: 7.0749\n",
      "\n",
      ". Japany of Asoflee surt cen is 1E6 inded achigas Loguth Eurth in mitinar Sease gase and Wird Japan \n",
      "Iter-58 loss: 6.9324\n",
      "\n",
      " ato nhing s.reaclated collcenon-langest and NoPean of Nihint Inperito alaeied is 1stacd eflimple Se\n",
      "Iter-59 loss: 6.7931\n",
      "\n",
      "The fourth-laties in ard highold peo1st ureont Japanese 日7, revised sixth in Chinkeledpecinstiof Nig\n",
      "Iter-60 loss: 6.6568\n",
      "\n",
      "Japan wos pmiited ofrliost in is the cimper Nagalaed as the worrold Diop, the R8panki, Khas rathe th\n",
      "Iter-61 loss: 6.5233\n",
      "\n",
      "-Japaness. The pexporth a fris ald. The War EIfleecally th cedse nowest riest rihoralled ts often Na\n",
      "Iter-62 loss: 6.3925\n",
      "\n",
      "kichgostan and the GRowed port Coxponthed. Japan ts artht reosal wesparmert Dihitan ssucounty by pea\n",
      "Iter-63 loss: 6.2644\n",
      "\n",
      "-8rowan, wectarn De oftenowided vilitaie io Hos micedes dant ate military Cate early 7jint Inean of \n",
      "Iter-64 loss: 6.1387\n",
      "\n",
      "Japan in the audan. In the witct risodar, Korea and hake purcen ofed Sist-nImenind inturceky of ghes\n",
      "Iter-65 loss: 6.0155\n",
      "\n",
      ". Werch calicl pupuries, upo98, JapangSe -fouth ralasian in the Simi's the city in the worl palecios\n",
      "Iter-66 loss: 5.8946\n",
      "\n",
      ". The worlldgllyry in the simgilan mion enth umnthe in the world's the cipotore fired Japan, ifsecou\n",
      "Iter-67 loss: 5.7760\n",
      "\n",
      ". Japan as eagd osd hictorean hes, thindss ragates ragand of Japan engest orugestory ced of inticia \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-68 loss: 5.6597\n",
      "\n",
      "-loug ontregial with aroKtion pepulaliccedslaciand is the leured, wirg, the Great-laigssoug olst5eof\n",
      "Iter-69 loss: 5.5456\n",
      "\n",
      "Japan Diatin in Asmako ferst witod Gnteina and icited and Saiges Westlbyg is the Inded icoty as audi\n",
      "Iter-70 loss: 5.4337\n",
      "\n",
      "Turchu, ron6 ap of Japan the Gmper ar O–E本Kconsuked The torld, make umpor. Japan hist intand Comae C\n",
      "Iter-71 loss: 5.3240\n",
      "\n",
      "In the peorllmbbe frumbe riging athichiand moral sint cyuntry surgest mellect mipore rowently in civ\n",
      "Iter-72 loss: 5.2164\n",
      "\n",
      "Se fourth restary of Nihotory is the Oimpal make opeat-kowed bidgromed rigina anked Japan wisty-dixt\n",
      "Iter-73 loss: 5.1109\n",
      "\n",
      "Japan 98.5% ofithe surn livh Westories. The Ward citr in lainteI and the worr donh Nipons. Japan in \n",
      "Iter-74 loss: 5.0075\n",
      "\n",
      "F Sito a red and aided the Eurth levon is and a dednite: Resolatit. I fertatess Japan sartes wrrtoky\n",
      "Iter-75 loss: 4.9062\n",
      "\n",
      " maleong. Streitar woslded lipe peropec Sofeorud of thelj. Intry, \"has micitary yush chandeccanceder\n",
      "Iter-76 loss: 4.8069\n",
      "\n",
      "Arth in the nsud mallozed consed forr destobel populargast of Hinotationity. Japan was ecoto the Ast\n",
      "Iter-77 loss: 4.7095\n",
      "\n",
      "Japan has ofrearly it the om offintarme trecearized Impercallodt rehotconan3y inglogg ran and thas t\n",
      "Iter-78 loss: 4.6142\n",
      "\n",
      "G-largest inturtek, which-Japanegi, the world's fef a in the worl panuto to 1915 undex boghsstorchai\n",
      "Iter-79 loss: 4.5208\n",
      "\n",
      "und Nihinake War h celitan inted fourth-largest rnestome piofte cato the easora, Toleter and itolete\n",
      "Iter-80 loss: 4.4294\n",
      "\n",
      "ve sogh ofer fousslarny the world's oftinitory Ear ess regst mecile to al ompareagese to pe'clatityo\n",
      "Iter-81 loss: 4.3400\n",
      "\n",
      "vo f rifleed is lagitat of Japan, inder and Japan, the fort periated Peated and the courted a lorgss\n",
      "Iter-82 loss: 4.2527\n",
      "\n",
      "-ragestutionally purelicanyy, Hrgh with owrld, Counomica es thece-lartekturealardest intlyurd 186 2i\n",
      "Iter-83 loss: 4.1675\n",
      "\n",
      "intry nargest a wong pomelobic To inslicalec's oJapanese G7, thin\"s ofllied disina 本ruts reght hossm\n",
      "Iter-84 loss: 4.0844\n",
      "\n",
      "In the fivite endistan3y mente pariontsy rexporihat-resty novisudiver Genal Diion easidg a silctain \n",
      "Iter-85 loss: 4.0034\n",
      "\n",
      "Ta ind, amunorSe g8ba earted and War ente plobomed regas of the world's and bimetiving fies alcolito\n",
      "Iter-86 loss: 3.9245\n",
      "\n",
      "ind with the norind and Chinar a gits ana Seichal tas Inaimed for felotided inter, ugest Since, pari\n",
      "Iter-87 loss: 3.8477\n",
      "\n",
      "Japan intin and to ten an th fectituras wots the ntungry purithe moke augosth and the 18–2–'s ther0,\n",
      "Iter-88 loss: 3.7729\n",
      "\n",
      "in the Searos.. The Parcedksived Hinh peate gurlo-Asen miin in 1941, founs lode 18, Japan\") ishich-J\n",
      "Iter-89 loss: 3.7001\n",
      "\n",
      "In an endstaticl Apeborigl 1ob bate tierny m, thich lyon the Resional mantory-sixt-loren caumal bere\n",
      "Iter-90 loss: 3.6293\n",
      "\n",
      "Japan Nas alcety or anRese expollarcalited nerea in ofrTokyop. The world limes1 nomecality in the wi\n",
      "Iter-91 loss: 3.5604\n",
      "\n",
      "in the RDeatm2. Brefokoifind foo allowided inte owholatso Aloge is a strerchanded in powetiruand op \n",
      "Iter-92 loss: 3.4934\n",
      "\n",
      "Japan popiotent power.-Japan Japan thy collion eama in the nimemel paige of 19317s main the Chixis t\n",
      "Iter-93 loss: 3.4282\n",
      "\n",
      "-largestitutivinese War e8's largest the huthich os the Eurded arjo sizgingina and indec Nake countr\n",
      "Iter-94 loss: 3.3647\n",
      "\n",
      "9. rank if the Russinaglodation ry, the nwigh lountry pirutora. The lores of the world2Wd itley sixt\n",
      "Iter-95 loss: 3.3030\n",
      "\n",
      ". ito ar 3KuthelaruI of Japan tse war a gimonal histan, with a of ithic to condin fopsoatemy by surn\n",
      "Iter-96 loss: 3.2428\n",
      "\n",
      ". Inupuntien whirh. The G8ppet Japan in in thindes of courtiones lardivine eanlyis fiomal coularteds\n",
      "Iter-97 loss: 3.1843\n",
      "\n",
      "T-koun ry. eaNr Japa, mhisuremec perisalato ofec wast of ligotan incenduninty is di4s in Chinal ferc\n",
      "Iter-98 loss: 3.1272\n",
      "\n",
      "en the Emperiad. The pexis thwand sioth loughan s lieg th centu in in mity by pexping mate a Japankh\n",
      "Iter-99 loss: 3.0716\n",
      "\n",
      "Japan, thichu Stace intexparoration liHing, has mial of the mmabin lacieat we1 th the has cate cond \n",
      "Iter-100 loss: 3.0174\n",
      "\n",
      "Japan is ralled it comyord retionest arde–(aKk本int of ane reas strumat reict and ardeverdesacenaly w\n",
      "Iter-101 loss: 2.9644\n",
      "\n",
      "20 fromtox47 2oritakia divised inte in ou in of Japan's arsed Wirg ros counoryjo wrobllofud rigg oft\n",
      "Iter-102 loss: 2.9128\n",
      "\n",
      "Japan \"ipont meand Sint pirteanenounc lorgasese Uppex. Japan's tontory, the forrldtingy a periatamy \n",
      "Iter-103 loss: 2.8624\n",
      "\n",
      "in the GDP and ofparthitat and insived Wor dint Ocearoly 197, Kored and ifperea werch in the with-la\n",
      "Iter-104 loss: 2.8131\n",
      "\n",
      "Te the War and intlimuint-lalopitary surhe dixgst meinat a largest area. Japan has offimtorall ittor\n",
      "Iter-105 loss: 2.7650\n",
      "\n",
      ". inolitad in the of is and the worlddst Sinf-rage of Tokudixi of Japan Emper oftint ripot in ubith \n",
      "Iter-106 loss: 2.7181\n",
      "\n",
      "-lfrutic and in 1947, Kexth a dtStomy 16the worllato yo nary, Tokyond Reporterded, in 19thidso Was t\n",
      "Iter-107 loss: 2.6722\n",
      "\n",
      "-lopulatiomaliding lict pountey Asin\". Japan ke of ithicde, Napananed of Japan higand of Japan war o\n",
      "Iter-108 loss: 2.6273\n",
      "\n",
      "en the Nitholarn decality Empeon porist in the nombin econopectwing rin\". Japan Lofotiting in an etw\n",
      "Iter-109 loss: 2.5835\n",
      "\n",
      ". Stecondedin the Na9jo te pirbar histore of sivtitac of Japan inder whico Incend inta in city 2016 \n",
      "Iter-110 loss: 2.5407\n",
      "\n",
      "-ndmaiest rourthigendudes or Nially pmeined and Sinit of an end th se3pplrinty, the has puorth Japan\n",
      "Iter-111 loss: 2.4990\n",
      "\n",
      ". Japan's hiato-narisa, Ohossuemport ryhel Ce in easorac natie Japan war, Lona, thicesovin Seanto th\n",
      "Iter-112 loss: 2.4582\n",
      "\n",
      ". Japan was a groper memslatid in the G7te an te crrlatiom lare Chinate  opportargest inoding stret.\n",
      "Iter-113 loss: 2.4184\n",
      "\n",
      ". wroth the worr peried, in petity by surrectence eppontirges. Japan (Ohissucheag sorst bompotinirin\n",
      "Iter-114 loss: 2.3796\n",
      "\n",
      "-Japanese Swerobulargh sout of Japan inges lagenosy 19th asmality. Japan has ofcecolled an leent ena\n",
      "Iter-115 loss: 2.3417\n",
      "\n",
      "-largest into outh Japan, the with the SinEulitan a ling parealito an which solttrregs of stistory t\n",
      "Iter-116 loss: 2.3047\n",
      "\n",
      "in the G9titalict mirin it in cimctaingy sudtorodss ind Japan who nhingl the Sinity of stherarcedsti\n",
      "Iter-117 loss: 2.2686\n",
      "\n",
      ". revits exppenjodss ofcimearcenty in Aait Wint. Nippont regiso, whichuknc inta ward Hung pioptetwor\n",
      "Iter-118 loss: 2.2335\n",
      "\n",
      ". Othe worbal ts frest riest ictande: wand offanji the cationa nsmane nanie counories, Japan PalatuC\n",
      "Iter-119 loss: 2.1992\n",
      "\n",
      "-urrand whist roxest inttorae ceveled and Napangest ronklation to highest retoealy populuHing mane o\n",
      "Iter-120 loss: 2.1657\n",
      "\n",
      "-largest. euprox whith latity. In the worrladis sounced 8, the worl purtar a wal wos kreaceded boper\n",
      "Iter-121 loss: 2.1332\n",
      "\n",
      "-northe eaplobed fors deventom.1 19th a Sthos 2hinarly the \"Lan, which isuthe Iepand Tokeo-Japensed \n",
      "Iter-122 loss: 2.1014\n",
      "\n",
      "-largest import reacomicivorl Wa 19th and the Empire of Japan, the worllddst Chifer 35 thed roght th\n",
      "Iter-123 loss: 2.0705\n",
      "\n",
      ". Japan, 5astorlo-dun\" en of intereaden a gistan andbin, ffruta and has earesturealato the and milli\n",
      "Iter-124 loss: 2.0404\n",
      "\n",
      ". Japanes, thi histotutry vina Sencing peomeloweni. whird-landesi% of Japan is laed forst intabid th\n",
      "Iter-125 loss: 2.0110\n",
      "\n",
      ". The wor as mente in peopol purin ea lerealation llegs the G8,8, hast countermake uppinarly ptr and\n",
      "Iter-126 loss: 1.9824\n",
      "\n",
      ". Sthiceardsdiculargest imporr lited Tokyo Alctaientury ud the with a and ia kee Hins in meinten flo\n",
      "Iter-127 loss: 1.9546\n",
      "\n",
      ". Japan worsh in mimidaris, is thicolucand Iiponternak is the G8, Japan's tond-lare Humhe wort this \n",
      "Iter-128 loss: 1.9275\n",
      "\n",
      "Japan has oworld, inter Nihon of intind rogh hechastanmamile ty of Japan to expeonands isun-asofichi\n",
      "Iter-129 loss: 1.9011\n",
      "\n",
      "in the Empiral cwallyt in octanumenter OkyKoniral woth the 7eorbal of country with a sto the mowr pu\n",
      "Iter-130 loss: 1.8754\n",
      "\n",
      ". Japanese earlarly wrch eam larmedi. Alyopt evirea and is a deveds a demnding Inge 186 6ast merchan\n",
      "Iter-131 loss: 1.8503\n",
      "\n",
      "-lfrition East ar a worl somelidede-d frlee Pacing dectes legport of Japan's historugho the Riptonan\n",
      "Iter-132 loss: 1.8259\n",
      "\n",
      ". ripolaintaited bamwet GDP and is a meltint In of4JIpan Peass of the world'st economy. 2Inflicalard\n",
      "Iter-133 loss: 1.8021\n",
      "\n",
      ". Japan was inato the G8p,88.5% Japan who number lowes. Japan Gals. int. the rowh outhe Copperored a\n",
      "Iter-134 loss: 1.7790\n",
      "\n",
      "Ta whical ofpint ry hich 37th gast ching andeRalkokudes rhag tokyo the War a giman leades of erofe N\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-135 loss: 1.7564\n",
      "\n",
      ". Japan ws asd Hogkon, the coupilition Nepert ligite a lrgh hoke country per anter athich intan, Wer\n",
      "Iter-136 loss: 1.7344\n",
      "\n",
      "-loput ofpitivine a pirienta, shan coperowat perizgl aeloped Japan to ereftex Sratowithes ther Japan\n",
      "Iter-137 loss: 1.7130\n",
      "\n",
      "Ta it 120 and shac Comale the shirital ress maintorige ofpina 2thicecity of inystor l ghont-ropest i\n",
      "Iter-138 loss: 1.6921\n",
      "\n",
      ". Japanes earch wirto ancentu f atitined isth a gross irulagg is aku, of imiinded Shakunjilt. TaPean\n",
      "Iter-139 loss: 1.6718\n",
      "\n",
      "-loxgeforthe of the War, is laumelat romest. inuthe Sexic lamesextwangt of inchiled of in 1y6 make u\n",
      "Iter-140 loss: 1.6520\n",
      "\n",
      "-largest import runke munte in piefired a grohol popirirationys tan argons, uhigh-koku, Japan\n",
      "k in 1\n",
      "Iter-141 loss: 1.6327\n",
      "\n",
      " are maked reat piof lowest inta gast inta iamen seand Stated pmetien a periodskirura, hins Tokyo . \n",
      "Iter-142 loss: 1.6138\n",
      "\n",
      "ku th lary soct peftitan a Unitin Sina Sintes, Japan\") oflarching lirg perconomy. In the Chilatureco\n",
      "Iter-143 loss: 1.5954\n",
      "\n",
      "-normokili. Assand montresient ofUgs fourth undtan intor and in ecinded in 1941, hast city propn-1's\n",
      "Iter-144 loss: 1.5774\n",
      "\n",
      ". Japan cankodekt.ym the earth the Japan, the Ghister as a histovI the worl panece coperowe chire of\n",
      "Iter-145 loss: 1.5599\n",
      "\n",
      "-lore of the Ricinek arou\", wino the Worth-tary sixt liof orfabo ghea os the Empero the nargest into\n",
      "Iter-146 loss: 1.5428\n",
      "\n",
      ". Chinakkates ffectuint-Japan historrestorigst vounalic diviled as ofule-to ghin; forred orlandes th\n",
      "Iter-147 loss: 1.5260\n",
      "\n",
      ". Japan wored in Asia. Japan world, in the 1Erbide and of interidasited bupent enhitge o fovr Paotal\n",
      "Iter-148 loss: 1.5096\n",
      "\n",
      "-roles, cans founty is light eastrand ssuteves legisld't eare , Ra eollowited rale mikino Okyopan in\n",
      "Iter-149 loss: 1.4935\n",
      "\n",
      "wrod, whict purcinmengl perilled on the Emperor. Japan whiso the Russea. Japan called the to langest\n",
      "Iter-150 loss: 1.4778\n",
      "\n",
      "Thide alltdona Sea its ourth-largese ghorad rowest-renfel the Nipppoxn reghok. Thi aldot;t en to and\n",
      "Iter-151 loss: 1.4623\n",
      "\n",
      "-lorg porea Stat pores fourth-largesto gares is the Imperirandse condicaly Emper cape is the Japan h\n",
      "Iter-152 loss: 1.4472\n",
      "\n",
      ". ripolatitional boun to al hast miling Stat pefeict ecrnoy s fermokomet.-regisin, Kato an heast leg\n",
      "Iter-153 loss: 1.4323\n",
      "\n",
      "-largest intoxin Ease woral hishaku milet-rang isun-, Shicomitarese city raghkkokito the hifgefin se\n",
      "Iter-154 loss: 1.4176\n",
      "\n",
      ". Imperer pabesira. Japan, whi hist ioth peeced a and the Reporterea, whist rhe and the G7, thirg so\n",
      "Iter-155 loss: 1.4032\n",
      "\n",
      ". Japanes ourthe a larde histound Nag oa lome the wert ripke upex anc marefounc dectem largest impor\n",
      "Iter-156 loss: 1.3889\n",
      "\n",
      " arih iorlounnideve t of Japan is tonstore the Empere canie 1I and it in of Worssed Iige ga the came\n",
      "Iter-157 loss: 1.3749\n",
      "\n",
      "-largest ito n witto in Chine 1stican popul paigine as and Wol of in intart with the and the Emuliel\n",
      "Iter-158 loss: 1.3610\n",
      "\n",
      ". Japan whichisen's and Warle 日本 Nippeomert.\n",
      "ing Sifo-larea, of Japan, the OEropte ith agasl aslatio\n",
      "Iter-159 loss: 1.3473\n",
      "\n",
      ". Imperer paeconel andencensuperthagent of thes lowes regofowon the Emperorch inflitionyy Sence nfli\n",
      "Iter-160 loss: 1.3337\n",
      "\n",
      ". The wor dsuden 16tan sed milited a develombed inten the worlld's ourth- oftatear name of Tokud mai\n",
      "Iter-161 loss: 1.3203\n",
      "\n",
      ". Itree asla.chastorliodsie city int. Japan canard offJapan Ey, thicess hact of thes stred vhistonca\n",
      "Iter-162 loss: 1.3070\n",
      "\n",
      ". Japan has fourth-largest fror largest ar. The fictareato an Esun an Ember oftstrard strald3f GaDbe\n",
      "Iter-163 loss: 1.2939\n",
      "\n",
      ". 2016, kaiked % orthe a thia os eemper and Wa porbar historagas  hace fffis . Fveropo-JapaneTe enrl\n",
      "Iter-164 loss: 1.2808\n",
      "\n",
      ". countryh, whicho-t rinotor Ristony-sond, prouss make up bame the negis and the Empire the fictores\n",
      "Iter-165 loss: 1.2679\n",
      "\n",
      ". mprixal menalled in the early. Impira. Japan was expbon came country, ito t cotfo fleorlarce: Abin\n",
      "Iter-166 loss: 1.2551\n",
      "\n",
      ". ith hasichesed rigecount llowrred cinsiveness vefor. ralldd in th the world World countyoy mention\n",
      "Iter-167 loss: 1.2423\n",
      "\n",
      ". repet of tocldeteIn fleosy, wat roleriviter peritan a levese-dary ho the vor alled is ligenor. hev\n",
      "Iter-168 loss: 1.2297\n",
      "\n",
      ". wrorl the firss Tame ive cunto-ganes of Japan east UNipan histourdandsy ow 2015––p85%% in in thiro\n",
      "Iter-169 loss: 1.2171\n",
      "\n",
      "-lomen to the capiru to yo Adingino the world'st 941 xighout ourto an Eect motsoud. Japan has easthe\n",
      "Iter-170 loss: 1.2046\n",
      "\n",
      ". Japan was inhatovor gisthin Ear ofpan folsov-Japan wos the worrladien of 6,852st melome pite is th\n",
      "Iter-171 loss: 1.1921\n",
      "\n",
      ". Japan to even and sint Seand Seac to decalo decalled Japan was the worl pareacount-nary high of th\n",
      "Iter-172 loss: 1.1798\n",
      "\n",
      ". countryg, hossures of the foud and islarch, whtst retor3 a lomes Japanyy s dividese and its rigat \n",
      "Iter-173 loss: 1.1674\n",
      "\n",
      ". Archaeec lomy, wan Euran of Tokeat of histatial fits and tse 17thec lywixgh erons economiog liodal\n",
      "Iter-174 loss: 1.1552\n",
      "\n",
      ". Japan saleaglo the whiJad of to lare  and inteIma of Nobsldolled bous vevorull0has larcougan, whi \n",
      "Iter-175 loss: 1.1430\n",
      "\n",
      ". Japan is aro the Rmperowr abomst rigosouncily pipulatition tolldon Tekyos. The Report puectel endp\n",
      "Iter-176 loss: 1.1308\n",
      "\n",
      ". rexper offlife poreR largest. htare CD and Russekhes rigits of incalled and eas of the fird the Em\n",
      "Iter-177 loss: 1.1188\n",
      "\n",
      ". Brens mieitat and Nihenodout 20th0 asu mamemedt perssudectuntarn cinturnest livened a UnLtily. Abt\n",
      "Iter-178 loss: 1.1068\n",
      "\n",
      ". Aropict and is fimportallyunime, has inoldlded ittor memtory lutaty 20t5 and ean so the ftos devti\n",
      "Iter-179 loss: 1.0948\n",
      "\n",
      ". wrct milet-rence f rof eoNroddd, fits hicthec Acia Sirions regimp the Sinse ad the worrlabanes off\n",
      "Iter-180 loss: 1.0830\n",
      "\n",
      ". Japan was  fforter,ate in eas of tok and its emollarc minelIdolovan as the Emperol of Japar hest i\n",
      "Iter-181 loss: 1.0712\n",
      "\n",
      ". urban counoryaly War, is the world's ecale citsd vevonts and the worl ther of Japangis the asurch-\n",
      "Iter-182 loss: 1.0595\n",
      "\n",
      ". repolitary stralorded the atom th hestorcadds forst koe th redsteriolst into allown in in of the d\n",
      "Iter-183 loss: 1.0479\n",
      "\n",
      ". Japan tes pofflarchaiol ofibed is dividera, Dixthe worrs a Ubonk in the UN,8, thiching andederalat\n",
      "Iter-184 loss: 1.0364\n",
      "\n",
      ". Japan hoke amonternal hise milita, ince uprocetough, Japan was inhac uetixtest pronal Dierio o of \n",
      "Iter-185 loss: 1.0250\n",
      "\n",
      "C in 194153 The archtieat powerixalation, partokees of divity in to the Narchias in pixpanueccaniy i\n",
      "Iter-186 loss: 1.0137\n",
      "\n",
      ". It is hicterind a Un is a wrlowen fess offlaresercen meintery Cht a wimbem Japar ime a lone popuit\n",
      "Iter-187 loss: 1.0025\n",
      "\n",
      ". Japan to a and the kombbimed cand it is owileo dfiosul aggso-Japanese Hhigho historyvil tit1 the J\n",
      "Iter-188 loss: 0.9915\n",
      "\n",
      ". countrya, a develowet regisslounden enderea. The prrose . Eato asu mainEulies of Japan th the Empe\n",
      "Iter-189 loss: 0.9806\n",
      "\n",
      ". ceurth-lagg sski\"m in the worlddding an emperood loce city of stanchtwl offlits ane os to shanacon\n",
      "Iter-190 loss: 0.9698\n",
      "\n",
      ". Importality 17t regotopenic popularitso whor country gmolect cinsu, ate the Japen callodging dith \n",
      "Iter-191 loss: 0.9591\n",
      "\n",
      ". celitand sha, whichiche with the Seastrod. The decje iounco andrin early Asth a holsturea, to higi\n",
      "Iter-192 loss: 0.9486\n",
      "\n",
      ". itrlatixty mon thi Emperocal Dtes 1 sicttrigwto ovel wont lito a unLtioutr an Emper alasdis lage o\n",
      "Iter-193 loss: 0.9382\n",
      "\n",
      ". Japan ts amate is thith-l wafan, the .88888688568% Japan's sivited and eassodxdes Tolith largest I\n",
      "Iter-194 loss: 0.9280\n",
      "\n",
      ". itrlatec camdich inse allodu, which sha and Shias ofed Japan a divine aI in to the Rase Wurth cant\n",
      "Iter-195 loss: 0.9179\n",
      "\n",
      ". ith earle First woxth leading inter and in 19th south-largestore o8 anu of 1868 mbato the Russounc\n",
      "Iter-196 loss: 0.9080\n",
      "\n",
      ". cerrth went-ryne eall tw ren thirght of livine sest rexat cots of u8, Japan is the Incearl cempire\n",
      "Iter-197 loss: 0.8982\n",
      "\n",
      ". ith earch tuled's heconce fpireadiru, Hond the G20018, pand fourtPalestyrm the deatevilefame cons \n",
      "Iter-198 loss: 0.8886\n",
      "\n",
      ". Japan to a and the worrth. The  amboled and Reporterea of the Wes thenMe pupiof lauda \"Stal powhit\n",
      "Iter-199 loss: 0.8791\n",
      "\n",
      ". Apicaimelatdy highead a 1 mflcinatioutinuthir sorst in thina logesiragestovearort. The worllddding\n",
      "Iter-200 loss: 0.8698\n",
      "\n",
      ". ithand who telddd iost marianta yast China, has koked ith cang peeteon;s thirheved the tred at of \n",
      "Iter-201 loss: 0.8606\n",
      "\n",
      ". repolitan, Gyppon callogitan and Wimper was proust. Nbarly Asith Japgn toledglililange earts and i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-202 loss: 0.8516\n",
      "\n",
      ". itrlatecine ardo historilo world'st city propple regopopores inhen Ceipaturel parcelees of inate i\n",
      "Iter-203 loss: 0.8427\n",
      "\n",
      ". Whogands of 18685a, the world'd lore cinitarioutarmy-. in the Firotal Cetae to an by pincerios lar\n",
      "Iter-204 loss: 0.8340\n",
      "\n",
      ". Great of strtecran was proclatity-sea. Japan's hiseo-Japan's wourth-largisorhak of the Warted  and\n",
      "Iter-205 loss: 0.8255\n",
      "\n",
      ". Asix. Japan's liggrolo. Archiagecty un tomyor, nTien enjo the east treadion of 6,852 inde-hal to t\n",
      "Iter-206 loss: 0.8171\n",
      "\n",
      ". Japan to a and ofeligeginsy, Whiaa , ctanded Nipan a Sema, the Shicomare the sixth indthe gurram a\n",
      "Iter-207 loss: 0.8088\n",
      "\n",
      ". ith then sichac whict prefocoun inter wroth nang ard Russea, make uloun mestove  oftinal ampen cou\n",
      "Iter-208 loss: 0.8007\n",
      "\n",
      ". Greate. Japan wos the Japan was inhabiter garto Stame sdkbomy-sed of the fercideinally Asthirg thi\n",
      "Iter-209 loss: 0.7927\n",
      "\n",
      ". ith id is the numbente lare caunoryy. From exivircanis divine Iesixg Kored is the Eurchature the T\n",
      "Iter-210 loss: 0.7848\n",
      "\n",
      ". Japan to are war, country suled Japan in ereat retoe 1stitended, it of third lowethF vrrth outh ca\n",
      "Iter-211 loss: 0.7771\n",
      "\n",
      ". ith earle G7, the ease Ubel cite a perroke to the worth and pfrituen masechuland early wht rom thi\n",
      "Iter-212 loss: 0.7695\n",
      "\n",
      ". itrand yorld, the rating as eaping portitain sictenderoptiourge se porthiolldtitelogg oa in the Me\n",
      "Iter-213 loss: 0.7621\n",
      "\n",
      ". merrall upret constutatustr Chiin is the worllddgine en ereoddanly which xaleodkadioy im in owithe\n",
      "Iter-214 loss: 0.7547\n",
      "\n",
      ". Area of the Risixtan\"ist eroptt nitaicalegji the wat, the nECD and warl butec and lareaden schine \n",
      "Iter-215 loss: 0.7475\n",
      "\n",
      " arl has East Hotas .oJapan to alortents fropter. The copperoced Japan which aslagal ardiven percans\n",
      "Iter-216 loss: 0.7404\n",
      "\n",
      ". Japan to alation, ia the keipte en expeaakke expandeveragins largestot metaly wrrost leghest loge \n",
      "Iter-217 loss: 0.7335\n",
      "\n",
      ". In the world'st Repore coudor. \"Stho the Emperor asterigh seanto Nopanes largest indorrr. Then per\n",
      "Iter-218 loss: 0.7266\n",
      "\n",
      ". Area of the Rusixt worlldtitive a gos tivine ene in the \"Sten rehicearl Abia mame ty proxl 35 the \n",
      "Iter-219 loss: 0.7198\n",
      "\n",
      ". ith Japan wen of Japan wons . Japan was inhthe whima ecalled the sound lime an tred and eas sucrop\n",
      "Iter-220 loss: 0.7132\n",
      "\n",
      ". itrlatity or Nighingss deaststerng s reina, Frettengs of Japan's seastho d comperoxl the ato the E\n",
      "Iter-221 loss: 0.7066\n",
      "\n",
      ". wrobld cyt itt intin 19rbedtreg of the outh and Senco nfpreas peimined in As aror lympex Japan is \n",
      "Iter-222 loss: 0.7002\n",
      "\n",
      "Totira, wate of Hirosukeu forr sidthe first camled south by's  Eorthoral highest repereised in the U\n",
      "Iter-223 loss: 0.6938\n",
      "\n",
      ". Japan to evortak, Ghe Ruporleeoluhanjy sunt ense foural Dien in 1853 who empan East urrove fourth-\n",
      "Iter-224 loss: 0.6875\n",
      "\n",
      ". Gcea, Hokko, the Chin mikinse as ofean of Hty of thiver gesting of ince and Asivesoltordes lopeate\n",
      "Iter-225 loss: 0.6814\n",
      "\n",
      ". itrlatitovelead roun to hestrexcturiestitu rnest irolstiruer ly pres ares. Japan to erecteridg of \n",
      "Iter-226 loss: 0.6753\n",
      "\n",
      ". Asex.2-007日本 atos 185using ofte of alowid'n and Japan to and ofpurtocy. Arigaka memast is divired \n",
      "Iter-227 loss: 0.6693\n",
      "\n",
      ". ith earle 20thised ranked runarHo the whicate owt nilly-numons, pretered an hygtolot of the Rippro\n",
      "Iter-228 loss: 0.6633\n",
      "\n",
      ". Neppen to the Wenclaed counordess in the world's ecand it acchiinonsivel an incecoung sort bitet v\n",
      "Iter-229 loss: 0.6575\n",
      "\n",
      ". ith east Chige, an electen Ibipinate rons  capurceant Iy in Eartok-dera, has eouth lare with a an \n",
      "Iter-230 loss: 0.6518\n",
      "\n",
      ". Arex, whicht of a sturr. The an en, popuperiols in the world War , histoliciPeladic a mentrenis ke\n",
      "Iter-231 loss: 0.6461\n",
      "\n",
      ". Japan to aleoAkized Japan war and caunory ral the gith and anuEocea It inta inato th .8535% of dio\n",
      "Iter-232 loss: 0.6406\n",
      "\n",
      ". Arowan the Japanes erigand a divte ip nesty renonco therg const ixpand ofed Sea. Japan Ey ssdoJanc\n",
      "Iter-233 loss: 0.6351\n",
      "\n",
      ". The vorrr an helthirg fortands dictan anlonh. Japan in cauntry suloobin%ly militaryyss. The whib7O\n",
      "Iter-234 loss: 0.6297\n",
      "\n",
      ". Seart liest rigotolere pored rifeloun\"t. Area, whichor headen impan inco mpereries in thicadesc de\n",
      "Iter-235 loss: 0.6244\n",
      "\n",
      ". Sunce deate n peopor and errth censs a9tima a Undigin\", and Sinc-kagand earla world Narly 20th our\n",
      "Iter-236 loss: 0.6192\n",
      "\n",
      ". urra-kokulead reant as and earls. The War, witary caleolsthe hictended in exthidh callodide a7dere\n",
      "Iter-237 loss: 0.6141\n",
      "\n",
      " aris is the Empericaka Stae ouper Himoth n puperies is the Nase whith lovet. Japan was abomec 1ntre\n",
      "Iter-238 loss: 0.6090\n",
      "\n",
      ". cour 1higest irth arihomeis nasto-Japanese Japan was inhorter. The suxth corrde testhir regional s\n",
      "Iter-239 loss: 0.6041\n",
      "\n",
      ". It aimnobiled Japan was the forlffec by firs tha onth periost in 1853 which lowglo-Janese Chinaso \n",
      "Iter-240 loss: 0.5992\n",
      "\n",
      ". Japan to ofon-Jase e9 Paako Japan a gislatany country pmec pouth o-d cincicates a and a divty im t\n",
      "Iter-241 loss: 0.5944\n",
      "\n",
      ". Importer alnsd in the worldddine al owedtbe Seati a, tho negecean forl ditan selfliwon, in in in t\n",
      "Iter-242 loss: 0.5896\n",
      "\n",
      ". Japanese earol whixhas  earandus. Japan to alsticea.chast mipire ofturcal fourthe from and canso h\n",
      "Iter-243 loss: 0.5850\n",
      "\n",
      ". cenrth reost enftr esea. Japan wos the oflare  hecturis, as a monflaime cauneryo, to al ofed appro\n",
      "Iter-244 loss: 0.5805\n",
      "\n",
      ". itrla. The sed As alocaim largese en the the durades houd Japan ko the worrralloddan-agl the Eare \n",
      "Iter-245 loss: 0.5760\n",
      "\n",
      ". Sen. Japan wecturie, Japan, whi head the dos . Japan was inhint militerysudec ufrbollarchaicl Chin\n",
      "Iter-246 loss: 0.5716\n",
      "\n",
      ". Japan to exppreaken fimede and of toe thiredso ghe caing pint pexia laglopon's  efrumeatures, is t\n",
      "Iter-247 loss: 0.5674\n",
      "\n",
      ". Arixg comertopnca Seano dhia thi Onegionality mperil . Japan woth liee country lympin kake itt cit\n",
      "Iter-248 loss: 0.5632\n",
      "\n",
      ". itrlammer lerge of Japan EClina and thest rbo ere5 Wes. Altssurn laimome. Shiggg an Eopan hest ort\n",
      "Iter-249 loss: 0.5591\n",
      "\n",
      ". itrla. Thes coudtrymy issa mamnd In the worllddd in mititarly a orubyHs the histh-largest res of t\n",
      "Iter-250 loss: 0.5551\n",
      "\n",
      ". ith Japan wor porea which lare GWe paris Chine warty rmperiollation ex45 folsoceanIl 1947, thic me\n",
      "Iter-251 loss: 0.5511\n",
      "\n",
      ". Area wol thirgest. 6nhtin pefcestoweriono, of lieat porllowinory, and if a dist bwho at ooth name \n",
      "Iter-252 loss: 0.5473\n",
      "\n",
      ". Japan was puocturiallyof I frreat on ton in the the fimmater Chints of an hastutes and eartedgs an\n",
      "Iter-253 loss: 0.5435\n",
      "\n",
      ". Stech calest mint an followr 17ty to gh kake Hudneky of Hind Japan to the Narchtic alled the G7,pt\n",
      "Iter-254 loss: 0.5399\n",
      "\n",
      ". Japan was pawitac pepulation io thecand power, with orex, Hokkowing th the geordasoD whinh puritec\n",
      "Iter-255 loss: 0.5363\n",
      "\n",
      ". Arixt with a an endich chanomo Eags out Japan\") whi at woced-dase rowes.-gerop-Japan Counorol  Imp\n",
      "Iter-256 loss: 0.5327\n",
      "\n",
      ". itrla. The d gies to the Pailitaty or e aido, Japan, whicag so \"Lhines of encecendptitse Wanded th\n",
      "Iter-257 loss: 0.5292\n",
      "\n",
      ". Japan was puat of therd-lares as ueconolly Appophecaldmion laret esoth-Japan East Asix. Japan Eurt\n",
      "Iter-258 loss: 0.5258\n",
      "\n",
      ". It is uhech induto to par empericade ippen Okhinomic Gomed an counomy. Japan ince ppoearly. Abur r\n",
      "Iter-259 loss: 0.5225\n",
      "\n",
      ". It is wandy cinyurnes of in of thet atofte name te pas neging militaryyy surcea. ve tullevids of t\n",
      "Iter-260 loss: 0.5192\n",
      "\n",
      ". cour 194gSe Waitake uper and inder and the worrladion interegipolbic G8, and ifrcongillion peofes \n",
      "Iter-261 loss: 0.5160\n",
      "\n",
      ". Japan was puwit 6ndtin mavinese peopaegissdevest Sino Ipuearly the trod const a dex,;ku, ral oftin\n",
      "Iter-262 loss: 0.5128\n",
      "\n",
      ". Japan was puobol the G8pen larea colectari Eurodety-sexgleght sixt pixper Japan\") istand oflandead\n",
      "Iter-263 loss: 0.5097\n",
      "\n",
      ". Japan was puec reghest militarly-sy historrle Conation is the ens reas sea wor ding in Asia mame p\n",
      "Iter-264 loss: 0.5066\n",
      "\n",
      ". core peeplomel 12thial Chinar a hinle Infriceto of in the cored is the anct. Japan was puobol to d\n",
      "Iter-265 loss: 0.5035\n",
      "\n",
      ". itrlaticutev foust-bate th the loge the make te of Japan is ranked Japan wot poped Japan to of the\n",
      "Iter-266 loss: 0.5005\n",
      "\n",
      ". inten the world't es theneso heast wrroponi9gitaletwigg ortanese .hJapan Empont pof at ito n Die e\n",
      "Iter-267 loss: 0.4975\n",
      "\n",
      ". ito ndginflee iaturocat milaturest. reace feccese allm. wrr whigh lowan 1rcale the FRurlanch. The \n",
      "Iter-268 loss: 0.4945\n",
      "\n",
      ". itrla the worr deriodd in the Search and inta iast maid Ho therghs olltwrrosturestire cite instin \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-269 loss: 0.4915\n",
      "\n",
      ". Japan to everea, of ind Nigolande ehicerro nallitdin East exrerch and ear ostand oflargek, uhour h\n",
      "Iter-270 loss: 0.4886\n",
      "\n",
      ". Japan was puobe th largest eroprluriestorund a Uniten 1hig Sima and Naguna Shaias bountrly, \"Ldole\n",
      "Iter-271 loss: 0.4857\n",
      "\n",
      ". Japan was purith. Inuthe G7 ixpard of intercel iladin\", and itrcenil copnty th exppporberiven sulc\n",
      "Iter-272 loss: 0.4828\n",
      "\n",
      ". From the re5d of liad nigidtd inct rensimalitat and Gas ofel wich anstity peroin country Brand in \n",
      "Iter-273 loss: 0.4799\n",
      "\n",
      ". it lege pobeleodst imporc laec aided Japan islargest nenes a an has chang hof leares in 1Nibsecour\n",
      "Iter-274 loss: 0.4770\n",
      "\n",
      ". itrlatitet of Wisrthe Smaet of and therd laesea to states ilogeno ixpan inter anktmoruln to experi\n",
      "Iter-275 loss: 0.4741\n",
      "\n",
      ". Japan was pu5co andeande eariod ing porlsountsy adfriten, the Combing the th c pfourth-largistony \n",
      "Iter-276 loss: 0.4712\n",
      "\n",
      ". ith Japan to aEd stand ofts ioporthead is and the Ruprrtere as e retee Axpereod by poreit cing pfo\n",
      "Iter-277 loss: 0.4683\n",
      "\n",
      ". Japan wat pobes. Jada, ihocu, rex,an. Im and War, stred and solt counterda, whico thaiast 20t5 con\n",
      "Iter-278 loss: 0.4654\n",
      "\n",
      ". Japan's histoxNn7tr and ear edt liginanisold. Japan Empiread war id laicalatovol uthi agan , Hong \n",
      "Iter-279 loss: 0.4625\n",
      "\n",
      "Japan who emain lare witake of Wa hics ipptrchatho  labe eightht conllde didhtan yudth largest into \n",
      "Iter-280 loss: 0.4596\n",
      "\n",
      ". merrall uper the worl Was ress coulate the OES6nd Sinouncid the firuthin s ound koked Ia tol geste\n",
      "Iter-281 loss: 0.4567\n",
      "\n",
      ". country,  highestion if indids t cenf Pealef-koku, which wargest erroso. The Japan has toked Hopen\n",
      "Iter-282 loss: 0.4538\n",
      "\n",
      ". Japan was puetex enhtrunnmy in thet revisel 1obfel Peat of siarit en the thicd lice 's sentuliis s\n",
      "Iter-283 loss: 0.4508\n",
      "\n",
      ". Freflarlest rese rexte ghoged Sin eouspin 1stuthe d porea ito and esrat country hight ast mofaleac\n",
      "Iter-284 loss: 0.4479\n",
      "\n",
      ". Japan was puac are counte pepperea wiot lned in the Earcederged, as thas shacite ind Worlandes the\n",
      "Iter-285 loss: 0.4449\n",
      "\n",
      ". 18, ve5d of the warl rag to ton the ear parien umwint pooutorive, As a mellyon an hyuth. Thesticed\n",
      "Iter-286 loss: 0.4419\n",
      "\n",
      ". Japan was phiciaily 20the G7, rgest in the worl parcelofike add, whithm  empire . Japan's histourt\n",
      "Iter-287 loss: 0.4390\n",
      "\n",
      ". Japan was pupulaits livent etr and its rang solfi201, gioponeny sexjo dhia. Japan was inhecaden co\n",
      "Iter-288 loss: 0.4360\n",
      "\n",
      ". itrch isstumen lamenodd in Afiat 201xupand foltole 1868 and imper regsouge of inothi Eass Hime pre\n",
      "Iter-289 loss: 0.4330\n",
      "\n",
      ". imperot bobfal mien a and Japan was the foll the G86,868,8vint redsia womntend1 twhinas lyunnt ext\n",
      "Iter-290 loss: 0.4300\n",
      "\n",
      ". Japan to end intuncallato ul 35kkkkand followrr China, Kyurth Jargest. Japan worodenoas. Japan was\n",
      "Iter-291 loss: 0.4270\n",
      "\n",
      ". couloby-nane es chandts of ence purcinty und16nIstcen cindtitit lige audal powest-rente paria the \n",
      "Iter-292 loss: 0.4239\n",
      "\n",
      ". Sea. Japan is a memb leed counoryall . Nmperah south-largese san, period hiral Chinasea.lowllt-ran\n",
      "Iter-293 loss: 0.4209\n",
      "\n",
      ". Sea. Japan is in Chinese gheg China, Hound of eartho menn pefoe 19th stral Dowesturesker ceanide a\n",
      "Iter-294 loss: 0.4177\n",
      "\n",
      ". chichtr garte poount peoplowag of kfotper Periono-deres, as seante nymby ral exppcouf licitar yo t\n",
      "Iter-295 loss: 0.4146\n",
      "\n",
      ". corectinget Nigan, the aEuntry und make up Japan inhina lowe the ats thi and Shigas sharict milise\n",
      "Iter-296 loss: 0.4114\n",
      "\n",
      ". Japan wor to gesteren Chinssion loouth Japanel largika, Jagan\") israg shichinstorn Firuthe  Eagg o\n",
      "Iter-297 loss: 0.4083\n",
      "\n",
      ". Japan was pueter ea counordess regenty in 1868,att conder warly two ded at of en hast th l realles\n",
      "Iter-298 loss: 0.4050\n",
      "\n",
      ". Japan was pupcinocident es, Hi anc norilation eijo tureou,han and Secon the etorden\"aly it the OEy\n",
      "Iter-299 loss: 0.4018\n",
      "\n",
      ". Neppen tas in the G7,bber const a gessarcenpipulotior astic country syd whicall. The parcympore co\n",
      "Iter-300 loss: 0.3985\n",
      "\n",
      ". itoled Japent  efpumealitovor dist in the G868, buthe th century um. Japaneen renshity or a world.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRETEp4QgIiKAEoKIiPiUEEREBID/B2/DlTnTHuiWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bfe0ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Hyper-parameters\n",
    "# time_step = 10 # width, minibatch size and test sample size as well\n",
    "# num_layers = 1 # depth\n",
    "# n_iter = 300 # epochs\n",
    "# alpha = 1e-4 # learning_rate\n",
    "# print_after = 1 # n_iter//10 # print training loss, valid, and test\n",
    "# num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "# num_input_units = len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "\n",
    "# # Build the network and learning it or optimizing it using SGD\n",
    "# net = GRU(D=num_input_units, H=num_hidden_units, L=num_layers, char2idx=char_to_idx, idx2char=idx_to_char)\n",
    "\n",
    "# # Start learning using BP-SGD-ADAM\n",
    "# adam_rnn(nn=net, X_train=X, y_train=y, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)\n",
    "\n",
    "# # # Display the learning curve and losses for training, validation, and testing\n",
    "# # %matplotlib inline\n",
    "# # %config InlineBackend.figure_format = 'retina'\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(net.losses['train'], label='Train loss')\n",
    "# plt.plot(net.losses['smooth train'], label='Train smooth loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
