{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import impl.layer as l\n",
    "\n",
    "# Dataset preparation and pre-processing\n",
    "mnist = input_data.read_data_sets('data/MNIST_data/', one_hot=False)\n",
    "\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "# y_test.shape, y_val.shape, y_train.shape\n",
    "# X_train.shape, X_train.dtype, X_val.shape, X_val.dtype, X_test.shape, X_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-processing: normalizing\n",
    "def normalize(X):\n",
    "    # max scale for images 255= 2**8= 8 bit grayscale for each channel\n",
    "    return (X - X.mean(axis=0)) #/ X.std(axis=0)\n",
    "\n",
    "X_train, X_val, X_test = normalize(X=X_train), normalize(X=X_val), normalize(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l # or from impl.layer import *\n",
    "from impl.loss import * # import all functions from impl.loss file # import impl.loss as loss_func\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "class FFNN:\n",
    "\n",
    "    def __init__(self, D, C, H, L):\n",
    "        self.L = L # number of layers or depth\n",
    "        self.losses = {'train':[], 'valid':[], 'valid_acc':[]}\n",
    "        \n",
    "        # The adaptive/learnable/updatable random feedforward\n",
    "        self.model = []\n",
    "        self.W_fixed = []\n",
    "        self.grads = []\n",
    "        self.ys_prev = []\n",
    "        low, high = -1, 1\n",
    "        \n",
    "        # Input layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.), b=np.zeros((1, H)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Input layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[0].items()})\n",
    "        # Previous output layer\n",
    "        self.ys_prev.append(0.0)\n",
    "\n",
    "        # Hidden layers: weights/ biases\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = dict(W=np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, H)))\n",
    "            m_L.append(m)\n",
    "        self.model.append(m_L)\n",
    "        # Fixed feedback weight\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.)\n",
    "            m_L.append(m)\n",
    "        self.W_fixed.append(m_L)\n",
    "        # Hidden layer: gradients\n",
    "        grad_L = []\n",
    "        for _ in range(L):\n",
    "            grad_L.append({key: np.zeros_like(val) for key, val in self.model[1][0].items()})\n",
    "        self.grads.append(grad_L)\n",
    "        # Previous output layer\n",
    "        ys_prev_L = []\n",
    "        for _ in range(L):\n",
    "            ys_prev_L.append(0.0)\n",
    "        self.ys_prev.append(ys_prev_L)\n",
    "        \n",
    "        # Output layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, C)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Outout layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[2].items()})\n",
    "        # Previous output layer\n",
    "        self.ys_prev.append(0.0)\n",
    "        \n",
    "    def fc_forward(self, X, W, b):\n",
    "        out = (X @ W) + b\n",
    "        cache = (W, X)\n",
    "        return out, cache\n",
    "\n",
    "    def fc_backward(self, dout, cache, W_fixed):\n",
    "        W, X = cache\n",
    "\n",
    "        dW = X.T @ dout\n",
    "        db = np.sum(dout, axis=0).reshape(1, -1) # db_1xn\n",
    "        \n",
    "        # dX = dout @ W.T # Backprop\n",
    "        dX = dout @ W_fixed.T # fb alignment\n",
    "\n",
    "        return dX, dW, db\n",
    "\n",
    "    def train_forward(self, X, train):\n",
    "        caches, ys = [], []\n",
    "        \n",
    "        # Input layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[0]['W'], b=self.model[0]['b']) # X_1xD, y_1xc\n",
    "#         y, _ = l.selu_forward(X=y)\n",
    "#         y = l.elu_fwd(X=y)\n",
    "#         y = l.sigmoid(X=y)\n",
    "#         y = np.tanh(y)\n",
    "#         a, b = 1.7519, 2/3\n",
    "#         y = a * np.tanh(b*y) # LeCun Tanh\n",
    "#         y = np.tanh(y/2)\n",
    "#         y = np.arctan(y)\n",
    "#         y = y / (1 + np.absolute(y)) # softsign\n",
    "#         y = ((((y**2) + 1)**0.5 + 1)/ 2) + y # bent identity\n",
    "#         y = 1 - np.exp(-1 * np.exp(y)) # log log\n",
    "#         y = np.exp(-1 * (y**2)) # Gaussian\n",
    "#         y = np.absolute(y)\n",
    "        y = np.sin(y)\n",
    "        if train:\n",
    "            caches.append(fc_cache)\n",
    "        ys.append(y) # ys[0]\n",
    "        X = y.copy() # pass to the next layer\n",
    "        \n",
    "        # Hidden layers\n",
    "        fc_caches, ys_L = [], []\n",
    "        for layer in range(self.L):\n",
    "            y, fc_cache = self.fc_forward(X=X, W=self.model[1][layer]['W'], b=self.model[1][layer]['b'])\n",
    "#             y, _ = l.selu_forward(X=y)\n",
    "#             y = l.elu_fwd(X=y)\n",
    "#             y = l.sigmoid(X=y)\n",
    "#             y = np.tanh(y)\n",
    "#             a, b = 1.7519, 2/3\n",
    "#             y = a * np.tanh(b*y)\n",
    "#             y = np.tanh(y/2)\n",
    "#             y = np.arctan(y)\n",
    "#             y = y / (1 + np.absolute(y)) # softsign\n",
    "#             y = ((((y**2) + 1)**0.5 + 1)/ 2) + y # bent identity\n",
    "#             y = 1 - np.exp(-1 * np.exp(y))\n",
    "#             y = np.exp(-1 * (y**2)) # Gaussian\n",
    "#             y = np.absolute(y)\n",
    "            y = np.sin(y)\n",
    "            fc_caches.append(fc_cache)\n",
    "            ys_L.append(y) # ys[1][layer]\n",
    "            X = y.copy() # pass to next layer\n",
    "        if train:\n",
    "            caches.append(fc_caches) # caches[1]\n",
    "        ys.append(ys_L) # ys[1]            \n",
    "        \n",
    "        # Output layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[2]['W'], b=self.model[2]['b'])\n",
    "        if train:\n",
    "            caches.append(fc_cache)\n",
    "        ys.append(y) # ys[2]\n",
    "\n",
    "        return ys, caches # for backpropating the error\n",
    "\n",
    "    def loss_function(self, y, y_train):\n",
    "        \n",
    "        loss = cross_entropy(y, y_train) # softmax is included\n",
    "        dy = dcross_entropy(y, y_train) # dsoftmax is included\n",
    "        \n",
    "        return loss, dy\n",
    "        \n",
    "    def train_backward(self, dy, caches, ys):\n",
    "        grads, ys_prev = self.grads, self.ys_prev # initialized by Zero in every iteration/epoch\n",
    "        \n",
    "        # Output layer\n",
    "        fc_cache = caches[2]\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[2])\n",
    "        dy = dX.copy()\n",
    "        grads[2]['W'] = dW\n",
    "        grads[2]['b'] = db\n",
    "\n",
    "        # Hidden layer\n",
    "        fc_caches = caches[1]\n",
    "        for layer in reversed(range(self.L)):\n",
    "            dy *= ys[1][layer] - ys_prev[1][layer] # temporal diff instead of differentiable function\n",
    "            dX, dW, db = self.fc_backward(dout=dy, cache=fc_caches[layer], W_fixed=self.W_fixed[1][layer])\n",
    "            dy = dX.copy()\n",
    "            grads[1][layer]['W'] = dW\n",
    "            grads[1][layer]['b'] = db\n",
    "        \n",
    "        # Input layer\n",
    "        fc_cache = caches[0]\n",
    "        dy *= ys[0] - ys_prev[0] # temporal diff instead of differentiable function\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[0])\n",
    "        grads[0]['W'] = dW\n",
    "        grads[0]['b'] = db\n",
    "\n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X):\n",
    "        ys_logit, _ = self.train_forward(X, train=False)\n",
    "        y_logit = ys_logit[2] # last layer\n",
    "        \n",
    "        # if self.mode == 'classification':\n",
    "        y_prob = l.softmax(y_logit) # for accuracy == acc\n",
    "        y_pred = np.argmax(y_prob, axis=1) # for loss ==err\n",
    "        \n",
    "        return y_pred, y_logit\n",
    "        \n",
    "    def get_minibatch(self, X, y, minibatch_size, shuffle):\n",
    "        minibatches = []\n",
    "\n",
    "        if shuffle:\n",
    "            X, y = skshuffle(X, y)\n",
    "\n",
    "        for i in range(0, X.shape[0], minibatch_size):\n",
    "            X_mini = X[i:i + minibatch_size]\n",
    "            y_mini = y[i:i + minibatch_size]\n",
    "            minibatches.append((X_mini, y_mini))\n",
    "\n",
    "        return minibatches\n",
    "\n",
    "    def sgd(self, train_set, val_set, alpha, mb_size, n_iter, print_after):\n",
    "        X_train, y_train = train_set\n",
    "        X_val, y_val = val_set\n",
    "\n",
    "        # Epochs\n",
    "        for iter in range(1, n_iter + 1):\n",
    "\n",
    "            # Minibatches\n",
    "            minibatches = self.get_minibatch(X_train, y_train, mb_size, shuffle=True)\n",
    "            idx = np.random.randint(0, len(minibatches))\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            \n",
    "            # Train the model\n",
    "            ys, caches = self.train_forward(X_mini, train=True)\n",
    "            loss, dy = self.loss_function(ys[2], y_mini)\n",
    "            _, grads = self.train_backward(dy, caches, ys) # ys[0], ys[1] and ys_prev are used for backprop\n",
    "            self.ys_prev = ys # for next iteration or epoch learning dW and db\n",
    "            self.losses['train'].append(loss)\n",
    "            \n",
    "            # Update the model for input layer\n",
    "            for key in grads[0].keys():\n",
    "                self.model[0][key] -= alpha * grads[0][key]\n",
    "\n",
    "            # Update the model for the hidden layers\n",
    "            for layer in range(self.L):\n",
    "                for key in grads[1][layer].keys():\n",
    "                    self.model[1][layer][key] -= alpha * grads[1][layer][key]\n",
    "\n",
    "            # Update the model for output layer\n",
    "            for key in grads[2].keys():\n",
    "                self.model[2][key] -= alpha * grads[2][key]\n",
    "                \n",
    "            # Validate the updated model\n",
    "            y_pred, y_logit = self.test(X_val)\n",
    "            valid_loss, _ = self.loss_function(y_logit, y_val) # softmax is included in entropy loss function\n",
    "            self.losses['valid'].append(valid_loss)\n",
    "            valid_acc = np.mean(y_pred == y_val) # confusion matrix\n",
    "            self.losses['valid_acc'].append(valid_acc)\n",
    "            \n",
    "            # Print the model info: loss & accuracy or err & acc\n",
    "            if iter % print_after == 0:\n",
    "                print('Iter-{} train loss: {:.4f} valid loss: {:.4f}, valid accuracy: {:.4f}'.format(\n",
    "                    iter, loss, valid_loss, valid_acc))\n",
    "\n",
    "        # Test the final model\n",
    "        y_pred, y_logit = nn.test(X_test)\n",
    "        loss, _ = self.loss_function(y_logit, y_test) # softmax is included in entropy loss function\n",
    "        acc = np.mean(y_pred == y_test)\n",
    "        print('Last iteration - Test accuracy mean: {:.4f}, std: {:.4f}, loss: {:.4f}'.format(\n",
    "            acc.mean(), acc.std(), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-100 train loss: 2.2874 valid loss: 2.2985, valid accuracy: 0.1034\n",
      "Iter-200 train loss: 2.3098 valid loss: 2.2974, valid accuracy: 0.1050\n",
      "Iter-300 train loss: 2.3161 valid loss: 2.2962, valid accuracy: 0.1084\n",
      "Iter-400 train loss: 2.2886 valid loss: 2.2951, valid accuracy: 0.1110\n",
      "Iter-500 train loss: 2.3041 valid loss: 2.2939, valid accuracy: 0.1126\n",
      "Iter-600 train loss: 2.3215 valid loss: 2.2928, valid accuracy: 0.1140\n",
      "Iter-700 train loss: 2.2824 valid loss: 2.2917, valid accuracy: 0.1164\n",
      "Iter-800 train loss: 2.2771 valid loss: 2.2906, valid accuracy: 0.1204\n",
      "Iter-900 train loss: 2.2797 valid loss: 2.2895, valid accuracy: 0.1230\n",
      "Iter-1000 train loss: 2.2638 valid loss: 2.2884, valid accuracy: 0.1250\n",
      "Iter-1100 train loss: 2.3023 valid loss: 2.2872, valid accuracy: 0.1282\n",
      "Iter-1200 train loss: 2.3043 valid loss: 2.2861, valid accuracy: 0.1316\n",
      "Iter-1300 train loss: 2.2869 valid loss: 2.2850, valid accuracy: 0.1340\n",
      "Iter-1400 train loss: 2.2808 valid loss: 2.2838, valid accuracy: 0.1352\n",
      "Iter-1500 train loss: 2.2908 valid loss: 2.2827, valid accuracy: 0.1384\n",
      "Iter-1600 train loss: 2.2608 valid loss: 2.2816, valid accuracy: 0.1420\n",
      "Iter-1700 train loss: 2.3084 valid loss: 2.2805, valid accuracy: 0.1432\n",
      "Iter-1800 train loss: 2.2728 valid loss: 2.2793, valid accuracy: 0.1450\n",
      "Iter-1900 train loss: 2.2727 valid loss: 2.2783, valid accuracy: 0.1484\n",
      "Iter-2000 train loss: 2.2687 valid loss: 2.2772, valid accuracy: 0.1496\n",
      "Iter-2100 train loss: 2.2488 valid loss: 2.2761, valid accuracy: 0.1522\n",
      "Iter-2200 train loss: 2.2938 valid loss: 2.2750, valid accuracy: 0.1556\n",
      "Iter-2300 train loss: 2.2786 valid loss: 2.2738, valid accuracy: 0.1594\n",
      "Iter-2400 train loss: 2.2830 valid loss: 2.2727, valid accuracy: 0.1628\n",
      "Iter-2500 train loss: 2.2784 valid loss: 2.2716, valid accuracy: 0.1664\n",
      "Iter-2600 train loss: 2.2646 valid loss: 2.2705, valid accuracy: 0.1696\n",
      "Iter-2700 train loss: 2.2764 valid loss: 2.2695, valid accuracy: 0.1724\n",
      "Iter-2800 train loss: 2.2769 valid loss: 2.2683, valid accuracy: 0.1766\n",
      "Iter-2900 train loss: 2.2600 valid loss: 2.2672, valid accuracy: 0.1804\n",
      "Iter-3000 train loss: 2.2942 valid loss: 2.2662, valid accuracy: 0.1832\n",
      "Iter-3100 train loss: 2.2913 valid loss: 2.2651, valid accuracy: 0.1866\n",
      "Iter-3200 train loss: 2.2663 valid loss: 2.2640, valid accuracy: 0.1896\n",
      "Iter-3300 train loss: 2.2612 valid loss: 2.2629, valid accuracy: 0.1926\n",
      "Iter-3400 train loss: 2.2498 valid loss: 2.2618, valid accuracy: 0.1956\n",
      "Iter-3500 train loss: 2.2579 valid loss: 2.2607, valid accuracy: 0.1976\n",
      "Iter-3600 train loss: 2.2512 valid loss: 2.2596, valid accuracy: 0.1990\n",
      "Iter-3700 train loss: 2.2815 valid loss: 2.2586, valid accuracy: 0.2010\n",
      "Iter-3800 train loss: 2.2103 valid loss: 2.2575, valid accuracy: 0.2032\n",
      "Iter-3900 train loss: 2.2495 valid loss: 2.2565, valid accuracy: 0.2054\n",
      "Iter-4000 train loss: 2.2460 valid loss: 2.2554, valid accuracy: 0.2072\n",
      "Iter-4100 train loss: 2.2531 valid loss: 2.2543, valid accuracy: 0.2100\n",
      "Iter-4200 train loss: 2.2720 valid loss: 2.2532, valid accuracy: 0.2130\n",
      "Iter-4300 train loss: 2.2738 valid loss: 2.2522, valid accuracy: 0.2154\n",
      "Iter-4400 train loss: 2.2576 valid loss: 2.2511, valid accuracy: 0.2182\n",
      "Iter-4500 train loss: 2.2277 valid loss: 2.2500, valid accuracy: 0.2226\n",
      "Iter-4600 train loss: 2.2370 valid loss: 2.2489, valid accuracy: 0.2242\n",
      "Iter-4700 train loss: 2.2265 valid loss: 2.2479, valid accuracy: 0.2246\n",
      "Iter-4800 train loss: 2.2111 valid loss: 2.2468, valid accuracy: 0.2276\n",
      "Iter-4900 train loss: 2.2395 valid loss: 2.2458, valid accuracy: 0.2304\n",
      "Iter-5000 train loss: 2.2236 valid loss: 2.2447, valid accuracy: 0.2336\n",
      "Iter-5100 train loss: 2.2244 valid loss: 2.2437, valid accuracy: 0.2354\n",
      "Iter-5200 train loss: 2.2698 valid loss: 2.2426, valid accuracy: 0.2382\n",
      "Iter-5300 train loss: 2.2473 valid loss: 2.2416, valid accuracy: 0.2406\n",
      "Iter-5400 train loss: 2.2516 valid loss: 2.2405, valid accuracy: 0.2422\n",
      "Iter-5500 train loss: 2.2387 valid loss: 2.2394, valid accuracy: 0.2440\n",
      "Iter-5600 train loss: 2.2235 valid loss: 2.2384, valid accuracy: 0.2460\n",
      "Iter-5700 train loss: 2.2501 valid loss: 2.2373, valid accuracy: 0.2468\n",
      "Iter-5800 train loss: 2.2233 valid loss: 2.2363, valid accuracy: 0.2482\n",
      "Iter-5900 train loss: 2.2443 valid loss: 2.2352, valid accuracy: 0.2504\n",
      "Iter-6000 train loss: 2.2187 valid loss: 2.2342, valid accuracy: 0.2524\n",
      "Iter-6100 train loss: 2.2292 valid loss: 2.2331, valid accuracy: 0.2542\n",
      "Iter-6200 train loss: 2.2629 valid loss: 2.2321, valid accuracy: 0.2566\n",
      "Iter-6300 train loss: 2.2398 valid loss: 2.2311, valid accuracy: 0.2592\n",
      "Iter-6400 train loss: 2.2126 valid loss: 2.2300, valid accuracy: 0.2616\n",
      "Iter-6500 train loss: 2.2265 valid loss: 2.2290, valid accuracy: 0.2636\n",
      "Iter-6600 train loss: 2.2143 valid loss: 2.2280, valid accuracy: 0.2654\n",
      "Iter-6700 train loss: 2.2048 valid loss: 2.2269, valid accuracy: 0.2680\n",
      "Iter-6800 train loss: 2.2378 valid loss: 2.2259, valid accuracy: 0.2690\n",
      "Iter-6900 train loss: 2.2607 valid loss: 2.2249, valid accuracy: 0.2702\n",
      "Iter-7000 train loss: 2.2086 valid loss: 2.2239, valid accuracy: 0.2712\n",
      "Iter-7100 train loss: 2.2256 valid loss: 2.2229, valid accuracy: 0.2732\n",
      "Iter-7200 train loss: 2.2130 valid loss: 2.2218, valid accuracy: 0.2752\n",
      "Iter-7300 train loss: 2.2400 valid loss: 2.2208, valid accuracy: 0.2764\n",
      "Iter-7400 train loss: 2.2293 valid loss: 2.2198, valid accuracy: 0.2774\n",
      "Iter-7500 train loss: 2.2215 valid loss: 2.2188, valid accuracy: 0.2796\n",
      "Iter-7600 train loss: 2.2249 valid loss: 2.2178, valid accuracy: 0.2808\n",
      "Iter-7700 train loss: 2.2329 valid loss: 2.2167, valid accuracy: 0.2826\n",
      "Iter-7800 train loss: 2.1654 valid loss: 2.2157, valid accuracy: 0.2844\n",
      "Iter-7900 train loss: 2.2067 valid loss: 2.2147, valid accuracy: 0.2870\n",
      "Iter-8000 train loss: 2.2432 valid loss: 2.2136, valid accuracy: 0.2882\n",
      "Iter-8100 train loss: 2.1824 valid loss: 2.2126, valid accuracy: 0.2896\n",
      "Iter-8200 train loss: 2.2252 valid loss: 2.2117, valid accuracy: 0.2916\n",
      "Iter-8300 train loss: 2.2191 valid loss: 2.2106, valid accuracy: 0.2936\n",
      "Iter-8400 train loss: 2.2328 valid loss: 2.2096, valid accuracy: 0.2940\n",
      "Iter-8500 train loss: 2.2200 valid loss: 2.2086, valid accuracy: 0.2948\n",
      "Iter-8600 train loss: 2.2297 valid loss: 2.2076, valid accuracy: 0.2956\n",
      "Iter-8700 train loss: 2.2355 valid loss: 2.2066, valid accuracy: 0.2968\n",
      "Iter-8800 train loss: 2.1893 valid loss: 2.2056, valid accuracy: 0.2962\n",
      "Iter-8900 train loss: 2.2119 valid loss: 2.2045, valid accuracy: 0.2974\n",
      "Iter-9000 train loss: 2.2015 valid loss: 2.2036, valid accuracy: 0.2988\n",
      "Iter-9100 train loss: 2.2168 valid loss: 2.2026, valid accuracy: 0.2998\n",
      "Iter-9200 train loss: 2.1720 valid loss: 2.2015, valid accuracy: 0.3014\n",
      "Iter-9300 train loss: 2.2326 valid loss: 2.2005, valid accuracy: 0.3020\n",
      "Iter-9400 train loss: 2.1904 valid loss: 2.1995, valid accuracy: 0.3020\n",
      "Iter-9500 train loss: 2.1806 valid loss: 2.1986, valid accuracy: 0.3032\n",
      "Iter-9600 train loss: 2.2014 valid loss: 2.1976, valid accuracy: 0.3044\n",
      "Iter-9700 train loss: 2.2374 valid loss: 2.1966, valid accuracy: 0.3052\n",
      "Iter-9800 train loss: 2.2128 valid loss: 2.1956, valid accuracy: 0.3056\n",
      "Iter-9900 train loss: 2.1778 valid loss: 2.1946, valid accuracy: 0.3056\n",
      "Iter-10000 train loss: 2.1871 valid loss: 2.1936, valid accuracy: 0.3058\n",
      "Last iteration - Test accuracy mean: 0.3129, std: 0.0000, loss: 2.1900\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "n_iter = 10000 # number of epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "mb_size = 50 # 2**10==1024 # width, timestep for sequential data or minibatch size\n",
    "print_after = 100 # n_iter//10 # print loss for train, valid, and test\n",
    "num_hidden_units = 32 # number of kernels/ filters in each layer\n",
    "num_input_units = X_train.shape[1] # noise added at the input lavel as input noise we can use dX or for more improvement\n",
    "num_output_units = y_train.max() + 1 # number of classes in this classification problem\n",
    "num_layers = 2 # depth \n",
    "\n",
    "# Build the model/NN and learn it: running session.\n",
    "nn = FFNN(C=num_output_units, D=num_input_units, H=num_hidden_units, L=num_layers)\n",
    "\n",
    "nn.sgd(train_set=(X_train, y_train), val_set=(X_val, y_val), mb_size=mb_size, alpha=alpha, \n",
    "           n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQRACEOEgCIIgBPD/dNULGaeF6U8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe926243048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(nn.losses['train'], label='Train loss')\n",
    "plt.plot(nn.losses['valid'], label='Valid loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCTcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe926243c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn.losses['valid_acc'], label='Valid accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
