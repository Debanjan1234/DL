{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "with open('data/text_data/japan.txt', 'r') as f:\n",
    "    txt = f.read()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    char_to_idx = {char: i for i, char in enumerate(set(txt))}\n",
    "    idx_to_char = {i: char for i, char in enumerate(set(txt))}\n",
    "    \n",
    "    X = [char_to_idx[x] for x in txt]\n",
    "    X = np.array(X)\n",
    "    y = [char_to_idx[x] for x in txt[1:]]\n",
    "    y.append(char_to_idx['.'])\n",
    "    y = np.array(y)\n",
    "    \n",
    "# # Data exploration\n",
    "# X.shape, y.shape, X, y, txt.split()[:2], \n",
    "# set(txt), \n",
    "# len(txt), len(set(txt)), set(txt)\n",
    "# # for val, key in enumerate(set(txt)):\n",
    "# #     print(val, key)\n",
    "# # val2char = {val: key for val, key in enumerate(set(txt))}\n",
    "# # val2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l\n",
    "\n",
    "class RNN:\n",
    "\n",
    "    def __init__(self, D, H, L, char2idx, idx2char, p_dropout):\n",
    "        self.D = D\n",
    "        self.H = H\n",
    "        self.L = L\n",
    "        self.char2idx = char2idx\n",
    "        self.idx2char = idx2char\n",
    "        self.vocab_size = len(char2idx)\n",
    "        self.losses = {'train':[], 'smooth train':[]}\n",
    "        self.p_dropout = p_dropout\n",
    "        \n",
    "        # Model parameters\n",
    "        m = dict(\n",
    "            Wxh=np.random.randn(D, H) / np.sqrt(D / 2.),\n",
    "            Whh=np.random.randn(H, H) / np.sqrt(H / 2.),\n",
    "            Why=np.random.randn(H, D) / np.sqrt(H / 2.),\n",
    "            bh=np.zeros((1, H)),\n",
    "            by=np.zeros((1, D))\n",
    "            )\n",
    "        self.model = []\n",
    "        for _ in range(self.L):\n",
    "            self.model.append(m)\n",
    "            \n",
    "    def initial_state(self):\n",
    "        return np.zeros((1, self.H))\n",
    "\n",
    "    def dropout_forward(self, X, p_dropout):\n",
    "        u = np.random.binomial(1, p_dropout, size=X.shape) / p_dropout\n",
    "        #         q = 1-p_dropout\n",
    "        #         u = np.random.binomial(1, q, size=X.shape)\n",
    "        out = X * u\n",
    "        cache = u\n",
    "        return out, cache\n",
    "\n",
    "    def dropout_backward(self, dout, cache):\n",
    "        dX = dout * cache\n",
    "        return dX\n",
    "    \n",
    "    def forward(self, X, h, m, train):\n",
    "        Wxh, Whh, Why = m['Wxh'], m['Whh'], m['Why']\n",
    "        bh, by = m['bh'], m['by']\n",
    "\n",
    "        hprev = h.copy()\n",
    "        X_one_hot = X.copy()\n",
    "    \n",
    "        X = (X_one_hot @ Wxh) + (hprev @ Whh) + bh\n",
    "        h, h_cache = l.tanh_forward(X)\n",
    "        \n",
    "        h += hprev # res connection\n",
    "        \n",
    "        y, y_cache = l.fc_forward(h, Why, by)\n",
    "\n",
    "        # Dropout for training\n",
    "        if train:\n",
    "            y, do_cache = self.dropout_forward(X=y, p_dropout=self.p_dropout)\n",
    "            cache = (X_one_hot, Wxh, hprev, Whh, h_cache, y_cache, do_cache)\n",
    "        else:\n",
    "            cache = (X_one_hot, Wxh, hprev, Whh, h_cache, y_cache)\n",
    "\n",
    "        return y, h, cache\n",
    "\n",
    "    def backward(self, dy, dh, cache, train):\n",
    "        if train:\n",
    "            X_one_hot, Wxh, hprev, Whh, h_cache, y_cache, do_cache = cache\n",
    "            dy = self.dropout_backward(dout=dy, cache=do_cache)\n",
    "        else:\n",
    "            X_one_hot, Wxh, hprev, Whh, h_cache, y_cache = cache\n",
    "\n",
    "        dh_next = dh.copy()\n",
    "        \n",
    "        dh, dWhy, dby = l.fc_backward(dy, y_cache)\n",
    "        dh += dh_next\n",
    "        dby = dby.reshape((1, -1))\n",
    "\n",
    "        dh_res = dh.copy() # residual gradient\n",
    "\n",
    "        dX_one_hot = l.tanh_backward(dh, h_cache)\n",
    "        dbh = dX_one_hot * 1.0\n",
    "        dWhh = hprev.T @ dX_one_hot\n",
    "        dWxh = X_one_hot.T @ dX_one_hot\n",
    "        \n",
    "        dX = dX_one_hot @ Wxh.T\n",
    "        dh = dX_one_hot @ Whh.T\n",
    "        \n",
    "        dh += dh_res # res connection\n",
    "\n",
    "        grad = dict(Wxh=dWxh, Whh=dWhh, Why=dWhy, bh=dbh, by=dby)\n",
    "        \n",
    "        return dX, dh, grad\n",
    "\n",
    "    def train_forward(self, X_train, h):\n",
    "        ys, caches = [], []\n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "            caches.append([])\n",
    "            \n",
    "        for X in X_train:\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], cache = self.forward(y, h[layer], self.model[layer], train=True)\n",
    "                caches[layer].append(cache)\n",
    "                \n",
    "            ys.append(y)\n",
    "            \n",
    "        return ys, caches\n",
    "\n",
    "    def cross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(prob[range(m), y_train])\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        grad_y = l.softmax(y_pred)\n",
    "        grad_y[range(m), y_train] -= 1.0\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "    \n",
    "    def loss_function(self, y_train, ys):\n",
    "        loss, dys = 0.0, []\n",
    "\n",
    "        for y_pred, y in zip(ys, y_train):\n",
    "            loss += self.cross_entropy(y_pred, y)\n",
    "            dy = self.dcross_entropy(y_pred, y)\n",
    "            dys.append(dy)\n",
    "            \n",
    "        return loss, dys\n",
    "\n",
    "    def train_backward(self, dys, caches):\n",
    "        dh, grad, grads = [], [], []\n",
    "        for layer in range(self.L):\n",
    "            dh.append(np.zeros((1, self.H)))\n",
    "            grad.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            grads.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            \n",
    "        for t in reversed(range(len(dys))):\n",
    "            dX = dys[t]\n",
    "            for layer in reversed(range(self.L)):\n",
    "                dX, dh[layer], grad[layer] = self.backward(dX, dh[layer], caches[layer][t], train=True)\n",
    "                for key in grad[layer].keys():\n",
    "                    grads[layer][key] += grad[layer][key]\n",
    "                \n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X_seed, h, size):\n",
    "        chars = [self.idx2char[X_seed]]\n",
    "        idx_list = list(range(self.vocab_size))\n",
    "        X = X_seed\n",
    "        \n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "\n",
    "        for _ in range(size):\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], _ = self.forward(y, h[layer], self.model[layer], train=False)\n",
    "                \n",
    "            prob = l.softmax(y)\n",
    "            idx = np.random.choice(idx_list, p=prob.ravel())\n",
    "            chars.append(self.idx2char[idx])\n",
    "            X = idx\n",
    "\n",
    "        return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "def get_minibatch(X, y, minibatch_size, shuffle):\n",
    "    minibatches = []\n",
    "\n",
    "    if shuffle:\n",
    "        X, y = skshuffle(X, y)\n",
    "\n",
    "    for i in range(0, X.shape[0], minibatch_size):\n",
    "    #     for i in range(0, X.shape[0] - minibatch_size + 1, 1):\n",
    "        X_mini = X[i:i + minibatch_size]\n",
    "        y_mini = y[i:i + minibatch_size]\n",
    "        minibatches.append((X_mini, y_mini))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "def adam_rnn(nn, X_train, y_train, alpha, mb_size, n_iter, print_after):\n",
    "    M, R = [], []\n",
    "    for layer in range(nn.L):\n",
    "        M.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        R.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        \n",
    "    beta1 = .99\n",
    "    beta2 = .999\n",
    "    state = nn.initial_state()\n",
    "    eps = 1e-8\n",
    "    smooth_loss = 1.0\n",
    "    minibatches = get_minibatch(X_train, y_train, mb_size, shuffle=False)\n",
    "\n",
    "    # Epochs\n",
    "    for iter in range(1, n_iter + 1):\n",
    "\n",
    "        # No full batch or files\n",
    "        # Minibatches\n",
    "        for idx in range(len(minibatches)):\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            ys, caches = nn.train_forward(X_mini, state)\n",
    "            loss, dys = nn.loss_function(y_mini, ys)\n",
    "            _, grads = nn.train_backward(dys, caches)\n",
    "            nn.losses['train'].append(loss)\n",
    "            smooth_loss = (0.999 * smooth_loss) + (0.001 * loss)\n",
    "            nn.losses['smooth train'].append(smooth_loss)\n",
    "\n",
    "            for layer in range(nn.L):\n",
    "                for key in grads[layer].keys(): #key, value: items\n",
    "                    M[layer][key] = l.exp_running_avg(M[layer][key], grads[layer][key], beta1)\n",
    "                    R[layer][key] = l.exp_running_avg(R[layer][key], grads[layer][key]**2, beta2)\n",
    "\n",
    "                    m_k_hat = M[layer][key] / (1. - (beta1**(iter)))\n",
    "                    r_k_hat = R[layer][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                    nn.model[layer][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + eps)\n",
    "    \n",
    "        # Print loss and test sample\n",
    "        if iter % print_after == 0:\n",
    "            print('Iter-{} loss: {:.4f}'.format(iter, loss))\n",
    "            sample = nn.test(X_mini[0], state, size=100)\n",
    "            print(sample)\n",
    "            \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-13 loss: 85.1513\n",
      "cTi.deddddddddddddddddddddddddddddddddddddddddd,,,,,,,,,,,,,,,,,UUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUU\n",
      "Iter-26 loss: 62.9943\n",
      "cCtEpapReep eeeeeeeeeeeeemhhhhmhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhehhhhe ehehhhh                         \n",
      "Iter-39 loss: 68.2293\n",
      "c5srEeeeleeeeoccmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
      "Iter-52 loss: 57.8742\n",
      "cEeGGui   o    uuuuuuuuu,huuhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "Iter-65 loss: 57.3846\n",
      "c6khapiJ ee p ppppp         uuuf111111f1fffffffffffffffffffffffffffffffffff1fff111f11111111f111111111\n",
      "Iter-78 loss: 56.6904\n",
      "c\n",
      "uuoml .u     hhhhJhhhhJhhhhhdhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "Iter-91 loss: 67.5418\n",
      "cG ohxaedea     e                             \"  2\"   \"9JJJ\"\"999\"9\"99999999999999999999999999RR99RRRR\n",
      "Iter-104 loss: 62.4195\n",
      "cK\n",
      "本本TyGGyGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGyGGGGGGGGyyGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG\n",
      "Iter-117 loss: 64.2072\n",
      "c dOCCsasaaaaaiaaaaaaaaaaaaaaaaama%.%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Iter-130 loss: 59.8097\n",
      "cfNrr.(i((w((((((((((((((((((((((((((((((((44((444(44444444444444444444444444444444444444444444444444\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8bcb24e2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "time_step = 10 # width, minibatch size and test sample size as well\n",
    "num_layers = 10 # depth\n",
    "n_iter = 130 # epochs\n",
    "alpha = 1e-4 # learning_rate\n",
    "p_dropout = 0.95 # q=1-p, q=keep_prob and p=dropout.\n",
    "print_after = n_iter//10 # print training loss, valid, and test\n",
    "num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "num_input_units = len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "\n",
    "# Build the network and learning it or optimizing it using SGD\n",
    "net = RNN(D=num_input_units, H=num_hidden_units, L=num_layers, char2idx=char_to_idx, idx2char=idx_to_char, \n",
    "          p_dropout=p_dropout)\n",
    "\n",
    "# Start learning using BP-SGD-ADAM\n",
    "adam_rnn(nn=net, X_train=X, y_train=y, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)\n",
    "\n",
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(net.losses['train'], label='Train loss')\n",
    "plt.plot(net.losses['smooth train'], label='Train smooth loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
