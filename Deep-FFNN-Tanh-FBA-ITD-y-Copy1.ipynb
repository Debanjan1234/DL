{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import impl.layer as l\n",
    "\n",
    "# Dataset preparation and pre-processing\n",
    "mnist = input_data.read_data_sets('data/MNIST_data/', one_hot=False)\n",
    "\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-processing: normalizing\n",
    "def normalize(X):\n",
    "    # max scale for images 255= 2**8= 8 bit grayscale for each channel\n",
    "    return (X - X.mean(axis=0)) #/ X.std(axis=0)\n",
    "\n",
    "X_train, X_val, X_test = normalize(X=X_train), normalize(X=X_val), normalize(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l # or from impl.layer import *\n",
    "from impl.loss import * # import all functions from impl.loss file # import impl.loss as loss_func\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "class FFNN:\n",
    "\n",
    "    def __init__(self, D, C, H, L):\n",
    "        self.L = L # layers\n",
    "        self.C = C # classes\n",
    "        self.losses = {'train':[], 'train_acc':[], \n",
    "                       'valid':[], 'valid_acc':[], \n",
    "                       'test':[], 'test_acc':[]}\n",
    "        \n",
    "        self.model = []\n",
    "        self.W_fixed = []\n",
    "        self.grads = []\n",
    "        self.dy_prev = np.zeros((1, C))\n",
    "        self.y_prev = np.zeros((1, C))\n",
    "        low, high = -1, 1\n",
    "        \n",
    "        # Input layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.), b=np.zeros((1, H)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Input layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[0].items()})\n",
    "\n",
    "        # Hidden layers: weights/ biases\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = dict(W=np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, H)))\n",
    "            m_L.append(m)\n",
    "        self.model.append(m_L)\n",
    "        # Fixed feedback weight\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.)\n",
    "            m_L.append(m)\n",
    "        self.W_fixed.append(m_L)\n",
    "        # Hidden layer: gradients\n",
    "        grad_L = []\n",
    "        for _ in range(L):\n",
    "            grad_L.append({key: np.zeros_like(val) for key, val in self.model[1][0].items()})\n",
    "        self.grads.append(grad_L)\n",
    "        \n",
    "        # Output layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, C)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Output layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[2].items()})\n",
    "        \n",
    "    def fc_forward(self, X, W, b):\n",
    "        out = (X @ W) + b\n",
    "        cache = (W, X)\n",
    "        return out, cache\n",
    "\n",
    "    def fc_backward(self, dout, cache, W_fixed):\n",
    "        W, X = cache\n",
    "\n",
    "        dW = X.T @ dout\n",
    "        db = np.sum(dout, axis=0).reshape(1, -1) # db_1xn\n",
    "        \n",
    "#         dX = dout @ W.T # vanilla Backprop\n",
    "        dX = dout @ W_fixed.T # fba backprop\n",
    "\n",
    "        return dX, dW, db\n",
    "\n",
    "    def train_forward(self, X, train):\n",
    "        caches, ys = [], []\n",
    "        \n",
    "        # Input layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[0]['W'], b=self.model[0]['b']) # X_1xD, y_1xc\n",
    "        y, nl_cache = l.tanh_forward(X=y)\n",
    "#         y, nl_cache = l.sigmoid_forward(X=y) # non-linearity/ activation\n",
    "#         y -= l.sigmoid(0.0) # zero-centered/ mean\n",
    "#         y *= 2.0 # uni-var/ std\n",
    "        if train:\n",
    "            caches.append((fc_cache, nl_cache))\n",
    "        X = y.copy() # pass to the next layer\n",
    "        \n",
    "        # Hidden layers\n",
    "        fc_caches, nl_caches = [], []\n",
    "        for layer in range(self.L):\n",
    "            y, fc_cache = self.fc_forward(X=X, W=self.model[1][layer]['W'], b=self.model[1][layer]['b'])\n",
    "            y, nl_cache = l.tanh_forward(X=y)\n",
    "#             y, nl_cache = l.sigmoid_forward(X=y) # non-linearity/ activation\n",
    "#             y -= l.sigmoid(0.0) # zero-centered/ mean\n",
    "#             y *= 2.0 # uni-var/ std\n",
    "            X = y.copy() # pass to next layer\n",
    "            if train:\n",
    "                fc_caches.append(fc_cache)\n",
    "                nl_caches.append(nl_cache)\n",
    "        if train:\n",
    "            caches.append((fc_caches, nl_caches)) # caches[1]            \n",
    "        \n",
    "        # Output layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[2]['W'], b=self.model[2]['b'])\n",
    "        y_prob = l.softmax(X=y)\n",
    "        if train:\n",
    "            caches.append(fc_cache)\n",
    "\n",
    "        return y_prob, caches # for backpropating the error\n",
    "\n",
    "    def cross_entropy(self, y_prob, y_train):\n",
    "        m = y_prob.shape[0]\n",
    "\n",
    "        #         prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(y_prob[range(m), y_train] + l.eps) # to avoid the devision by zero\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_prob, y_train): # this is equal for both since the reg_loss (noise) derivative is ZERO.\n",
    "        m = y_prob.shape[0]\n",
    "\n",
    "        #         grad_y = l.softmax(y_pred)\n",
    "        grad_y = y_prob\n",
    "        grad_y[range(m), y_train] -= 1.\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "\n",
    "    def loss_function(self, y_prob, y_train):\n",
    "        \n",
    "        loss = self.cross_entropy(y_prob, y_train) # softmax is included\n",
    "        dy = self.dcross_entropy(y_prob, y_train) # dsoftmax is included\n",
    "\n",
    "        return loss, dy\n",
    "        \n",
    "    def train_backward(self, dy, caches, y):\n",
    "        grads = self.grads.copy() # initialized by Zero in every iteration/epoch\n",
    "#         dy_prev = self.dy_prev.copy() # for temporal differencing\n",
    "#         self.dy_prev = dy.copy() # next iteration/ epoch\n",
    "        y_prev = self.y_prev.copy() # for temporal differencing\n",
    "        self.y_prev = y.copy() # next iteration/ epoch\n",
    "        \n",
    "        # Output layer\n",
    "        fc_cache = caches[2]\n",
    "        # softmax_backward is included in dcross_entropy.\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[2])\n",
    "        dy = dX.copy()\n",
    "# #         dy =  dy @ self.W_fixed[2].T # done\n",
    "#         dy_prev =  dy_prev @ self.W_fixed[2].T\n",
    "        y =  y @ self.W_fixed[2].T # done\n",
    "        y_prev =  y_prev @ self.W_fixed[2].T\n",
    "        grads[2]['W'] = dW\n",
    "        grads[2]['b'] = db\n",
    "\n",
    "        # Hidden layer\n",
    "        fc_caches, nl_caches = caches[1]\n",
    "        for layer in reversed(range(self.L)):\n",
    "#             dy = l.tanh_backward(cache=nl_caches[layer], dout=dy) # diffable function\n",
    "#             dy = l.sigmoid_backward(cache=nl_caches[layer], dout=dy) # diffable function\n",
    "#             dy *= dy - dy_prev # temporal diff instead of differentiable function\n",
    "            dy *= y - y_prev # temporal diff instead of differentiable function\n",
    "            dX, dW, db = self.fc_backward(dout=dy, cache=fc_caches[layer], W_fixed=self.W_fixed[1][layer])\n",
    "            dy = dX.copy()\n",
    "# #             dy =  dy @ self.W_fixed[2].T # done\n",
    "#             dy_prev =  dy_prev @ self.W_fixed[1][layer].T\n",
    "            y =  y @ self.W_fixed[1][layer].T # done\n",
    "            y_prev =  y_prev @ self.W_fixed[1][layer].T\n",
    "            grads[1][layer]['W'] = dW\n",
    "            grads[1][layer]['b'] = db\n",
    "        \n",
    "        # Input layer\n",
    "        fc_cache, nl_cache = caches[0]\n",
    "#         dy = l.tanh_backward(cache=nl_cache, dout=dy) # diffable function\n",
    "#         dy = l.sigmoid_backward(cache=nl_caches[layer], dout=dy) # diffable function\n",
    "#         dy *= dy - dy_prev # temporal diff instead of differentiable function\n",
    "        dy *= y - y_prev # temporal diff instead of differentiable function\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[0])\n",
    "        grads[0]['W'] = dW\n",
    "        grads[0]['b'] = db\n",
    "\n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X):\n",
    "        y_prob, _ = self.train_forward(X, train=False)\n",
    "        \n",
    "        # if self.mode == 'classification':\n",
    "        y_pred = np.argmax(y_prob, axis=1) # for loss ==err\n",
    "        \n",
    "        return y_pred, y_prob\n",
    "        \n",
    "    def get_minibatch(self, X, y, minibatch_size, shuffle):\n",
    "        minibatches = []\n",
    "\n",
    "        if shuffle:\n",
    "            X, y = skshuffle(X, y)\n",
    "\n",
    "        for i in range(0, X.shape[0], minibatch_size):\n",
    "            X_mini = X[i:i + minibatch_size]\n",
    "            y_mini = y[i:i + minibatch_size]\n",
    "            minibatches.append((X_mini, y_mini))\n",
    "\n",
    "        return minibatches\n",
    "\n",
    "    def sgd(self, train_set, val_set, alpha, mb_size, n_iter, print_after):\n",
    "        X_train, y_train = train_set\n",
    "        X_val, y_val = val_set\n",
    "\n",
    "        # Epochs\n",
    "        for iter in range(1, n_iter + 1):\n",
    "\n",
    "            # Minibatches\n",
    "            minibatches = self.get_minibatch(X_train, y_train, mb_size, shuffle=True)\n",
    "            idx = np.random.randint(0, len(minibatches))\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            \n",
    "            # Train the model\n",
    "            y_prob, caches = self.train_forward(X_mini, train=True)\n",
    "            _, dy = self.loss_function(y_prob, y_mini)\n",
    "            _, grads = self.train_backward(dy, caches, y_prob)\n",
    "            \n",
    "            # Update the model for input layer\n",
    "            for key in grads[0].keys():\n",
    "                self.model[0][key] -= alpha * grads[0][key]\n",
    "\n",
    "            # Update the model for the hidden layers\n",
    "            for layer in range(self.L):\n",
    "                for key in grads[1][layer].keys():\n",
    "                    self.model[1][layer][key] -= alpha * grads[1][layer][key]\n",
    "\n",
    "            # Update the model for output layer\n",
    "            for key in grads[2].keys():\n",
    "                self.model[2][key] -= alpha * grads[2][key]\n",
    "            \n",
    "            # Training accuracy\n",
    "            y_pred, y_prob = self.test(X_mini)\n",
    "            loss, _ = self.loss_function(y_prob, y_mini) # softmax is included in entropy loss function\n",
    "            self.losses['train'].append(loss)\n",
    "            acc = np.mean(y_pred == y_mini) # confusion matrix\n",
    "            self.losses['train_acc'].append(acc)\n",
    "\n",
    "            # Validate the updated model\n",
    "            y_pred, y_prob = self.test(X_val)\n",
    "            valid_loss, _ = self.loss_function(y_prob, y_val) # softmax is included in entropy loss function\n",
    "            self.losses['valid'].append(valid_loss)\n",
    "            valid_acc = np.mean(y_pred == y_val) # confusion matrix\n",
    "            self.losses['valid_acc'].append(valid_acc)\n",
    "            \n",
    "            # Test the final model\n",
    "            y_pred, y_prob = nn.test(X_test)\n",
    "            test_loss, _ = self.loss_function(y_prob, y_test) # softmax is included in entropy loss function\n",
    "            self.losses['test'].append(test_loss)\n",
    "            test_acc = np.mean(y_pred == y_test)\n",
    "            self.losses['test_acc'].append(test_acc)\n",
    "#             print('Test accuracy mean: {:.4f}, std: {:.4f}, loss: {:.4f}'.\n",
    "#             format(acc.mean(), acc.std(), loss))\n",
    "            \n",
    "            # Print the model info: loss & accuracy or err & acc\n",
    "            if iter % print_after == 0:\n",
    "                print('Iter-{}, train loss-{:.4f}, acc-{:.4f}, valid loss-{:.4f}, acc-{:.4f}, test loss-{:.4f}, acc-{:.4f}'.format(\n",
    "                   iter, loss, acc, valid_loss, valid_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-10, train loss-2.2982, acc-0.1200, valid loss-2.2982, acc-0.1064, test loss-2.3020, acc-0.1102\n",
      "Iter-20, train loss-2.2774, acc-0.1400, valid loss-2.2981, acc-0.1066, test loss-2.3019, acc-0.1100\n",
      "Iter-30, train loss-2.2796, acc-0.1000, valid loss-2.2981, acc-0.1062, test loss-2.3018, acc-0.1100\n",
      "Iter-40, train loss-2.3075, acc-0.0800, valid loss-2.2980, acc-0.1060, test loss-2.3017, acc-0.1103\n",
      "Iter-50, train loss-2.2879, acc-0.1400, valid loss-2.2979, acc-0.1064, test loss-2.3016, acc-0.1101\n",
      "Iter-60, train loss-2.3075, acc-0.1800, valid loss-2.2978, acc-0.1064, test loss-2.3015, acc-0.1103\n",
      "Iter-70, train loss-2.2745, acc-0.1800, valid loss-2.2977, acc-0.1064, test loss-2.3014, acc-0.1108\n",
      "Iter-80, train loss-2.3075, acc-0.1000, valid loss-2.2976, acc-0.1062, test loss-2.3013, acc-0.1109\n",
      "Iter-90, train loss-2.3128, acc-0.1200, valid loss-2.2975, acc-0.1062, test loss-2.3012, acc-0.1108\n",
      "Iter-100, train loss-2.3038, acc-0.1200, valid loss-2.2974, acc-0.1062, test loss-2.3011, acc-0.1111\n",
      "Iter-110, train loss-2.3114, acc-0.0800, valid loss-2.2973, acc-0.1066, test loss-2.3010, acc-0.1110\n",
      "Iter-120, train loss-2.2868, acc-0.1400, valid loss-2.2973, acc-0.1068, test loss-2.3009, acc-0.1113\n",
      "Iter-130, train loss-2.3094, acc-0.1400, valid loss-2.2972, acc-0.1072, test loss-2.3008, acc-0.1117\n",
      "Iter-140, train loss-2.2894, acc-0.1200, valid loss-2.2971, acc-0.1078, test loss-2.3007, acc-0.1119\n",
      "Iter-150, train loss-2.3082, acc-0.1800, valid loss-2.2970, acc-0.1078, test loss-2.3006, acc-0.1120\n",
      "Iter-160, train loss-2.2778, acc-0.1200, valid loss-2.2969, acc-0.1080, test loss-2.3005, acc-0.1123\n",
      "Iter-170, train loss-2.3057, acc-0.1000, valid loss-2.2968, acc-0.1080, test loss-2.3005, acc-0.1123\n",
      "Iter-180, train loss-2.3096, acc-0.1600, valid loss-2.2967, acc-0.1078, test loss-2.3004, acc-0.1123\n",
      "Iter-190, train loss-2.3055, acc-0.0800, valid loss-2.2966, acc-0.1082, test loss-2.3003, acc-0.1124\n",
      "Iter-200, train loss-2.3152, acc-0.1200, valid loss-2.2965, acc-0.1076, test loss-2.3002, acc-0.1124\n",
      "Iter-210, train loss-2.2966, acc-0.1000, valid loss-2.2965, acc-0.1078, test loss-2.3001, acc-0.1125\n",
      "Iter-220, train loss-2.2935, acc-0.1800, valid loss-2.2964, acc-0.1078, test loss-2.3000, acc-0.1126\n",
      "Iter-230, train loss-2.3209, acc-0.1000, valid loss-2.2963, acc-0.1078, test loss-2.2999, acc-0.1127\n",
      "Iter-240, train loss-2.2911, acc-0.1600, valid loss-2.2962, acc-0.1080, test loss-2.2998, acc-0.1127\n",
      "Iter-250, train loss-2.3038, acc-0.0800, valid loss-2.2961, acc-0.1072, test loss-2.2997, acc-0.1127\n",
      "Iter-260, train loss-2.2774, acc-0.2200, valid loss-2.2960, acc-0.1080, test loss-2.2996, acc-0.1130\n",
      "Iter-270, train loss-2.2892, acc-0.1600, valid loss-2.2959, acc-0.1082, test loss-2.2995, acc-0.1134\n",
      "Iter-280, train loss-2.2766, acc-0.1000, valid loss-2.2959, acc-0.1082, test loss-2.2994, acc-0.1134\n",
      "Iter-290, train loss-2.2854, acc-0.1400, valid loss-2.2958, acc-0.1086, test loss-2.2993, acc-0.1136\n",
      "Iter-300, train loss-2.2830, acc-0.1400, valid loss-2.2957, acc-0.1084, test loss-2.2992, acc-0.1137\n",
      "Iter-310, train loss-2.3026, acc-0.1600, valid loss-2.2956, acc-0.1092, test loss-2.2991, acc-0.1139\n",
      "Iter-320, train loss-2.3110, acc-0.0600, valid loss-2.2955, acc-0.1090, test loss-2.2990, acc-0.1132\n",
      "Iter-330, train loss-2.2973, acc-0.1400, valid loss-2.2954, acc-0.1090, test loss-2.2989, acc-0.1135\n",
      "Iter-340, train loss-2.3007, acc-0.1600, valid loss-2.2953, acc-0.1092, test loss-2.2988, acc-0.1135\n",
      "Iter-350, train loss-2.3095, acc-0.0600, valid loss-2.2953, acc-0.1088, test loss-2.2987, acc-0.1136\n",
      "Iter-360, train loss-2.3037, acc-0.1000, valid loss-2.2952, acc-0.1090, test loss-2.2987, acc-0.1137\n",
      "Iter-370, train loss-2.2869, acc-0.1600, valid loss-2.2951, acc-0.1094, test loss-2.2986, acc-0.1137\n",
      "Iter-380, train loss-2.3137, acc-0.0800, valid loss-2.2950, acc-0.1092, test loss-2.2985, acc-0.1138\n",
      "Iter-390, train loss-2.3156, acc-0.0400, valid loss-2.2949, acc-0.1092, test loss-2.2984, acc-0.1140\n",
      "Iter-400, train loss-2.2836, acc-0.1400, valid loss-2.2948, acc-0.1094, test loss-2.2983, acc-0.1141\n",
      "Iter-410, train loss-2.3117, acc-0.1000, valid loss-2.2947, acc-0.1094, test loss-2.2981, acc-0.1143\n",
      "Iter-420, train loss-2.3035, acc-0.1000, valid loss-2.2946, acc-0.1100, test loss-2.2981, acc-0.1145\n",
      "Iter-430, train loss-2.2891, acc-0.1200, valid loss-2.2945, acc-0.1100, test loss-2.2980, acc-0.1144\n",
      "Iter-440, train loss-2.3033, acc-0.1600, valid loss-2.2944, acc-0.1104, test loss-2.2979, acc-0.1145\n",
      "Iter-450, train loss-2.2889, acc-0.2200, valid loss-2.2944, acc-0.1106, test loss-2.2978, acc-0.1145\n",
      "Iter-460, train loss-2.2949, acc-0.1000, valid loss-2.2943, acc-0.1108, test loss-2.2977, acc-0.1149\n",
      "Iter-470, train loss-2.3109, acc-0.0800, valid loss-2.2942, acc-0.1108, test loss-2.2976, acc-0.1149\n",
      "Iter-480, train loss-2.2947, acc-0.1400, valid loss-2.2941, acc-0.1110, test loss-2.2975, acc-0.1150\n",
      "Iter-490, train loss-2.2976, acc-0.1000, valid loss-2.2940, acc-0.1110, test loss-2.2974, acc-0.1152\n",
      "Iter-500, train loss-2.3145, acc-0.0200, valid loss-2.2939, acc-0.1112, test loss-2.2973, acc-0.1153\n",
      "Iter-510, train loss-2.3080, acc-0.1600, valid loss-2.2938, acc-0.1118, test loss-2.2972, acc-0.1154\n",
      "Iter-520, train loss-2.2793, acc-0.1400, valid loss-2.2937, acc-0.1118, test loss-2.2971, acc-0.1156\n",
      "Iter-530, train loss-2.3086, acc-0.1000, valid loss-2.2937, acc-0.1114, test loss-2.2970, acc-0.1157\n",
      "Iter-540, train loss-2.3156, acc-0.1000, valid loss-2.2936, acc-0.1116, test loss-2.2969, acc-0.1163\n",
      "Iter-550, train loss-2.2841, acc-0.1400, valid loss-2.2935, acc-0.1118, test loss-2.2968, acc-0.1169\n",
      "Iter-560, train loss-2.2903, acc-0.1000, valid loss-2.2934, acc-0.1122, test loss-2.2967, acc-0.1168\n",
      "Iter-570, train loss-2.2977, acc-0.1000, valid loss-2.2933, acc-0.1122, test loss-2.2966, acc-0.1168\n",
      "Iter-580, train loss-2.2733, acc-0.1600, valid loss-2.2932, acc-0.1124, test loss-2.2965, acc-0.1168\n",
      "Iter-590, train loss-2.3082, acc-0.0200, valid loss-2.2931, acc-0.1126, test loss-2.2964, acc-0.1169\n",
      "Iter-600, train loss-2.2937, acc-0.1000, valid loss-2.2930, acc-0.1128, test loss-2.2963, acc-0.1167\n",
      "Iter-610, train loss-2.2793, acc-0.1000, valid loss-2.2929, acc-0.1124, test loss-2.2962, acc-0.1171\n",
      "Iter-620, train loss-2.3356, acc-0.0600, valid loss-2.2929, acc-0.1128, test loss-2.2961, acc-0.1170\n",
      "Iter-630, train loss-2.2948, acc-0.1000, valid loss-2.2928, acc-0.1130, test loss-2.2960, acc-0.1171\n",
      "Iter-640, train loss-2.2881, acc-0.2000, valid loss-2.2927, acc-0.1132, test loss-2.2959, acc-0.1176\n",
      "Iter-650, train loss-2.2983, acc-0.1400, valid loss-2.2926, acc-0.1134, test loss-2.2958, acc-0.1180\n",
      "Iter-660, train loss-2.3121, acc-0.1600, valid loss-2.2925, acc-0.1138, test loss-2.2957, acc-0.1180\n",
      "Iter-670, train loss-2.3107, acc-0.0800, valid loss-2.2924, acc-0.1138, test loss-2.2957, acc-0.1179\n",
      "Iter-680, train loss-2.2802, acc-0.1600, valid loss-2.2923, acc-0.1140, test loss-2.2956, acc-0.1179\n",
      "Iter-690, train loss-2.2960, acc-0.1800, valid loss-2.2922, acc-0.1138, test loss-2.2955, acc-0.1184\n",
      "Iter-700, train loss-2.2889, acc-0.1000, valid loss-2.2922, acc-0.1142, test loss-2.2954, acc-0.1185\n",
      "Iter-710, train loss-2.2947, acc-0.1000, valid loss-2.2921, acc-0.1144, test loss-2.2953, acc-0.1188\n",
      "Iter-720, train loss-2.2875, acc-0.1200, valid loss-2.2920, acc-0.1142, test loss-2.2952, acc-0.1195\n",
      "Iter-730, train loss-2.3063, acc-0.0800, valid loss-2.2919, acc-0.1144, test loss-2.2951, acc-0.1194\n",
      "Iter-740, train loss-2.3061, acc-0.1400, valid loss-2.2918, acc-0.1146, test loss-2.2950, acc-0.1195\n",
      "Iter-750, train loss-2.3153, acc-0.0600, valid loss-2.2917, acc-0.1148, test loss-2.2949, acc-0.1198\n",
      "Iter-760, train loss-2.2648, acc-0.2200, valid loss-2.2917, acc-0.1148, test loss-2.2948, acc-0.1194\n",
      "Iter-770, train loss-2.3211, acc-0.0800, valid loss-2.2916, acc-0.1150, test loss-2.2947, acc-0.1194\n",
      "Iter-780, train loss-2.2871, acc-0.1600, valid loss-2.2915, acc-0.1156, test loss-2.2946, acc-0.1194\n",
      "Iter-790, train loss-2.2898, acc-0.2200, valid loss-2.2914, acc-0.1154, test loss-2.2945, acc-0.1195\n",
      "Iter-800, train loss-2.2966, acc-0.1600, valid loss-2.2913, acc-0.1154, test loss-2.2944, acc-0.1198\n",
      "Iter-810, train loss-2.2725, acc-0.1000, valid loss-2.2912, acc-0.1160, test loss-2.2943, acc-0.1201\n",
      "Iter-820, train loss-2.2784, acc-0.2000, valid loss-2.2911, acc-0.1162, test loss-2.2942, acc-0.1201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-830, train loss-2.2956, acc-0.1000, valid loss-2.2910, acc-0.1164, test loss-2.2941, acc-0.1204\n",
      "Iter-840, train loss-2.2942, acc-0.1000, valid loss-2.2910, acc-0.1172, test loss-2.2940, acc-0.1207\n",
      "Iter-850, train loss-2.2835, acc-0.1400, valid loss-2.2909, acc-0.1170, test loss-2.2939, acc-0.1206\n",
      "Iter-860, train loss-2.2704, acc-0.1600, valid loss-2.2908, acc-0.1168, test loss-2.2938, acc-0.1206\n",
      "Iter-870, train loss-2.2868, acc-0.2000, valid loss-2.2907, acc-0.1172, test loss-2.2937, acc-0.1208\n",
      "Iter-880, train loss-2.3125, acc-0.1000, valid loss-2.2906, acc-0.1174, test loss-2.2937, acc-0.1211\n",
      "Iter-890, train loss-2.2918, acc-0.1200, valid loss-2.2905, acc-0.1180, test loss-2.2936, acc-0.1211\n",
      "Iter-900, train loss-2.3059, acc-0.1200, valid loss-2.2904, acc-0.1176, test loss-2.2935, acc-0.1212\n",
      "Iter-910, train loss-2.2753, acc-0.2000, valid loss-2.2904, acc-0.1176, test loss-2.2934, acc-0.1212\n",
      "Iter-920, train loss-2.3018, acc-0.0800, valid loss-2.2903, acc-0.1176, test loss-2.2933, acc-0.1213\n",
      "Iter-930, train loss-2.2954, acc-0.1000, valid loss-2.2902, acc-0.1176, test loss-2.2932, acc-0.1212\n",
      "Iter-940, train loss-2.2964, acc-0.1400, valid loss-2.2901, acc-0.1180, test loss-2.2931, acc-0.1214\n",
      "Iter-950, train loss-2.3020, acc-0.0800, valid loss-2.2900, acc-0.1178, test loss-2.2930, acc-0.1214\n",
      "Iter-960, train loss-2.2922, acc-0.1400, valid loss-2.2899, acc-0.1182, test loss-2.2929, acc-0.1215\n",
      "Iter-970, train loss-2.2985, acc-0.1000, valid loss-2.2898, acc-0.1178, test loss-2.2928, acc-0.1216\n",
      "Iter-980, train loss-2.2910, acc-0.1200, valid loss-2.2897, acc-0.1182, test loss-2.2927, acc-0.1215\n",
      "Iter-990, train loss-2.3197, acc-0.0200, valid loss-2.2897, acc-0.1184, test loss-2.2926, acc-0.1214\n",
      "Iter-1000, train loss-2.2741, acc-0.1200, valid loss-2.2896, acc-0.1184, test loss-2.2925, acc-0.1219\n",
      "Iter-1010, train loss-2.2785, acc-0.2200, valid loss-2.2895, acc-0.1186, test loss-2.2924, acc-0.1219\n",
      "Iter-1020, train loss-2.2802, acc-0.1400, valid loss-2.2894, acc-0.1188, test loss-2.2923, acc-0.1221\n",
      "Iter-1030, train loss-2.3144, acc-0.0400, valid loss-2.2893, acc-0.1188, test loss-2.2922, acc-0.1221\n",
      "Iter-1040, train loss-2.3369, acc-0.0800, valid loss-2.2892, acc-0.1192, test loss-2.2921, acc-0.1224\n",
      "Iter-1050, train loss-2.2749, acc-0.1200, valid loss-2.2891, acc-0.1194, test loss-2.2920, acc-0.1228\n",
      "Iter-1060, train loss-2.3084, acc-0.1200, valid loss-2.2891, acc-0.1196, test loss-2.2919, acc-0.1229\n",
      "Iter-1070, train loss-2.2969, acc-0.1200, valid loss-2.2890, acc-0.1198, test loss-2.2918, acc-0.1231\n",
      "Iter-1080, train loss-2.3126, acc-0.0600, valid loss-2.2889, acc-0.1200, test loss-2.2917, acc-0.1233\n",
      "Iter-1090, train loss-2.3021, acc-0.1200, valid loss-2.2888, acc-0.1198, test loss-2.2917, acc-0.1233\n",
      "Iter-1100, train loss-2.2942, acc-0.0800, valid loss-2.2887, acc-0.1198, test loss-2.2916, acc-0.1237\n",
      "Iter-1110, train loss-2.2866, acc-0.1600, valid loss-2.2886, acc-0.1204, test loss-2.2915, acc-0.1241\n",
      "Iter-1120, train loss-2.2672, acc-0.1600, valid loss-2.2885, acc-0.1206, test loss-2.2914, acc-0.1242\n",
      "Iter-1130, train loss-2.2817, acc-0.1400, valid loss-2.2884, acc-0.1208, test loss-2.2913, acc-0.1243\n",
      "Iter-1140, train loss-2.2857, acc-0.0600, valid loss-2.2884, acc-0.1206, test loss-2.2912, acc-0.1243\n",
      "Iter-1150, train loss-2.2978, acc-0.0800, valid loss-2.2883, acc-0.1212, test loss-2.2911, acc-0.1243\n",
      "Iter-1160, train loss-2.3163, acc-0.1000, valid loss-2.2882, acc-0.1216, test loss-2.2910, acc-0.1247\n",
      "Iter-1170, train loss-2.2920, acc-0.1400, valid loss-2.2881, acc-0.1216, test loss-2.2909, acc-0.1247\n",
      "Iter-1180, train loss-2.2964, acc-0.1000, valid loss-2.2880, acc-0.1220, test loss-2.2908, acc-0.1249\n",
      "Iter-1190, train loss-2.2941, acc-0.1600, valid loss-2.2879, acc-0.1218, test loss-2.2907, acc-0.1250\n",
      "Iter-1200, train loss-2.3251, acc-0.0200, valid loss-2.2878, acc-0.1220, test loss-2.2906, acc-0.1251\n",
      "Iter-1210, train loss-2.2978, acc-0.0800, valid loss-2.2878, acc-0.1222, test loss-2.2905, acc-0.1250\n",
      "Iter-1220, train loss-2.2868, acc-0.1000, valid loss-2.2877, acc-0.1222, test loss-2.2904, acc-0.1252\n",
      "Iter-1230, train loss-2.3161, acc-0.0600, valid loss-2.2876, acc-0.1222, test loss-2.2903, acc-0.1252\n",
      "Iter-1240, train loss-2.2745, acc-0.1600, valid loss-2.2875, acc-0.1224, test loss-2.2902, acc-0.1254\n",
      "Iter-1250, train loss-2.2584, acc-0.1200, valid loss-2.2874, acc-0.1224, test loss-2.2902, acc-0.1255\n",
      "Iter-1260, train loss-2.2940, acc-0.1600, valid loss-2.2873, acc-0.1226, test loss-2.2901, acc-0.1258\n",
      "Iter-1270, train loss-2.2801, acc-0.1600, valid loss-2.2872, acc-0.1228, test loss-2.2900, acc-0.1258\n",
      "Iter-1280, train loss-2.2688, acc-0.1600, valid loss-2.2871, acc-0.1234, test loss-2.2899, acc-0.1258\n",
      "Iter-1290, train loss-2.2660, acc-0.2200, valid loss-2.2871, acc-0.1234, test loss-2.2898, acc-0.1259\n",
      "Iter-1300, train loss-2.2674, acc-0.2000, valid loss-2.2870, acc-0.1234, test loss-2.2897, acc-0.1260\n",
      "Iter-1310, train loss-2.2980, acc-0.0800, valid loss-2.2869, acc-0.1238, test loss-2.2896, acc-0.1266\n",
      "Iter-1320, train loss-2.2819, acc-0.2200, valid loss-2.2868, acc-0.1238, test loss-2.2895, acc-0.1268\n",
      "Iter-1330, train loss-2.2857, acc-0.1400, valid loss-2.2867, acc-0.1240, test loss-2.2894, acc-0.1269\n",
      "Iter-1340, train loss-2.3018, acc-0.1000, valid loss-2.2866, acc-0.1240, test loss-2.2893, acc-0.1271\n",
      "Iter-1350, train loss-2.2902, acc-0.1800, valid loss-2.2866, acc-0.1240, test loss-2.2892, acc-0.1273\n",
      "Iter-1360, train loss-2.2882, acc-0.1800, valid loss-2.2865, acc-0.1240, test loss-2.2891, acc-0.1272\n",
      "Iter-1370, train loss-2.2968, acc-0.1600, valid loss-2.2864, acc-0.1240, test loss-2.2890, acc-0.1276\n",
      "Iter-1380, train loss-2.2830, acc-0.1400, valid loss-2.2863, acc-0.1244, test loss-2.2889, acc-0.1275\n",
      "Iter-1390, train loss-2.2839, acc-0.0800, valid loss-2.2862, acc-0.1244, test loss-2.2888, acc-0.1275\n",
      "Iter-1400, train loss-2.2918, acc-0.0800, valid loss-2.2861, acc-0.1250, test loss-2.2888, acc-0.1279\n",
      "Iter-1410, train loss-2.2838, acc-0.1600, valid loss-2.2861, acc-0.1250, test loss-2.2887, acc-0.1282\n",
      "Iter-1420, train loss-2.2783, acc-0.1600, valid loss-2.2860, acc-0.1256, test loss-2.2886, acc-0.1283\n",
      "Iter-1430, train loss-2.2890, acc-0.0400, valid loss-2.2859, acc-0.1256, test loss-2.2885, acc-0.1283\n",
      "Iter-1440, train loss-2.2816, acc-0.0800, valid loss-2.2858, acc-0.1260, test loss-2.2884, acc-0.1287\n",
      "Iter-1450, train loss-2.2941, acc-0.1800, valid loss-2.2857, acc-0.1264, test loss-2.2883, acc-0.1287\n",
      "Iter-1460, train loss-2.2793, acc-0.1000, valid loss-2.2856, acc-0.1268, test loss-2.2882, acc-0.1290\n",
      "Iter-1470, train loss-2.3085, acc-0.1400, valid loss-2.2855, acc-0.1264, test loss-2.2881, acc-0.1292\n",
      "Iter-1480, train loss-2.2822, acc-0.1200, valid loss-2.2854, acc-0.1264, test loss-2.2880, acc-0.1293\n",
      "Iter-1490, train loss-2.2828, acc-0.1400, valid loss-2.2854, acc-0.1266, test loss-2.2879, acc-0.1296\n",
      "Iter-1500, train loss-2.2893, acc-0.2200, valid loss-2.2853, acc-0.1266, test loss-2.2878, acc-0.1296\n",
      "Iter-1510, train loss-2.2949, acc-0.1000, valid loss-2.2852, acc-0.1264, test loss-2.2877, acc-0.1295\n",
      "Iter-1520, train loss-2.2781, acc-0.1400, valid loss-2.2851, acc-0.1266, test loss-2.2876, acc-0.1299\n",
      "Iter-1530, train loss-2.2927, acc-0.1000, valid loss-2.2850, acc-0.1272, test loss-2.2875, acc-0.1300\n",
      "Iter-1540, train loss-2.2868, acc-0.1200, valid loss-2.2849, acc-0.1274, test loss-2.2874, acc-0.1300\n",
      "Iter-1550, train loss-2.2933, acc-0.1200, valid loss-2.2848, acc-0.1270, test loss-2.2873, acc-0.1301\n",
      "Iter-1560, train loss-2.2956, acc-0.1000, valid loss-2.2848, acc-0.1270, test loss-2.2872, acc-0.1303\n",
      "Iter-1570, train loss-2.2909, acc-0.1600, valid loss-2.2847, acc-0.1270, test loss-2.2871, acc-0.1303\n",
      "Iter-1580, train loss-2.2896, acc-0.1000, valid loss-2.2846, acc-0.1272, test loss-2.2871, acc-0.1303\n",
      "Iter-1590, train loss-2.3066, acc-0.0600, valid loss-2.2845, acc-0.1276, test loss-2.2870, acc-0.1304\n",
      "Iter-1600, train loss-2.2835, acc-0.2000, valid loss-2.2844, acc-0.1278, test loss-2.2869, acc-0.1304\n",
      "Iter-1610, train loss-2.3022, acc-0.0800, valid loss-2.2843, acc-0.1276, test loss-2.2868, acc-0.1305\n",
      "Iter-1620, train loss-2.2903, acc-0.0800, valid loss-2.2843, acc-0.1278, test loss-2.2867, acc-0.1305\n",
      "Iter-1630, train loss-2.2687, acc-0.2000, valid loss-2.2842, acc-0.1278, test loss-2.2866, acc-0.1303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1640, train loss-2.3068, acc-0.1400, valid loss-2.2841, acc-0.1280, test loss-2.2865, acc-0.1303\n",
      "Iter-1650, train loss-2.2668, acc-0.2200, valid loss-2.2840, acc-0.1278, test loss-2.2864, acc-0.1307\n",
      "Iter-1660, train loss-2.2876, acc-0.1400, valid loss-2.2839, acc-0.1280, test loss-2.2863, acc-0.1310\n",
      "Iter-1670, train loss-2.3023, acc-0.1800, valid loss-2.2838, acc-0.1282, test loss-2.2862, acc-0.1310\n",
      "Iter-1680, train loss-2.2896, acc-0.1400, valid loss-2.2837, acc-0.1280, test loss-2.2861, acc-0.1311\n",
      "Iter-1690, train loss-2.2816, acc-0.1200, valid loss-2.2837, acc-0.1288, test loss-2.2860, acc-0.1310\n",
      "Iter-1700, train loss-2.2822, acc-0.1800, valid loss-2.2836, acc-0.1288, test loss-2.2859, acc-0.1310\n",
      "Iter-1710, train loss-2.2700, acc-0.1400, valid loss-2.2835, acc-0.1288, test loss-2.2858, acc-0.1310\n",
      "Iter-1720, train loss-2.2979, acc-0.1000, valid loss-2.2834, acc-0.1288, test loss-2.2857, acc-0.1311\n",
      "Iter-1730, train loss-2.2682, acc-0.1800, valid loss-2.2833, acc-0.1292, test loss-2.2856, acc-0.1313\n",
      "Iter-1740, train loss-2.2944, acc-0.1600, valid loss-2.2832, acc-0.1292, test loss-2.2855, acc-0.1315\n",
      "Iter-1750, train loss-2.2970, acc-0.0600, valid loss-2.2831, acc-0.1292, test loss-2.2855, acc-0.1317\n",
      "Iter-1760, train loss-2.2874, acc-0.1800, valid loss-2.2831, acc-0.1294, test loss-2.2854, acc-0.1319\n",
      "Iter-1770, train loss-2.2829, acc-0.1800, valid loss-2.2830, acc-0.1292, test loss-2.2853, acc-0.1319\n",
      "Iter-1780, train loss-2.2815, acc-0.1800, valid loss-2.2829, acc-0.1290, test loss-2.2852, acc-0.1319\n",
      "Iter-1790, train loss-2.2736, acc-0.1200, valid loss-2.2828, acc-0.1292, test loss-2.2851, acc-0.1318\n",
      "Iter-1800, train loss-2.2875, acc-0.0800, valid loss-2.2827, acc-0.1290, test loss-2.2850, acc-0.1319\n",
      "Iter-1810, train loss-2.2847, acc-0.1000, valid loss-2.2826, acc-0.1296, test loss-2.2849, acc-0.1321\n",
      "Iter-1820, train loss-2.2855, acc-0.1400, valid loss-2.2825, acc-0.1294, test loss-2.2848, acc-0.1324\n",
      "Iter-1830, train loss-2.2691, acc-0.2200, valid loss-2.2824, acc-0.1298, test loss-2.2847, acc-0.1326\n",
      "Iter-1840, train loss-2.2960, acc-0.1000, valid loss-2.2824, acc-0.1296, test loss-2.2846, acc-0.1330\n",
      "Iter-1850, train loss-2.2894, acc-0.0800, valid loss-2.2823, acc-0.1302, test loss-2.2845, acc-0.1331\n",
      "Iter-1860, train loss-2.2792, acc-0.1000, valid loss-2.2822, acc-0.1300, test loss-2.2844, acc-0.1330\n",
      "Iter-1870, train loss-2.2921, acc-0.0600, valid loss-2.2821, acc-0.1298, test loss-2.2843, acc-0.1332\n",
      "Iter-1880, train loss-2.2827, acc-0.1000, valid loss-2.2820, acc-0.1300, test loss-2.2842, acc-0.1331\n",
      "Iter-1890, train loss-2.2746, acc-0.1800, valid loss-2.2819, acc-0.1302, test loss-2.2841, acc-0.1331\n",
      "Iter-1900, train loss-2.2690, acc-0.2000, valid loss-2.2819, acc-0.1308, test loss-2.2840, acc-0.1333\n",
      "Iter-1910, train loss-2.3128, acc-0.0600, valid loss-2.2818, acc-0.1310, test loss-2.2839, acc-0.1338\n",
      "Iter-1920, train loss-2.2790, acc-0.2200, valid loss-2.2817, acc-0.1318, test loss-2.2839, acc-0.1340\n",
      "Iter-1930, train loss-2.2770, acc-0.1600, valid loss-2.2816, acc-0.1314, test loss-2.2838, acc-0.1343\n",
      "Iter-1940, train loss-2.2781, acc-0.1400, valid loss-2.2815, acc-0.1320, test loss-2.2837, acc-0.1342\n",
      "Iter-1950, train loss-2.3237, acc-0.0800, valid loss-2.2814, acc-0.1320, test loss-2.2836, acc-0.1345\n",
      "Iter-1960, train loss-2.2486, acc-0.2400, valid loss-2.2813, acc-0.1324, test loss-2.2835, acc-0.1346\n",
      "Iter-1970, train loss-2.2928, acc-0.0800, valid loss-2.2812, acc-0.1326, test loss-2.2834, acc-0.1350\n",
      "Iter-1980, train loss-2.2534, acc-0.2800, valid loss-2.2812, acc-0.1330, test loss-2.2833, acc-0.1350\n",
      "Iter-1990, train loss-2.2677, acc-0.1600, valid loss-2.2811, acc-0.1332, test loss-2.2832, acc-0.1351\n",
      "Iter-2000, train loss-2.2598, acc-0.1800, valid loss-2.2810, acc-0.1336, test loss-2.2831, acc-0.1355\n",
      "Iter-2010, train loss-2.2937, acc-0.0600, valid loss-2.2809, acc-0.1336, test loss-2.2830, acc-0.1358\n",
      "Iter-2020, train loss-2.2565, acc-0.2400, valid loss-2.2808, acc-0.1340, test loss-2.2829, acc-0.1358\n",
      "Iter-2030, train loss-2.2613, acc-0.0800, valid loss-2.2807, acc-0.1344, test loss-2.2828, acc-0.1361\n",
      "Iter-2040, train loss-2.2860, acc-0.0800, valid loss-2.2806, acc-0.1346, test loss-2.2827, acc-0.1361\n",
      "Iter-2050, train loss-2.2981, acc-0.1200, valid loss-2.2806, acc-0.1352, test loss-2.2826, acc-0.1363\n",
      "Iter-2060, train loss-2.2687, acc-0.1800, valid loss-2.2805, acc-0.1354, test loss-2.2825, acc-0.1362\n",
      "Iter-2070, train loss-2.2891, acc-0.1800, valid loss-2.2804, acc-0.1358, test loss-2.2824, acc-0.1363\n",
      "Iter-2080, train loss-2.2736, acc-0.1600, valid loss-2.2803, acc-0.1356, test loss-2.2823, acc-0.1367\n",
      "Iter-2090, train loss-2.2878, acc-0.1200, valid loss-2.2802, acc-0.1358, test loss-2.2823, acc-0.1368\n",
      "Iter-2100, train loss-2.2930, acc-0.0800, valid loss-2.2802, acc-0.1362, test loss-2.2822, acc-0.1370\n",
      "Iter-2110, train loss-2.3126, acc-0.0800, valid loss-2.2801, acc-0.1364, test loss-2.2821, acc-0.1371\n",
      "Iter-2120, train loss-2.3002, acc-0.1000, valid loss-2.2800, acc-0.1368, test loss-2.2820, acc-0.1371\n",
      "Iter-2130, train loss-2.2843, acc-0.1000, valid loss-2.2799, acc-0.1364, test loss-2.2819, acc-0.1373\n",
      "Iter-2140, train loss-2.2884, acc-0.1000, valid loss-2.2798, acc-0.1366, test loss-2.2818, acc-0.1373\n",
      "Iter-2150, train loss-2.2912, acc-0.1400, valid loss-2.2797, acc-0.1368, test loss-2.2817, acc-0.1376\n",
      "Iter-2160, train loss-2.3155, acc-0.1000, valid loss-2.2796, acc-0.1370, test loss-2.2816, acc-0.1377\n",
      "Iter-2170, train loss-2.2836, acc-0.1600, valid loss-2.2796, acc-0.1374, test loss-2.2815, acc-0.1383\n",
      "Iter-2180, train loss-2.2808, acc-0.1200, valid loss-2.2795, acc-0.1376, test loss-2.2814, acc-0.1382\n",
      "Iter-2190, train loss-2.2777, acc-0.1200, valid loss-2.2794, acc-0.1386, test loss-2.2813, acc-0.1383\n",
      "Iter-2200, train loss-2.2869, acc-0.1000, valid loss-2.2793, acc-0.1382, test loss-2.2812, acc-0.1385\n",
      "Iter-2210, train loss-2.2664, acc-0.1400, valid loss-2.2792, acc-0.1382, test loss-2.2812, acc-0.1381\n",
      "Iter-2220, train loss-2.2789, acc-0.0600, valid loss-2.2791, acc-0.1382, test loss-2.2811, acc-0.1383\n",
      "Iter-2230, train loss-2.2963, acc-0.1400, valid loss-2.2791, acc-0.1384, test loss-2.2810, acc-0.1383\n",
      "Iter-2240, train loss-2.2924, acc-0.0800, valid loss-2.2790, acc-0.1386, test loss-2.2809, acc-0.1385\n",
      "Iter-2250, train loss-2.2975, acc-0.1600, valid loss-2.2789, acc-0.1388, test loss-2.2808, acc-0.1387\n",
      "Iter-2260, train loss-2.2828, acc-0.0800, valid loss-2.2788, acc-0.1390, test loss-2.2807, acc-0.1385\n",
      "Iter-2270, train loss-2.2968, acc-0.1200, valid loss-2.2787, acc-0.1390, test loss-2.2806, acc-0.1388\n",
      "Iter-2280, train loss-2.2909, acc-0.1400, valid loss-2.2786, acc-0.1390, test loss-2.2805, acc-0.1389\n",
      "Iter-2290, train loss-2.2639, acc-0.1800, valid loss-2.2786, acc-0.1392, test loss-2.2804, acc-0.1388\n",
      "Iter-2300, train loss-2.2649, acc-0.2400, valid loss-2.2785, acc-0.1390, test loss-2.2803, acc-0.1391\n",
      "Iter-2310, train loss-2.2850, acc-0.1200, valid loss-2.2784, acc-0.1390, test loss-2.2802, acc-0.1393\n",
      "Iter-2320, train loss-2.2680, acc-0.1600, valid loss-2.2783, acc-0.1392, test loss-2.2801, acc-0.1394\n",
      "Iter-2330, train loss-2.2798, acc-0.1600, valid loss-2.2782, acc-0.1390, test loss-2.2800, acc-0.1394\n",
      "Iter-2340, train loss-2.2646, acc-0.1400, valid loss-2.2781, acc-0.1394, test loss-2.2799, acc-0.1397\n",
      "Iter-2350, train loss-2.2773, acc-0.1000, valid loss-2.2780, acc-0.1392, test loss-2.2799, acc-0.1398\n",
      "Iter-2360, train loss-2.2626, acc-0.1200, valid loss-2.2780, acc-0.1394, test loss-2.2798, acc-0.1399\n",
      "Iter-2370, train loss-2.2773, acc-0.1800, valid loss-2.2779, acc-0.1392, test loss-2.2797, acc-0.1401\n",
      "Iter-2380, train loss-2.2789, acc-0.1400, valid loss-2.2778, acc-0.1398, test loss-2.2796, acc-0.1402\n",
      "Iter-2390, train loss-2.2993, acc-0.1400, valid loss-2.2777, acc-0.1402, test loss-2.2795, acc-0.1406\n",
      "Iter-2400, train loss-2.2667, acc-0.1800, valid loss-2.2776, acc-0.1402, test loss-2.2794, acc-0.1408\n",
      "Iter-2410, train loss-2.2932, acc-0.1800, valid loss-2.2775, acc-0.1406, test loss-2.2793, acc-0.1413\n",
      "Iter-2420, train loss-2.2815, acc-0.1200, valid loss-2.2775, acc-0.1404, test loss-2.2792, acc-0.1412\n",
      "Iter-2430, train loss-2.3049, acc-0.0400, valid loss-2.2774, acc-0.1408, test loss-2.2791, acc-0.1416\n",
      "Iter-2440, train loss-2.2482, acc-0.1800, valid loss-2.2773, acc-0.1408, test loss-2.2790, acc-0.1417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-2450, train loss-2.2910, acc-0.1200, valid loss-2.2772, acc-0.1410, test loss-2.2789, acc-0.1420\n",
      "Iter-2460, train loss-2.2829, acc-0.0800, valid loss-2.2771, acc-0.1412, test loss-2.2788, acc-0.1421\n",
      "Iter-2470, train loss-2.2730, acc-0.1600, valid loss-2.2770, acc-0.1412, test loss-2.2787, acc-0.1418\n",
      "Iter-2480, train loss-2.2745, acc-0.1000, valid loss-2.2769, acc-0.1414, test loss-2.2786, acc-0.1426\n",
      "Iter-2490, train loss-2.2887, acc-0.0800, valid loss-2.2768, acc-0.1416, test loss-2.2785, acc-0.1427\n",
      "Iter-2500, train loss-2.2551, acc-0.1000, valid loss-2.2768, acc-0.1416, test loss-2.2784, acc-0.1428\n",
      "Iter-2510, train loss-2.3081, acc-0.0800, valid loss-2.2767, acc-0.1418, test loss-2.2784, acc-0.1428\n",
      "Iter-2520, train loss-2.2792, acc-0.0400, valid loss-2.2766, acc-0.1418, test loss-2.2783, acc-0.1430\n",
      "Iter-2530, train loss-2.2728, acc-0.1200, valid loss-2.2765, acc-0.1420, test loss-2.2782, acc-0.1431\n",
      "Iter-2540, train loss-2.2653, acc-0.2400, valid loss-2.2764, acc-0.1420, test loss-2.2781, acc-0.1436\n",
      "Iter-2550, train loss-2.3074, acc-0.1400, valid loss-2.2764, acc-0.1420, test loss-2.2780, acc-0.1440\n",
      "Iter-2560, train loss-2.2584, acc-0.2200, valid loss-2.2763, acc-0.1424, test loss-2.2779, acc-0.1440\n",
      "Iter-2570, train loss-2.2939, acc-0.0800, valid loss-2.2762, acc-0.1424, test loss-2.2778, acc-0.1441\n",
      "Iter-2580, train loss-2.2827, acc-0.1600, valid loss-2.2761, acc-0.1428, test loss-2.2777, acc-0.1443\n",
      "Iter-2590, train loss-2.2762, acc-0.0800, valid loss-2.2760, acc-0.1426, test loss-2.2776, acc-0.1447\n",
      "Iter-2600, train loss-2.2881, acc-0.1000, valid loss-2.2759, acc-0.1436, test loss-2.2775, acc-0.1448\n",
      "Iter-2610, train loss-2.2645, acc-0.1600, valid loss-2.2759, acc-0.1436, test loss-2.2775, acc-0.1450\n",
      "Iter-2620, train loss-2.2595, acc-0.1200, valid loss-2.2758, acc-0.1440, test loss-2.2774, acc-0.1454\n",
      "Iter-2630, train loss-2.2810, acc-0.1800, valid loss-2.2757, acc-0.1440, test loss-2.2773, acc-0.1455\n",
      "Iter-2640, train loss-2.2600, acc-0.1000, valid loss-2.2756, acc-0.1444, test loss-2.2772, acc-0.1458\n",
      "Iter-2650, train loss-2.2709, acc-0.1600, valid loss-2.2755, acc-0.1442, test loss-2.2771, acc-0.1460\n",
      "Iter-2660, train loss-2.2795, acc-0.2000, valid loss-2.2754, acc-0.1444, test loss-2.2770, acc-0.1460\n",
      "Iter-2670, train loss-2.2798, acc-0.0800, valid loss-2.2754, acc-0.1446, test loss-2.2769, acc-0.1461\n",
      "Iter-2680, train loss-2.2716, acc-0.2000, valid loss-2.2753, acc-0.1448, test loss-2.2768, acc-0.1464\n",
      "Iter-2690, train loss-2.2790, acc-0.1800, valid loss-2.2752, acc-0.1448, test loss-2.2767, acc-0.1463\n",
      "Iter-2700, train loss-2.2699, acc-0.1800, valid loss-2.2751, acc-0.1448, test loss-2.2766, acc-0.1465\n",
      "Iter-2710, train loss-2.2922, acc-0.1200, valid loss-2.2750, acc-0.1446, test loss-2.2765, acc-0.1463\n",
      "Iter-2720, train loss-2.2736, acc-0.1400, valid loss-2.2749, acc-0.1450, test loss-2.2764, acc-0.1464\n",
      "Iter-2730, train loss-2.2537, acc-0.3400, valid loss-2.2749, acc-0.1450, test loss-2.2763, acc-0.1467\n",
      "Iter-2740, train loss-2.2802, acc-0.1200, valid loss-2.2748, acc-0.1450, test loss-2.2763, acc-0.1465\n",
      "Iter-2750, train loss-2.2884, acc-0.1000, valid loss-2.2747, acc-0.1452, test loss-2.2762, acc-0.1466\n",
      "Iter-2760, train loss-2.2807, acc-0.1800, valid loss-2.2746, acc-0.1462, test loss-2.2761, acc-0.1468\n",
      "Iter-2770, train loss-2.2826, acc-0.1200, valid loss-2.2745, acc-0.1464, test loss-2.2760, acc-0.1473\n",
      "Iter-2780, train loss-2.2868, acc-0.1000, valid loss-2.2744, acc-0.1470, test loss-2.2759, acc-0.1476\n",
      "Iter-2790, train loss-2.2745, acc-0.2000, valid loss-2.2744, acc-0.1476, test loss-2.2758, acc-0.1478\n",
      "Iter-2800, train loss-2.2536, acc-0.1600, valid loss-2.2743, acc-0.1476, test loss-2.2757, acc-0.1479\n",
      "Iter-2810, train loss-2.2824, acc-0.1200, valid loss-2.2742, acc-0.1478, test loss-2.2756, acc-0.1479\n",
      "Iter-2820, train loss-2.2927, acc-0.1600, valid loss-2.2741, acc-0.1476, test loss-2.2755, acc-0.1482\n",
      "Iter-2830, train loss-2.2629, acc-0.1400, valid loss-2.2740, acc-0.1472, test loss-2.2754, acc-0.1484\n",
      "Iter-2840, train loss-2.2621, acc-0.2200, valid loss-2.2739, acc-0.1480, test loss-2.2753, acc-0.1484\n",
      "Iter-2850, train loss-2.2736, acc-0.1600, valid loss-2.2738, acc-0.1476, test loss-2.2752, acc-0.1488\n",
      "Iter-2860, train loss-2.2735, acc-0.1800, valid loss-2.2738, acc-0.1478, test loss-2.2751, acc-0.1487\n",
      "Iter-2870, train loss-2.2874, acc-0.1000, valid loss-2.2737, acc-0.1476, test loss-2.2751, acc-0.1492\n",
      "Iter-2880, train loss-2.2792, acc-0.1200, valid loss-2.2736, acc-0.1478, test loss-2.2750, acc-0.1492\n",
      "Iter-2890, train loss-2.2841, acc-0.1600, valid loss-2.2735, acc-0.1480, test loss-2.2749, acc-0.1494\n",
      "Iter-2900, train loss-2.2866, acc-0.1200, valid loss-2.2734, acc-0.1480, test loss-2.2748, acc-0.1498\n",
      "Iter-2910, train loss-2.2792, acc-0.1200, valid loss-2.2733, acc-0.1482, test loss-2.2747, acc-0.1499\n",
      "Iter-2920, train loss-2.3127, acc-0.1200, valid loss-2.2732, acc-0.1482, test loss-2.2746, acc-0.1500\n",
      "Iter-2930, train loss-2.2499, acc-0.2400, valid loss-2.2732, acc-0.1480, test loss-2.2745, acc-0.1500\n",
      "Iter-2940, train loss-2.2733, acc-0.1400, valid loss-2.2731, acc-0.1480, test loss-2.2744, acc-0.1504\n",
      "Iter-2950, train loss-2.2716, acc-0.1800, valid loss-2.2730, acc-0.1482, test loss-2.2743, acc-0.1505\n",
      "Iter-2960, train loss-2.2728, acc-0.1600, valid loss-2.2729, acc-0.1492, test loss-2.2742, acc-0.1505\n",
      "Iter-2970, train loss-2.2662, acc-0.1400, valid loss-2.2728, acc-0.1494, test loss-2.2741, acc-0.1508\n",
      "Iter-2980, train loss-2.2586, acc-0.1800, valid loss-2.2727, acc-0.1494, test loss-2.2740, acc-0.1510\n",
      "Iter-2990, train loss-2.2686, acc-0.1000, valid loss-2.2726, acc-0.1494, test loss-2.2740, acc-0.1509\n",
      "Iter-3000, train loss-2.2655, acc-0.1200, valid loss-2.2726, acc-0.1498, test loss-2.2739, acc-0.1510\n",
      "Iter-3010, train loss-2.2521, acc-0.2200, valid loss-2.2725, acc-0.1498, test loss-2.2738, acc-0.1513\n",
      "Iter-3020, train loss-2.2752, acc-0.1800, valid loss-2.2724, acc-0.1496, test loss-2.2737, acc-0.1515\n",
      "Iter-3030, train loss-2.2629, acc-0.2000, valid loss-2.2723, acc-0.1496, test loss-2.2736, acc-0.1518\n",
      "Iter-3040, train loss-2.3076, acc-0.1200, valid loss-2.2722, acc-0.1498, test loss-2.2735, acc-0.1520\n",
      "Iter-3050, train loss-2.2796, acc-0.1800, valid loss-2.2722, acc-0.1500, test loss-2.2734, acc-0.1522\n",
      "Iter-3060, train loss-2.2762, acc-0.1600, valid loss-2.2721, acc-0.1500, test loss-2.2733, acc-0.1523\n",
      "Iter-3070, train loss-2.2885, acc-0.1400, valid loss-2.2720, acc-0.1500, test loss-2.2732, acc-0.1525\n",
      "Iter-3080, train loss-2.2690, acc-0.1800, valid loss-2.2719, acc-0.1500, test loss-2.2731, acc-0.1524\n",
      "Iter-3090, train loss-2.2798, acc-0.1800, valid loss-2.2718, acc-0.1502, test loss-2.2731, acc-0.1531\n",
      "Iter-3100, train loss-2.2685, acc-0.1600, valid loss-2.2718, acc-0.1502, test loss-2.2730, acc-0.1530\n",
      "Iter-3110, train loss-2.2648, acc-0.1400, valid loss-2.2717, acc-0.1504, test loss-2.2729, acc-0.1531\n",
      "Iter-3120, train loss-2.2738, acc-0.1400, valid loss-2.2716, acc-0.1508, test loss-2.2728, acc-0.1532\n",
      "Iter-3130, train loss-2.2563, acc-0.2600, valid loss-2.2715, acc-0.1514, test loss-2.2727, acc-0.1533\n",
      "Iter-3140, train loss-2.2776, acc-0.1200, valid loss-2.2714, acc-0.1514, test loss-2.2726, acc-0.1536\n",
      "Iter-3150, train loss-2.2710, acc-0.1600, valid loss-2.2713, acc-0.1518, test loss-2.2725, acc-0.1538\n",
      "Iter-3160, train loss-2.2552, acc-0.1800, valid loss-2.2713, acc-0.1512, test loss-2.2724, acc-0.1539\n",
      "Iter-3170, train loss-2.2890, acc-0.1400, valid loss-2.2712, acc-0.1512, test loss-2.2723, acc-0.1544\n",
      "Iter-3180, train loss-2.2617, acc-0.1400, valid loss-2.2711, acc-0.1514, test loss-2.2722, acc-0.1544\n",
      "Iter-3190, train loss-2.2740, acc-0.2200, valid loss-2.2710, acc-0.1516, test loss-2.2721, acc-0.1544\n",
      "Iter-3200, train loss-2.2675, acc-0.1200, valid loss-2.2709, acc-0.1514, test loss-2.2720, acc-0.1545\n",
      "Iter-3210, train loss-2.2518, acc-0.2400, valid loss-2.2708, acc-0.1516, test loss-2.2720, acc-0.1546\n",
      "Iter-3220, train loss-2.2755, acc-0.1800, valid loss-2.2708, acc-0.1520, test loss-2.2719, acc-0.1546\n",
      "Iter-3230, train loss-2.2606, acc-0.1800, valid loss-2.2707, acc-0.1524, test loss-2.2718, acc-0.1549\n",
      "Iter-3240, train loss-2.2729, acc-0.1800, valid loss-2.2706, acc-0.1530, test loss-2.2717, acc-0.1551\n",
      "Iter-3250, train loss-2.2790, acc-0.1600, valid loss-2.2705, acc-0.1528, test loss-2.2716, acc-0.1549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-3260, train loss-2.2734, acc-0.1800, valid loss-2.2704, acc-0.1526, test loss-2.2715, acc-0.1553\n",
      "Iter-3270, train loss-2.2961, acc-0.1600, valid loss-2.2703, acc-0.1534, test loss-2.2714, acc-0.1554\n",
      "Iter-3280, train loss-2.2751, acc-0.1400, valid loss-2.2703, acc-0.1530, test loss-2.2713, acc-0.1556\n",
      "Iter-3290, train loss-2.2842, acc-0.1800, valid loss-2.2702, acc-0.1536, test loss-2.2712, acc-0.1561\n",
      "Iter-3300, train loss-2.2849, acc-0.2000, valid loss-2.2701, acc-0.1538, test loss-2.2712, acc-0.1564\n",
      "Iter-3310, train loss-2.2844, acc-0.2000, valid loss-2.2700, acc-0.1542, test loss-2.2711, acc-0.1565\n",
      "Iter-3320, train loss-2.2678, acc-0.1600, valid loss-2.2699, acc-0.1550, test loss-2.2710, acc-0.1568\n",
      "Iter-3330, train loss-2.2691, acc-0.2200, valid loss-2.2698, acc-0.1550, test loss-2.2709, acc-0.1569\n",
      "Iter-3340, train loss-2.2508, acc-0.1400, valid loss-2.2698, acc-0.1554, test loss-2.2708, acc-0.1570\n",
      "Iter-3350, train loss-2.2827, acc-0.1800, valid loss-2.2697, acc-0.1554, test loss-2.2707, acc-0.1571\n",
      "Iter-3360, train loss-2.2795, acc-0.1400, valid loss-2.2696, acc-0.1556, test loss-2.2706, acc-0.1575\n",
      "Iter-3370, train loss-2.2539, acc-0.1400, valid loss-2.2695, acc-0.1556, test loss-2.2705, acc-0.1576\n",
      "Iter-3380, train loss-2.2990, acc-0.1400, valid loss-2.2694, acc-0.1558, test loss-2.2704, acc-0.1578\n",
      "Iter-3390, train loss-2.2748, acc-0.0800, valid loss-2.2693, acc-0.1556, test loss-2.2703, acc-0.1580\n",
      "Iter-3400, train loss-2.2597, acc-0.2400, valid loss-2.2692, acc-0.1560, test loss-2.2702, acc-0.1579\n",
      "Iter-3410, train loss-2.2614, acc-0.1800, valid loss-2.2692, acc-0.1562, test loss-2.2701, acc-0.1580\n",
      "Iter-3420, train loss-2.2752, acc-0.2200, valid loss-2.2691, acc-0.1564, test loss-2.2700, acc-0.1584\n",
      "Iter-3430, train loss-2.2800, acc-0.1400, valid loss-2.2690, acc-0.1562, test loss-2.2699, acc-0.1585\n",
      "Iter-3440, train loss-2.2721, acc-0.1400, valid loss-2.2689, acc-0.1562, test loss-2.2699, acc-0.1589\n",
      "Iter-3450, train loss-2.2728, acc-0.1400, valid loss-2.2688, acc-0.1564, test loss-2.2698, acc-0.1590\n",
      "Iter-3460, train loss-2.2615, acc-0.1000, valid loss-2.2688, acc-0.1566, test loss-2.2697, acc-0.1593\n",
      "Iter-3470, train loss-2.2554, acc-0.1600, valid loss-2.2687, acc-0.1568, test loss-2.2696, acc-0.1598\n",
      "Iter-3480, train loss-2.2612, acc-0.1400, valid loss-2.2686, acc-0.1572, test loss-2.2695, acc-0.1601\n",
      "Iter-3490, train loss-2.2460, acc-0.2400, valid loss-2.2685, acc-0.1572, test loss-2.2694, acc-0.1606\n",
      "Iter-3500, train loss-2.2744, acc-0.1800, valid loss-2.2684, acc-0.1576, test loss-2.2693, acc-0.1609\n",
      "Iter-3510, train loss-2.2784, acc-0.0600, valid loss-2.2683, acc-0.1580, test loss-2.2692, acc-0.1613\n",
      "Iter-3520, train loss-2.2770, acc-0.2000, valid loss-2.2683, acc-0.1582, test loss-2.2691, acc-0.1611\n",
      "Iter-3530, train loss-2.2580, acc-0.2000, valid loss-2.2682, acc-0.1586, test loss-2.2691, acc-0.1612\n",
      "Iter-3540, train loss-2.2487, acc-0.2000, valid loss-2.2681, acc-0.1590, test loss-2.2690, acc-0.1617\n",
      "Iter-3550, train loss-2.2662, acc-0.1400, valid loss-2.2680, acc-0.1586, test loss-2.2689, acc-0.1621\n",
      "Iter-3560, train loss-2.2820, acc-0.1600, valid loss-2.2679, acc-0.1590, test loss-2.2688, acc-0.1624\n",
      "Iter-3570, train loss-2.2875, acc-0.1200, valid loss-2.2678, acc-0.1590, test loss-2.2687, acc-0.1626\n",
      "Iter-3580, train loss-2.2497, acc-0.2200, valid loss-2.2677, acc-0.1592, test loss-2.2686, acc-0.1624\n",
      "Iter-3590, train loss-2.2658, acc-0.1600, valid loss-2.2677, acc-0.1592, test loss-2.2685, acc-0.1628\n",
      "Iter-3600, train loss-2.2576, acc-0.1800, valid loss-2.2676, acc-0.1592, test loss-2.2684, acc-0.1627\n",
      "Iter-3610, train loss-2.2608, acc-0.2000, valid loss-2.2675, acc-0.1598, test loss-2.2683, acc-0.1628\n",
      "Iter-3620, train loss-2.2604, acc-0.1600, valid loss-2.2674, acc-0.1598, test loss-2.2682, acc-0.1629\n",
      "Iter-3630, train loss-2.2507, acc-0.2600, valid loss-2.2673, acc-0.1602, test loss-2.2681, acc-0.1631\n",
      "Iter-3640, train loss-2.2457, acc-0.1600, valid loss-2.2672, acc-0.1602, test loss-2.2680, acc-0.1632\n",
      "Iter-3650, train loss-2.2501, acc-0.1600, valid loss-2.2672, acc-0.1604, test loss-2.2679, acc-0.1635\n",
      "Iter-3660, train loss-2.2441, acc-0.2800, valid loss-2.2671, acc-0.1604, test loss-2.2679, acc-0.1636\n",
      "Iter-3670, train loss-2.2805, acc-0.1000, valid loss-2.2670, acc-0.1604, test loss-2.2678, acc-0.1640\n",
      "Iter-3680, train loss-2.2681, acc-0.1400, valid loss-2.2669, acc-0.1604, test loss-2.2677, acc-0.1644\n",
      "Iter-3690, train loss-2.2702, acc-0.2200, valid loss-2.2668, acc-0.1604, test loss-2.2676, acc-0.1642\n",
      "Iter-3700, train loss-2.2627, acc-0.1600, valid loss-2.2668, acc-0.1604, test loss-2.2675, acc-0.1641\n",
      "Iter-3710, train loss-2.2604, acc-0.2000, valid loss-2.2667, acc-0.1606, test loss-2.2674, acc-0.1646\n",
      "Iter-3720, train loss-2.2696, acc-0.2000, valid loss-2.2666, acc-0.1608, test loss-2.2673, acc-0.1648\n",
      "Iter-3730, train loss-2.2486, acc-0.1800, valid loss-2.2665, acc-0.1608, test loss-2.2672, acc-0.1649\n",
      "Iter-3740, train loss-2.2959, acc-0.1600, valid loss-2.2664, acc-0.1610, test loss-2.2671, acc-0.1651\n",
      "Iter-3750, train loss-2.2798, acc-0.1600, valid loss-2.2664, acc-0.1610, test loss-2.2671, acc-0.1653\n",
      "Iter-3760, train loss-2.2467, acc-0.2000, valid loss-2.2663, acc-0.1612, test loss-2.2670, acc-0.1657\n",
      "Iter-3770, train loss-2.2774, acc-0.2200, valid loss-2.2662, acc-0.1618, test loss-2.2669, acc-0.1661\n",
      "Iter-3780, train loss-2.2730, acc-0.1800, valid loss-2.2661, acc-0.1614, test loss-2.2668, acc-0.1659\n",
      "Iter-3790, train loss-2.2663, acc-0.1600, valid loss-2.2660, acc-0.1614, test loss-2.2667, acc-0.1660\n",
      "Iter-3800, train loss-2.2721, acc-0.1200, valid loss-2.2659, acc-0.1614, test loss-2.2666, acc-0.1662\n",
      "Iter-3810, train loss-2.2745, acc-0.1600, valid loss-2.2658, acc-0.1612, test loss-2.2665, acc-0.1666\n",
      "Iter-3820, train loss-2.2753, acc-0.2800, valid loss-2.2658, acc-0.1620, test loss-2.2664, acc-0.1669\n",
      "Iter-3830, train loss-2.2820, acc-0.1000, valid loss-2.2657, acc-0.1622, test loss-2.2663, acc-0.1670\n",
      "Iter-3840, train loss-2.2714, acc-0.2000, valid loss-2.2656, acc-0.1624, test loss-2.2662, acc-0.1668\n",
      "Iter-3850, train loss-2.2535, acc-0.2200, valid loss-2.2655, acc-0.1626, test loss-2.2661, acc-0.1671\n",
      "Iter-3860, train loss-2.2465, acc-0.2200, valid loss-2.2654, acc-0.1630, test loss-2.2660, acc-0.1673\n",
      "Iter-3870, train loss-2.2817, acc-0.1000, valid loss-2.2654, acc-0.1634, test loss-2.2660, acc-0.1675\n",
      "Iter-3880, train loss-2.2712, acc-0.1600, valid loss-2.2653, acc-0.1634, test loss-2.2659, acc-0.1676\n",
      "Iter-3890, train loss-2.2762, acc-0.1000, valid loss-2.2652, acc-0.1636, test loss-2.2658, acc-0.1681\n",
      "Iter-3900, train loss-2.2781, acc-0.0600, valid loss-2.2651, acc-0.1634, test loss-2.2657, acc-0.1680\n",
      "Iter-3910, train loss-2.2768, acc-0.1600, valid loss-2.2650, acc-0.1636, test loss-2.2656, acc-0.1684\n",
      "Iter-3920, train loss-2.2642, acc-0.1800, valid loss-2.2650, acc-0.1638, test loss-2.2655, acc-0.1685\n",
      "Iter-3930, train loss-2.2834, acc-0.1400, valid loss-2.2649, acc-0.1638, test loss-2.2654, acc-0.1690\n",
      "Iter-3940, train loss-2.2622, acc-0.1800, valid loss-2.2648, acc-0.1642, test loss-2.2654, acc-0.1690\n",
      "Iter-3950, train loss-2.2896, acc-0.1000, valid loss-2.2647, acc-0.1646, test loss-2.2653, acc-0.1692\n",
      "Iter-3960, train loss-2.2617, acc-0.1800, valid loss-2.2646, acc-0.1650, test loss-2.2652, acc-0.1694\n",
      "Iter-3970, train loss-2.2598, acc-0.1800, valid loss-2.2646, acc-0.1652, test loss-2.2651, acc-0.1695\n",
      "Iter-3980, train loss-2.2685, acc-0.2000, valid loss-2.2645, acc-0.1654, test loss-2.2650, acc-0.1698\n",
      "Iter-3990, train loss-2.2755, acc-0.1000, valid loss-2.2644, acc-0.1654, test loss-2.2649, acc-0.1700\n",
      "Iter-4000, train loss-2.2854, acc-0.1200, valid loss-2.2643, acc-0.1650, test loss-2.2648, acc-0.1702\n",
      "Iter-4010, train loss-2.2739, acc-0.1800, valid loss-2.2642, acc-0.1652, test loss-2.2647, acc-0.1707\n",
      "Iter-4020, train loss-2.2548, acc-0.2000, valid loss-2.2642, acc-0.1658, test loss-2.2646, acc-0.1705\n",
      "Iter-4030, train loss-2.2563, acc-0.1400, valid loss-2.2641, acc-0.1658, test loss-2.2645, acc-0.1706\n",
      "Iter-4040, train loss-2.2584, acc-0.2600, valid loss-2.2640, acc-0.1660, test loss-2.2645, acc-0.1706\n",
      "Iter-4050, train loss-2.2808, acc-0.0400, valid loss-2.2639, acc-0.1664, test loss-2.2644, acc-0.1710\n",
      "Iter-4060, train loss-2.2364, acc-0.2000, valid loss-2.2638, acc-0.1666, test loss-2.2643, acc-0.1714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-4070, train loss-2.2571, acc-0.1600, valid loss-2.2638, acc-0.1666, test loss-2.2642, acc-0.1716\n",
      "Iter-4080, train loss-2.2261, acc-0.2400, valid loss-2.2637, acc-0.1670, test loss-2.2641, acc-0.1720\n",
      "Iter-4090, train loss-2.2761, acc-0.1600, valid loss-2.2636, acc-0.1670, test loss-2.2640, acc-0.1724\n",
      "Iter-4100, train loss-2.2813, acc-0.1200, valid loss-2.2635, acc-0.1672, test loss-2.2639, acc-0.1724\n",
      "Iter-4110, train loss-2.2771, acc-0.1400, valid loss-2.2634, acc-0.1672, test loss-2.2638, acc-0.1725\n",
      "Iter-4120, train loss-2.2687, acc-0.1400, valid loss-2.2634, acc-0.1672, test loss-2.2637, acc-0.1726\n",
      "Iter-4130, train loss-2.2737, acc-0.2400, valid loss-2.2633, acc-0.1674, test loss-2.2637, acc-0.1729\n",
      "Iter-4140, train loss-2.2656, acc-0.0800, valid loss-2.2632, acc-0.1684, test loss-2.2636, acc-0.1733\n",
      "Iter-4150, train loss-2.2729, acc-0.1600, valid loss-2.2631, acc-0.1686, test loss-2.2635, acc-0.1735\n",
      "Iter-4160, train loss-2.2547, acc-0.2000, valid loss-2.2630, acc-0.1686, test loss-2.2634, acc-0.1736\n",
      "Iter-4170, train loss-2.2882, acc-0.0600, valid loss-2.2629, acc-0.1686, test loss-2.2633, acc-0.1736\n",
      "Iter-4180, train loss-2.2648, acc-0.1800, valid loss-2.2629, acc-0.1686, test loss-2.2632, acc-0.1736\n",
      "Iter-4190, train loss-2.2845, acc-0.1200, valid loss-2.2628, acc-0.1688, test loss-2.2631, acc-0.1739\n",
      "Iter-4200, train loss-2.2524, acc-0.2400, valid loss-2.2627, acc-0.1692, test loss-2.2630, acc-0.1740\n",
      "Iter-4210, train loss-2.2838, acc-0.1200, valid loss-2.2626, acc-0.1698, test loss-2.2629, acc-0.1740\n",
      "Iter-4220, train loss-2.2415, acc-0.3000, valid loss-2.2625, acc-0.1696, test loss-2.2628, acc-0.1744\n",
      "Iter-4230, train loss-2.2410, acc-0.1600, valid loss-2.2624, acc-0.1694, test loss-2.2627, acc-0.1744\n",
      "Iter-4240, train loss-2.2625, acc-0.2000, valid loss-2.2623, acc-0.1698, test loss-2.2626, acc-0.1745\n",
      "Iter-4250, train loss-2.2400, acc-0.2600, valid loss-2.2623, acc-0.1700, test loss-2.2626, acc-0.1747\n",
      "Iter-4260, train loss-2.2770, acc-0.1400, valid loss-2.2622, acc-0.1698, test loss-2.2625, acc-0.1750\n",
      "Iter-4270, train loss-2.2696, acc-0.2000, valid loss-2.2621, acc-0.1700, test loss-2.2624, acc-0.1751\n",
      "Iter-4280, train loss-2.2534, acc-0.2200, valid loss-2.2620, acc-0.1702, test loss-2.2623, acc-0.1752\n",
      "Iter-4290, train loss-2.2740, acc-0.1800, valid loss-2.2619, acc-0.1704, test loss-2.2622, acc-0.1756\n",
      "Iter-4300, train loss-2.2902, acc-0.1600, valid loss-2.2619, acc-0.1706, test loss-2.2621, acc-0.1754\n",
      "Iter-4310, train loss-2.2782, acc-0.2000, valid loss-2.2618, acc-0.1708, test loss-2.2620, acc-0.1756\n",
      "Iter-4320, train loss-2.2545, acc-0.1400, valid loss-2.2617, acc-0.1706, test loss-2.2619, acc-0.1756\n",
      "Iter-4330, train loss-2.2803, acc-0.1600, valid loss-2.2616, acc-0.1704, test loss-2.2618, acc-0.1757\n",
      "Iter-4340, train loss-2.2440, acc-0.2000, valid loss-2.2615, acc-0.1706, test loss-2.2618, acc-0.1757\n",
      "Iter-4350, train loss-2.2356, acc-0.2200, valid loss-2.2614, acc-0.1708, test loss-2.2617, acc-0.1764\n",
      "Iter-4360, train loss-2.2600, acc-0.1600, valid loss-2.2614, acc-0.1710, test loss-2.2616, acc-0.1766\n",
      "Iter-4370, train loss-2.2507, acc-0.1200, valid loss-2.2613, acc-0.1710, test loss-2.2615, acc-0.1768\n",
      "Iter-4380, train loss-2.2404, acc-0.2800, valid loss-2.2612, acc-0.1708, test loss-2.2614, acc-0.1771\n",
      "Iter-4390, train loss-2.2650, acc-0.1200, valid loss-2.2611, acc-0.1708, test loss-2.2613, acc-0.1768\n",
      "Iter-4400, train loss-2.2584, acc-0.2600, valid loss-2.2610, acc-0.1716, test loss-2.2612, acc-0.1773\n",
      "Iter-4410, train loss-2.2948, acc-0.1400, valid loss-2.2609, acc-0.1718, test loss-2.2611, acc-0.1773\n",
      "Iter-4420, train loss-2.2571, acc-0.1800, valid loss-2.2609, acc-0.1724, test loss-2.2610, acc-0.1781\n",
      "Iter-4430, train loss-2.2654, acc-0.1400, valid loss-2.2608, acc-0.1728, test loss-2.2609, acc-0.1783\n",
      "Iter-4440, train loss-2.2636, acc-0.1400, valid loss-2.2607, acc-0.1728, test loss-2.2608, acc-0.1784\n",
      "Iter-4450, train loss-2.2649, acc-0.2400, valid loss-2.2606, acc-0.1730, test loss-2.2607, acc-0.1788\n",
      "Iter-4460, train loss-2.2527, acc-0.1800, valid loss-2.2605, acc-0.1732, test loss-2.2607, acc-0.1788\n",
      "Iter-4470, train loss-2.2680, acc-0.2000, valid loss-2.2604, acc-0.1732, test loss-2.2606, acc-0.1792\n",
      "Iter-4480, train loss-2.2659, acc-0.1400, valid loss-2.2604, acc-0.1734, test loss-2.2605, acc-0.1794\n",
      "Iter-4490, train loss-2.2464, acc-0.1800, valid loss-2.2603, acc-0.1734, test loss-2.2604, acc-0.1795\n",
      "Iter-4500, train loss-2.2590, acc-0.1400, valid loss-2.2602, acc-0.1734, test loss-2.2603, acc-0.1795\n",
      "Iter-4510, train loss-2.2710, acc-0.1400, valid loss-2.2601, acc-0.1736, test loss-2.2602, acc-0.1798\n",
      "Iter-4520, train loss-2.2454, acc-0.2200, valid loss-2.2600, acc-0.1742, test loss-2.2601, acc-0.1796\n",
      "Iter-4530, train loss-2.2570, acc-0.1800, valid loss-2.2599, acc-0.1742, test loss-2.2600, acc-0.1795\n",
      "Iter-4540, train loss-2.2363, acc-0.1600, valid loss-2.2599, acc-0.1740, test loss-2.2599, acc-0.1796\n",
      "Iter-4550, train loss-2.2556, acc-0.1400, valid loss-2.2598, acc-0.1742, test loss-2.2598, acc-0.1796\n",
      "Iter-4560, train loss-2.2640, acc-0.2200, valid loss-2.2597, acc-0.1748, test loss-2.2598, acc-0.1796\n",
      "Iter-4570, train loss-2.2630, acc-0.1600, valid loss-2.2596, acc-0.1750, test loss-2.2597, acc-0.1798\n",
      "Iter-4580, train loss-2.2785, acc-0.1800, valid loss-2.2595, acc-0.1752, test loss-2.2596, acc-0.1796\n",
      "Iter-4590, train loss-2.2661, acc-0.1400, valid loss-2.2595, acc-0.1748, test loss-2.2595, acc-0.1802\n",
      "Iter-4600, train loss-2.2524, acc-0.2000, valid loss-2.2594, acc-0.1754, test loss-2.2594, acc-0.1803\n",
      "Iter-4610, train loss-2.2454, acc-0.2200, valid loss-2.2593, acc-0.1754, test loss-2.2593, acc-0.1805\n",
      "Iter-4620, train loss-2.2784, acc-0.0800, valid loss-2.2592, acc-0.1756, test loss-2.2592, acc-0.1805\n",
      "Iter-4630, train loss-2.2705, acc-0.2600, valid loss-2.2592, acc-0.1760, test loss-2.2592, acc-0.1811\n",
      "Iter-4640, train loss-2.2376, acc-0.2400, valid loss-2.2591, acc-0.1762, test loss-2.2591, acc-0.1811\n",
      "Iter-4650, train loss-2.2657, acc-0.0800, valid loss-2.2590, acc-0.1758, test loss-2.2590, acc-0.1812\n",
      "Iter-4660, train loss-2.2611, acc-0.1600, valid loss-2.2589, acc-0.1762, test loss-2.2589, acc-0.1818\n",
      "Iter-4670, train loss-2.2502, acc-0.2400, valid loss-2.2588, acc-0.1760, test loss-2.2588, acc-0.1820\n",
      "Iter-4680, train loss-2.2488, acc-0.1800, valid loss-2.2588, acc-0.1764, test loss-2.2587, acc-0.1824\n",
      "Iter-4690, train loss-2.2599, acc-0.1400, valid loss-2.2587, acc-0.1766, test loss-2.2586, acc-0.1823\n",
      "Iter-4700, train loss-2.2743, acc-0.1200, valid loss-2.2586, acc-0.1770, test loss-2.2585, acc-0.1823\n",
      "Iter-4710, train loss-2.2398, acc-0.2800, valid loss-2.2585, acc-0.1778, test loss-2.2585, acc-0.1825\n",
      "Iter-4720, train loss-2.2655, acc-0.2000, valid loss-2.2584, acc-0.1780, test loss-2.2584, acc-0.1826\n",
      "Iter-4730, train loss-2.2614, acc-0.1400, valid loss-2.2583, acc-0.1774, test loss-2.2583, acc-0.1823\n",
      "Iter-4740, train loss-2.2408, acc-0.1800, valid loss-2.2583, acc-0.1776, test loss-2.2582, acc-0.1826\n",
      "Iter-4750, train loss-2.2530, acc-0.2000, valid loss-2.2582, acc-0.1780, test loss-2.2581, acc-0.1828\n",
      "Iter-4760, train loss-2.2607, acc-0.0800, valid loss-2.2581, acc-0.1782, test loss-2.2580, acc-0.1828\n",
      "Iter-4770, train loss-2.2533, acc-0.2000, valid loss-2.2580, acc-0.1782, test loss-2.2579, acc-0.1829\n",
      "Iter-4780, train loss-2.2382, acc-0.2600, valid loss-2.2580, acc-0.1782, test loss-2.2578, acc-0.1830\n",
      "Iter-4790, train loss-2.2416, acc-0.2200, valid loss-2.2579, acc-0.1786, test loss-2.2577, acc-0.1833\n",
      "Iter-4800, train loss-2.2776, acc-0.0600, valid loss-2.2578, acc-0.1784, test loss-2.2577, acc-0.1835\n",
      "Iter-4810, train loss-2.2631, acc-0.1600, valid loss-2.2577, acc-0.1788, test loss-2.2576, acc-0.1836\n",
      "Iter-4820, train loss-2.2739, acc-0.1400, valid loss-2.2576, acc-0.1792, test loss-2.2575, acc-0.1837\n",
      "Iter-4830, train loss-2.2493, acc-0.1600, valid loss-2.2576, acc-0.1792, test loss-2.2574, acc-0.1835\n",
      "Iter-4840, train loss-2.2458, acc-0.2000, valid loss-2.2575, acc-0.1790, test loss-2.2573, acc-0.1836\n",
      "Iter-4850, train loss-2.2458, acc-0.1800, valid loss-2.2574, acc-0.1796, test loss-2.2572, acc-0.1838\n",
      "Iter-4860, train loss-2.2647, acc-0.1600, valid loss-2.2573, acc-0.1794, test loss-2.2571, acc-0.1838\n",
      "Iter-4870, train loss-2.2619, acc-0.2400, valid loss-2.2573, acc-0.1798, test loss-2.2571, acc-0.1838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-4880, train loss-2.2546, acc-0.1400, valid loss-2.2572, acc-0.1798, test loss-2.2570, acc-0.1840\n",
      "Iter-4890, train loss-2.2743, acc-0.2000, valid loss-2.2571, acc-0.1796, test loss-2.2569, acc-0.1841\n",
      "Iter-4900, train loss-2.2827, acc-0.1400, valid loss-2.2570, acc-0.1798, test loss-2.2568, acc-0.1842\n",
      "Iter-4910, train loss-2.2397, acc-0.2600, valid loss-2.2569, acc-0.1804, test loss-2.2567, acc-0.1845\n",
      "Iter-4920, train loss-2.2469, acc-0.1400, valid loss-2.2569, acc-0.1806, test loss-2.2566, acc-0.1848\n",
      "Iter-4930, train loss-2.2427, acc-0.2400, valid loss-2.2568, acc-0.1806, test loss-2.2565, acc-0.1847\n",
      "Iter-4940, train loss-2.2388, acc-0.2800, valid loss-2.2567, acc-0.1816, test loss-2.2564, acc-0.1846\n",
      "Iter-4950, train loss-2.2661, acc-0.1200, valid loss-2.2566, acc-0.1824, test loss-2.2564, acc-0.1850\n",
      "Iter-4960, train loss-2.3016, acc-0.1200, valid loss-2.2565, acc-0.1826, test loss-2.2563, acc-0.1854\n",
      "Iter-4970, train loss-2.2588, acc-0.2200, valid loss-2.2564, acc-0.1824, test loss-2.2562, acc-0.1854\n",
      "Iter-4980, train loss-2.2785, acc-0.1600, valid loss-2.2564, acc-0.1828, test loss-2.2561, acc-0.1856\n",
      "Iter-4990, train loss-2.2451, acc-0.1600, valid loss-2.2563, acc-0.1826, test loss-2.2560, acc-0.1856\n",
      "Iter-5000, train loss-2.2676, acc-0.1200, valid loss-2.2562, acc-0.1826, test loss-2.2559, acc-0.1857\n",
      "Iter-5010, train loss-2.2774, acc-0.1400, valid loss-2.2561, acc-0.1828, test loss-2.2558, acc-0.1858\n",
      "Iter-5020, train loss-2.2515, acc-0.1600, valid loss-2.2560, acc-0.1832, test loss-2.2557, acc-0.1859\n",
      "Iter-5030, train loss-2.2527, acc-0.1800, valid loss-2.2560, acc-0.1834, test loss-2.2556, acc-0.1862\n",
      "Iter-5040, train loss-2.2564, acc-0.1400, valid loss-2.2559, acc-0.1832, test loss-2.2556, acc-0.1862\n",
      "Iter-5050, train loss-2.2595, acc-0.2000, valid loss-2.2558, acc-0.1834, test loss-2.2555, acc-0.1862\n",
      "Iter-5060, train loss-2.2532, acc-0.2800, valid loss-2.2557, acc-0.1838, test loss-2.2554, acc-0.1865\n",
      "Iter-5070, train loss-2.2455, acc-0.2200, valid loss-2.2556, acc-0.1842, test loss-2.2553, acc-0.1865\n",
      "Iter-5080, train loss-2.2319, acc-0.2400, valid loss-2.2556, acc-0.1842, test loss-2.2552, acc-0.1867\n",
      "Iter-5090, train loss-2.2606, acc-0.1600, valid loss-2.2555, acc-0.1844, test loss-2.2551, acc-0.1869\n",
      "Iter-5100, train loss-2.2701, acc-0.1400, valid loss-2.2554, acc-0.1844, test loss-2.2550, acc-0.1871\n",
      "Iter-5110, train loss-2.2584, acc-0.2600, valid loss-2.2553, acc-0.1848, test loss-2.2549, acc-0.1873\n",
      "Iter-5120, train loss-2.2631, acc-0.1200, valid loss-2.2553, acc-0.1848, test loss-2.2549, acc-0.1874\n",
      "Iter-5130, train loss-2.2402, acc-0.2800, valid loss-2.2552, acc-0.1850, test loss-2.2548, acc-0.1874\n",
      "Iter-5140, train loss-2.2442, acc-0.1000, valid loss-2.2551, acc-0.1854, test loss-2.2547, acc-0.1877\n",
      "Iter-5150, train loss-2.2900, acc-0.1400, valid loss-2.2550, acc-0.1854, test loss-2.2546, acc-0.1878\n",
      "Iter-5160, train loss-2.2498, acc-0.1600, valid loss-2.2549, acc-0.1860, test loss-2.2545, acc-0.1876\n",
      "Iter-5170, train loss-2.2359, acc-0.2200, valid loss-2.2549, acc-0.1864, test loss-2.2544, acc-0.1877\n",
      "Iter-5180, train loss-2.2369, acc-0.2000, valid loss-2.2548, acc-0.1866, test loss-2.2543, acc-0.1874\n",
      "Iter-5190, train loss-2.2396, acc-0.2400, valid loss-2.2547, acc-0.1870, test loss-2.2542, acc-0.1881\n",
      "Iter-5200, train loss-2.2738, acc-0.1200, valid loss-2.2546, acc-0.1874, test loss-2.2542, acc-0.1887\n",
      "Iter-5210, train loss-2.2608, acc-0.1600, valid loss-2.2545, acc-0.1876, test loss-2.2541, acc-0.1887\n",
      "Iter-5220, train loss-2.2472, acc-0.2400, valid loss-2.2545, acc-0.1882, test loss-2.2540, acc-0.1890\n",
      "Iter-5230, train loss-2.2521, acc-0.2800, valid loss-2.2544, acc-0.1884, test loss-2.2539, acc-0.1889\n",
      "Iter-5240, train loss-2.2450, acc-0.2200, valid loss-2.2543, acc-0.1884, test loss-2.2538, acc-0.1894\n",
      "Iter-5250, train loss-2.2650, acc-0.1000, valid loss-2.2542, acc-0.1880, test loss-2.2537, acc-0.1899\n",
      "Iter-5260, train loss-2.2567, acc-0.2800, valid loss-2.2541, acc-0.1888, test loss-2.2536, acc-0.1901\n",
      "Iter-5270, train loss-2.2549, acc-0.2000, valid loss-2.2541, acc-0.1890, test loss-2.2535, acc-0.1906\n",
      "Iter-5280, train loss-2.2436, acc-0.1800, valid loss-2.2540, acc-0.1890, test loss-2.2535, acc-0.1908\n",
      "Iter-5290, train loss-2.2357, acc-0.2600, valid loss-2.2539, acc-0.1892, test loss-2.2534, acc-0.1911\n",
      "Iter-5300, train loss-2.2506, acc-0.1600, valid loss-2.2538, acc-0.1894, test loss-2.2533, acc-0.1913\n",
      "Iter-5310, train loss-2.2434, acc-0.2400, valid loss-2.2538, acc-0.1898, test loss-2.2532, acc-0.1914\n",
      "Iter-5320, train loss-2.2858, acc-0.1800, valid loss-2.2537, acc-0.1900, test loss-2.2531, acc-0.1917\n",
      "Iter-5330, train loss-2.2508, acc-0.2000, valid loss-2.2536, acc-0.1898, test loss-2.2530, acc-0.1917\n",
      "Iter-5340, train loss-2.2530, acc-0.2000, valid loss-2.2535, acc-0.1902, test loss-2.2529, acc-0.1921\n",
      "Iter-5350, train loss-2.2465, acc-0.1800, valid loss-2.2534, acc-0.1904, test loss-2.2528, acc-0.1925\n",
      "Iter-5360, train loss-2.2503, acc-0.2200, valid loss-2.2534, acc-0.1908, test loss-2.2528, acc-0.1928\n",
      "Iter-5370, train loss-2.2547, acc-0.2200, valid loss-2.2533, acc-0.1906, test loss-2.2527, acc-0.1932\n",
      "Iter-5380, train loss-2.3010, acc-0.1200, valid loss-2.2532, acc-0.1906, test loss-2.2526, acc-0.1932\n",
      "Iter-5390, train loss-2.2593, acc-0.1200, valid loss-2.2531, acc-0.1906, test loss-2.2525, acc-0.1934\n",
      "Iter-5400, train loss-2.2548, acc-0.2800, valid loss-2.2530, acc-0.1908, test loss-2.2524, acc-0.1935\n",
      "Iter-5410, train loss-2.2481, acc-0.1600, valid loss-2.2530, acc-0.1908, test loss-2.2523, acc-0.1940\n",
      "Iter-5420, train loss-2.2558, acc-0.1600, valid loss-2.2529, acc-0.1910, test loss-2.2522, acc-0.1938\n",
      "Iter-5430, train loss-2.2839, acc-0.1200, valid loss-2.2528, acc-0.1908, test loss-2.2522, acc-0.1938\n",
      "Iter-5440, train loss-2.2755, acc-0.1800, valid loss-2.2527, acc-0.1910, test loss-2.2521, acc-0.1940\n",
      "Iter-5450, train loss-2.2557, acc-0.2400, valid loss-2.2527, acc-0.1910, test loss-2.2520, acc-0.1943\n",
      "Iter-5460, train loss-2.2630, acc-0.1400, valid loss-2.2526, acc-0.1914, test loss-2.2519, acc-0.1945\n",
      "Iter-5470, train loss-2.2668, acc-0.0600, valid loss-2.2525, acc-0.1916, test loss-2.2518, acc-0.1945\n",
      "Iter-5480, train loss-2.2376, acc-0.2600, valid loss-2.2524, acc-0.1914, test loss-2.2517, acc-0.1948\n",
      "Iter-5490, train loss-2.2325, acc-0.2200, valid loss-2.2523, acc-0.1916, test loss-2.2516, acc-0.1947\n",
      "Iter-5500, train loss-2.2526, acc-0.2800, valid loss-2.2523, acc-0.1918, test loss-2.2515, acc-0.1951\n",
      "Iter-5510, train loss-2.2703, acc-0.1000, valid loss-2.2522, acc-0.1920, test loss-2.2515, acc-0.1952\n",
      "Iter-5520, train loss-2.2593, acc-0.1800, valid loss-2.2521, acc-0.1922, test loss-2.2514, acc-0.1955\n",
      "Iter-5530, train loss-2.2920, acc-0.0800, valid loss-2.2520, acc-0.1922, test loss-2.2513, acc-0.1954\n",
      "Iter-5540, train loss-2.2407, acc-0.2000, valid loss-2.2520, acc-0.1922, test loss-2.2512, acc-0.1954\n",
      "Iter-5550, train loss-2.2444, acc-0.1800, valid loss-2.2519, acc-0.1928, test loss-2.2511, acc-0.1956\n",
      "Iter-5560, train loss-2.2626, acc-0.1800, valid loss-2.2518, acc-0.1922, test loss-2.2510, acc-0.1958\n",
      "Iter-5570, train loss-2.2732, acc-0.1200, valid loss-2.2517, acc-0.1922, test loss-2.2509, acc-0.1960\n",
      "Iter-5580, train loss-2.2660, acc-0.1600, valid loss-2.2516, acc-0.1928, test loss-2.2508, acc-0.1960\n",
      "Iter-5590, train loss-2.2167, acc-0.2600, valid loss-2.2515, acc-0.1930, test loss-2.2508, acc-0.1963\n",
      "Iter-5600, train loss-2.2578, acc-0.1800, valid loss-2.2514, acc-0.1928, test loss-2.2507, acc-0.1963\n",
      "Iter-5610, train loss-2.2600, acc-0.1000, valid loss-2.2514, acc-0.1932, test loss-2.2506, acc-0.1966\n",
      "Iter-5620, train loss-2.2430, acc-0.2200, valid loss-2.2513, acc-0.1932, test loss-2.2505, acc-0.1965\n",
      "Iter-5630, train loss-2.2156, acc-0.3600, valid loss-2.2512, acc-0.1930, test loss-2.2504, acc-0.1968\n",
      "Iter-5640, train loss-2.2668, acc-0.1400, valid loss-2.2511, acc-0.1930, test loss-2.2503, acc-0.1970\n",
      "Iter-5650, train loss-2.2277, acc-0.2400, valid loss-2.2511, acc-0.1942, test loss-2.2502, acc-0.1973\n",
      "Iter-5660, train loss-2.2656, acc-0.1200, valid loss-2.2510, acc-0.1940, test loss-2.2501, acc-0.1975\n",
      "Iter-5670, train loss-2.2512, acc-0.2400, valid loss-2.2509, acc-0.1946, test loss-2.2501, acc-0.1980\n",
      "Iter-5680, train loss-2.2411, acc-0.1600, valid loss-2.2508, acc-0.1952, test loss-2.2500, acc-0.1979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-5690, train loss-2.2476, acc-0.1600, valid loss-2.2507, acc-0.1950, test loss-2.2499, acc-0.1981\n",
      "Iter-5700, train loss-2.2435, acc-0.1600, valid loss-2.2507, acc-0.1956, test loss-2.2498, acc-0.1980\n",
      "Iter-5710, train loss-2.2610, acc-0.2000, valid loss-2.2506, acc-0.1962, test loss-2.2497, acc-0.1979\n",
      "Iter-5720, train loss-2.2541, acc-0.2200, valid loss-2.2505, acc-0.1964, test loss-2.2496, acc-0.1978\n",
      "Iter-5730, train loss-2.2510, acc-0.2200, valid loss-2.2504, acc-0.1970, test loss-2.2495, acc-0.1978\n",
      "Iter-5740, train loss-2.2580, acc-0.1400, valid loss-2.2504, acc-0.1972, test loss-2.2494, acc-0.1985\n",
      "Iter-5750, train loss-2.2526, acc-0.1800, valid loss-2.2503, acc-0.1974, test loss-2.2493, acc-0.1987\n",
      "Iter-5760, train loss-2.2342, acc-0.2400, valid loss-2.2502, acc-0.1968, test loss-2.2493, acc-0.1987\n",
      "Iter-5770, train loss-2.2818, acc-0.1600, valid loss-2.2501, acc-0.1966, test loss-2.2492, acc-0.1987\n",
      "Iter-5780, train loss-2.2531, acc-0.1400, valid loss-2.2500, acc-0.1976, test loss-2.2491, acc-0.1988\n",
      "Iter-5790, train loss-2.2178, acc-0.2000, valid loss-2.2500, acc-0.1978, test loss-2.2490, acc-0.1993\n",
      "Iter-5800, train loss-2.2305, acc-0.3400, valid loss-2.2499, acc-0.1982, test loss-2.2489, acc-0.1992\n",
      "Iter-5810, train loss-2.2383, acc-0.2400, valid loss-2.2498, acc-0.1986, test loss-2.2488, acc-0.1995\n",
      "Iter-5820, train loss-2.2872, acc-0.1000, valid loss-2.2497, acc-0.1984, test loss-2.2487, acc-0.1995\n",
      "Iter-5830, train loss-2.2587, acc-0.1200, valid loss-2.2496, acc-0.1986, test loss-2.2487, acc-0.1998\n",
      "Iter-5840, train loss-2.2516, acc-0.2000, valid loss-2.2496, acc-0.1992, test loss-2.2486, acc-0.1999\n",
      "Iter-5850, train loss-2.2437, acc-0.1800, valid loss-2.2495, acc-0.1992, test loss-2.2485, acc-0.1999\n",
      "Iter-5860, train loss-2.2617, acc-0.2000, valid loss-2.2494, acc-0.1992, test loss-2.2484, acc-0.1996\n",
      "Iter-5870, train loss-2.2776, acc-0.2000, valid loss-2.2493, acc-0.1994, test loss-2.2483, acc-0.2001\n",
      "Iter-5880, train loss-2.2465, acc-0.2400, valid loss-2.2492, acc-0.2000, test loss-2.2482, acc-0.2002\n",
      "Iter-5890, train loss-2.2509, acc-0.2600, valid loss-2.2492, acc-0.2004, test loss-2.2481, acc-0.2006\n",
      "Iter-5900, train loss-2.2079, acc-0.3200, valid loss-2.2491, acc-0.2004, test loss-2.2480, acc-0.2005\n",
      "Iter-5910, train loss-2.2321, acc-0.2800, valid loss-2.2490, acc-0.2000, test loss-2.2480, acc-0.2007\n",
      "Iter-5920, train loss-2.2764, acc-0.1400, valid loss-2.2489, acc-0.2006, test loss-2.2479, acc-0.2005\n",
      "Iter-5930, train loss-2.2571, acc-0.3200, valid loss-2.2488, acc-0.2010, test loss-2.2478, acc-0.2008\n",
      "Iter-5940, train loss-2.2070, acc-0.3400, valid loss-2.2488, acc-0.2010, test loss-2.2477, acc-0.2010\n",
      "Iter-5950, train loss-2.2608, acc-0.1800, valid loss-2.2487, acc-0.2014, test loss-2.2476, acc-0.2015\n",
      "Iter-5960, train loss-2.2582, acc-0.1800, valid loss-2.2486, acc-0.2014, test loss-2.2475, acc-0.2018\n",
      "Iter-5970, train loss-2.2678, acc-0.1400, valid loss-2.2485, acc-0.2012, test loss-2.2474, acc-0.2022\n",
      "Iter-5980, train loss-2.2479, acc-0.2200, valid loss-2.2485, acc-0.2016, test loss-2.2474, acc-0.2025\n",
      "Iter-5990, train loss-2.2574, acc-0.1400, valid loss-2.2484, acc-0.2014, test loss-2.2473, acc-0.2023\n",
      "Iter-6000, train loss-2.2456, acc-0.1600, valid loss-2.2483, acc-0.2016, test loss-2.2472, acc-0.2026\n",
      "Iter-6010, train loss-2.2768, acc-0.2200, valid loss-2.2482, acc-0.2020, test loss-2.2471, acc-0.2028\n",
      "Iter-6020, train loss-2.2486, acc-0.2200, valid loss-2.2482, acc-0.2028, test loss-2.2470, acc-0.2028\n",
      "Iter-6030, train loss-2.2556, acc-0.2400, valid loss-2.2481, acc-0.2030, test loss-2.2470, acc-0.2029\n",
      "Iter-6040, train loss-2.2686, acc-0.1400, valid loss-2.2480, acc-0.2028, test loss-2.2469, acc-0.2028\n",
      "Iter-6050, train loss-2.2450, acc-0.1600, valid loss-2.2479, acc-0.2032, test loss-2.2468, acc-0.2034\n",
      "Iter-6060, train loss-2.2700, acc-0.1200, valid loss-2.2479, acc-0.2032, test loss-2.2467, acc-0.2036\n",
      "Iter-6070, train loss-2.2606, acc-0.1000, valid loss-2.2478, acc-0.2038, test loss-2.2466, acc-0.2035\n",
      "Iter-6080, train loss-2.2616, acc-0.0600, valid loss-2.2477, acc-0.2032, test loss-2.2465, acc-0.2037\n",
      "Iter-6090, train loss-2.2186, acc-0.2800, valid loss-2.2476, acc-0.2034, test loss-2.2464, acc-0.2042\n",
      "Iter-6100, train loss-2.2415, acc-0.2600, valid loss-2.2475, acc-0.2038, test loss-2.2463, acc-0.2044\n",
      "Iter-6110, train loss-2.2586, acc-0.2200, valid loss-2.2475, acc-0.2042, test loss-2.2463, acc-0.2044\n",
      "Iter-6120, train loss-2.2484, acc-0.2800, valid loss-2.2474, acc-0.2044, test loss-2.2462, acc-0.2046\n",
      "Iter-6130, train loss-2.2576, acc-0.1600, valid loss-2.2473, acc-0.2044, test loss-2.2461, acc-0.2050\n",
      "Iter-6140, train loss-2.2352, acc-0.2000, valid loss-2.2472, acc-0.2046, test loss-2.2460, acc-0.2050\n",
      "Iter-6150, train loss-2.2456, acc-0.2000, valid loss-2.2471, acc-0.2052, test loss-2.2459, acc-0.2053\n",
      "Iter-6160, train loss-2.2511, acc-0.1600, valid loss-2.2471, acc-0.2056, test loss-2.2458, acc-0.2057\n",
      "Iter-6170, train loss-2.2343, acc-0.2200, valid loss-2.2470, acc-0.2060, test loss-2.2457, acc-0.2059\n",
      "Iter-6180, train loss-2.2423, acc-0.2200, valid loss-2.2469, acc-0.2062, test loss-2.2457, acc-0.2058\n",
      "Iter-6190, train loss-2.2606, acc-0.1600, valid loss-2.2468, acc-0.2068, test loss-2.2456, acc-0.2062\n",
      "Iter-6200, train loss-2.2353, acc-0.3000, valid loss-2.2468, acc-0.2066, test loss-2.2455, acc-0.2065\n",
      "Iter-6210, train loss-2.2581, acc-0.1400, valid loss-2.2467, acc-0.2066, test loss-2.2454, acc-0.2068\n",
      "Iter-6220, train loss-2.2384, acc-0.2200, valid loss-2.2466, acc-0.2068, test loss-2.2453, acc-0.2069\n",
      "Iter-6230, train loss-2.2390, acc-0.1200, valid loss-2.2465, acc-0.2070, test loss-2.2452, acc-0.2072\n",
      "Iter-6240, train loss-2.2582, acc-0.1000, valid loss-2.2465, acc-0.2072, test loss-2.2451, acc-0.2073\n",
      "Iter-6250, train loss-2.2450, acc-0.3000, valid loss-2.2464, acc-0.2078, test loss-2.2451, acc-0.2073\n",
      "Iter-6260, train loss-2.2497, acc-0.2000, valid loss-2.2463, acc-0.2080, test loss-2.2450, acc-0.2075\n",
      "Iter-6270, train loss-2.2571, acc-0.1600, valid loss-2.2462, acc-0.2078, test loss-2.2449, acc-0.2078\n",
      "Iter-6280, train loss-2.2617, acc-0.1200, valid loss-2.2461, acc-0.2076, test loss-2.2448, acc-0.2078\n",
      "Iter-6290, train loss-2.2781, acc-0.1000, valid loss-2.2461, acc-0.2080, test loss-2.2447, acc-0.2082\n",
      "Iter-6300, train loss-2.2589, acc-0.1400, valid loss-2.2460, acc-0.2084, test loss-2.2446, acc-0.2079\n",
      "Iter-6310, train loss-2.2512, acc-0.2000, valid loss-2.2459, acc-0.2084, test loss-2.2445, acc-0.2081\n",
      "Iter-6320, train loss-2.2629, acc-0.1400, valid loss-2.2458, acc-0.2092, test loss-2.2444, acc-0.2083\n",
      "Iter-6330, train loss-2.2665, acc-0.2400, valid loss-2.2457, acc-0.2088, test loss-2.2444, acc-0.2086\n",
      "Iter-6340, train loss-2.2340, acc-0.2200, valid loss-2.2457, acc-0.2092, test loss-2.2443, acc-0.2089\n",
      "Iter-6350, train loss-2.2629, acc-0.1600, valid loss-2.2456, acc-0.2094, test loss-2.2442, acc-0.2089\n",
      "Iter-6360, train loss-2.2340, acc-0.1400, valid loss-2.2455, acc-0.2098, test loss-2.2441, acc-0.2091\n",
      "Iter-6370, train loss-2.2563, acc-0.2000, valid loss-2.2454, acc-0.2098, test loss-2.2440, acc-0.2095\n",
      "Iter-6380, train loss-2.2464, acc-0.2800, valid loss-2.2453, acc-0.2100, test loss-2.2439, acc-0.2098\n",
      "Iter-6390, train loss-2.2385, acc-0.3000, valid loss-2.2453, acc-0.2104, test loss-2.2438, acc-0.2100\n",
      "Iter-6400, train loss-2.2064, acc-0.2200, valid loss-2.2452, acc-0.2100, test loss-2.2438, acc-0.2098\n",
      "Iter-6410, train loss-2.2452, acc-0.2800, valid loss-2.2451, acc-0.2104, test loss-2.2437, acc-0.2101\n",
      "Iter-6420, train loss-2.2453, acc-0.1200, valid loss-2.2450, acc-0.2106, test loss-2.2436, acc-0.2104\n",
      "Iter-6430, train loss-2.2465, acc-0.2000, valid loss-2.2450, acc-0.2110, test loss-2.2435, acc-0.2106\n",
      "Iter-6440, train loss-2.2394, acc-0.2400, valid loss-2.2449, acc-0.2114, test loss-2.2434, acc-0.2106\n",
      "Iter-6450, train loss-2.2610, acc-0.1600, valid loss-2.2448, acc-0.2110, test loss-2.2433, acc-0.2106\n",
      "Iter-6460, train loss-2.2239, acc-0.1800, valid loss-2.2447, acc-0.2112, test loss-2.2432, acc-0.2108\n",
      "Iter-6470, train loss-2.2319, acc-0.2200, valid loss-2.2446, acc-0.2120, test loss-2.2431, acc-0.2108\n",
      "Iter-6480, train loss-2.2594, acc-0.1800, valid loss-2.2446, acc-0.2122, test loss-2.2431, acc-0.2109\n",
      "Iter-6490, train loss-2.2258, acc-0.2000, valid loss-2.2445, acc-0.2120, test loss-2.2430, acc-0.2114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-6500, train loss-2.2246, acc-0.2400, valid loss-2.2444, acc-0.2124, test loss-2.2429, acc-0.2115\n",
      "Iter-6510, train loss-2.2309, acc-0.2400, valid loss-2.2443, acc-0.2130, test loss-2.2428, acc-0.2117\n",
      "Iter-6520, train loss-2.2474, acc-0.1800, valid loss-2.2443, acc-0.2132, test loss-2.2427, acc-0.2116\n",
      "Iter-6530, train loss-2.2269, acc-0.2000, valid loss-2.2442, acc-0.2130, test loss-2.2426, acc-0.2118\n",
      "Iter-6540, train loss-2.2231, acc-0.2400, valid loss-2.2441, acc-0.2132, test loss-2.2426, acc-0.2118\n",
      "Iter-6550, train loss-2.2420, acc-0.3000, valid loss-2.2440, acc-0.2132, test loss-2.2425, acc-0.2119\n",
      "Iter-6560, train loss-2.2325, acc-0.2400, valid loss-2.2439, acc-0.2136, test loss-2.2424, acc-0.2121\n",
      "Iter-6570, train loss-2.2349, acc-0.2000, valid loss-2.2439, acc-0.2136, test loss-2.2423, acc-0.2124\n",
      "Iter-6580, train loss-2.2462, acc-0.1800, valid loss-2.2438, acc-0.2138, test loss-2.2422, acc-0.2126\n",
      "Iter-6590, train loss-2.2256, acc-0.2200, valid loss-2.2437, acc-0.2140, test loss-2.2421, acc-0.2130\n",
      "Iter-6600, train loss-2.2321, acc-0.1800, valid loss-2.2436, acc-0.2144, test loss-2.2420, acc-0.2131\n",
      "Iter-6610, train loss-2.2506, acc-0.1600, valid loss-2.2436, acc-0.2148, test loss-2.2420, acc-0.2132\n",
      "Iter-6620, train loss-2.2701, acc-0.1000, valid loss-2.2435, acc-0.2152, test loss-2.2419, acc-0.2136\n",
      "Iter-6630, train loss-2.2334, acc-0.3000, valid loss-2.2434, acc-0.2158, test loss-2.2418, acc-0.2137\n",
      "Iter-6640, train loss-2.2374, acc-0.2600, valid loss-2.2433, acc-0.2154, test loss-2.2417, acc-0.2141\n",
      "Iter-6650, train loss-2.2421, acc-0.2400, valid loss-2.2432, acc-0.2162, test loss-2.2416, acc-0.2141\n",
      "Iter-6660, train loss-2.2483, acc-0.1800, valid loss-2.2432, acc-0.2158, test loss-2.2415, acc-0.2144\n",
      "Iter-6670, train loss-2.2305, acc-0.1800, valid loss-2.2431, acc-0.2164, test loss-2.2414, acc-0.2144\n",
      "Iter-6680, train loss-2.2140, acc-0.3400, valid loss-2.2430, acc-0.2166, test loss-2.2413, acc-0.2150\n",
      "Iter-6690, train loss-2.2274, acc-0.2200, valid loss-2.2429, acc-0.2166, test loss-2.2413, acc-0.2152\n",
      "Iter-6700, train loss-2.2651, acc-0.1600, valid loss-2.2429, acc-0.2170, test loss-2.2412, acc-0.2156\n",
      "Iter-6710, train loss-2.2461, acc-0.3000, valid loss-2.2428, acc-0.2174, test loss-2.2411, acc-0.2156\n",
      "Iter-6720, train loss-2.2473, acc-0.2200, valid loss-2.2427, acc-0.2180, test loss-2.2410, acc-0.2155\n",
      "Iter-6730, train loss-2.2495, acc-0.2200, valid loss-2.2426, acc-0.2176, test loss-2.2409, acc-0.2153\n",
      "Iter-6740, train loss-2.2433, acc-0.1600, valid loss-2.2425, acc-0.2180, test loss-2.2408, acc-0.2157\n",
      "Iter-6750, train loss-2.2369, acc-0.1800, valid loss-2.2425, acc-0.2186, test loss-2.2407, acc-0.2161\n",
      "Iter-6760, train loss-2.2494, acc-0.1400, valid loss-2.2424, acc-0.2188, test loss-2.2407, acc-0.2162\n",
      "Iter-6770, train loss-2.2504, acc-0.2400, valid loss-2.2423, acc-0.2188, test loss-2.2406, acc-0.2166\n",
      "Iter-6780, train loss-2.2505, acc-0.1800, valid loss-2.2422, acc-0.2192, test loss-2.2405, acc-0.2167\n",
      "Iter-6790, train loss-2.2148, acc-0.3400, valid loss-2.2422, acc-0.2192, test loss-2.2404, acc-0.2172\n",
      "Iter-6800, train loss-2.2703, acc-0.0400, valid loss-2.2421, acc-0.2188, test loss-2.2403, acc-0.2173\n",
      "Iter-6810, train loss-2.2389, acc-0.2200, valid loss-2.2420, acc-0.2190, test loss-2.2402, acc-0.2176\n",
      "Iter-6820, train loss-2.2434, acc-0.2000, valid loss-2.2419, acc-0.2196, test loss-2.2402, acc-0.2176\n",
      "Iter-6830, train loss-2.2528, acc-0.2400, valid loss-2.2419, acc-0.2194, test loss-2.2401, acc-0.2177\n",
      "Iter-6840, train loss-2.2229, acc-0.3000, valid loss-2.2418, acc-0.2198, test loss-2.2400, acc-0.2181\n",
      "Iter-6850, train loss-2.2399, acc-0.2000, valid loss-2.2417, acc-0.2198, test loss-2.2399, acc-0.2184\n",
      "Iter-6860, train loss-2.2514, acc-0.0800, valid loss-2.2416, acc-0.2208, test loss-2.2398, acc-0.2184\n",
      "Iter-6870, train loss-2.2331, acc-0.2600, valid loss-2.2415, acc-0.2212, test loss-2.2397, acc-0.2186\n",
      "Iter-6880, train loss-2.2626, acc-0.2400, valid loss-2.2415, acc-0.2206, test loss-2.2396, acc-0.2189\n",
      "Iter-6890, train loss-2.2279, acc-0.1600, valid loss-2.2414, acc-0.2206, test loss-2.2395, acc-0.2190\n",
      "Iter-6900, train loss-2.2296, acc-0.2200, valid loss-2.2413, acc-0.2210, test loss-2.2395, acc-0.2193\n",
      "Iter-6910, train loss-2.2469, acc-0.1400, valid loss-2.2412, acc-0.2214, test loss-2.2394, acc-0.2196\n",
      "Iter-6920, train loss-2.2685, acc-0.1400, valid loss-2.2411, acc-0.2212, test loss-2.2393, acc-0.2195\n",
      "Iter-6930, train loss-2.2339, acc-0.1800, valid loss-2.2411, acc-0.2214, test loss-2.2392, acc-0.2196\n",
      "Iter-6940, train loss-2.2495, acc-0.1200, valid loss-2.2410, acc-0.2214, test loss-2.2391, acc-0.2199\n",
      "Iter-6950, train loss-2.2456, acc-0.2000, valid loss-2.2409, acc-0.2214, test loss-2.2390, acc-0.2200\n",
      "Iter-6960, train loss-2.2567, acc-0.1200, valid loss-2.2408, acc-0.2216, test loss-2.2389, acc-0.2203\n",
      "Iter-6970, train loss-2.2395, acc-0.1800, valid loss-2.2407, acc-0.2224, test loss-2.2389, acc-0.2202\n",
      "Iter-6980, train loss-2.2416, acc-0.2000, valid loss-2.2407, acc-0.2220, test loss-2.2388, acc-0.2205\n",
      "Iter-6990, train loss-2.2366, acc-0.2600, valid loss-2.2406, acc-0.2226, test loss-2.2387, acc-0.2210\n",
      "Iter-7000, train loss-2.2315, acc-0.2000, valid loss-2.2405, acc-0.2226, test loss-2.2386, acc-0.2218\n",
      "Iter-7010, train loss-2.2449, acc-0.1400, valid loss-2.2405, acc-0.2226, test loss-2.2385, acc-0.2220\n",
      "Iter-7020, train loss-2.2663, acc-0.1200, valid loss-2.2404, acc-0.2228, test loss-2.2385, acc-0.2220\n",
      "Iter-7030, train loss-2.2381, acc-0.2000, valid loss-2.2403, acc-0.2228, test loss-2.2384, acc-0.2221\n",
      "Iter-7040, train loss-2.2562, acc-0.2800, valid loss-2.2402, acc-0.2230, test loss-2.2383, acc-0.2226\n",
      "Iter-7050, train loss-2.2496, acc-0.1000, valid loss-2.2402, acc-0.2230, test loss-2.2382, acc-0.2228\n",
      "Iter-7060, train loss-2.2418, acc-0.2800, valid loss-2.2401, acc-0.2234, test loss-2.2381, acc-0.2226\n",
      "Iter-7070, train loss-2.2349, acc-0.1200, valid loss-2.2400, acc-0.2232, test loss-2.2381, acc-0.2230\n",
      "Iter-7080, train loss-2.2537, acc-0.2600, valid loss-2.2399, acc-0.2232, test loss-2.2380, acc-0.2233\n",
      "Iter-7090, train loss-2.2405, acc-0.2000, valid loss-2.2399, acc-0.2232, test loss-2.2379, acc-0.2234\n",
      "Iter-7100, train loss-2.2478, acc-0.1400, valid loss-2.2398, acc-0.2238, test loss-2.2378, acc-0.2234\n",
      "Iter-7110, train loss-2.2140, acc-0.3600, valid loss-2.2397, acc-0.2240, test loss-2.2377, acc-0.2231\n",
      "Iter-7120, train loss-2.2631, acc-0.1200, valid loss-2.2396, acc-0.2240, test loss-2.2376, acc-0.2237\n",
      "Iter-7130, train loss-2.2353, acc-0.2200, valid loss-2.2396, acc-0.2242, test loss-2.2375, acc-0.2238\n",
      "Iter-7140, train loss-2.2573, acc-0.1800, valid loss-2.2395, acc-0.2246, test loss-2.2375, acc-0.2240\n",
      "Iter-7150, train loss-2.2492, acc-0.2200, valid loss-2.2394, acc-0.2244, test loss-2.2374, acc-0.2242\n",
      "Iter-7160, train loss-2.2568, acc-0.1400, valid loss-2.2393, acc-0.2250, test loss-2.2373, acc-0.2243\n",
      "Iter-7170, train loss-2.2356, acc-0.2800, valid loss-2.2392, acc-0.2244, test loss-2.2372, acc-0.2244\n",
      "Iter-7180, train loss-2.2656, acc-0.1400, valid loss-2.2392, acc-0.2246, test loss-2.2371, acc-0.2246\n",
      "Iter-7190, train loss-2.2463, acc-0.1800, valid loss-2.2391, acc-0.2248, test loss-2.2370, acc-0.2242\n",
      "Iter-7200, train loss-2.2430, acc-0.2600, valid loss-2.2390, acc-0.2254, test loss-2.2369, acc-0.2244\n",
      "Iter-7210, train loss-2.2615, acc-0.2600, valid loss-2.2389, acc-0.2254, test loss-2.2368, acc-0.2248\n",
      "Iter-7220, train loss-2.2269, acc-0.3000, valid loss-2.2388, acc-0.2250, test loss-2.2368, acc-0.2249\n",
      "Iter-7230, train loss-2.2527, acc-0.2000, valid loss-2.2388, acc-0.2250, test loss-2.2367, acc-0.2253\n",
      "Iter-7240, train loss-2.2357, acc-0.3200, valid loss-2.2387, acc-0.2252, test loss-2.2366, acc-0.2252\n",
      "Iter-7250, train loss-2.2291, acc-0.3200, valid loss-2.2386, acc-0.2254, test loss-2.2365, acc-0.2253\n",
      "Iter-7260, train loss-2.2415, acc-0.2200, valid loss-2.2385, acc-0.2254, test loss-2.2364, acc-0.2254\n",
      "Iter-7270, train loss-2.2205, acc-0.3000, valid loss-2.2385, acc-0.2256, test loss-2.2363, acc-0.2256\n",
      "Iter-7280, train loss-2.2383, acc-0.2600, valid loss-2.2384, acc-0.2262, test loss-2.2363, acc-0.2256\n",
      "Iter-7290, train loss-2.2460, acc-0.2600, valid loss-2.2383, acc-0.2264, test loss-2.2362, acc-0.2257\n",
      "Iter-7300, train loss-2.2811, acc-0.1000, valid loss-2.2382, acc-0.2264, test loss-2.2361, acc-0.2260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-7310, train loss-2.2094, acc-0.3200, valid loss-2.2381, acc-0.2266, test loss-2.2360, acc-0.2265\n",
      "Iter-7320, train loss-2.2409, acc-0.2200, valid loss-2.2381, acc-0.2266, test loss-2.2359, acc-0.2268\n",
      "Iter-7330, train loss-2.2358, acc-0.2400, valid loss-2.2380, acc-0.2270, test loss-2.2358, acc-0.2269\n",
      "Iter-7340, train loss-2.2326, acc-0.2800, valid loss-2.2379, acc-0.2272, test loss-2.2358, acc-0.2268\n",
      "Iter-7350, train loss-2.2333, acc-0.2400, valid loss-2.2378, acc-0.2276, test loss-2.2357, acc-0.2269\n",
      "Iter-7360, train loss-2.2298, acc-0.3000, valid loss-2.2378, acc-0.2280, test loss-2.2356, acc-0.2266\n",
      "Iter-7370, train loss-2.2307, acc-0.2000, valid loss-2.2377, acc-0.2282, test loss-2.2355, acc-0.2270\n",
      "Iter-7380, train loss-2.2603, acc-0.1800, valid loss-2.2376, acc-0.2280, test loss-2.2354, acc-0.2276\n",
      "Iter-7390, train loss-2.2447, acc-0.1600, valid loss-2.2375, acc-0.2282, test loss-2.2353, acc-0.2279\n",
      "Iter-7400, train loss-2.2478, acc-0.1600, valid loss-2.2375, acc-0.2276, test loss-2.2353, acc-0.2279\n",
      "Iter-7410, train loss-2.2418, acc-0.2200, valid loss-2.2374, acc-0.2280, test loss-2.2352, acc-0.2279\n",
      "Iter-7420, train loss-2.2433, acc-0.2400, valid loss-2.2373, acc-0.2284, test loss-2.2351, acc-0.2282\n",
      "Iter-7430, train loss-2.2428, acc-0.2800, valid loss-2.2372, acc-0.2290, test loss-2.2350, acc-0.2287\n",
      "Iter-7440, train loss-2.2416, acc-0.2400, valid loss-2.2371, acc-0.2294, test loss-2.2349, acc-0.2292\n",
      "Iter-7450, train loss-2.2598, acc-0.1600, valid loss-2.2371, acc-0.2296, test loss-2.2348, acc-0.2295\n",
      "Iter-7460, train loss-2.2330, acc-0.3000, valid loss-2.2370, acc-0.2294, test loss-2.2348, acc-0.2295\n",
      "Iter-7470, train loss-2.2306, acc-0.1600, valid loss-2.2369, acc-0.2296, test loss-2.2347, acc-0.2296\n",
      "Iter-7480, train loss-2.2470, acc-0.2400, valid loss-2.2368, acc-0.2290, test loss-2.2346, acc-0.2302\n",
      "Iter-7490, train loss-2.2329, acc-0.2600, valid loss-2.2368, acc-0.2294, test loss-2.2345, acc-0.2305\n",
      "Iter-7500, train loss-2.2475, acc-0.2600, valid loss-2.2367, acc-0.2300, test loss-2.2344, acc-0.2308\n",
      "Iter-7510, train loss-2.2397, acc-0.2000, valid loss-2.2366, acc-0.2298, test loss-2.2343, acc-0.2309\n",
      "Iter-7520, train loss-2.2411, acc-0.1400, valid loss-2.2365, acc-0.2300, test loss-2.2343, acc-0.2312\n",
      "Iter-7530, train loss-2.2540, acc-0.1600, valid loss-2.2365, acc-0.2304, test loss-2.2342, acc-0.2313\n",
      "Iter-7540, train loss-2.2340, acc-0.2000, valid loss-2.2364, acc-0.2308, test loss-2.2341, acc-0.2316\n",
      "Iter-7550, train loss-2.2408, acc-0.1600, valid loss-2.2363, acc-0.2300, test loss-2.2340, acc-0.2316\n",
      "Iter-7560, train loss-2.2332, acc-0.1800, valid loss-2.2362, acc-0.2302, test loss-2.2339, acc-0.2319\n",
      "Iter-7570, train loss-2.2171, acc-0.2800, valid loss-2.2362, acc-0.2298, test loss-2.2338, acc-0.2318\n",
      "Iter-7580, train loss-2.2267, acc-0.2600, valid loss-2.2361, acc-0.2302, test loss-2.2338, acc-0.2319\n",
      "Iter-7590, train loss-2.2423, acc-0.2800, valid loss-2.2360, acc-0.2302, test loss-2.2337, acc-0.2321\n",
      "Iter-7600, train loss-2.2403, acc-0.1800, valid loss-2.2359, acc-0.2310, test loss-2.2336, acc-0.2318\n",
      "Iter-7610, train loss-2.2369, acc-0.2000, valid loss-2.2359, acc-0.2310, test loss-2.2335, acc-0.2321\n",
      "Iter-7620, train loss-2.2284, acc-0.2800, valid loss-2.2358, acc-0.2310, test loss-2.2334, acc-0.2325\n",
      "Iter-7630, train loss-2.2305, acc-0.1800, valid loss-2.2357, acc-0.2310, test loss-2.2333, acc-0.2326\n",
      "Iter-7640, train loss-2.2701, acc-0.2000, valid loss-2.2356, acc-0.2308, test loss-2.2332, acc-0.2331\n",
      "Iter-7650, train loss-2.2477, acc-0.2200, valid loss-2.2356, acc-0.2308, test loss-2.2332, acc-0.2331\n",
      "Iter-7660, train loss-2.2256, acc-0.2800, valid loss-2.2355, acc-0.2308, test loss-2.2331, acc-0.2339\n",
      "Iter-7670, train loss-2.2445, acc-0.2400, valid loss-2.2354, acc-0.2310, test loss-2.2330, acc-0.2341\n",
      "Iter-7680, train loss-2.2654, acc-0.1800, valid loss-2.2353, acc-0.2316, test loss-2.2329, acc-0.2343\n",
      "Iter-7690, train loss-2.2218, acc-0.3200, valid loss-2.2352, acc-0.2318, test loss-2.2328, acc-0.2344\n",
      "Iter-7700, train loss-2.2733, acc-0.1200, valid loss-2.2352, acc-0.2318, test loss-2.2328, acc-0.2346\n",
      "Iter-7710, train loss-2.2300, acc-0.2800, valid loss-2.2351, acc-0.2316, test loss-2.2327, acc-0.2348\n",
      "Iter-7720, train loss-2.2226, acc-0.3200, valid loss-2.2350, acc-0.2318, test loss-2.2326, acc-0.2349\n",
      "Iter-7730, train loss-2.2074, acc-0.2600, valid loss-2.2350, acc-0.2318, test loss-2.2325, acc-0.2351\n",
      "Iter-7740, train loss-2.2298, acc-0.2400, valid loss-2.2349, acc-0.2324, test loss-2.2324, acc-0.2352\n",
      "Iter-7750, train loss-2.2367, acc-0.1800, valid loss-2.2348, acc-0.2332, test loss-2.2323, acc-0.2355\n",
      "Iter-7760, train loss-2.2300, acc-0.2600, valid loss-2.2347, acc-0.2328, test loss-2.2323, acc-0.2357\n",
      "Iter-7770, train loss-2.2670, acc-0.1800, valid loss-2.2347, acc-0.2334, test loss-2.2322, acc-0.2364\n",
      "Iter-7780, train loss-2.2346, acc-0.3000, valid loss-2.2346, acc-0.2334, test loss-2.2321, acc-0.2365\n",
      "Iter-7790, train loss-2.2532, acc-0.1400, valid loss-2.2345, acc-0.2336, test loss-2.2320, acc-0.2369\n",
      "Iter-7800, train loss-2.2396, acc-0.2000, valid loss-2.2344, acc-0.2336, test loss-2.2319, acc-0.2366\n",
      "Iter-7810, train loss-2.2263, acc-0.2800, valid loss-2.2344, acc-0.2344, test loss-2.2319, acc-0.2371\n",
      "Iter-7820, train loss-2.2635, acc-0.2200, valid loss-2.2343, acc-0.2348, test loss-2.2318, acc-0.2372\n",
      "Iter-7830, train loss-2.2197, acc-0.2400, valid loss-2.2342, acc-0.2350, test loss-2.2317, acc-0.2374\n",
      "Iter-7840, train loss-2.1946, acc-0.3800, valid loss-2.2341, acc-0.2352, test loss-2.2316, acc-0.2377\n",
      "Iter-7850, train loss-2.2242, acc-0.3400, valid loss-2.2340, acc-0.2348, test loss-2.2315, acc-0.2379\n",
      "Iter-7860, train loss-2.2366, acc-0.2400, valid loss-2.2340, acc-0.2358, test loss-2.2314, acc-0.2381\n",
      "Iter-7870, train loss-2.2227, acc-0.2600, valid loss-2.2339, acc-0.2358, test loss-2.2314, acc-0.2380\n",
      "Iter-7880, train loss-2.2486, acc-0.2000, valid loss-2.2338, acc-0.2356, test loss-2.2313, acc-0.2383\n",
      "Iter-7890, train loss-2.2131, acc-0.2600, valid loss-2.2338, acc-0.2360, test loss-2.2312, acc-0.2384\n",
      "Iter-7900, train loss-2.2291, acc-0.2000, valid loss-2.2337, acc-0.2358, test loss-2.2311, acc-0.2386\n",
      "Iter-7910, train loss-2.2367, acc-0.2400, valid loss-2.2336, acc-0.2358, test loss-2.2310, acc-0.2387\n",
      "Iter-7920, train loss-2.2142, acc-0.2600, valid loss-2.2335, acc-0.2358, test loss-2.2310, acc-0.2394\n",
      "Iter-7930, train loss-2.2668, acc-0.1200, valid loss-2.2334, acc-0.2364, test loss-2.2309, acc-0.2395\n",
      "Iter-7940, train loss-2.2433, acc-0.2000, valid loss-2.2334, acc-0.2366, test loss-2.2308, acc-0.2398\n",
      "Iter-7950, train loss-2.2815, acc-0.2200, valid loss-2.2333, acc-0.2370, test loss-2.2307, acc-0.2400\n",
      "Iter-7960, train loss-2.2493, acc-0.2400, valid loss-2.2332, acc-0.2374, test loss-2.2306, acc-0.2401\n",
      "Iter-7970, train loss-2.2201, acc-0.1800, valid loss-2.2331, acc-0.2374, test loss-2.2305, acc-0.2401\n",
      "Iter-7980, train loss-2.2200, acc-0.3600, valid loss-2.2331, acc-0.2382, test loss-2.2304, acc-0.2401\n",
      "Iter-7990, train loss-2.2273, acc-0.2400, valid loss-2.2330, acc-0.2386, test loss-2.2303, acc-0.2404\n",
      "Iter-8000, train loss-2.2267, acc-0.2400, valid loss-2.2329, acc-0.2390, test loss-2.2303, acc-0.2401\n",
      "Iter-8010, train loss-2.2449, acc-0.2400, valid loss-2.2328, acc-0.2384, test loss-2.2302, acc-0.2403\n",
      "Iter-8020, train loss-2.2554, acc-0.2000, valid loss-2.2328, acc-0.2386, test loss-2.2301, acc-0.2404\n",
      "Iter-8030, train loss-2.2194, acc-0.1800, valid loss-2.2327, acc-0.2390, test loss-2.2300, acc-0.2408\n",
      "Iter-8040, train loss-2.2223, acc-0.3000, valid loss-2.2326, acc-0.2390, test loss-2.2299, acc-0.2410\n",
      "Iter-8050, train loss-2.2372, acc-0.2400, valid loss-2.2325, acc-0.2392, test loss-2.2299, acc-0.2414\n",
      "Iter-8060, train loss-2.2156, acc-0.3200, valid loss-2.2325, acc-0.2396, test loss-2.2298, acc-0.2415\n",
      "Iter-8070, train loss-2.2527, acc-0.2000, valid loss-2.2324, acc-0.2396, test loss-2.2297, acc-0.2416\n",
      "Iter-8080, train loss-2.2421, acc-0.2000, valid loss-2.2323, acc-0.2398, test loss-2.2296, acc-0.2420\n",
      "Iter-8090, train loss-2.2263, acc-0.2200, valid loss-2.2322, acc-0.2402, test loss-2.2295, acc-0.2419\n",
      "Iter-8100, train loss-2.2268, acc-0.2600, valid loss-2.2322, acc-0.2398, test loss-2.2294, acc-0.2423\n",
      "Iter-8110, train loss-2.2214, acc-0.2800, valid loss-2.2321, acc-0.2400, test loss-2.2294, acc-0.2423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-8120, train loss-2.2330, acc-0.2200, valid loss-2.2320, acc-0.2404, test loss-2.2293, acc-0.2425\n",
      "Iter-8130, train loss-2.2258, acc-0.2000, valid loss-2.2319, acc-0.2406, test loss-2.2292, acc-0.2430\n",
      "Iter-8140, train loss-2.2548, acc-0.1200, valid loss-2.2318, acc-0.2408, test loss-2.2291, acc-0.2431\n",
      "Iter-8150, train loss-2.2424, acc-0.3400, valid loss-2.2318, acc-0.2412, test loss-2.2290, acc-0.2434\n",
      "Iter-8160, train loss-2.2141, acc-0.3000, valid loss-2.2317, acc-0.2416, test loss-2.2290, acc-0.2435\n",
      "Iter-8170, train loss-2.2241, acc-0.2800, valid loss-2.2316, acc-0.2414, test loss-2.2289, acc-0.2433\n",
      "Iter-8180, train loss-2.2466, acc-0.2800, valid loss-2.2316, acc-0.2418, test loss-2.2288, acc-0.2439\n",
      "Iter-8190, train loss-2.2304, acc-0.2000, valid loss-2.2315, acc-0.2420, test loss-2.2287, acc-0.2442\n",
      "Iter-8200, train loss-2.2589, acc-0.1800, valid loss-2.2314, acc-0.2422, test loss-2.2286, acc-0.2444\n",
      "Iter-8210, train loss-2.2402, acc-0.2600, valid loss-2.2313, acc-0.2430, test loss-2.2286, acc-0.2446\n",
      "Iter-8220, train loss-2.2483, acc-0.2600, valid loss-2.2313, acc-0.2430, test loss-2.2285, acc-0.2449\n",
      "Iter-8230, train loss-2.2460, acc-0.1800, valid loss-2.2312, acc-0.2432, test loss-2.2284, acc-0.2449\n",
      "Iter-8240, train loss-2.2447, acc-0.1200, valid loss-2.2311, acc-0.2432, test loss-2.2283, acc-0.2454\n",
      "Iter-8250, train loss-2.2524, acc-0.2200, valid loss-2.2310, acc-0.2430, test loss-2.2282, acc-0.2455\n",
      "Iter-8260, train loss-2.2673, acc-0.1800, valid loss-2.2310, acc-0.2438, test loss-2.2282, acc-0.2452\n",
      "Iter-8270, train loss-2.2286, acc-0.2400, valid loss-2.2309, acc-0.2440, test loss-2.2281, acc-0.2454\n",
      "Iter-8280, train loss-2.2507, acc-0.2400, valid loss-2.2308, acc-0.2440, test loss-2.2280, acc-0.2460\n",
      "Iter-8290, train loss-2.2161, acc-0.2800, valid loss-2.2307, acc-0.2438, test loss-2.2279, acc-0.2464\n",
      "Iter-8300, train loss-2.2053, acc-0.3000, valid loss-2.2307, acc-0.2442, test loss-2.2278, acc-0.2468\n",
      "Iter-8310, train loss-2.2635, acc-0.1000, valid loss-2.2306, acc-0.2444, test loss-2.2277, acc-0.2466\n",
      "Iter-8320, train loss-2.2167, acc-0.2600, valid loss-2.2305, acc-0.2446, test loss-2.2277, acc-0.2474\n",
      "Iter-8330, train loss-2.2307, acc-0.2600, valid loss-2.2304, acc-0.2446, test loss-2.2276, acc-0.2475\n",
      "Iter-8340, train loss-2.2213, acc-0.2200, valid loss-2.2304, acc-0.2450, test loss-2.2275, acc-0.2476\n",
      "Iter-8350, train loss-2.2332, acc-0.2200, valid loss-2.2303, acc-0.2450, test loss-2.2274, acc-0.2480\n",
      "Iter-8360, train loss-2.2321, acc-0.2200, valid loss-2.2302, acc-0.2456, test loss-2.2273, acc-0.2483\n",
      "Iter-8370, train loss-2.2434, acc-0.2200, valid loss-2.2301, acc-0.2454, test loss-2.2273, acc-0.2485\n",
      "Iter-8380, train loss-2.2168, acc-0.2400, valid loss-2.2301, acc-0.2456, test loss-2.2272, acc-0.2488\n",
      "Iter-8390, train loss-2.2326, acc-0.3400, valid loss-2.2300, acc-0.2458, test loss-2.2271, acc-0.2489\n",
      "Iter-8400, train loss-2.2114, acc-0.3200, valid loss-2.2299, acc-0.2458, test loss-2.2270, acc-0.2488\n",
      "Iter-8410, train loss-2.2309, acc-0.1600, valid loss-2.2298, acc-0.2458, test loss-2.2269, acc-0.2487\n",
      "Iter-8420, train loss-2.2429, acc-0.2400, valid loss-2.2298, acc-0.2458, test loss-2.2268, acc-0.2490\n",
      "Iter-8430, train loss-2.2132, acc-0.2800, valid loss-2.2297, acc-0.2464, test loss-2.2268, acc-0.2487\n",
      "Iter-8440, train loss-2.2028, acc-0.4000, valid loss-2.2296, acc-0.2474, test loss-2.2267, acc-0.2487\n",
      "Iter-8450, train loss-2.2256, acc-0.3200, valid loss-2.2295, acc-0.2474, test loss-2.2266, acc-0.2489\n",
      "Iter-8460, train loss-2.2092, acc-0.2600, valid loss-2.2294, acc-0.2478, test loss-2.2265, acc-0.2491\n",
      "Iter-8470, train loss-2.2037, acc-0.3400, valid loss-2.2294, acc-0.2478, test loss-2.2264, acc-0.2490\n",
      "Iter-8480, train loss-2.2087, acc-0.3400, valid loss-2.2293, acc-0.2484, test loss-2.2263, acc-0.2489\n",
      "Iter-8490, train loss-2.2331, acc-0.2800, valid loss-2.2292, acc-0.2482, test loss-2.2262, acc-0.2499\n",
      "Iter-8500, train loss-2.2074, acc-0.3800, valid loss-2.2291, acc-0.2490, test loss-2.2262, acc-0.2491\n",
      "Iter-8510, train loss-2.2139, acc-0.3000, valid loss-2.2291, acc-0.2486, test loss-2.2261, acc-0.2495\n",
      "Iter-8520, train loss-2.2132, acc-0.3200, valid loss-2.2290, acc-0.2488, test loss-2.2260, acc-0.2498\n",
      "Iter-8530, train loss-2.2402, acc-0.1600, valid loss-2.2289, acc-0.2490, test loss-2.2259, acc-0.2501\n",
      "Iter-8540, train loss-2.2073, acc-0.2800, valid loss-2.2288, acc-0.2502, test loss-2.2258, acc-0.2502\n",
      "Iter-8550, train loss-2.2137, acc-0.3000, valid loss-2.2287, acc-0.2492, test loss-2.2257, acc-0.2504\n",
      "Iter-8560, train loss-2.2228, acc-0.1800, valid loss-2.2287, acc-0.2494, test loss-2.2257, acc-0.2508\n",
      "Iter-8570, train loss-2.2110, acc-0.2800, valid loss-2.2286, acc-0.2498, test loss-2.2256, acc-0.2510\n",
      "Iter-8580, train loss-2.2573, acc-0.2200, valid loss-2.2285, acc-0.2496, test loss-2.2255, acc-0.2512\n",
      "Iter-8590, train loss-2.2145, acc-0.3200, valid loss-2.2284, acc-0.2498, test loss-2.2254, acc-0.2512\n",
      "Iter-8600, train loss-2.2427, acc-0.1200, valid loss-2.2284, acc-0.2500, test loss-2.2253, acc-0.2517\n",
      "Iter-8610, train loss-2.2417, acc-0.2000, valid loss-2.2283, acc-0.2502, test loss-2.2253, acc-0.2518\n",
      "Iter-8620, train loss-2.2239, acc-0.2600, valid loss-2.2282, acc-0.2508, test loss-2.2252, acc-0.2524\n",
      "Iter-8630, train loss-2.2127, acc-0.3000, valid loss-2.2281, acc-0.2512, test loss-2.2251, acc-0.2523\n",
      "Iter-8640, train loss-2.2100, acc-0.2400, valid loss-2.2281, acc-0.2514, test loss-2.2250, acc-0.2523\n",
      "Iter-8650, train loss-2.2164, acc-0.3400, valid loss-2.2280, acc-0.2516, test loss-2.2249, acc-0.2524\n",
      "Iter-8660, train loss-2.2052, acc-0.3200, valid loss-2.2279, acc-0.2514, test loss-2.2249, acc-0.2524\n",
      "Iter-8670, train loss-2.2174, acc-0.2600, valid loss-2.2278, acc-0.2520, test loss-2.2248, acc-0.2526\n",
      "Iter-8680, train loss-2.1994, acc-0.3400, valid loss-2.2278, acc-0.2522, test loss-2.2247, acc-0.2528\n",
      "Iter-8690, train loss-2.2202, acc-0.2200, valid loss-2.2277, acc-0.2516, test loss-2.2246, acc-0.2530\n",
      "Iter-8700, train loss-2.2263, acc-0.2000, valid loss-2.2276, acc-0.2516, test loss-2.2245, acc-0.2531\n",
      "Iter-8710, train loss-2.2497, acc-0.2200, valid loss-2.2275, acc-0.2522, test loss-2.2244, acc-0.2532\n",
      "Iter-8720, train loss-2.2107, acc-0.2400, valid loss-2.2275, acc-0.2524, test loss-2.2244, acc-0.2533\n",
      "Iter-8730, train loss-2.2222, acc-0.2200, valid loss-2.2274, acc-0.2524, test loss-2.2243, acc-0.2533\n",
      "Iter-8740, train loss-2.2137, acc-0.2800, valid loss-2.2273, acc-0.2524, test loss-2.2242, acc-0.2534\n",
      "Iter-8750, train loss-2.2186, acc-0.2400, valid loss-2.2273, acc-0.2522, test loss-2.2241, acc-0.2540\n",
      "Iter-8760, train loss-2.1960, acc-0.3000, valid loss-2.2272, acc-0.2520, test loss-2.2240, acc-0.2540\n",
      "Iter-8770, train loss-2.2224, acc-0.2800, valid loss-2.2271, acc-0.2526, test loss-2.2240, acc-0.2542\n",
      "Iter-8780, train loss-2.2347, acc-0.2200, valid loss-2.2270, acc-0.2522, test loss-2.2239, acc-0.2544\n",
      "Iter-8790, train loss-2.2311, acc-0.2600, valid loss-2.2270, acc-0.2524, test loss-2.2238, acc-0.2543\n",
      "Iter-8800, train loss-2.2258, acc-0.2800, valid loss-2.2269, acc-0.2526, test loss-2.2237, acc-0.2546\n",
      "Iter-8810, train loss-2.2264, acc-0.2200, valid loss-2.2268, acc-0.2524, test loss-2.2236, acc-0.2546\n",
      "Iter-8820, train loss-2.2285, acc-0.2200, valid loss-2.2267, acc-0.2534, test loss-2.2236, acc-0.2546\n",
      "Iter-8830, train loss-2.2121, acc-0.2800, valid loss-2.2267, acc-0.2534, test loss-2.2235, acc-0.2550\n",
      "Iter-8840, train loss-2.2293, acc-0.1400, valid loss-2.2266, acc-0.2540, test loss-2.2234, acc-0.2550\n",
      "Iter-8850, train loss-2.1945, acc-0.3600, valid loss-2.2265, acc-0.2542, test loss-2.2233, acc-0.2553\n",
      "Iter-8860, train loss-2.2230, acc-0.3200, valid loss-2.2264, acc-0.2542, test loss-2.2232, acc-0.2557\n",
      "Iter-8870, train loss-2.2485, acc-0.1400, valid loss-2.2264, acc-0.2550, test loss-2.2231, acc-0.2558\n",
      "Iter-8880, train loss-2.2357, acc-0.2200, valid loss-2.2263, acc-0.2556, test loss-2.2231, acc-0.2559\n",
      "Iter-8890, train loss-2.2473, acc-0.2600, valid loss-2.2262, acc-0.2562, test loss-2.2230, acc-0.2559\n",
      "Iter-8900, train loss-2.2302, acc-0.2600, valid loss-2.2261, acc-0.2566, test loss-2.2229, acc-0.2562\n",
      "Iter-8910, train loss-2.2063, acc-0.3200, valid loss-2.2261, acc-0.2562, test loss-2.2228, acc-0.2566\n",
      "Iter-8920, train loss-2.2056, acc-0.2600, valid loss-2.2260, acc-0.2560, test loss-2.2227, acc-0.2569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-8930, train loss-2.2502, acc-0.1800, valid loss-2.2259, acc-0.2566, test loss-2.2227, acc-0.2570\n",
      "Iter-8940, train loss-2.2200, acc-0.2200, valid loss-2.2259, acc-0.2560, test loss-2.2226, acc-0.2569\n",
      "Iter-8950, train loss-2.2122, acc-0.2800, valid loss-2.2258, acc-0.2564, test loss-2.2225, acc-0.2573\n",
      "Iter-8960, train loss-2.2209, acc-0.3200, valid loss-2.2257, acc-0.2564, test loss-2.2224, acc-0.2575\n",
      "Iter-8970, train loss-2.2392, acc-0.3200, valid loss-2.2256, acc-0.2560, test loss-2.2223, acc-0.2572\n",
      "Iter-8980, train loss-2.2393, acc-0.1800, valid loss-2.2255, acc-0.2566, test loss-2.2222, acc-0.2576\n",
      "Iter-8990, train loss-2.1918, acc-0.3600, valid loss-2.2255, acc-0.2566, test loss-2.2222, acc-0.2580\n",
      "Iter-9000, train loss-2.2623, acc-0.2000, valid loss-2.2254, acc-0.2562, test loss-2.2221, acc-0.2581\n",
      "Iter-9010, train loss-2.2345, acc-0.2200, valid loss-2.2253, acc-0.2564, test loss-2.2220, acc-0.2583\n",
      "Iter-9020, train loss-2.2236, acc-0.2000, valid loss-2.2252, acc-0.2564, test loss-2.2219, acc-0.2586\n",
      "Iter-9030, train loss-2.2277, acc-0.2600, valid loss-2.2252, acc-0.2564, test loss-2.2218, acc-0.2589\n",
      "Iter-9040, train loss-2.2168, acc-0.2600, valid loss-2.2251, acc-0.2570, test loss-2.2217, acc-0.2591\n",
      "Iter-9050, train loss-2.2526, acc-0.2000, valid loss-2.2250, acc-0.2580, test loss-2.2217, acc-0.2593\n",
      "Iter-9060, train loss-2.2141, acc-0.3000, valid loss-2.2249, acc-0.2582, test loss-2.2216, acc-0.2597\n",
      "Iter-9070, train loss-2.2096, acc-0.3400, valid loss-2.2249, acc-0.2584, test loss-2.2215, acc-0.2597\n",
      "Iter-9080, train loss-2.2382, acc-0.2600, valid loss-2.2248, acc-0.2582, test loss-2.2214, acc-0.2598\n",
      "Iter-9090, train loss-2.2334, acc-0.2200, valid loss-2.2247, acc-0.2588, test loss-2.2213, acc-0.2601\n",
      "Iter-9100, train loss-2.2097, acc-0.2400, valid loss-2.2246, acc-0.2584, test loss-2.2213, acc-0.2599\n",
      "Iter-9110, train loss-2.2292, acc-0.2200, valid loss-2.2246, acc-0.2588, test loss-2.2212, acc-0.2601\n",
      "Iter-9120, train loss-2.2161, acc-0.3000, valid loss-2.2245, acc-0.2586, test loss-2.2211, acc-0.2602\n",
      "Iter-9130, train loss-2.2370, acc-0.1800, valid loss-2.2244, acc-0.2596, test loss-2.2210, acc-0.2609\n",
      "Iter-9140, train loss-2.2275, acc-0.2200, valid loss-2.2244, acc-0.2596, test loss-2.2209, acc-0.2609\n",
      "Iter-9150, train loss-2.2552, acc-0.2200, valid loss-2.2243, acc-0.2594, test loss-2.2209, acc-0.2610\n",
      "Iter-9160, train loss-2.2332, acc-0.2400, valid loss-2.2242, acc-0.2600, test loss-2.2208, acc-0.2608\n",
      "Iter-9170, train loss-2.2105, acc-0.2200, valid loss-2.2241, acc-0.2602, test loss-2.2207, acc-0.2614\n",
      "Iter-9180, train loss-2.2100, acc-0.2400, valid loss-2.2241, acc-0.2604, test loss-2.2206, acc-0.2613\n",
      "Iter-9190, train loss-2.2348, acc-0.3000, valid loss-2.2240, acc-0.2600, test loss-2.2205, acc-0.2616\n",
      "Iter-9200, train loss-2.2131, acc-0.3400, valid loss-2.2239, acc-0.2602, test loss-2.2205, acc-0.2627\n",
      "Iter-9210, train loss-2.2460, acc-0.2600, valid loss-2.2239, acc-0.2600, test loss-2.2204, acc-0.2622\n",
      "Iter-9220, train loss-2.2459, acc-0.1000, valid loss-2.2238, acc-0.2608, test loss-2.2203, acc-0.2621\n",
      "Iter-9230, train loss-2.2152, acc-0.3200, valid loss-2.2237, acc-0.2614, test loss-2.2202, acc-0.2623\n",
      "Iter-9240, train loss-2.2445, acc-0.2600, valid loss-2.2236, acc-0.2612, test loss-2.2201, acc-0.2629\n",
      "Iter-9250, train loss-2.2130, acc-0.2400, valid loss-2.2236, acc-0.2616, test loss-2.2201, acc-0.2628\n",
      "Iter-9260, train loss-2.2389, acc-0.1600, valid loss-2.2235, acc-0.2620, test loss-2.2200, acc-0.2629\n",
      "Iter-9270, train loss-2.2193, acc-0.2000, valid loss-2.2234, acc-0.2618, test loss-2.2199, acc-0.2632\n",
      "Iter-9280, train loss-2.2036, acc-0.3000, valid loss-2.2233, acc-0.2622, test loss-2.2198, acc-0.2636\n",
      "Iter-9290, train loss-2.2532, acc-0.1600, valid loss-2.2233, acc-0.2620, test loss-2.2197, acc-0.2639\n",
      "Iter-9300, train loss-2.2164, acc-0.3000, valid loss-2.2232, acc-0.2626, test loss-2.2196, acc-0.2640\n",
      "Iter-9310, train loss-2.2212, acc-0.2600, valid loss-2.2231, acc-0.2626, test loss-2.2196, acc-0.2641\n",
      "Iter-9320, train loss-2.2165, acc-0.2400, valid loss-2.2230, acc-0.2634, test loss-2.2195, acc-0.2642\n",
      "Iter-9330, train loss-2.2170, acc-0.2400, valid loss-2.2230, acc-0.2642, test loss-2.2194, acc-0.2643\n",
      "Iter-9340, train loss-2.2381, acc-0.2000, valid loss-2.2229, acc-0.2646, test loss-2.2193, acc-0.2646\n",
      "Iter-9350, train loss-2.2177, acc-0.2200, valid loss-2.2228, acc-0.2648, test loss-2.2192, acc-0.2651\n",
      "Iter-9360, train loss-2.2484, acc-0.2200, valid loss-2.2227, acc-0.2646, test loss-2.2192, acc-0.2649\n",
      "Iter-9370, train loss-2.2259, acc-0.3000, valid loss-2.2227, acc-0.2648, test loss-2.2191, acc-0.2653\n",
      "Iter-9380, train loss-2.2261, acc-0.1800, valid loss-2.2226, acc-0.2650, test loss-2.2190, acc-0.2656\n",
      "Iter-9390, train loss-2.2377, acc-0.2800, valid loss-2.2225, acc-0.2656, test loss-2.2189, acc-0.2659\n",
      "Iter-9400, train loss-2.2266, acc-0.3600, valid loss-2.2225, acc-0.2654, test loss-2.2188, acc-0.2657\n",
      "Iter-9410, train loss-2.1969, acc-0.3600, valid loss-2.2224, acc-0.2656, test loss-2.2188, acc-0.2660\n",
      "Iter-9420, train loss-2.2444, acc-0.2200, valid loss-2.2223, acc-0.2652, test loss-2.2187, acc-0.2661\n",
      "Iter-9430, train loss-2.2380, acc-0.2000, valid loss-2.2222, acc-0.2658, test loss-2.2186, acc-0.2665\n",
      "Iter-9440, train loss-2.2281, acc-0.1800, valid loss-2.2222, acc-0.2662, test loss-2.2185, acc-0.2668\n",
      "Iter-9450, train loss-2.2258, acc-0.3400, valid loss-2.2221, acc-0.2662, test loss-2.2185, acc-0.2666\n",
      "Iter-9460, train loss-2.1950, acc-0.3000, valid loss-2.2220, acc-0.2662, test loss-2.2184, acc-0.2669\n",
      "Iter-9470, train loss-2.2177, acc-0.3200, valid loss-2.2220, acc-0.2658, test loss-2.2183, acc-0.2671\n",
      "Iter-9480, train loss-2.2241, acc-0.2200, valid loss-2.2219, acc-0.2662, test loss-2.2182, acc-0.2673\n",
      "Iter-9490, train loss-2.2272, acc-0.1800, valid loss-2.2218, acc-0.2662, test loss-2.2181, acc-0.2673\n",
      "Iter-9500, train loss-2.2216, acc-0.3200, valid loss-2.2217, acc-0.2664, test loss-2.2181, acc-0.2676\n",
      "Iter-9510, train loss-2.2412, acc-0.2800, valid loss-2.2217, acc-0.2668, test loss-2.2180, acc-0.2677\n",
      "Iter-9520, train loss-2.2465, acc-0.2400, valid loss-2.2216, acc-0.2668, test loss-2.2179, acc-0.2681\n",
      "Iter-9530, train loss-2.2139, acc-0.2200, valid loss-2.2215, acc-0.2674, test loss-2.2178, acc-0.2687\n",
      "Iter-9540, train loss-2.2271, acc-0.3400, valid loss-2.2215, acc-0.2670, test loss-2.2177, acc-0.2686\n",
      "Iter-9550, train loss-2.2360, acc-0.3200, valid loss-2.2214, acc-0.2668, test loss-2.2177, acc-0.2688\n",
      "Iter-9560, train loss-2.2154, acc-0.3200, valid loss-2.2213, acc-0.2670, test loss-2.2176, acc-0.2691\n",
      "Iter-9570, train loss-2.2363, acc-0.2200, valid loss-2.2212, acc-0.2672, test loss-2.2175, acc-0.2691\n",
      "Iter-9580, train loss-2.2106, acc-0.3200, valid loss-2.2212, acc-0.2674, test loss-2.2174, acc-0.2696\n",
      "Iter-9590, train loss-2.2588, acc-0.2200, valid loss-2.2211, acc-0.2678, test loss-2.2173, acc-0.2697\n",
      "Iter-9600, train loss-2.2224, acc-0.2400, valid loss-2.2210, acc-0.2678, test loss-2.2172, acc-0.2701\n",
      "Iter-9610, train loss-2.2232, acc-0.3400, valid loss-2.2210, acc-0.2678, test loss-2.2172, acc-0.2703\n",
      "Iter-9620, train loss-2.1973, acc-0.3000, valid loss-2.2209, acc-0.2676, test loss-2.2171, acc-0.2702\n",
      "Iter-9630, train loss-2.2142, acc-0.2600, valid loss-2.2208, acc-0.2680, test loss-2.2170, acc-0.2702\n",
      "Iter-9640, train loss-2.2353, acc-0.1200, valid loss-2.2207, acc-0.2680, test loss-2.2169, acc-0.2704\n",
      "Iter-9650, train loss-2.2062, acc-0.3800, valid loss-2.2207, acc-0.2680, test loss-2.2168, acc-0.2704\n",
      "Iter-9660, train loss-2.2323, acc-0.2600, valid loss-2.2206, acc-0.2684, test loss-2.2168, acc-0.2710\n",
      "Iter-9670, train loss-2.2328, acc-0.2800, valid loss-2.2205, acc-0.2684, test loss-2.2167, acc-0.2712\n",
      "Iter-9680, train loss-2.2331, acc-0.2400, valid loss-2.2204, acc-0.2684, test loss-2.2166, acc-0.2710\n",
      "Iter-9690, train loss-2.2453, acc-0.2000, valid loss-2.2204, acc-0.2684, test loss-2.2165, acc-0.2713\n",
      "Iter-9700, train loss-2.2364, acc-0.2200, valid loss-2.2203, acc-0.2684, test loss-2.2164, acc-0.2715\n",
      "Iter-9710, train loss-2.2357, acc-0.2800, valid loss-2.2202, acc-0.2684, test loss-2.2164, acc-0.2715\n",
      "Iter-9720, train loss-2.1980, acc-0.3400, valid loss-2.2202, acc-0.2686, test loss-2.2163, acc-0.2719\n",
      "Iter-9730, train loss-2.2529, acc-0.1800, valid loss-2.2201, acc-0.2684, test loss-2.2162, acc-0.2718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-9740, train loss-2.1969, acc-0.2400, valid loss-2.2200, acc-0.2684, test loss-2.2161, acc-0.2721\n",
      "Iter-9750, train loss-2.2167, acc-0.3400, valid loss-2.2199, acc-0.2688, test loss-2.2160, acc-0.2720\n",
      "Iter-9760, train loss-2.2126, acc-0.2400, valid loss-2.2199, acc-0.2690, test loss-2.2159, acc-0.2724\n",
      "Iter-9770, train loss-2.2531, acc-0.1400, valid loss-2.2198, acc-0.2690, test loss-2.2159, acc-0.2728\n",
      "Iter-9780, train loss-2.2152, acc-0.3000, valid loss-2.2197, acc-0.2696, test loss-2.2158, acc-0.2729\n",
      "Iter-9790, train loss-2.2447, acc-0.2200, valid loss-2.2196, acc-0.2694, test loss-2.2157, acc-0.2733\n",
      "Iter-9800, train loss-2.2461, acc-0.2200, valid loss-2.2196, acc-0.2700, test loss-2.2156, acc-0.2732\n",
      "Iter-9810, train loss-2.2422, acc-0.1400, valid loss-2.2195, acc-0.2694, test loss-2.2156, acc-0.2734\n",
      "Iter-9820, train loss-2.2232, acc-0.2400, valid loss-2.2194, acc-0.2700, test loss-2.2155, acc-0.2741\n",
      "Iter-9830, train loss-2.2194, acc-0.2600, valid loss-2.2194, acc-0.2706, test loss-2.2154, acc-0.2740\n",
      "Iter-9840, train loss-2.1730, acc-0.4200, valid loss-2.2193, acc-0.2704, test loss-2.2153, acc-0.2736\n",
      "Iter-9850, train loss-2.2191, acc-0.2200, valid loss-2.2192, acc-0.2704, test loss-2.2152, acc-0.2741\n",
      "Iter-9860, train loss-2.2236, acc-0.2600, valid loss-2.2191, acc-0.2704, test loss-2.2152, acc-0.2739\n",
      "Iter-9870, train loss-2.2276, acc-0.3000, valid loss-2.2191, acc-0.2710, test loss-2.2151, acc-0.2740\n",
      "Iter-9880, train loss-2.1963, acc-0.3600, valid loss-2.2190, acc-0.2714, test loss-2.2150, acc-0.2742\n",
      "Iter-9890, train loss-2.1923, acc-0.3000, valid loss-2.2189, acc-0.2708, test loss-2.2149, acc-0.2743\n",
      "Iter-9900, train loss-2.1905, acc-0.3800, valid loss-2.2188, acc-0.2712, test loss-2.2148, acc-0.2744\n",
      "Iter-9910, train loss-2.2346, acc-0.3400, valid loss-2.2188, acc-0.2716, test loss-2.2147, acc-0.2747\n",
      "Iter-9920, train loss-2.2392, acc-0.2000, valid loss-2.2187, acc-0.2712, test loss-2.2147, acc-0.2752\n",
      "Iter-9930, train loss-2.2577, acc-0.1600, valid loss-2.2186, acc-0.2708, test loss-2.2146, acc-0.2751\n",
      "Iter-9940, train loss-2.2321, acc-0.3200, valid loss-2.2185, acc-0.2710, test loss-2.2145, acc-0.2754\n",
      "Iter-9950, train loss-2.2369, acc-0.2600, valid loss-2.2185, acc-0.2716, test loss-2.2144, acc-0.2751\n",
      "Iter-9960, train loss-2.2186, acc-0.2800, valid loss-2.2184, acc-0.2710, test loss-2.2143, acc-0.2756\n",
      "Iter-9970, train loss-2.2333, acc-0.2600, valid loss-2.2183, acc-0.2718, test loss-2.2143, acc-0.2758\n",
      "Iter-9980, train loss-2.2104, acc-0.3000, valid loss-2.2182, acc-0.2722, test loss-2.2142, acc-0.2757\n",
      "Iter-9990, train loss-2.2030, acc-0.2400, valid loss-2.2182, acc-0.2730, test loss-2.2141, acc-0.2761\n",
      "Iter-10000, train loss-2.1949, acc-0.3400, valid loss-2.2181, acc-0.2732, test loss-2.2140, acc-0.2761\n",
      "Iter-10010, train loss-2.2244, acc-0.2400, valid loss-2.2180, acc-0.2738, test loss-2.2139, acc-0.2762\n",
      "Iter-10020, train loss-2.2070, acc-0.2400, valid loss-2.2180, acc-0.2744, test loss-2.2139, acc-0.2761\n",
      "Iter-10030, train loss-2.2403, acc-0.1800, valid loss-2.2179, acc-0.2746, test loss-2.2138, acc-0.2762\n",
      "Iter-10040, train loss-2.2230, acc-0.1600, valid loss-2.2178, acc-0.2750, test loss-2.2137, acc-0.2765\n",
      "Iter-10050, train loss-2.2382, acc-0.2600, valid loss-2.2177, acc-0.2750, test loss-2.2136, acc-0.2766\n",
      "Iter-10060, train loss-2.2133, acc-0.2000, valid loss-2.2177, acc-0.2754, test loss-2.2136, acc-0.2770\n",
      "Iter-10070, train loss-2.2292, acc-0.3200, valid loss-2.2176, acc-0.2758, test loss-2.2135, acc-0.2772\n",
      "Iter-10080, train loss-2.2381, acc-0.2400, valid loss-2.2175, acc-0.2756, test loss-2.2134, acc-0.2774\n",
      "Iter-10090, train loss-2.2426, acc-0.2400, valid loss-2.2175, acc-0.2760, test loss-2.2133, acc-0.2780\n",
      "Iter-10100, train loss-2.2321, acc-0.3000, valid loss-2.2174, acc-0.2758, test loss-2.2132, acc-0.2782\n",
      "Iter-10110, train loss-2.2301, acc-0.2000, valid loss-2.2173, acc-0.2760, test loss-2.2132, acc-0.2783\n",
      "Iter-10120, train loss-2.1877, acc-0.3200, valid loss-2.2172, acc-0.2756, test loss-2.2131, acc-0.2784\n",
      "Iter-10130, train loss-2.1951, acc-0.3600, valid loss-2.2172, acc-0.2758, test loss-2.2130, acc-0.2782\n",
      "Iter-10140, train loss-2.2127, acc-0.2200, valid loss-2.2171, acc-0.2762, test loss-2.2129, acc-0.2786\n",
      "Iter-10150, train loss-2.2291, acc-0.2800, valid loss-2.2170, acc-0.2766, test loss-2.2129, acc-0.2788\n",
      "Iter-10160, train loss-2.2476, acc-0.2200, valid loss-2.2170, acc-0.2768, test loss-2.2128, acc-0.2790\n",
      "Iter-10170, train loss-2.1970, acc-0.2800, valid loss-2.2169, acc-0.2768, test loss-2.2127, acc-0.2790\n",
      "Iter-10180, train loss-2.2085, acc-0.3600, valid loss-2.2168, acc-0.2772, test loss-2.2126, acc-0.2796\n",
      "Iter-10190, train loss-2.2197, acc-0.3000, valid loss-2.2167, acc-0.2774, test loss-2.2125, acc-0.2795\n",
      "Iter-10200, train loss-2.2037, acc-0.3400, valid loss-2.2167, acc-0.2772, test loss-2.2124, acc-0.2797\n",
      "Iter-10210, train loss-2.2188, acc-0.2600, valid loss-2.2166, acc-0.2772, test loss-2.2124, acc-0.2799\n",
      "Iter-10220, train loss-2.2212, acc-0.2800, valid loss-2.2165, acc-0.2770, test loss-2.2123, acc-0.2801\n",
      "Iter-10230, train loss-2.2306, acc-0.1600, valid loss-2.2165, acc-0.2772, test loss-2.2122, acc-0.2803\n",
      "Iter-10240, train loss-2.2354, acc-0.2400, valid loss-2.2164, acc-0.2774, test loss-2.2121, acc-0.2803\n",
      "Iter-10250, train loss-2.2341, acc-0.2200, valid loss-2.2163, acc-0.2774, test loss-2.2121, acc-0.2810\n",
      "Iter-10260, train loss-2.2153, acc-0.2800, valid loss-2.2162, acc-0.2774, test loss-2.2120, acc-0.2811\n",
      "Iter-10270, train loss-2.2068, acc-0.3000, valid loss-2.2162, acc-0.2774, test loss-2.2119, acc-0.2812\n",
      "Iter-10280, train loss-2.2022, acc-0.3000, valid loss-2.2161, acc-0.2776, test loss-2.2118, acc-0.2814\n",
      "Iter-10290, train loss-2.1964, acc-0.3400, valid loss-2.2160, acc-0.2780, test loss-2.2118, acc-0.2816\n",
      "Iter-10300, train loss-2.2141, acc-0.3000, valid loss-2.2160, acc-0.2780, test loss-2.2117, acc-0.2819\n",
      "Iter-10310, train loss-2.2323, acc-0.2200, valid loss-2.2159, acc-0.2782, test loss-2.2116, acc-0.2824\n",
      "Iter-10320, train loss-2.2241, acc-0.3000, valid loss-2.2158, acc-0.2780, test loss-2.2115, acc-0.2820\n",
      "Iter-10330, train loss-2.1852, acc-0.3200, valid loss-2.2157, acc-0.2782, test loss-2.2114, acc-0.2821\n",
      "Iter-10340, train loss-2.2089, acc-0.2800, valid loss-2.2157, acc-0.2780, test loss-2.2114, acc-0.2821\n",
      "Iter-10350, train loss-2.2158, acc-0.3000, valid loss-2.2156, acc-0.2786, test loss-2.2113, acc-0.2826\n",
      "Iter-10360, train loss-2.2283, acc-0.3000, valid loss-2.2155, acc-0.2782, test loss-2.2112, acc-0.2829\n",
      "Iter-10370, train loss-2.2013, acc-0.3400, valid loss-2.2155, acc-0.2780, test loss-2.2111, acc-0.2830\n",
      "Iter-10380, train loss-2.2551, acc-0.2600, valid loss-2.2154, acc-0.2782, test loss-2.2110, acc-0.2833\n",
      "Iter-10390, train loss-2.2003, acc-0.3600, valid loss-2.2153, acc-0.2786, test loss-2.2110, acc-0.2837\n",
      "Iter-10400, train loss-2.2051, acc-0.3000, valid loss-2.2152, acc-0.2792, test loss-2.2109, acc-0.2835\n",
      "Iter-10410, train loss-2.2130, acc-0.2800, valid loss-2.2152, acc-0.2794, test loss-2.2108, acc-0.2839\n",
      "Iter-10420, train loss-2.2007, acc-0.3200, valid loss-2.2151, acc-0.2792, test loss-2.2107, acc-0.2839\n",
      "Iter-10430, train loss-2.2284, acc-0.2800, valid loss-2.2150, acc-0.2796, test loss-2.2106, acc-0.2844\n",
      "Iter-10440, train loss-2.2133, acc-0.2200, valid loss-2.2150, acc-0.2798, test loss-2.2106, acc-0.2846\n",
      "Iter-10450, train loss-2.2044, acc-0.1800, valid loss-2.2149, acc-0.2800, test loss-2.2105, acc-0.2849\n",
      "Iter-10460, train loss-2.2021, acc-0.3200, valid loss-2.2148, acc-0.2798, test loss-2.2104, acc-0.2847\n",
      "Iter-10470, train loss-2.2111, acc-0.3400, valid loss-2.2148, acc-0.2800, test loss-2.2103, acc-0.2854\n",
      "Iter-10480, train loss-2.2135, acc-0.2000, valid loss-2.2147, acc-0.2804, test loss-2.2102, acc-0.2857\n",
      "Iter-10490, train loss-2.2220, acc-0.1600, valid loss-2.2146, acc-0.2802, test loss-2.2102, acc-0.2858\n",
      "Iter-10500, train loss-2.2238, acc-0.2400, valid loss-2.2145, acc-0.2802, test loss-2.2101, acc-0.2856\n",
      "Iter-10510, train loss-2.2403, acc-0.2000, valid loss-2.2145, acc-0.2800, test loss-2.2100, acc-0.2857\n",
      "Iter-10520, train loss-2.2343, acc-0.1600, valid loss-2.2144, acc-0.2804, test loss-2.2099, acc-0.2860\n",
      "Iter-10530, train loss-2.2287, acc-0.2400, valid loss-2.2143, acc-0.2802, test loss-2.2099, acc-0.2859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-10540, train loss-2.2264, acc-0.3000, valid loss-2.2142, acc-0.2800, test loss-2.2098, acc-0.2861\n",
      "Iter-10550, train loss-2.2115, acc-0.2200, valid loss-2.2142, acc-0.2798, test loss-2.2097, acc-0.2862\n",
      "Iter-10560, train loss-2.1784, acc-0.3800, valid loss-2.2141, acc-0.2806, test loss-2.2096, acc-0.2866\n",
      "Iter-10570, train loss-2.2042, acc-0.3000, valid loss-2.2140, acc-0.2804, test loss-2.2096, acc-0.2866\n",
      "Iter-10580, train loss-2.2099, acc-0.3200, valid loss-2.2140, acc-0.2808, test loss-2.2095, acc-0.2867\n",
      "Iter-10590, train loss-2.2053, acc-0.3600, valid loss-2.2139, acc-0.2810, test loss-2.2094, acc-0.2875\n",
      "Iter-10600, train loss-2.2167, acc-0.2600, valid loss-2.2138, acc-0.2810, test loss-2.2093, acc-0.2874\n",
      "Iter-10610, train loss-2.2220, acc-0.2000, valid loss-2.2137, acc-0.2812, test loss-2.2092, acc-0.2875\n",
      "Iter-10620, train loss-2.2222, acc-0.3400, valid loss-2.2137, acc-0.2814, test loss-2.2092, acc-0.2883\n",
      "Iter-10630, train loss-2.1943, acc-0.2400, valid loss-2.2136, acc-0.2814, test loss-2.2091, acc-0.2880\n",
      "Iter-10640, train loss-2.2082, acc-0.3600, valid loss-2.2135, acc-0.2818, test loss-2.2090, acc-0.2880\n",
      "Iter-10650, train loss-2.2024, acc-0.3000, valid loss-2.2134, acc-0.2824, test loss-2.2089, acc-0.2882\n",
      "Iter-10660, train loss-2.2127, acc-0.1800, valid loss-2.2134, acc-0.2828, test loss-2.2088, acc-0.2885\n",
      "Iter-10670, train loss-2.2249, acc-0.2000, valid loss-2.2133, acc-0.2828, test loss-2.2088, acc-0.2884\n",
      "Iter-10680, train loss-2.2056, acc-0.2800, valid loss-2.2132, acc-0.2832, test loss-2.2087, acc-0.2886\n",
      "Iter-10690, train loss-2.2167, acc-0.3200, valid loss-2.2131, acc-0.2832, test loss-2.2086, acc-0.2886\n",
      "Iter-10700, train loss-2.2239, acc-0.2800, valid loss-2.2131, acc-0.2832, test loss-2.2085, acc-0.2888\n",
      "Iter-10710, train loss-2.2242, acc-0.2200, valid loss-2.2130, acc-0.2834, test loss-2.2084, acc-0.2886\n",
      "Iter-10720, train loss-2.2201, acc-0.2800, valid loss-2.2129, acc-0.2832, test loss-2.2084, acc-0.2891\n",
      "Iter-10730, train loss-2.2165, acc-0.3200, valid loss-2.2129, acc-0.2832, test loss-2.2083, acc-0.2893\n",
      "Iter-10740, train loss-2.2183, acc-0.2800, valid loss-2.2128, acc-0.2836, test loss-2.2082, acc-0.2894\n",
      "Iter-10750, train loss-2.1932, acc-0.3000, valid loss-2.2127, acc-0.2836, test loss-2.2081, acc-0.2895\n",
      "Iter-10760, train loss-2.2075, acc-0.4400, valid loss-2.2127, acc-0.2838, test loss-2.2080, acc-0.2894\n",
      "Iter-10770, train loss-2.2177, acc-0.3200, valid loss-2.2126, acc-0.2832, test loss-2.2080, acc-0.2895\n",
      "Iter-10780, train loss-2.2422, acc-0.1800, valid loss-2.2125, acc-0.2844, test loss-2.2079, acc-0.2895\n",
      "Iter-10790, train loss-2.2267, acc-0.2600, valid loss-2.2124, acc-0.2846, test loss-2.2078, acc-0.2899\n",
      "Iter-10800, train loss-2.2321, acc-0.2400, valid loss-2.2124, acc-0.2848, test loss-2.2077, acc-0.2897\n",
      "Iter-10810, train loss-2.2115, acc-0.2000, valid loss-2.2123, acc-0.2850, test loss-2.2077, acc-0.2903\n",
      "Iter-10820, train loss-2.2166, acc-0.3000, valid loss-2.2122, acc-0.2848, test loss-2.2076, acc-0.2903\n",
      "Iter-10830, train loss-2.1865, acc-0.3600, valid loss-2.2122, acc-0.2846, test loss-2.2075, acc-0.2905\n",
      "Iter-10840, train loss-2.2166, acc-0.2200, valid loss-2.2121, acc-0.2850, test loss-2.2074, acc-0.2909\n",
      "Iter-10850, train loss-2.2244, acc-0.3000, valid loss-2.2120, acc-0.2850, test loss-2.2073, acc-0.2906\n",
      "Iter-10860, train loss-2.2223, acc-0.1600, valid loss-2.2119, acc-0.2848, test loss-2.2073, acc-0.2911\n",
      "Iter-10870, train loss-2.2126, acc-0.3200, valid loss-2.2119, acc-0.2850, test loss-2.2072, acc-0.2913\n",
      "Iter-10880, train loss-2.1879, acc-0.3000, valid loss-2.2118, acc-0.2850, test loss-2.2071, acc-0.2915\n",
      "Iter-10890, train loss-2.1843, acc-0.4200, valid loss-2.2117, acc-0.2852, test loss-2.2070, acc-0.2918\n",
      "Iter-10900, train loss-2.1936, acc-0.3000, valid loss-2.2117, acc-0.2858, test loss-2.2069, acc-0.2919\n",
      "Iter-10910, train loss-2.2053, acc-0.2600, valid loss-2.2116, acc-0.2856, test loss-2.2069, acc-0.2919\n",
      "Iter-10920, train loss-2.1910, acc-0.3000, valid loss-2.2115, acc-0.2858, test loss-2.2068, acc-0.2925\n",
      "Iter-10930, train loss-2.1520, acc-0.4000, valid loss-2.2114, acc-0.2864, test loss-2.2067, acc-0.2928\n",
      "Iter-10940, train loss-2.2263, acc-0.3200, valid loss-2.2114, acc-0.2868, test loss-2.2066, acc-0.2928\n",
      "Iter-10950, train loss-2.2000, acc-0.2200, valid loss-2.2113, acc-0.2866, test loss-2.2065, acc-0.2930\n",
      "Iter-10960, train loss-2.1952, acc-0.3200, valid loss-2.2112, acc-0.2862, test loss-2.2065, acc-0.2932\n",
      "Iter-10970, train loss-2.2066, acc-0.2400, valid loss-2.2111, acc-0.2870, test loss-2.2064, acc-0.2928\n",
      "Iter-10980, train loss-2.2182, acc-0.3600, valid loss-2.2111, acc-0.2870, test loss-2.2063, acc-0.2928\n",
      "Iter-10990, train loss-2.2281, acc-0.3200, valid loss-2.2110, acc-0.2876, test loss-2.2062, acc-0.2931\n",
      "Iter-11000, train loss-2.2208, acc-0.2600, valid loss-2.2109, acc-0.2884, test loss-2.2061, acc-0.2930\n",
      "Iter-11010, train loss-2.2234, acc-0.2200, valid loss-2.2108, acc-0.2886, test loss-2.2061, acc-0.2932\n",
      "Iter-11020, train loss-2.2128, acc-0.2600, valid loss-2.2108, acc-0.2888, test loss-2.2060, acc-0.2933\n",
      "Iter-11030, train loss-2.2072, acc-0.2600, valid loss-2.2107, acc-0.2886, test loss-2.2059, acc-0.2934\n",
      "Iter-11040, train loss-2.2193, acc-0.2400, valid loss-2.2106, acc-0.2884, test loss-2.2058, acc-0.2938\n",
      "Iter-11050, train loss-2.2221, acc-0.2600, valid loss-2.2106, acc-0.2884, test loss-2.2057, acc-0.2944\n",
      "Iter-11060, train loss-2.2157, acc-0.3200, valid loss-2.2105, acc-0.2890, test loss-2.2057, acc-0.2944\n",
      "Iter-11070, train loss-2.1861, acc-0.3600, valid loss-2.2104, acc-0.2888, test loss-2.2056, acc-0.2946\n",
      "Iter-11080, train loss-2.2279, acc-0.3600, valid loss-2.2103, acc-0.2890, test loss-2.2055, acc-0.2949\n",
      "Iter-11090, train loss-2.2065, acc-0.2800, valid loss-2.2103, acc-0.2888, test loss-2.2054, acc-0.2943\n",
      "Iter-11100, train loss-2.2015, acc-0.2800, valid loss-2.2102, acc-0.2888, test loss-2.2054, acc-0.2946\n",
      "Iter-11110, train loss-2.2026, acc-0.2400, valid loss-2.2101, acc-0.2888, test loss-2.2053, acc-0.2947\n",
      "Iter-11120, train loss-2.2028, acc-0.3200, valid loss-2.2101, acc-0.2888, test loss-2.2052, acc-0.2950\n",
      "Iter-11130, train loss-2.1990, acc-0.2800, valid loss-2.2100, acc-0.2894, test loss-2.2051, acc-0.2947\n",
      "Iter-11140, train loss-2.2228, acc-0.2400, valid loss-2.2099, acc-0.2896, test loss-2.2050, acc-0.2948\n",
      "Iter-11150, train loss-2.2179, acc-0.3200, valid loss-2.2098, acc-0.2898, test loss-2.2049, acc-0.2948\n",
      "Iter-11160, train loss-2.1915, acc-0.3000, valid loss-2.2098, acc-0.2898, test loss-2.2049, acc-0.2948\n",
      "Iter-11170, train loss-2.1941, acc-0.3800, valid loss-2.2097, acc-0.2902, test loss-2.2048, acc-0.2952\n",
      "Iter-11180, train loss-2.1880, acc-0.4000, valid loss-2.2096, acc-0.2900, test loss-2.2047, acc-0.2955\n",
      "Iter-11190, train loss-2.2056, acc-0.2600, valid loss-2.2095, acc-0.2906, test loss-2.2046, acc-0.2957\n",
      "Iter-11200, train loss-2.2206, acc-0.3000, valid loss-2.2094, acc-0.2910, test loss-2.2045, acc-0.2959\n",
      "Iter-11210, train loss-2.1906, acc-0.3200, valid loss-2.2094, acc-0.2912, test loss-2.2045, acc-0.2961\n",
      "Iter-11220, train loss-2.2224, acc-0.3000, valid loss-2.2093, acc-0.2920, test loss-2.2044, acc-0.2965\n",
      "Iter-11230, train loss-2.2072, acc-0.3400, valid loss-2.2092, acc-0.2922, test loss-2.2043, acc-0.2965\n",
      "Iter-11240, train loss-2.2212, acc-0.2600, valid loss-2.2092, acc-0.2918, test loss-2.2042, acc-0.2965\n",
      "Iter-11250, train loss-2.2059, acc-0.2600, valid loss-2.2091, acc-0.2918, test loss-2.2041, acc-0.2963\n",
      "Iter-11260, train loss-2.2035, acc-0.3000, valid loss-2.2090, acc-0.2918, test loss-2.2041, acc-0.2964\n",
      "Iter-11270, train loss-2.1953, acc-0.3800, valid loss-2.2089, acc-0.2924, test loss-2.2040, acc-0.2970\n",
      "Iter-11280, train loss-2.1937, acc-0.3800, valid loss-2.2089, acc-0.2928, test loss-2.2039, acc-0.2967\n",
      "Iter-11290, train loss-2.1974, acc-0.3600, valid loss-2.2088, acc-0.2926, test loss-2.2038, acc-0.2969\n",
      "Iter-11300, train loss-2.1884, acc-0.3800, valid loss-2.2087, acc-0.2928, test loss-2.2038, acc-0.2968\n",
      "Iter-11310, train loss-2.2245, acc-0.3000, valid loss-2.2087, acc-0.2928, test loss-2.2037, acc-0.2974\n",
      "Iter-11320, train loss-2.1767, acc-0.3400, valid loss-2.2086, acc-0.2930, test loss-2.2036, acc-0.2975\n",
      "Iter-11330, train loss-2.2191, acc-0.2200, valid loss-2.2085, acc-0.2932, test loss-2.2035, acc-0.2973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-11340, train loss-2.2050, acc-0.2200, valid loss-2.2085, acc-0.2922, test loss-2.2034, acc-0.2973\n",
      "Iter-11350, train loss-2.2065, acc-0.3400, valid loss-2.2084, acc-0.2926, test loss-2.2034, acc-0.2976\n",
      "Iter-11360, train loss-2.2166, acc-0.3200, valid loss-2.2083, acc-0.2928, test loss-2.2033, acc-0.2978\n",
      "Iter-11370, train loss-2.2000, acc-0.2800, valid loss-2.2083, acc-0.2934, test loss-2.2032, acc-0.2979\n",
      "Iter-11380, train loss-2.2171, acc-0.2800, valid loss-2.2082, acc-0.2932, test loss-2.2031, acc-0.2985\n",
      "Iter-11390, train loss-2.2046, acc-0.3000, valid loss-2.2081, acc-0.2932, test loss-2.2031, acc-0.2986\n",
      "Iter-11400, train loss-2.2414, acc-0.2600, valid loss-2.2081, acc-0.2936, test loss-2.2030, acc-0.2989\n",
      "Iter-11410, train loss-2.2051, acc-0.2200, valid loss-2.2080, acc-0.2940, test loss-2.2029, acc-0.2994\n",
      "Iter-11420, train loss-2.2299, acc-0.2800, valid loss-2.2079, acc-0.2936, test loss-2.2028, acc-0.2993\n",
      "Iter-11430, train loss-2.2201, acc-0.2600, valid loss-2.2078, acc-0.2940, test loss-2.2028, acc-0.2992\n",
      "Iter-11440, train loss-2.2035, acc-0.2000, valid loss-2.2078, acc-0.2944, test loss-2.2027, acc-0.2991\n",
      "Iter-11450, train loss-2.1952, acc-0.2600, valid loss-2.2077, acc-0.2944, test loss-2.2026, acc-0.2998\n",
      "Iter-11460, train loss-2.2080, acc-0.3000, valid loss-2.2076, acc-0.2946, test loss-2.2025, acc-0.3000\n",
      "Iter-11470, train loss-2.1965, acc-0.4200, valid loss-2.2075, acc-0.2950, test loss-2.2024, acc-0.2999\n",
      "Iter-11480, train loss-2.1931, acc-0.2600, valid loss-2.2075, acc-0.2956, test loss-2.2024, acc-0.3002\n",
      "Iter-11490, train loss-2.2305, acc-0.2600, valid loss-2.2074, acc-0.2960, test loss-2.2023, acc-0.3002\n",
      "Iter-11500, train loss-2.2151, acc-0.2400, valid loss-2.2073, acc-0.2962, test loss-2.2022, acc-0.3004\n",
      "Iter-11510, train loss-2.2050, acc-0.2600, valid loss-2.2073, acc-0.2962, test loss-2.2021, acc-0.3004\n",
      "Iter-11520, train loss-2.2289, acc-0.2000, valid loss-2.2072, acc-0.2962, test loss-2.2021, acc-0.3008\n",
      "Iter-11530, train loss-2.1689, acc-0.4200, valid loss-2.2071, acc-0.2966, test loss-2.2020, acc-0.3014\n",
      "Iter-11540, train loss-2.2057, acc-0.3200, valid loss-2.2071, acc-0.2962, test loss-2.2019, acc-0.3015\n",
      "Iter-11550, train loss-2.2359, acc-0.2800, valid loss-2.2070, acc-0.2966, test loss-2.2018, acc-0.3014\n",
      "Iter-11560, train loss-2.1878, acc-0.3000, valid loss-2.2069, acc-0.2966, test loss-2.2017, acc-0.3012\n",
      "Iter-11570, train loss-2.2028, acc-0.2400, valid loss-2.2069, acc-0.2972, test loss-2.2017, acc-0.3013\n",
      "Iter-11580, train loss-2.2238, acc-0.2000, valid loss-2.2068, acc-0.2968, test loss-2.2016, acc-0.3015\n",
      "Iter-11590, train loss-2.1912, acc-0.2800, valid loss-2.2067, acc-0.2974, test loss-2.2015, acc-0.3014\n",
      "Iter-11600, train loss-2.2398, acc-0.1800, valid loss-2.2067, acc-0.2984, test loss-2.2014, acc-0.3012\n",
      "Iter-11610, train loss-2.1858, acc-0.3400, valid loss-2.2066, acc-0.2978, test loss-2.2014, acc-0.3018\n",
      "Iter-11620, train loss-2.2004, acc-0.3000, valid loss-2.2065, acc-0.2984, test loss-2.2013, acc-0.3021\n",
      "Iter-11630, train loss-2.1934, acc-0.3400, valid loss-2.2065, acc-0.2990, test loss-2.2012, acc-0.3019\n",
      "Iter-11640, train loss-2.2235, acc-0.2800, valid loss-2.2064, acc-0.2992, test loss-2.2011, acc-0.3020\n",
      "Iter-11650, train loss-2.1810, acc-0.4400, valid loss-2.2063, acc-0.2998, test loss-2.2011, acc-0.3024\n",
      "Iter-11660, train loss-2.2220, acc-0.2800, valid loss-2.2062, acc-0.2996, test loss-2.2010, acc-0.3025\n",
      "Iter-11670, train loss-2.2286, acc-0.3000, valid loss-2.2062, acc-0.2996, test loss-2.2009, acc-0.3029\n",
      "Iter-11680, train loss-2.2030, acc-0.3000, valid loss-2.2061, acc-0.2994, test loss-2.2008, acc-0.3029\n",
      "Iter-11690, train loss-2.2031, acc-0.3800, valid loss-2.2060, acc-0.3000, test loss-2.2007, acc-0.3027\n",
      "Iter-11700, train loss-2.2195, acc-0.2400, valid loss-2.2060, acc-0.2998, test loss-2.2007, acc-0.3029\n",
      "Iter-11710, train loss-2.1997, acc-0.3200, valid loss-2.2059, acc-0.3002, test loss-2.2006, acc-0.3033\n",
      "Iter-11720, train loss-2.2486, acc-0.2200, valid loss-2.2058, acc-0.3002, test loss-2.2005, acc-0.3035\n",
      "Iter-11730, train loss-2.2086, acc-0.2200, valid loss-2.2058, acc-0.3000, test loss-2.2004, acc-0.3035\n",
      "Iter-11740, train loss-2.2073, acc-0.3600, valid loss-2.2057, acc-0.3004, test loss-2.2004, acc-0.3040\n",
      "Iter-11750, train loss-2.2117, acc-0.3200, valid loss-2.2056, acc-0.3002, test loss-2.2003, acc-0.3040\n",
      "Iter-11760, train loss-2.1936, acc-0.2800, valid loss-2.2055, acc-0.3006, test loss-2.2002, acc-0.3041\n",
      "Iter-11770, train loss-2.2340, acc-0.2800, valid loss-2.2055, acc-0.3004, test loss-2.2001, acc-0.3044\n",
      "Iter-11780, train loss-2.1816, acc-0.4200, valid loss-2.2054, acc-0.3006, test loss-2.2000, acc-0.3044\n",
      "Iter-11790, train loss-2.1664, acc-0.3600, valid loss-2.2053, acc-0.3002, test loss-2.2000, acc-0.3047\n",
      "Iter-11800, train loss-2.2120, acc-0.2000, valid loss-2.2053, acc-0.3002, test loss-2.1999, acc-0.3051\n",
      "Iter-11810, train loss-2.1814, acc-0.4400, valid loss-2.2052, acc-0.3004, test loss-2.1998, acc-0.3050\n",
      "Iter-11820, train loss-2.1938, acc-0.2800, valid loss-2.2051, acc-0.3006, test loss-2.1997, acc-0.3049\n",
      "Iter-11830, train loss-2.1936, acc-0.2800, valid loss-2.2050, acc-0.3006, test loss-2.1997, acc-0.3052\n",
      "Iter-11840, train loss-2.1969, acc-0.3200, valid loss-2.2050, acc-0.3016, test loss-2.1996, acc-0.3054\n",
      "Iter-11850, train loss-2.2086, acc-0.2400, valid loss-2.2049, acc-0.3016, test loss-2.1995, acc-0.3053\n",
      "Iter-11860, train loss-2.1973, acc-0.3400, valid loss-2.2048, acc-0.3014, test loss-2.1994, acc-0.3058\n",
      "Iter-11870, train loss-2.2129, acc-0.3600, valid loss-2.2048, acc-0.3020, test loss-2.1994, acc-0.3061\n",
      "Iter-11880, train loss-2.2196, acc-0.2600, valid loss-2.2047, acc-0.3022, test loss-2.1993, acc-0.3065\n",
      "Iter-11890, train loss-2.2087, acc-0.2800, valid loss-2.2046, acc-0.3022, test loss-2.1992, acc-0.3065\n",
      "Iter-11900, train loss-2.1937, acc-0.3400, valid loss-2.2045, acc-0.3020, test loss-2.1991, acc-0.3067\n",
      "Iter-11910, train loss-2.2274, acc-0.2200, valid loss-2.2045, acc-0.3024, test loss-2.1990, acc-0.3065\n",
      "Iter-11920, train loss-2.2073, acc-0.2200, valid loss-2.2044, acc-0.3024, test loss-2.1990, acc-0.3067\n",
      "Iter-11930, train loss-2.2016, acc-0.2800, valid loss-2.2043, acc-0.3024, test loss-2.1989, acc-0.3072\n",
      "Iter-11940, train loss-2.2107, acc-0.2600, valid loss-2.2043, acc-0.3022, test loss-2.1988, acc-0.3074\n",
      "Iter-11950, train loss-2.2017, acc-0.3400, valid loss-2.2042, acc-0.3026, test loss-2.1987, acc-0.3070\n",
      "Iter-11960, train loss-2.1963, acc-0.2800, valid loss-2.2041, acc-0.3028, test loss-2.1987, acc-0.3076\n",
      "Iter-11970, train loss-2.2074, acc-0.3400, valid loss-2.2041, acc-0.3026, test loss-2.1986, acc-0.3078\n",
      "Iter-11980, train loss-2.2414, acc-0.1400, valid loss-2.2040, acc-0.3028, test loss-2.1985, acc-0.3085\n",
      "Iter-11990, train loss-2.2711, acc-0.0800, valid loss-2.2039, acc-0.3028, test loss-2.1984, acc-0.3089\n",
      "Iter-12000, train loss-2.2178, acc-0.3200, valid loss-2.2039, acc-0.3032, test loss-2.1984, acc-0.3092\n",
      "Iter-12010, train loss-2.1792, acc-0.2600, valid loss-2.2038, acc-0.3036, test loss-2.1983, acc-0.3093\n",
      "Iter-12020, train loss-2.1884, acc-0.3600, valid loss-2.2037, acc-0.3036, test loss-2.1982, acc-0.3096\n",
      "Iter-12030, train loss-2.1921, acc-0.3000, valid loss-2.2037, acc-0.3038, test loss-2.1981, acc-0.3098\n",
      "Iter-12040, train loss-2.1981, acc-0.2600, valid loss-2.2036, acc-0.3042, test loss-2.1981, acc-0.3102\n",
      "Iter-12050, train loss-2.2185, acc-0.3000, valid loss-2.2035, acc-0.3042, test loss-2.1980, acc-0.3100\n",
      "Iter-12060, train loss-2.1954, acc-0.3400, valid loss-2.2034, acc-0.3044, test loss-2.1979, acc-0.3099\n",
      "Iter-12070, train loss-2.1934, acc-0.2400, valid loss-2.2034, acc-0.3046, test loss-2.1978, acc-0.3105\n",
      "Iter-12080, train loss-2.1952, acc-0.3600, valid loss-2.2033, acc-0.3046, test loss-2.1978, acc-0.3106\n",
      "Iter-12090, train loss-2.1939, acc-0.2600, valid loss-2.2032, acc-0.3042, test loss-2.1977, acc-0.3103\n",
      "Iter-12100, train loss-2.1894, acc-0.3000, valid loss-2.2032, acc-0.3044, test loss-2.1976, acc-0.3105\n",
      "Iter-12110, train loss-2.2112, acc-0.3000, valid loss-2.2031, acc-0.3046, test loss-2.1975, acc-0.3110\n",
      "Iter-12120, train loss-2.1992, acc-0.3000, valid loss-2.2030, acc-0.3044, test loss-2.1974, acc-0.3107\n",
      "Iter-12130, train loss-2.1781, acc-0.2400, valid loss-2.2029, acc-0.3046, test loss-2.1974, acc-0.3108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-12140, train loss-2.2138, acc-0.3200, valid loss-2.2029, acc-0.3046, test loss-2.1973, acc-0.3107\n",
      "Iter-12150, train loss-2.1892, acc-0.3800, valid loss-2.2028, acc-0.3052, test loss-2.1972, acc-0.3105\n",
      "Iter-12160, train loss-2.2247, acc-0.3200, valid loss-2.2027, acc-0.3046, test loss-2.1971, acc-0.3112\n",
      "Iter-12170, train loss-2.1658, acc-0.3000, valid loss-2.2027, acc-0.3044, test loss-2.1971, acc-0.3106\n",
      "Iter-12180, train loss-2.2114, acc-0.2400, valid loss-2.2026, acc-0.3046, test loss-2.1970, acc-0.3113\n",
      "Iter-12190, train loss-2.2094, acc-0.2400, valid loss-2.2025, acc-0.3048, test loss-2.1969, acc-0.3113\n",
      "Iter-12200, train loss-2.2147, acc-0.3200, valid loss-2.2025, acc-0.3048, test loss-2.1968, acc-0.3116\n",
      "Iter-12210, train loss-2.1892, acc-0.3000, valid loss-2.2024, acc-0.3054, test loss-2.1967, acc-0.3114\n",
      "Iter-12220, train loss-2.1904, acc-0.3400, valid loss-2.2023, acc-0.3058, test loss-2.1967, acc-0.3120\n",
      "Iter-12230, train loss-2.1946, acc-0.3800, valid loss-2.2022, acc-0.3060, test loss-2.1966, acc-0.3119\n",
      "Iter-12240, train loss-2.1904, acc-0.3400, valid loss-2.2022, acc-0.3062, test loss-2.1965, acc-0.3120\n",
      "Iter-12250, train loss-2.1903, acc-0.3000, valid loss-2.2021, acc-0.3060, test loss-2.1964, acc-0.3122\n",
      "Iter-12260, train loss-2.1976, acc-0.3000, valid loss-2.2020, acc-0.3058, test loss-2.1964, acc-0.3123\n",
      "Iter-12270, train loss-2.2267, acc-0.2000, valid loss-2.2020, acc-0.3060, test loss-2.1963, acc-0.3127\n",
      "Iter-12280, train loss-2.1927, acc-0.3000, valid loss-2.2019, acc-0.3060, test loss-2.1962, acc-0.3127\n",
      "Iter-12290, train loss-2.2188, acc-0.2000, valid loss-2.2018, acc-0.3058, test loss-2.1961, acc-0.3128\n",
      "Iter-12300, train loss-2.1994, acc-0.3000, valid loss-2.2018, acc-0.3058, test loss-2.1961, acc-0.3129\n",
      "Iter-12310, train loss-2.1860, acc-0.3000, valid loss-2.2017, acc-0.3064, test loss-2.1960, acc-0.3130\n",
      "Iter-12320, train loss-2.1900, acc-0.3000, valid loss-2.2016, acc-0.3060, test loss-2.1959, acc-0.3132\n",
      "Iter-12330, train loss-2.2040, acc-0.2800, valid loss-2.2016, acc-0.3064, test loss-2.1958, acc-0.3136\n",
      "Iter-12340, train loss-2.1895, acc-0.3800, valid loss-2.2015, acc-0.3060, test loss-2.1958, acc-0.3136\n",
      "Iter-12350, train loss-2.2018, acc-0.3200, valid loss-2.2014, acc-0.3060, test loss-2.1957, acc-0.3139\n",
      "Iter-12360, train loss-2.1775, acc-0.3200, valid loss-2.2014, acc-0.3064, test loss-2.1956, acc-0.3137\n",
      "Iter-12370, train loss-2.2105, acc-0.3200, valid loss-2.2013, acc-0.3062, test loss-2.1955, acc-0.3135\n",
      "Iter-12380, train loss-2.2174, acc-0.2000, valid loss-2.2012, acc-0.3072, test loss-2.1955, acc-0.3138\n",
      "Iter-12390, train loss-2.2103, acc-0.2800, valid loss-2.2012, acc-0.3072, test loss-2.1954, acc-0.3139\n",
      "Iter-12400, train loss-2.2188, acc-0.3400, valid loss-2.2011, acc-0.3080, test loss-2.1953, acc-0.3140\n",
      "Iter-12410, train loss-2.2170, acc-0.2800, valid loss-2.2010, acc-0.3080, test loss-2.1952, acc-0.3137\n",
      "Iter-12420, train loss-2.1848, acc-0.3800, valid loss-2.2009, acc-0.3078, test loss-2.1952, acc-0.3141\n",
      "Iter-12430, train loss-2.1967, acc-0.2800, valid loss-2.2009, acc-0.3080, test loss-2.1951, acc-0.3140\n",
      "Iter-12440, train loss-2.2117, acc-0.3800, valid loss-2.2008, acc-0.3082, test loss-2.1950, acc-0.3142\n",
      "Iter-12450, train loss-2.1836, acc-0.2400, valid loss-2.2007, acc-0.3082, test loss-2.1949, acc-0.3141\n",
      "Iter-12460, train loss-2.2175, acc-0.3600, valid loss-2.2007, acc-0.3084, test loss-2.1949, acc-0.3144\n",
      "Iter-12470, train loss-2.1851, acc-0.3600, valid loss-2.2006, acc-0.3086, test loss-2.1948, acc-0.3141\n",
      "Iter-12480, train loss-2.1681, acc-0.3000, valid loss-2.2005, acc-0.3086, test loss-2.1947, acc-0.3142\n",
      "Iter-12490, train loss-2.2034, acc-0.2200, valid loss-2.2005, acc-0.3090, test loss-2.1946, acc-0.3145\n",
      "Iter-12500, train loss-2.1994, acc-0.4000, valid loss-2.2004, acc-0.3086, test loss-2.1945, acc-0.3145\n",
      "Iter-12510, train loss-2.2251, acc-0.2400, valid loss-2.2003, acc-0.3094, test loss-2.1945, acc-0.3150\n",
      "Iter-12520, train loss-2.2106, acc-0.2800, valid loss-2.2003, acc-0.3098, test loss-2.1944, acc-0.3150\n",
      "Iter-12530, train loss-2.1955, acc-0.2600, valid loss-2.2002, acc-0.3098, test loss-2.1943, acc-0.3149\n",
      "Iter-12540, train loss-2.1927, acc-0.3800, valid loss-2.2001, acc-0.3096, test loss-2.1942, acc-0.3150\n",
      "Iter-12550, train loss-2.2160, acc-0.2400, valid loss-2.2000, acc-0.3096, test loss-2.1942, acc-0.3148\n",
      "Iter-12560, train loss-2.2087, acc-0.3200, valid loss-2.2000, acc-0.3094, test loss-2.1941, acc-0.3148\n",
      "Iter-12570, train loss-2.2135, acc-0.1600, valid loss-2.1999, acc-0.3092, test loss-2.1940, acc-0.3153\n",
      "Iter-12580, train loss-2.1854, acc-0.3200, valid loss-2.1998, acc-0.3094, test loss-2.1939, acc-0.3153\n",
      "Iter-12590, train loss-2.1859, acc-0.3600, valid loss-2.1998, acc-0.3102, test loss-2.1939, acc-0.3152\n",
      "Iter-12600, train loss-2.2058, acc-0.3400, valid loss-2.1997, acc-0.3110, test loss-2.1938, acc-0.3153\n",
      "Iter-12610, train loss-2.1999, acc-0.2800, valid loss-2.1996, acc-0.3104, test loss-2.1937, acc-0.3153\n",
      "Iter-12620, train loss-2.2199, acc-0.2400, valid loss-2.1996, acc-0.3106, test loss-2.1936, acc-0.3156\n",
      "Iter-12630, train loss-2.2023, acc-0.3000, valid loss-2.1995, acc-0.3110, test loss-2.1935, acc-0.3155\n",
      "Iter-12640, train loss-2.1953, acc-0.3800, valid loss-2.1994, acc-0.3114, test loss-2.1935, acc-0.3164\n",
      "Iter-12650, train loss-2.1816, acc-0.3200, valid loss-2.1993, acc-0.3112, test loss-2.1934, acc-0.3164\n",
      "Iter-12660, train loss-2.2145, acc-0.3200, valid loss-2.1993, acc-0.3116, test loss-2.1933, acc-0.3164\n",
      "Iter-12670, train loss-2.1955, acc-0.2200, valid loss-2.1992, acc-0.3112, test loss-2.1932, acc-0.3163\n",
      "Iter-12680, train loss-2.1850, acc-0.3000, valid loss-2.1991, acc-0.3120, test loss-2.1932, acc-0.3166\n",
      "Iter-12690, train loss-2.1675, acc-0.4000, valid loss-2.1990, acc-0.3126, test loss-2.1931, acc-0.3167\n",
      "Iter-12700, train loss-2.2017, acc-0.4200, valid loss-2.1990, acc-0.3120, test loss-2.1930, acc-0.3166\n",
      "Iter-12710, train loss-2.1819, acc-0.3600, valid loss-2.1989, acc-0.3124, test loss-2.1929, acc-0.3164\n",
      "Iter-12720, train loss-2.1942, acc-0.2800, valid loss-2.1988, acc-0.3130, test loss-2.1929, acc-0.3166\n",
      "Iter-12730, train loss-2.1728, acc-0.3200, valid loss-2.1988, acc-0.3128, test loss-2.1928, acc-0.3163\n",
      "Iter-12740, train loss-2.2108, acc-0.2800, valid loss-2.1987, acc-0.3128, test loss-2.1927, acc-0.3162\n",
      "Iter-12750, train loss-2.2071, acc-0.2400, valid loss-2.1986, acc-0.3132, test loss-2.1926, acc-0.3165\n",
      "Iter-12760, train loss-2.1813, acc-0.2600, valid loss-2.1986, acc-0.3134, test loss-2.1925, acc-0.3166\n",
      "Iter-12770, train loss-2.2273, acc-0.2200, valid loss-2.1985, acc-0.3136, test loss-2.1925, acc-0.3167\n",
      "Iter-12780, train loss-2.1751, acc-0.3600, valid loss-2.1984, acc-0.3136, test loss-2.1924, acc-0.3171\n",
      "Iter-12790, train loss-2.1921, acc-0.2600, valid loss-2.1984, acc-0.3134, test loss-2.1923, acc-0.3167\n",
      "Iter-12800, train loss-2.1898, acc-0.4000, valid loss-2.1983, acc-0.3134, test loss-2.1922, acc-0.3170\n",
      "Iter-12810, train loss-2.1990, acc-0.2000, valid loss-2.1982, acc-0.3146, test loss-2.1921, acc-0.3169\n",
      "Iter-12820, train loss-2.1938, acc-0.3400, valid loss-2.1981, acc-0.3154, test loss-2.1921, acc-0.3175\n",
      "Iter-12830, train loss-2.1950, acc-0.3200, valid loss-2.1981, acc-0.3154, test loss-2.1920, acc-0.3175\n",
      "Iter-12840, train loss-2.2168, acc-0.2800, valid loss-2.1980, acc-0.3150, test loss-2.1919, acc-0.3174\n",
      "Iter-12850, train loss-2.2114, acc-0.3000, valid loss-2.1979, acc-0.3156, test loss-2.1918, acc-0.3177\n",
      "Iter-12860, train loss-2.1894, acc-0.3800, valid loss-2.1979, acc-0.3154, test loss-2.1918, acc-0.3180\n",
      "Iter-12870, train loss-2.1732, acc-0.3400, valid loss-2.1978, acc-0.3156, test loss-2.1917, acc-0.3180\n",
      "Iter-12880, train loss-2.1835, acc-0.4200, valid loss-2.1977, acc-0.3156, test loss-2.1916, acc-0.3183\n",
      "Iter-12890, train loss-2.2489, acc-0.2800, valid loss-2.1976, acc-0.3154, test loss-2.1915, acc-0.3184\n",
      "Iter-12900, train loss-2.2062, acc-0.2000, valid loss-2.1976, acc-0.3154, test loss-2.1914, acc-0.3183\n",
      "Iter-12910, train loss-2.1540, acc-0.4200, valid loss-2.1975, acc-0.3164, test loss-2.1914, acc-0.3187\n",
      "Iter-12920, train loss-2.1966, acc-0.2600, valid loss-2.1974, acc-0.3156, test loss-2.1913, acc-0.3183\n",
      "Iter-12930, train loss-2.2063, acc-0.3800, valid loss-2.1974, acc-0.3156, test loss-2.1912, acc-0.3184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-12940, train loss-2.2022, acc-0.3200, valid loss-2.1973, acc-0.3160, test loss-2.1911, acc-0.3188\n",
      "Iter-12950, train loss-2.2027, acc-0.3600, valid loss-2.1972, acc-0.3168, test loss-2.1911, acc-0.3184\n",
      "Iter-12960, train loss-2.2082, acc-0.2800, valid loss-2.1971, acc-0.3170, test loss-2.1910, acc-0.3185\n",
      "Iter-12970, train loss-2.2326, acc-0.2800, valid loss-2.1971, acc-0.3168, test loss-2.1909, acc-0.3188\n",
      "Iter-12980, train loss-2.1850, acc-0.3400, valid loss-2.1970, acc-0.3170, test loss-2.1908, acc-0.3191\n",
      "Iter-12990, train loss-2.1642, acc-0.2800, valid loss-2.1969, acc-0.3182, test loss-2.1908, acc-0.3189\n",
      "Iter-13000, train loss-2.2154, acc-0.2800, valid loss-2.1969, acc-0.3180, test loss-2.1907, acc-0.3191\n",
      "Iter-13010, train loss-2.2360, acc-0.2200, valid loss-2.1968, acc-0.3180, test loss-2.1906, acc-0.3193\n",
      "Iter-13020, train loss-2.2080, acc-0.3600, valid loss-2.1967, acc-0.3188, test loss-2.1905, acc-0.3194\n",
      "Iter-13030, train loss-2.1833, acc-0.4000, valid loss-2.1966, acc-0.3182, test loss-2.1905, acc-0.3193\n",
      "Iter-13040, train loss-2.2126, acc-0.3200, valid loss-2.1966, acc-0.3184, test loss-2.1904, acc-0.3191\n",
      "Iter-13050, train loss-2.1830, acc-0.4000, valid loss-2.1965, acc-0.3186, test loss-2.1903, acc-0.3193\n",
      "Iter-13060, train loss-2.1917, acc-0.3600, valid loss-2.1965, acc-0.3186, test loss-2.1902, acc-0.3193\n",
      "Iter-13070, train loss-2.1966, acc-0.4000, valid loss-2.1964, acc-0.3186, test loss-2.1902, acc-0.3196\n",
      "Iter-13080, train loss-2.1760, acc-0.3400, valid loss-2.1963, acc-0.3194, test loss-2.1901, acc-0.3197\n",
      "Iter-13090, train loss-2.1978, acc-0.2400, valid loss-2.1962, acc-0.3192, test loss-2.1900, acc-0.3201\n",
      "Iter-13100, train loss-2.1961, acc-0.4000, valid loss-2.1962, acc-0.3198, test loss-2.1899, acc-0.3201\n",
      "Iter-13110, train loss-2.1937, acc-0.2800, valid loss-2.1961, acc-0.3200, test loss-2.1899, acc-0.3201\n",
      "Iter-13120, train loss-2.1923, acc-0.3600, valid loss-2.1960, acc-0.3200, test loss-2.1898, acc-0.3202\n",
      "Iter-13130, train loss-2.2039, acc-0.3200, valid loss-2.1960, acc-0.3196, test loss-2.1897, acc-0.3203\n",
      "Iter-13140, train loss-2.1535, acc-0.3600, valid loss-2.1959, acc-0.3200, test loss-2.1896, acc-0.3208\n",
      "Iter-13150, train loss-2.2065, acc-0.2800, valid loss-2.1958, acc-0.3206, test loss-2.1896, acc-0.3206\n",
      "Iter-13160, train loss-2.1868, acc-0.3200, valid loss-2.1958, acc-0.3204, test loss-2.1895, acc-0.3211\n",
      "Iter-13170, train loss-2.1970, acc-0.3600, valid loss-2.1957, acc-0.3210, test loss-2.1894, acc-0.3212\n",
      "Iter-13180, train loss-2.1554, acc-0.5000, valid loss-2.1956, acc-0.3208, test loss-2.1893, acc-0.3214\n",
      "Iter-13190, train loss-2.1957, acc-0.3600, valid loss-2.1955, acc-0.3208, test loss-2.1892, acc-0.3216\n",
      "Iter-13200, train loss-2.2113, acc-0.2800, valid loss-2.1955, acc-0.3208, test loss-2.1892, acc-0.3218\n",
      "Iter-13210, train loss-2.2017, acc-0.3200, valid loss-2.1954, acc-0.3210, test loss-2.1891, acc-0.3220\n",
      "Iter-13220, train loss-2.1942, acc-0.3200, valid loss-2.1953, acc-0.3216, test loss-2.1890, acc-0.3218\n",
      "Iter-13230, train loss-2.1498, acc-0.3600, valid loss-2.1953, acc-0.3216, test loss-2.1889, acc-0.3218\n",
      "Iter-13240, train loss-2.1725, acc-0.4200, valid loss-2.1952, acc-0.3218, test loss-2.1889, acc-0.3226\n",
      "Iter-13250, train loss-2.2046, acc-0.2000, valid loss-2.1951, acc-0.3216, test loss-2.1888, acc-0.3226\n",
      "Iter-13260, train loss-2.1851, acc-0.3000, valid loss-2.1951, acc-0.3220, test loss-2.1887, acc-0.3226\n",
      "Iter-13270, train loss-2.1815, acc-0.3000, valid loss-2.1950, acc-0.3224, test loss-2.1886, acc-0.3224\n",
      "Iter-13280, train loss-2.2195, acc-0.3800, valid loss-2.1949, acc-0.3220, test loss-2.1886, acc-0.3226\n",
      "Iter-13290, train loss-2.2105, acc-0.2600, valid loss-2.1949, acc-0.3220, test loss-2.1885, acc-0.3226\n",
      "Iter-13300, train loss-2.1754, acc-0.3600, valid loss-2.1948, acc-0.3216, test loss-2.1884, acc-0.3228\n",
      "Iter-13310, train loss-2.1756, acc-0.3800, valid loss-2.1947, acc-0.3218, test loss-2.1883, acc-0.3230\n",
      "Iter-13320, train loss-2.1959, acc-0.3800, valid loss-2.1946, acc-0.3230, test loss-2.1882, acc-0.3232\n",
      "Iter-13330, train loss-2.1838, acc-0.3400, valid loss-2.1946, acc-0.3224, test loss-2.1882, acc-0.3231\n",
      "Iter-13340, train loss-2.1901, acc-0.3200, valid loss-2.1945, acc-0.3228, test loss-2.1881, acc-0.3231\n",
      "Iter-13350, train loss-2.1845, acc-0.3400, valid loss-2.1944, acc-0.3230, test loss-2.1880, acc-0.3235\n",
      "Iter-13360, train loss-2.2093, acc-0.2600, valid loss-2.1944, acc-0.3234, test loss-2.1879, acc-0.3238\n",
      "Iter-13370, train loss-2.1825, acc-0.3200, valid loss-2.1943, acc-0.3230, test loss-2.1879, acc-0.3242\n",
      "Iter-13380, train loss-2.1778, acc-0.3600, valid loss-2.1942, acc-0.3234, test loss-2.1878, acc-0.3240\n",
      "Iter-13390, train loss-2.1810, acc-0.3000, valid loss-2.1942, acc-0.3234, test loss-2.1877, acc-0.3243\n",
      "Iter-13400, train loss-2.1708, acc-0.3800, valid loss-2.1941, acc-0.3234, test loss-2.1876, acc-0.3240\n",
      "Iter-13410, train loss-2.1789, acc-0.3600, valid loss-2.1940, acc-0.3232, test loss-2.1876, acc-0.3244\n",
      "Iter-13420, train loss-2.1828, acc-0.2800, valid loss-2.1939, acc-0.3236, test loss-2.1875, acc-0.3242\n",
      "Iter-13430, train loss-2.1696, acc-0.3600, valid loss-2.1939, acc-0.3234, test loss-2.1874, acc-0.3247\n",
      "Iter-13440, train loss-2.1828, acc-0.3400, valid loss-2.1938, acc-0.3236, test loss-2.1873, acc-0.3251\n",
      "Iter-13450, train loss-2.2151, acc-0.2400, valid loss-2.1937, acc-0.3240, test loss-2.1873, acc-0.3255\n",
      "Iter-13460, train loss-2.2010, acc-0.3600, valid loss-2.1937, acc-0.3238, test loss-2.1872, acc-0.3255\n",
      "Iter-13470, train loss-2.1890, acc-0.3000, valid loss-2.1936, acc-0.3240, test loss-2.1871, acc-0.3258\n",
      "Iter-13480, train loss-2.1709, acc-0.3600, valid loss-2.1935, acc-0.3244, test loss-2.1870, acc-0.3255\n",
      "Iter-13490, train loss-2.1603, acc-0.3200, valid loss-2.1935, acc-0.3238, test loss-2.1870, acc-0.3261\n",
      "Iter-13500, train loss-2.1464, acc-0.4600, valid loss-2.1934, acc-0.3242, test loss-2.1869, acc-0.3264\n",
      "Iter-13510, train loss-2.1928, acc-0.3800, valid loss-2.1933, acc-0.3242, test loss-2.1868, acc-0.3266\n",
      "Iter-13520, train loss-2.1601, acc-0.3200, valid loss-2.1933, acc-0.3244, test loss-2.1867, acc-0.3265\n",
      "Iter-13530, train loss-2.1876, acc-0.3000, valid loss-2.1932, acc-0.3252, test loss-2.1867, acc-0.3265\n",
      "Iter-13540, train loss-2.2115, acc-0.3000, valid loss-2.1931, acc-0.3252, test loss-2.1866, acc-0.3268\n",
      "Iter-13550, train loss-2.1634, acc-0.3200, valid loss-2.1931, acc-0.3256, test loss-2.1865, acc-0.3268\n",
      "Iter-13560, train loss-2.1764, acc-0.3800, valid loss-2.1930, acc-0.3256, test loss-2.1864, acc-0.3272\n",
      "Iter-13570, train loss-2.2019, acc-0.2400, valid loss-2.1929, acc-0.3258, test loss-2.1863, acc-0.3273\n",
      "Iter-13580, train loss-2.2110, acc-0.2400, valid loss-2.1928, acc-0.3260, test loss-2.1863, acc-0.3276\n",
      "Iter-13590, train loss-2.1917, acc-0.3400, valid loss-2.1928, acc-0.3258, test loss-2.1862, acc-0.3277\n",
      "Iter-13600, train loss-2.2096, acc-0.2600, valid loss-2.1927, acc-0.3258, test loss-2.1861, acc-0.3277\n",
      "Iter-13610, train loss-2.1860, acc-0.3000, valid loss-2.1926, acc-0.3258, test loss-2.1860, acc-0.3278\n",
      "Iter-13620, train loss-2.2222, acc-0.2600, valid loss-2.1926, acc-0.3260, test loss-2.1860, acc-0.3282\n",
      "Iter-13630, train loss-2.2140, acc-0.2600, valid loss-2.1925, acc-0.3264, test loss-2.1859, acc-0.3283\n",
      "Iter-13640, train loss-2.1866, acc-0.4200, valid loss-2.1924, acc-0.3262, test loss-2.1858, acc-0.3283\n",
      "Iter-13650, train loss-2.1970, acc-0.3400, valid loss-2.1924, acc-0.3260, test loss-2.1857, acc-0.3287\n",
      "Iter-13660, train loss-2.1819, acc-0.3800, valid loss-2.1923, acc-0.3256, test loss-2.1856, acc-0.3284\n",
      "Iter-13670, train loss-2.2425, acc-0.1600, valid loss-2.1922, acc-0.3264, test loss-2.1856, acc-0.3288\n",
      "Iter-13680, train loss-2.2163, acc-0.3000, valid loss-2.1922, acc-0.3266, test loss-2.1855, acc-0.3290\n",
      "Iter-13690, train loss-2.2033, acc-0.2400, valid loss-2.1921, acc-0.3266, test loss-2.1854, acc-0.3292\n",
      "Iter-13700, train loss-2.1847, acc-0.3200, valid loss-2.1920, acc-0.3266, test loss-2.1854, acc-0.3294\n",
      "Iter-13710, train loss-2.2015, acc-0.2800, valid loss-2.1920, acc-0.3274, test loss-2.1853, acc-0.3294\n",
      "Iter-13720, train loss-2.1843, acc-0.4200, valid loss-2.1919, acc-0.3278, test loss-2.1852, acc-0.3296\n",
      "Iter-13730, train loss-2.1700, acc-0.4000, valid loss-2.1918, acc-0.3280, test loss-2.1851, acc-0.3295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-13740, train loss-2.1751, acc-0.3800, valid loss-2.1918, acc-0.3282, test loss-2.1851, acc-0.3298\n",
      "Iter-13750, train loss-2.1783, acc-0.3600, valid loss-2.1917, acc-0.3282, test loss-2.1850, acc-0.3300\n",
      "Iter-13760, train loss-2.1641, acc-0.2800, valid loss-2.1916, acc-0.3280, test loss-2.1849, acc-0.3305\n",
      "Iter-13770, train loss-2.1882, acc-0.2800, valid loss-2.1915, acc-0.3282, test loss-2.1848, acc-0.3304\n",
      "Iter-13780, train loss-2.1990, acc-0.3600, valid loss-2.1915, acc-0.3280, test loss-2.1848, acc-0.3305\n",
      "Iter-13790, train loss-2.1887, acc-0.3000, valid loss-2.1914, acc-0.3278, test loss-2.1847, acc-0.3305\n",
      "Iter-13800, train loss-2.1987, acc-0.3200, valid loss-2.1913, acc-0.3288, test loss-2.1846, acc-0.3308\n",
      "Iter-13810, train loss-2.1663, acc-0.3600, valid loss-2.1913, acc-0.3290, test loss-2.1845, acc-0.3309\n",
      "Iter-13820, train loss-2.1709, acc-0.3200, valid loss-2.1912, acc-0.3286, test loss-2.1844, acc-0.3310\n",
      "Iter-13830, train loss-2.1841, acc-0.3000, valid loss-2.1911, acc-0.3294, test loss-2.1844, acc-0.3313\n",
      "Iter-13840, train loss-2.2089, acc-0.2400, valid loss-2.1910, acc-0.3302, test loss-2.1843, acc-0.3312\n",
      "Iter-13850, train loss-2.2049, acc-0.3000, valid loss-2.1910, acc-0.3302, test loss-2.1842, acc-0.3313\n",
      "Iter-13860, train loss-2.1760, acc-0.2200, valid loss-2.1909, acc-0.3306, test loss-2.1841, acc-0.3315\n",
      "Iter-13870, train loss-2.2097, acc-0.3600, valid loss-2.1909, acc-0.3310, test loss-2.1841, acc-0.3317\n",
      "Iter-13880, train loss-2.1592, acc-0.3400, valid loss-2.1908, acc-0.3306, test loss-2.1840, acc-0.3321\n",
      "Iter-13890, train loss-2.1981, acc-0.1800, valid loss-2.1907, acc-0.3306, test loss-2.1839, acc-0.3322\n",
      "Iter-13900, train loss-2.1857, acc-0.3200, valid loss-2.1906, acc-0.3308, test loss-2.1839, acc-0.3325\n",
      "Iter-13910, train loss-2.1745, acc-0.4000, valid loss-2.1906, acc-0.3302, test loss-2.1838, acc-0.3329\n",
      "Iter-13920, train loss-2.1660, acc-0.2400, valid loss-2.1905, acc-0.3306, test loss-2.1837, acc-0.3327\n",
      "Iter-13930, train loss-2.1786, acc-0.2800, valid loss-2.1904, acc-0.3312, test loss-2.1836, acc-0.3331\n",
      "Iter-13940, train loss-2.1563, acc-0.4400, valid loss-2.1904, acc-0.3316, test loss-2.1835, acc-0.3334\n",
      "Iter-13950, train loss-2.1499, acc-0.4000, valid loss-2.1903, acc-0.3318, test loss-2.1835, acc-0.3334\n",
      "Iter-13960, train loss-2.1774, acc-0.3800, valid loss-2.1902, acc-0.3314, test loss-2.1834, acc-0.3331\n",
      "Iter-13970, train loss-2.2298, acc-0.1600, valid loss-2.1901, acc-0.3318, test loss-2.1833, acc-0.3329\n",
      "Iter-13980, train loss-2.1912, acc-0.3000, valid loss-2.1901, acc-0.3314, test loss-2.1832, acc-0.3334\n",
      "Iter-13990, train loss-2.1861, acc-0.3800, valid loss-2.1900, acc-0.3316, test loss-2.1832, acc-0.3335\n",
      "Iter-14000, train loss-2.1433, acc-0.4000, valid loss-2.1899, acc-0.3318, test loss-2.1831, acc-0.3337\n",
      "Iter-14010, train loss-2.2039, acc-0.3200, valid loss-2.1899, acc-0.3322, test loss-2.1830, acc-0.3339\n",
      "Iter-14020, train loss-2.2163, acc-0.1800, valid loss-2.1898, acc-0.3324, test loss-2.1829, acc-0.3339\n",
      "Iter-14030, train loss-2.1858, acc-0.2600, valid loss-2.1897, acc-0.3324, test loss-2.1829, acc-0.3340\n",
      "Iter-14040, train loss-2.1995, acc-0.2400, valid loss-2.1897, acc-0.3326, test loss-2.1828, acc-0.3342\n",
      "Iter-14050, train loss-2.1511, acc-0.3800, valid loss-2.1896, acc-0.3326, test loss-2.1827, acc-0.3343\n",
      "Iter-14060, train loss-2.1979, acc-0.3200, valid loss-2.1895, acc-0.3324, test loss-2.1826, acc-0.3342\n",
      "Iter-14070, train loss-2.1944, acc-0.3600, valid loss-2.1895, acc-0.3326, test loss-2.1826, acc-0.3343\n",
      "Iter-14080, train loss-2.2113, acc-0.2000, valid loss-2.1894, acc-0.3324, test loss-2.1825, acc-0.3342\n",
      "Iter-14090, train loss-2.1671, acc-0.3400, valid loss-2.1893, acc-0.3328, test loss-2.1824, acc-0.3347\n",
      "Iter-14100, train loss-2.1738, acc-0.4000, valid loss-2.1893, acc-0.3330, test loss-2.1823, acc-0.3349\n",
      "Iter-14110, train loss-2.1823, acc-0.4800, valid loss-2.1892, acc-0.3330, test loss-2.1823, acc-0.3348\n",
      "Iter-14120, train loss-2.1947, acc-0.3200, valid loss-2.1891, acc-0.3330, test loss-2.1822, acc-0.3353\n",
      "Iter-14130, train loss-2.1978, acc-0.4000, valid loss-2.1891, acc-0.3332, test loss-2.1821, acc-0.3355\n",
      "Iter-14140, train loss-2.1961, acc-0.3400, valid loss-2.1890, acc-0.3334, test loss-2.1821, acc-0.3359\n",
      "Iter-14150, train loss-2.2104, acc-0.2200, valid loss-2.1889, acc-0.3344, test loss-2.1820, acc-0.3364\n",
      "Iter-14160, train loss-2.1611, acc-0.4600, valid loss-2.1889, acc-0.3344, test loss-2.1819, acc-0.3367\n",
      "Iter-14170, train loss-2.1811, acc-0.3600, valid loss-2.1888, acc-0.3350, test loss-2.1818, acc-0.3366\n",
      "Iter-14180, train loss-2.1971, acc-0.3800, valid loss-2.1887, acc-0.3350, test loss-2.1818, acc-0.3368\n",
      "Iter-14190, train loss-2.1601, acc-0.3200, valid loss-2.1887, acc-0.3348, test loss-2.1817, acc-0.3367\n",
      "Iter-14200, train loss-2.1676, acc-0.3200, valid loss-2.1886, acc-0.3348, test loss-2.1816, acc-0.3364\n",
      "Iter-14210, train loss-2.1930, acc-0.3000, valid loss-2.1885, acc-0.3350, test loss-2.1815, acc-0.3367\n",
      "Iter-14220, train loss-2.2107, acc-0.2800, valid loss-2.1884, acc-0.3348, test loss-2.1815, acc-0.3369\n",
      "Iter-14230, train loss-2.1565, acc-0.3400, valid loss-2.1884, acc-0.3352, test loss-2.1814, acc-0.3372\n",
      "Iter-14240, train loss-2.1651, acc-0.3600, valid loss-2.1883, acc-0.3346, test loss-2.1813, acc-0.3374\n",
      "Iter-14250, train loss-2.2005, acc-0.3400, valid loss-2.1882, acc-0.3348, test loss-2.1812, acc-0.3376\n",
      "Iter-14260, train loss-2.1936, acc-0.3000, valid loss-2.1882, acc-0.3348, test loss-2.1812, acc-0.3378\n",
      "Iter-14270, train loss-2.2062, acc-0.2800, valid loss-2.1881, acc-0.3348, test loss-2.1811, acc-0.3379\n",
      "Iter-14280, train loss-2.1813, acc-0.3000, valid loss-2.1880, acc-0.3350, test loss-2.1810, acc-0.3380\n",
      "Iter-14290, train loss-2.2035, acc-0.3400, valid loss-2.1880, acc-0.3352, test loss-2.1809, acc-0.3382\n",
      "Iter-14300, train loss-2.1632, acc-0.3600, valid loss-2.1879, acc-0.3348, test loss-2.1809, acc-0.3385\n",
      "Iter-14310, train loss-2.1998, acc-0.3200, valid loss-2.1879, acc-0.3350, test loss-2.1808, acc-0.3386\n",
      "Iter-14320, train loss-2.1479, acc-0.3600, valid loss-2.1878, acc-0.3356, test loss-2.1807, acc-0.3383\n",
      "Iter-14330, train loss-2.1602, acc-0.4200, valid loss-2.1877, acc-0.3358, test loss-2.1806, acc-0.3386\n",
      "Iter-14340, train loss-2.1839, acc-0.4000, valid loss-2.1876, acc-0.3358, test loss-2.1806, acc-0.3382\n",
      "Iter-14350, train loss-2.1894, acc-0.3400, valid loss-2.1876, acc-0.3362, test loss-2.1805, acc-0.3386\n",
      "Iter-14360, train loss-2.2025, acc-0.3600, valid loss-2.1875, acc-0.3358, test loss-2.1804, acc-0.3396\n",
      "Iter-14370, train loss-2.1866, acc-0.3600, valid loss-2.1874, acc-0.3360, test loss-2.1803, acc-0.3398\n",
      "Iter-14380, train loss-2.1566, acc-0.4400, valid loss-2.1874, acc-0.3364, test loss-2.1803, acc-0.3398\n",
      "Iter-14390, train loss-2.1899, acc-0.4000, valid loss-2.1873, acc-0.3366, test loss-2.1802, acc-0.3399\n",
      "Iter-14400, train loss-2.1932, acc-0.3200, valid loss-2.1872, acc-0.3368, test loss-2.1801, acc-0.3395\n",
      "Iter-14410, train loss-2.1788, acc-0.3200, valid loss-2.1872, acc-0.3370, test loss-2.1800, acc-0.3398\n",
      "Iter-14420, train loss-2.1745, acc-0.3400, valid loss-2.1871, acc-0.3370, test loss-2.1800, acc-0.3397\n",
      "Iter-14430, train loss-2.2074, acc-0.2200, valid loss-2.1870, acc-0.3370, test loss-2.1799, acc-0.3399\n",
      "Iter-14440, train loss-2.1868, acc-0.3000, valid loss-2.1870, acc-0.3374, test loss-2.1798, acc-0.3399\n",
      "Iter-14450, train loss-2.1855, acc-0.3200, valid loss-2.1869, acc-0.3370, test loss-2.1798, acc-0.3399\n",
      "Iter-14460, train loss-2.1799, acc-0.3400, valid loss-2.1868, acc-0.3370, test loss-2.1797, acc-0.3401\n",
      "Iter-14470, train loss-2.1790, acc-0.2800, valid loss-2.1868, acc-0.3378, test loss-2.1796, acc-0.3401\n",
      "Iter-14480, train loss-2.1705, acc-0.3600, valid loss-2.1867, acc-0.3380, test loss-2.1795, acc-0.3401\n",
      "Iter-14490, train loss-2.2081, acc-0.1800, valid loss-2.1866, acc-0.3378, test loss-2.1794, acc-0.3404\n",
      "Iter-14500, train loss-2.2066, acc-0.2600, valid loss-2.1866, acc-0.3382, test loss-2.1794, acc-0.3407\n",
      "Iter-14510, train loss-2.1955, acc-0.3000, valid loss-2.1865, acc-0.3384, test loss-2.1793, acc-0.3405\n",
      "Iter-14520, train loss-2.1880, acc-0.2800, valid loss-2.1864, acc-0.3382, test loss-2.1792, acc-0.3407\n",
      "Iter-14530, train loss-2.1604, acc-0.4600, valid loss-2.1864, acc-0.3384, test loss-2.1791, acc-0.3410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-14540, train loss-2.1633, acc-0.4400, valid loss-2.1863, acc-0.3386, test loss-2.1791, acc-0.3410\n",
      "Iter-14550, train loss-2.2027, acc-0.3200, valid loss-2.1862, acc-0.3386, test loss-2.1790, acc-0.3408\n",
      "Iter-14560, train loss-2.1713, acc-0.3400, valid loss-2.1862, acc-0.3384, test loss-2.1789, acc-0.3411\n",
      "Iter-14570, train loss-2.1810, acc-0.4200, valid loss-2.1861, acc-0.3382, test loss-2.1788, acc-0.3414\n",
      "Iter-14580, train loss-2.1746, acc-0.3800, valid loss-2.1860, acc-0.3388, test loss-2.1788, acc-0.3417\n",
      "Iter-14590, train loss-2.1750, acc-0.3200, valid loss-2.1860, acc-0.3388, test loss-2.1787, acc-0.3420\n",
      "Iter-14600, train loss-2.1952, acc-0.2400, valid loss-2.1859, acc-0.3386, test loss-2.1786, acc-0.3421\n",
      "Iter-14610, train loss-2.1924, acc-0.2600, valid loss-2.1858, acc-0.3388, test loss-2.1786, acc-0.3418\n",
      "Iter-14620, train loss-2.1993, acc-0.2600, valid loss-2.1858, acc-0.3390, test loss-2.1785, acc-0.3420\n",
      "Iter-14630, train loss-2.2235, acc-0.3000, valid loss-2.1857, acc-0.3392, test loss-2.1784, acc-0.3421\n",
      "Iter-14640, train loss-2.1677, acc-0.4200, valid loss-2.1856, acc-0.3394, test loss-2.1783, acc-0.3422\n",
      "Iter-14650, train loss-2.1998, acc-0.3000, valid loss-2.1856, acc-0.3394, test loss-2.1783, acc-0.3426\n",
      "Iter-14660, train loss-2.1530, acc-0.4200, valid loss-2.1855, acc-0.3398, test loss-2.1782, acc-0.3424\n",
      "Iter-14670, train loss-2.2246, acc-0.2400, valid loss-2.1854, acc-0.3400, test loss-2.1781, acc-0.3431\n",
      "Iter-14680, train loss-2.1742, acc-0.2800, valid loss-2.1853, acc-0.3402, test loss-2.1780, acc-0.3433\n",
      "Iter-14690, train loss-2.1939, acc-0.3200, valid loss-2.1853, acc-0.3402, test loss-2.1780, acc-0.3431\n",
      "Iter-14700, train loss-2.1870, acc-0.4000, valid loss-2.1852, acc-0.3408, test loss-2.1779, acc-0.3430\n",
      "Iter-14710, train loss-2.2107, acc-0.2600, valid loss-2.1851, acc-0.3406, test loss-2.1778, acc-0.3434\n",
      "Iter-14720, train loss-2.1476, acc-0.2800, valid loss-2.1851, acc-0.3410, test loss-2.1777, acc-0.3437\n",
      "Iter-14730, train loss-2.2110, acc-0.3600, valid loss-2.1850, acc-0.3408, test loss-2.1777, acc-0.3435\n",
      "Iter-14740, train loss-2.1854, acc-0.3000, valid loss-2.1849, acc-0.3410, test loss-2.1776, acc-0.3437\n",
      "Iter-14750, train loss-2.2071, acc-0.3000, valid loss-2.1849, acc-0.3414, test loss-2.1775, acc-0.3438\n",
      "Iter-14760, train loss-2.1987, acc-0.2800, valid loss-2.1848, acc-0.3412, test loss-2.1774, acc-0.3438\n",
      "Iter-14770, train loss-2.2037, acc-0.2800, valid loss-2.1847, acc-0.3410, test loss-2.1774, acc-0.3439\n",
      "Iter-14780, train loss-2.2022, acc-0.3400, valid loss-2.1847, acc-0.3410, test loss-2.1773, acc-0.3439\n",
      "Iter-14790, train loss-2.1873, acc-0.2800, valid loss-2.1846, acc-0.3412, test loss-2.1772, acc-0.3438\n",
      "Iter-14800, train loss-2.1945, acc-0.4400, valid loss-2.1846, acc-0.3416, test loss-2.1772, acc-0.3438\n",
      "Iter-14810, train loss-2.1705, acc-0.4200, valid loss-2.1845, acc-0.3414, test loss-2.1771, acc-0.3438\n",
      "Iter-14820, train loss-2.2078, acc-0.2400, valid loss-2.1844, acc-0.3418, test loss-2.1770, acc-0.3435\n",
      "Iter-14830, train loss-2.1849, acc-0.3200, valid loss-2.1844, acc-0.3418, test loss-2.1769, acc-0.3437\n",
      "Iter-14840, train loss-2.1771, acc-0.3000, valid loss-2.1843, acc-0.3414, test loss-2.1769, acc-0.3440\n",
      "Iter-14850, train loss-2.1346, acc-0.4400, valid loss-2.1842, acc-0.3416, test loss-2.1768, acc-0.3440\n",
      "Iter-14860, train loss-2.1949, acc-0.2600, valid loss-2.1842, acc-0.3414, test loss-2.1767, acc-0.3444\n",
      "Iter-14870, train loss-2.1490, acc-0.4000, valid loss-2.1841, acc-0.3420, test loss-2.1766, acc-0.3443\n",
      "Iter-14880, train loss-2.1369, acc-0.5000, valid loss-2.1840, acc-0.3422, test loss-2.1766, acc-0.3442\n",
      "Iter-14890, train loss-2.1916, acc-0.3200, valid loss-2.1840, acc-0.3422, test loss-2.1765, acc-0.3447\n",
      "Iter-14900, train loss-2.1653, acc-0.3800, valid loss-2.1839, acc-0.3420, test loss-2.1764, acc-0.3444\n",
      "Iter-14910, train loss-2.1752, acc-0.3600, valid loss-2.1838, acc-0.3424, test loss-2.1763, acc-0.3447\n",
      "Iter-14920, train loss-2.1790, acc-0.3200, valid loss-2.1837, acc-0.3426, test loss-2.1762, acc-0.3449\n",
      "Iter-14930, train loss-2.2019, acc-0.3600, valid loss-2.1837, acc-0.3432, test loss-2.1762, acc-0.3447\n",
      "Iter-14940, train loss-2.1724, acc-0.3400, valid loss-2.1836, acc-0.3432, test loss-2.1761, acc-0.3448\n",
      "Iter-14950, train loss-2.2076, acc-0.3200, valid loss-2.1835, acc-0.3428, test loss-2.1760, acc-0.3449\n",
      "Iter-14960, train loss-2.1668, acc-0.3800, valid loss-2.1835, acc-0.3428, test loss-2.1759, acc-0.3451\n",
      "Iter-14970, train loss-2.2110, acc-0.2600, valid loss-2.1834, acc-0.3434, test loss-2.1759, acc-0.3451\n",
      "Iter-14980, train loss-2.2507, acc-0.2800, valid loss-2.1833, acc-0.3436, test loss-2.1758, acc-0.3449\n",
      "Iter-14990, train loss-2.1806, acc-0.3800, valid loss-2.1833, acc-0.3438, test loss-2.1757, acc-0.3452\n",
      "Iter-15000, train loss-2.2055, acc-0.3000, valid loss-2.1832, acc-0.3436, test loss-2.1757, acc-0.3456\n",
      "Iter-15010, train loss-2.1519, acc-0.3200, valid loss-2.1832, acc-0.3436, test loss-2.1756, acc-0.3460\n",
      "Iter-15020, train loss-2.1900, acc-0.3000, valid loss-2.1831, acc-0.3440, test loss-2.1755, acc-0.3462\n",
      "Iter-15030, train loss-2.1931, acc-0.2800, valid loss-2.1830, acc-0.3438, test loss-2.1754, acc-0.3464\n",
      "Iter-15040, train loss-2.1685, acc-0.3800, valid loss-2.1830, acc-0.3440, test loss-2.1754, acc-0.3469\n",
      "Iter-15050, train loss-2.1660, acc-0.3200, valid loss-2.1829, acc-0.3434, test loss-2.1753, acc-0.3467\n",
      "Iter-15060, train loss-2.1656, acc-0.3800, valid loss-2.1828, acc-0.3436, test loss-2.1752, acc-0.3467\n",
      "Iter-15070, train loss-2.2020, acc-0.3600, valid loss-2.1828, acc-0.3434, test loss-2.1751, acc-0.3469\n",
      "Iter-15080, train loss-2.1931, acc-0.3800, valid loss-2.1827, acc-0.3432, test loss-2.1751, acc-0.3469\n",
      "Iter-15090, train loss-2.1717, acc-0.3000, valid loss-2.1826, acc-0.3436, test loss-2.1750, acc-0.3470\n",
      "Iter-15100, train loss-2.1667, acc-0.2600, valid loss-2.1826, acc-0.3438, test loss-2.1749, acc-0.3474\n",
      "Iter-15110, train loss-2.1708, acc-0.3600, valid loss-2.1825, acc-0.3440, test loss-2.1748, acc-0.3477\n",
      "Iter-15120, train loss-2.2031, acc-0.2600, valid loss-2.1824, acc-0.3440, test loss-2.1748, acc-0.3479\n",
      "Iter-15130, train loss-2.1949, acc-0.3000, valid loss-2.1824, acc-0.3436, test loss-2.1747, acc-0.3479\n",
      "Iter-15140, train loss-2.1391, acc-0.3800, valid loss-2.1823, acc-0.3432, test loss-2.1746, acc-0.3484\n",
      "Iter-15150, train loss-2.2147, acc-0.2400, valid loss-2.1822, acc-0.3434, test loss-2.1746, acc-0.3484\n",
      "Iter-15160, train loss-2.1603, acc-0.3400, valid loss-2.1822, acc-0.3436, test loss-2.1745, acc-0.3487\n",
      "Iter-15170, train loss-2.2039, acc-0.2800, valid loss-2.1821, acc-0.3438, test loss-2.1744, acc-0.3485\n",
      "Iter-15180, train loss-2.1861, acc-0.3800, valid loss-2.1820, acc-0.3438, test loss-2.1743, acc-0.3486\n",
      "Iter-15190, train loss-2.1716, acc-0.2600, valid loss-2.1820, acc-0.3440, test loss-2.1743, acc-0.3485\n",
      "Iter-15200, train loss-2.1833, acc-0.3800, valid loss-2.1819, acc-0.3444, test loss-2.1742, acc-0.3488\n",
      "Iter-15210, train loss-2.1383, acc-0.5600, valid loss-2.1818, acc-0.3444, test loss-2.1741, acc-0.3488\n",
      "Iter-15220, train loss-2.1810, acc-0.4000, valid loss-2.1818, acc-0.3442, test loss-2.1740, acc-0.3486\n",
      "Iter-15230, train loss-2.1371, acc-0.4200, valid loss-2.1817, acc-0.3446, test loss-2.1740, acc-0.3488\n",
      "Iter-15240, train loss-2.1680, acc-0.3400, valid loss-2.1816, acc-0.3452, test loss-2.1739, acc-0.3490\n",
      "Iter-15250, train loss-2.2072, acc-0.2400, valid loss-2.1815, acc-0.3454, test loss-2.1738, acc-0.3494\n",
      "Iter-15260, train loss-2.1936, acc-0.3600, valid loss-2.1815, acc-0.3452, test loss-2.1737, acc-0.3494\n",
      "Iter-15270, train loss-2.1680, acc-0.3600, valid loss-2.1814, acc-0.3454, test loss-2.1737, acc-0.3492\n",
      "Iter-15280, train loss-2.1734, acc-0.4200, valid loss-2.1813, acc-0.3454, test loss-2.1736, acc-0.3490\n",
      "Iter-15290, train loss-2.1674, acc-0.3600, valid loss-2.1813, acc-0.3454, test loss-2.1735, acc-0.3495\n",
      "Iter-15300, train loss-2.1850, acc-0.3200, valid loss-2.1812, acc-0.3454, test loss-2.1734, acc-0.3495\n",
      "Iter-15310, train loss-2.1617, acc-0.3800, valid loss-2.1811, acc-0.3458, test loss-2.1734, acc-0.3494\n",
      "Iter-15320, train loss-2.1965, acc-0.3200, valid loss-2.1811, acc-0.3458, test loss-2.1733, acc-0.3496\n",
      "Iter-15330, train loss-2.1898, acc-0.3200, valid loss-2.1810, acc-0.3464, test loss-2.1732, acc-0.3499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-15340, train loss-2.1977, acc-0.2200, valid loss-2.1809, acc-0.3464, test loss-2.1731, acc-0.3501\n",
      "Iter-15350, train loss-2.1682, acc-0.3600, valid loss-2.1809, acc-0.3464, test loss-2.1731, acc-0.3506\n",
      "Iter-15360, train loss-2.1599, acc-0.3600, valid loss-2.1808, acc-0.3464, test loss-2.1730, acc-0.3506\n",
      "Iter-15370, train loss-2.1954, acc-0.3800, valid loss-2.1807, acc-0.3464, test loss-2.1729, acc-0.3505\n",
      "Iter-15380, train loss-2.1582, acc-0.3400, valid loss-2.1807, acc-0.3466, test loss-2.1729, acc-0.3510\n",
      "Iter-15390, train loss-2.1581, acc-0.4200, valid loss-2.1806, acc-0.3466, test loss-2.1728, acc-0.3512\n",
      "Iter-15400, train loss-2.1636, acc-0.3000, valid loss-2.1805, acc-0.3466, test loss-2.1727, acc-0.3512\n",
      "Iter-15410, train loss-2.1923, acc-0.3000, valid loss-2.1805, acc-0.3474, test loss-2.1726, acc-0.3509\n",
      "Iter-15420, train loss-2.1608, acc-0.4200, valid loss-2.1804, acc-0.3480, test loss-2.1726, acc-0.3514\n",
      "Iter-15430, train loss-2.1630, acc-0.3000, valid loss-2.1803, acc-0.3474, test loss-2.1725, acc-0.3518\n",
      "Iter-15440, train loss-2.1801, acc-0.3600, valid loss-2.1803, acc-0.3472, test loss-2.1724, acc-0.3518\n",
      "Iter-15450, train loss-2.1739, acc-0.4000, valid loss-2.1802, acc-0.3468, test loss-2.1723, acc-0.3520\n",
      "Iter-15460, train loss-2.1615, acc-0.4000, valid loss-2.1801, acc-0.3466, test loss-2.1723, acc-0.3517\n",
      "Iter-15470, train loss-2.1788, acc-0.3600, valid loss-2.1801, acc-0.3468, test loss-2.1722, acc-0.3519\n",
      "Iter-15480, train loss-2.1732, acc-0.3200, valid loss-2.1800, acc-0.3474, test loss-2.1721, acc-0.3520\n",
      "Iter-15490, train loss-2.1890, acc-0.3400, valid loss-2.1799, acc-0.3472, test loss-2.1721, acc-0.3522\n",
      "Iter-15500, train loss-2.1809, acc-0.3000, valid loss-2.1799, acc-0.3476, test loss-2.1720, acc-0.3523\n",
      "Iter-15510, train loss-2.2146, acc-0.2600, valid loss-2.1798, acc-0.3482, test loss-2.1719, acc-0.3524\n",
      "Iter-15520, train loss-2.1780, acc-0.2600, valid loss-2.1797, acc-0.3484, test loss-2.1718, acc-0.3527\n",
      "Iter-15530, train loss-2.1589, acc-0.3000, valid loss-2.1797, acc-0.3486, test loss-2.1718, acc-0.3525\n",
      "Iter-15540, train loss-2.1983, acc-0.3800, valid loss-2.1796, acc-0.3486, test loss-2.1717, acc-0.3528\n",
      "Iter-15550, train loss-2.2217, acc-0.3600, valid loss-2.1795, acc-0.3484, test loss-2.1716, acc-0.3528\n",
      "Iter-15560, train loss-2.1732, acc-0.2800, valid loss-2.1795, acc-0.3482, test loss-2.1716, acc-0.3534\n",
      "Iter-15570, train loss-2.2021, acc-0.2800, valid loss-2.1794, acc-0.3484, test loss-2.1715, acc-0.3536\n",
      "Iter-15580, train loss-2.1788, acc-0.3400, valid loss-2.1793, acc-0.3484, test loss-2.1714, acc-0.3540\n",
      "Iter-15590, train loss-2.1319, acc-0.4400, valid loss-2.1793, acc-0.3488, test loss-2.1713, acc-0.3539\n",
      "Iter-15600, train loss-2.1770, acc-0.3600, valid loss-2.1792, acc-0.3486, test loss-2.1713, acc-0.3539\n",
      "Iter-15610, train loss-2.1947, acc-0.3000, valid loss-2.1791, acc-0.3486, test loss-2.1712, acc-0.3540\n",
      "Iter-15620, train loss-2.1899, acc-0.3000, valid loss-2.1791, acc-0.3492, test loss-2.1711, acc-0.3544\n",
      "Iter-15630, train loss-2.1389, acc-0.3400, valid loss-2.1790, acc-0.3494, test loss-2.1710, acc-0.3544\n",
      "Iter-15640, train loss-2.1625, acc-0.3400, valid loss-2.1789, acc-0.3492, test loss-2.1710, acc-0.3545\n",
      "Iter-15650, train loss-2.1624, acc-0.3200, valid loss-2.1789, acc-0.3492, test loss-2.1709, acc-0.3545\n",
      "Iter-15660, train loss-2.1873, acc-0.3600, valid loss-2.1788, acc-0.3492, test loss-2.1708, acc-0.3548\n",
      "Iter-15670, train loss-2.1950, acc-0.3200, valid loss-2.1787, acc-0.3500, test loss-2.1708, acc-0.3553\n",
      "Iter-15680, train loss-2.1757, acc-0.3800, valid loss-2.1787, acc-0.3500, test loss-2.1707, acc-0.3555\n",
      "Iter-15690, train loss-2.1551, acc-0.3800, valid loss-2.1786, acc-0.3502, test loss-2.1706, acc-0.3556\n",
      "Iter-15700, train loss-2.1820, acc-0.2800, valid loss-2.1785, acc-0.3502, test loss-2.1705, acc-0.3559\n",
      "Iter-15710, train loss-2.1489, acc-0.4200, valid loss-2.1785, acc-0.3506, test loss-2.1705, acc-0.3560\n",
      "Iter-15720, train loss-2.1616, acc-0.3600, valid loss-2.1784, acc-0.3504, test loss-2.1704, acc-0.3564\n",
      "Iter-15730, train loss-2.1963, acc-0.3400, valid loss-2.1783, acc-0.3504, test loss-2.1703, acc-0.3563\n",
      "Iter-15740, train loss-2.1873, acc-0.2600, valid loss-2.1783, acc-0.3504, test loss-2.1702, acc-0.3567\n",
      "Iter-15750, train loss-2.1512, acc-0.4200, valid loss-2.1782, acc-0.3512, test loss-2.1702, acc-0.3566\n",
      "Iter-15760, train loss-2.2061, acc-0.1800, valid loss-2.1781, acc-0.3514, test loss-2.1701, acc-0.3566\n",
      "Iter-15770, train loss-2.1637, acc-0.4800, valid loss-2.1781, acc-0.3514, test loss-2.1700, acc-0.3563\n",
      "Iter-15780, train loss-2.1507, acc-0.3200, valid loss-2.1780, acc-0.3516, test loss-2.1700, acc-0.3564\n",
      "Iter-15790, train loss-2.2093, acc-0.3200, valid loss-2.1779, acc-0.3512, test loss-2.1699, acc-0.3563\n",
      "Iter-15800, train loss-2.1752, acc-0.4000, valid loss-2.1779, acc-0.3514, test loss-2.1698, acc-0.3564\n",
      "Iter-15810, train loss-2.1276, acc-0.3800, valid loss-2.1778, acc-0.3518, test loss-2.1697, acc-0.3567\n",
      "Iter-15820, train loss-2.1666, acc-0.3200, valid loss-2.1777, acc-0.3518, test loss-2.1697, acc-0.3570\n",
      "Iter-15830, train loss-2.1800, acc-0.3000, valid loss-2.1777, acc-0.3516, test loss-2.1696, acc-0.3571\n",
      "Iter-15840, train loss-2.1906, acc-0.3800, valid loss-2.1776, acc-0.3520, test loss-2.1695, acc-0.3574\n",
      "Iter-15850, train loss-2.1441, acc-0.3800, valid loss-2.1775, acc-0.3522, test loss-2.1694, acc-0.3575\n",
      "Iter-15860, train loss-2.2031, acc-0.2600, valid loss-2.1775, acc-0.3518, test loss-2.1694, acc-0.3575\n",
      "Iter-15870, train loss-2.1690, acc-0.5000, valid loss-2.1774, acc-0.3518, test loss-2.1693, acc-0.3576\n",
      "Iter-15880, train loss-2.1627, acc-0.4000, valid loss-2.1773, acc-0.3516, test loss-2.1692, acc-0.3573\n",
      "Iter-15890, train loss-2.1574, acc-0.3800, valid loss-2.1773, acc-0.3514, test loss-2.1692, acc-0.3575\n",
      "Iter-15900, train loss-2.1829, acc-0.3400, valid loss-2.1772, acc-0.3520, test loss-2.1691, acc-0.3580\n",
      "Iter-15910, train loss-2.1882, acc-0.2600, valid loss-2.1772, acc-0.3514, test loss-2.1690, acc-0.3578\n",
      "Iter-15920, train loss-2.1769, acc-0.2800, valid loss-2.1771, acc-0.3520, test loss-2.1689, acc-0.3581\n",
      "Iter-15930, train loss-2.1815, acc-0.2800, valid loss-2.1770, acc-0.3518, test loss-2.1689, acc-0.3581\n",
      "Iter-15940, train loss-2.1953, acc-0.2600, valid loss-2.1770, acc-0.3520, test loss-2.1688, acc-0.3582\n",
      "Iter-15950, train loss-2.1508, acc-0.4800, valid loss-2.1769, acc-0.3526, test loss-2.1687, acc-0.3580\n",
      "Iter-15960, train loss-2.1429, acc-0.4200, valid loss-2.1768, acc-0.3534, test loss-2.1687, acc-0.3582\n",
      "Iter-15970, train loss-2.1663, acc-0.4200, valid loss-2.1767, acc-0.3538, test loss-2.1686, acc-0.3582\n",
      "Iter-15980, train loss-2.2118, acc-0.3200, valid loss-2.1767, acc-0.3540, test loss-2.1685, acc-0.3580\n",
      "Iter-15990, train loss-2.1748, acc-0.3400, valid loss-2.1766, acc-0.3540, test loss-2.1684, acc-0.3583\n",
      "Iter-16000, train loss-2.1576, acc-0.3400, valid loss-2.1766, acc-0.3540, test loss-2.1684, acc-0.3583\n",
      "Iter-16010, train loss-2.1837, acc-0.3000, valid loss-2.1765, acc-0.3544, test loss-2.1683, acc-0.3584\n",
      "Iter-16020, train loss-2.1529, acc-0.4200, valid loss-2.1764, acc-0.3536, test loss-2.1682, acc-0.3586\n",
      "Iter-16030, train loss-2.1842, acc-0.3200, valid loss-2.1763, acc-0.3536, test loss-2.1681, acc-0.3587\n",
      "Iter-16040, train loss-2.1821, acc-0.3400, valid loss-2.1763, acc-0.3534, test loss-2.1681, acc-0.3588\n",
      "Iter-16050, train loss-2.1588, acc-0.3400, valid loss-2.1762, acc-0.3534, test loss-2.1680, acc-0.3589\n",
      "Iter-16060, train loss-2.1922, acc-0.2600, valid loss-2.1761, acc-0.3534, test loss-2.1679, acc-0.3595\n",
      "Iter-16070, train loss-2.1486, acc-0.3800, valid loss-2.1761, acc-0.3532, test loss-2.1678, acc-0.3594\n",
      "Iter-16080, train loss-2.1950, acc-0.3200, valid loss-2.1760, acc-0.3530, test loss-2.1678, acc-0.3597\n",
      "Iter-16090, train loss-2.1683, acc-0.4000, valid loss-2.1759, acc-0.3528, test loss-2.1677, acc-0.3599\n",
      "Iter-16100, train loss-2.1729, acc-0.3400, valid loss-2.1759, acc-0.3532, test loss-2.1676, acc-0.3599\n",
      "Iter-16110, train loss-2.2054, acc-0.2000, valid loss-2.1758, acc-0.3532, test loss-2.1675, acc-0.3601\n",
      "Iter-16120, train loss-2.1328, acc-0.3800, valid loss-2.1757, acc-0.3530, test loss-2.1675, acc-0.3601\n",
      "Iter-16130, train loss-2.1797, acc-0.3600, valid loss-2.1757, acc-0.3526, test loss-2.1674, acc-0.3599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-16140, train loss-2.1834, acc-0.3200, valid loss-2.1756, acc-0.3528, test loss-2.1673, acc-0.3608\n",
      "Iter-16150, train loss-2.1666, acc-0.4600, valid loss-2.1755, acc-0.3524, test loss-2.1672, acc-0.3609\n",
      "Iter-16160, train loss-2.1900, acc-0.2600, valid loss-2.1755, acc-0.3528, test loss-2.1672, acc-0.3610\n",
      "Iter-16170, train loss-2.1902, acc-0.3400, valid loss-2.1754, acc-0.3532, test loss-2.1671, acc-0.3608\n",
      "Iter-16180, train loss-2.1635, acc-0.3200, valid loss-2.1753, acc-0.3530, test loss-2.1670, acc-0.3613\n",
      "Iter-16190, train loss-2.1924, acc-0.2800, valid loss-2.1753, acc-0.3532, test loss-2.1669, acc-0.3612\n",
      "Iter-16200, train loss-2.1525, acc-0.2800, valid loss-2.1752, acc-0.3532, test loss-2.1669, acc-0.3615\n",
      "Iter-16210, train loss-2.1584, acc-0.4000, valid loss-2.1751, acc-0.3532, test loss-2.1668, acc-0.3615\n",
      "Iter-16220, train loss-2.1543, acc-0.4000, valid loss-2.1751, acc-0.3536, test loss-2.1667, acc-0.3615\n",
      "Iter-16230, train loss-2.1994, acc-0.2600, valid loss-2.1750, acc-0.3534, test loss-2.1667, acc-0.3612\n",
      "Iter-16240, train loss-2.1673, acc-0.3000, valid loss-2.1749, acc-0.3538, test loss-2.1666, acc-0.3615\n",
      "Iter-16250, train loss-2.1621, acc-0.3800, valid loss-2.1749, acc-0.3534, test loss-2.1665, acc-0.3615\n",
      "Iter-16260, train loss-2.1810, acc-0.3600, valid loss-2.1748, acc-0.3532, test loss-2.1664, acc-0.3616\n",
      "Iter-16270, train loss-2.1595, acc-0.4400, valid loss-2.1747, acc-0.3530, test loss-2.1664, acc-0.3619\n",
      "Iter-16280, train loss-2.1880, acc-0.3000, valid loss-2.1747, acc-0.3530, test loss-2.1663, acc-0.3616\n",
      "Iter-16290, train loss-2.2034, acc-0.3200, valid loss-2.1746, acc-0.3532, test loss-2.1662, acc-0.3617\n",
      "Iter-16300, train loss-2.1653, acc-0.4000, valid loss-2.1745, acc-0.3532, test loss-2.1662, acc-0.3615\n",
      "Iter-16310, train loss-2.1294, acc-0.4400, valid loss-2.1745, acc-0.3532, test loss-2.1661, acc-0.3613\n",
      "Iter-16320, train loss-2.1904, acc-0.3200, valid loss-2.1744, acc-0.3534, test loss-2.1660, acc-0.3613\n",
      "Iter-16330, train loss-2.1170, acc-0.5600, valid loss-2.1743, acc-0.3530, test loss-2.1659, acc-0.3615\n",
      "Iter-16340, train loss-2.1618, acc-0.4400, valid loss-2.1743, acc-0.3534, test loss-2.1659, acc-0.3616\n",
      "Iter-16350, train loss-2.1158, acc-0.4400, valid loss-2.1742, acc-0.3534, test loss-2.1658, acc-0.3616\n",
      "Iter-16360, train loss-2.1527, acc-0.4400, valid loss-2.1741, acc-0.3536, test loss-2.1657, acc-0.3618\n",
      "Iter-16370, train loss-2.1652, acc-0.3400, valid loss-2.1741, acc-0.3534, test loss-2.1656, acc-0.3621\n",
      "Iter-16380, train loss-2.1406, acc-0.5200, valid loss-2.1740, acc-0.3534, test loss-2.1656, acc-0.3621\n",
      "Iter-16390, train loss-2.1640, acc-0.4200, valid loss-2.1739, acc-0.3536, test loss-2.1655, acc-0.3618\n",
      "Iter-16400, train loss-2.1519, acc-0.3400, valid loss-2.1739, acc-0.3536, test loss-2.1654, acc-0.3618\n",
      "Iter-16410, train loss-2.1675, acc-0.3200, valid loss-2.1738, acc-0.3538, test loss-2.1654, acc-0.3620\n",
      "Iter-16420, train loss-2.1672, acc-0.5000, valid loss-2.1738, acc-0.3536, test loss-2.1653, acc-0.3624\n",
      "Iter-16430, train loss-2.1577, acc-0.4000, valid loss-2.1737, acc-0.3536, test loss-2.1652, acc-0.3625\n",
      "Iter-16440, train loss-2.1281, acc-0.4200, valid loss-2.1736, acc-0.3544, test loss-2.1651, acc-0.3626\n",
      "Iter-16450, train loss-2.1613, acc-0.2600, valid loss-2.1736, acc-0.3544, test loss-2.1651, acc-0.3627\n",
      "Iter-16460, train loss-2.1504, acc-0.3400, valid loss-2.1735, acc-0.3544, test loss-2.1650, acc-0.3629\n",
      "Iter-16470, train loss-2.1338, acc-0.5200, valid loss-2.1734, acc-0.3544, test loss-2.1649, acc-0.3632\n",
      "Iter-16480, train loss-2.1530, acc-0.3600, valid loss-2.1734, acc-0.3548, test loss-2.1648, acc-0.3630\n",
      "Iter-16490, train loss-2.1881, acc-0.3200, valid loss-2.1733, acc-0.3542, test loss-2.1648, acc-0.3631\n",
      "Iter-16500, train loss-2.1621, acc-0.4600, valid loss-2.1732, acc-0.3550, test loss-2.1647, acc-0.3630\n",
      "Iter-16510, train loss-2.1720, acc-0.4000, valid loss-2.1732, acc-0.3548, test loss-2.1646, acc-0.3633\n",
      "Iter-16520, train loss-2.1733, acc-0.3800, valid loss-2.1731, acc-0.3554, test loss-2.1646, acc-0.3631\n",
      "Iter-16530, train loss-2.1833, acc-0.3000, valid loss-2.1730, acc-0.3546, test loss-2.1645, acc-0.3640\n",
      "Iter-16540, train loss-2.1845, acc-0.3400, valid loss-2.1730, acc-0.3548, test loss-2.1644, acc-0.3640\n",
      "Iter-16550, train loss-2.2095, acc-0.2400, valid loss-2.1729, acc-0.3550, test loss-2.1643, acc-0.3638\n",
      "Iter-16560, train loss-2.1897, acc-0.2400, valid loss-2.1728, acc-0.3552, test loss-2.1643, acc-0.3638\n",
      "Iter-16570, train loss-2.1842, acc-0.3000, valid loss-2.1728, acc-0.3552, test loss-2.1642, acc-0.3640\n",
      "Iter-16580, train loss-2.1717, acc-0.2800, valid loss-2.1727, acc-0.3556, test loss-2.1641, acc-0.3640\n",
      "Iter-16590, train loss-2.1928, acc-0.4200, valid loss-2.1726, acc-0.3556, test loss-2.1641, acc-0.3640\n",
      "Iter-16600, train loss-2.1668, acc-0.3000, valid loss-2.1726, acc-0.3552, test loss-2.1640, acc-0.3645\n",
      "Iter-16610, train loss-2.1679, acc-0.3800, valid loss-2.1725, acc-0.3554, test loss-2.1639, acc-0.3649\n",
      "Iter-16620, train loss-2.1253, acc-0.5400, valid loss-2.1724, acc-0.3552, test loss-2.1639, acc-0.3649\n",
      "Iter-16630, train loss-2.1710, acc-0.4000, valid loss-2.1724, acc-0.3554, test loss-2.1638, acc-0.3649\n",
      "Iter-16640, train loss-2.1438, acc-0.3400, valid loss-2.1723, acc-0.3554, test loss-2.1637, acc-0.3648\n",
      "Iter-16650, train loss-2.1322, acc-0.4200, valid loss-2.1722, acc-0.3550, test loss-2.1636, acc-0.3650\n",
      "Iter-16660, train loss-2.1477, acc-0.4400, valid loss-2.1722, acc-0.3556, test loss-2.1636, acc-0.3652\n",
      "Iter-16670, train loss-2.1515, acc-0.2600, valid loss-2.1721, acc-0.3556, test loss-2.1635, acc-0.3652\n",
      "Iter-16680, train loss-2.1704, acc-0.3600, valid loss-2.1721, acc-0.3554, test loss-2.1634, acc-0.3653\n",
      "Iter-16690, train loss-2.1563, acc-0.4000, valid loss-2.1720, acc-0.3562, test loss-2.1633, acc-0.3657\n",
      "Iter-16700, train loss-2.1892, acc-0.3400, valid loss-2.1719, acc-0.3556, test loss-2.1633, acc-0.3657\n",
      "Iter-16710, train loss-2.2068, acc-0.3200, valid loss-2.1719, acc-0.3550, test loss-2.1632, acc-0.3658\n",
      "Iter-16720, train loss-2.1798, acc-0.3800, valid loss-2.1718, acc-0.3560, test loss-2.1631, acc-0.3662\n",
      "Iter-16730, train loss-2.1652, acc-0.3800, valid loss-2.1717, acc-0.3558, test loss-2.1631, acc-0.3665\n",
      "Iter-16740, train loss-2.1510, acc-0.3400, valid loss-2.1716, acc-0.3564, test loss-2.1630, acc-0.3664\n",
      "Iter-16750, train loss-2.1567, acc-0.3600, valid loss-2.1716, acc-0.3560, test loss-2.1629, acc-0.3664\n",
      "Iter-16760, train loss-2.1541, acc-0.4400, valid loss-2.1715, acc-0.3560, test loss-2.1628, acc-0.3664\n",
      "Iter-16770, train loss-2.1501, acc-0.3600, valid loss-2.1715, acc-0.3564, test loss-2.1628, acc-0.3670\n",
      "Iter-16780, train loss-2.1835, acc-0.2800, valid loss-2.1714, acc-0.3564, test loss-2.1627, acc-0.3670\n",
      "Iter-16790, train loss-2.1410, acc-0.4000, valid loss-2.1713, acc-0.3564, test loss-2.1626, acc-0.3666\n",
      "Iter-16800, train loss-2.1614, acc-0.3200, valid loss-2.1713, acc-0.3568, test loss-2.1626, acc-0.3667\n",
      "Iter-16810, train loss-2.1612, acc-0.3800, valid loss-2.1712, acc-0.3566, test loss-2.1625, acc-0.3669\n",
      "Iter-16820, train loss-2.1808, acc-0.2400, valid loss-2.1711, acc-0.3570, test loss-2.1624, acc-0.3671\n",
      "Iter-16830, train loss-2.1535, acc-0.4200, valid loss-2.1711, acc-0.3572, test loss-2.1623, acc-0.3672\n",
      "Iter-16840, train loss-2.1737, acc-0.3200, valid loss-2.1710, acc-0.3572, test loss-2.1623, acc-0.3673\n",
      "Iter-16850, train loss-2.1774, acc-0.3600, valid loss-2.1709, acc-0.3574, test loss-2.1622, acc-0.3673\n",
      "Iter-16860, train loss-2.1748, acc-0.3000, valid loss-2.1709, acc-0.3574, test loss-2.1621, acc-0.3672\n",
      "Iter-16870, train loss-2.1564, acc-0.3400, valid loss-2.1708, acc-0.3574, test loss-2.1621, acc-0.3672\n",
      "Iter-16880, train loss-2.1560, acc-0.4800, valid loss-2.1707, acc-0.3572, test loss-2.1620, acc-0.3673\n",
      "Iter-16890, train loss-2.1783, acc-0.3600, valid loss-2.1707, acc-0.3578, test loss-2.1619, acc-0.3674\n",
      "Iter-16900, train loss-2.1950, acc-0.2400, valid loss-2.1706, acc-0.3578, test loss-2.1618, acc-0.3675\n",
      "Iter-16910, train loss-2.1441, acc-0.3600, valid loss-2.1705, acc-0.3576, test loss-2.1618, acc-0.3675\n",
      "Iter-16920, train loss-2.1523, acc-0.5000, valid loss-2.1705, acc-0.3582, test loss-2.1617, acc-0.3680\n",
      "Iter-16930, train loss-2.1917, acc-0.3400, valid loss-2.1704, acc-0.3580, test loss-2.1616, acc-0.3680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-16940, train loss-2.1585, acc-0.3800, valid loss-2.1704, acc-0.3580, test loss-2.1616, acc-0.3683\n",
      "Iter-16950, train loss-2.1422, acc-0.3800, valid loss-2.1703, acc-0.3584, test loss-2.1615, acc-0.3682\n",
      "Iter-16960, train loss-2.1163, acc-0.3600, valid loss-2.1702, acc-0.3584, test loss-2.1614, acc-0.3682\n",
      "Iter-16970, train loss-2.1157, acc-0.5600, valid loss-2.1702, acc-0.3586, test loss-2.1614, acc-0.3685\n",
      "Iter-16980, train loss-2.1926, acc-0.2800, valid loss-2.1701, acc-0.3584, test loss-2.1613, acc-0.3684\n",
      "Iter-16990, train loss-2.1737, acc-0.3000, valid loss-2.1701, acc-0.3584, test loss-2.1612, acc-0.3682\n",
      "Iter-17000, train loss-2.1594, acc-0.3600, valid loss-2.1700, acc-0.3584, test loss-2.1611, acc-0.3684\n",
      "Iter-17010, train loss-2.1155, acc-0.4400, valid loss-2.1699, acc-0.3588, test loss-2.1611, acc-0.3686\n",
      "Iter-17020, train loss-2.2170, acc-0.2600, valid loss-2.1699, acc-0.3588, test loss-2.1610, acc-0.3692\n",
      "Iter-17030, train loss-2.1513, acc-0.4200, valid loss-2.1698, acc-0.3590, test loss-2.1609, acc-0.3694\n",
      "Iter-17040, train loss-2.1256, acc-0.3600, valid loss-2.1697, acc-0.3594, test loss-2.1609, acc-0.3700\n",
      "Iter-17050, train loss-2.1775, acc-0.4200, valid loss-2.1696, acc-0.3596, test loss-2.1608, acc-0.3696\n",
      "Iter-17060, train loss-2.1494, acc-0.3400, valid loss-2.1696, acc-0.3598, test loss-2.1607, acc-0.3696\n",
      "Iter-17070, train loss-2.1696, acc-0.2800, valid loss-2.1695, acc-0.3598, test loss-2.1606, acc-0.3700\n",
      "Iter-17080, train loss-2.1753, acc-0.3600, valid loss-2.1695, acc-0.3598, test loss-2.1606, acc-0.3699\n",
      "Iter-17090, train loss-2.1989, acc-0.3200, valid loss-2.1694, acc-0.3600, test loss-2.1605, acc-0.3700\n",
      "Iter-17100, train loss-2.2009, acc-0.3600, valid loss-2.1693, acc-0.3600, test loss-2.1604, acc-0.3699\n",
      "Iter-17110, train loss-2.1490, acc-0.4600, valid loss-2.1693, acc-0.3602, test loss-2.1604, acc-0.3702\n",
      "Iter-17120, train loss-2.1743, acc-0.3600, valid loss-2.1692, acc-0.3602, test loss-2.1603, acc-0.3701\n",
      "Iter-17130, train loss-2.1382, acc-0.3600, valid loss-2.1691, acc-0.3606, test loss-2.1602, acc-0.3704\n",
      "Iter-17140, train loss-2.1475, acc-0.4600, valid loss-2.1691, acc-0.3606, test loss-2.1601, acc-0.3703\n",
      "Iter-17150, train loss-2.1635, acc-0.3400, valid loss-2.1690, acc-0.3606, test loss-2.1601, acc-0.3705\n",
      "Iter-17160, train loss-2.2100, acc-0.2800, valid loss-2.1689, acc-0.3604, test loss-2.1600, acc-0.3708\n",
      "Iter-17170, train loss-2.2032, acc-0.2200, valid loss-2.1689, acc-0.3608, test loss-2.1599, acc-0.3707\n",
      "Iter-17180, train loss-2.1454, acc-0.3800, valid loss-2.1688, acc-0.3608, test loss-2.1599, acc-0.3705\n",
      "Iter-17190, train loss-2.1329, acc-0.4000, valid loss-2.1687, acc-0.3612, test loss-2.1598, acc-0.3705\n",
      "Iter-17200, train loss-2.1391, acc-0.5400, valid loss-2.1687, acc-0.3608, test loss-2.1597, acc-0.3704\n",
      "Iter-17210, train loss-2.1538, acc-0.4200, valid loss-2.1686, acc-0.3616, test loss-2.1596, acc-0.3706\n",
      "Iter-17220, train loss-2.2075, acc-0.3200, valid loss-2.1685, acc-0.3616, test loss-2.1596, acc-0.3707\n",
      "Iter-17230, train loss-2.2121, acc-0.3200, valid loss-2.1685, acc-0.3616, test loss-2.1595, acc-0.3709\n",
      "Iter-17240, train loss-2.1762, acc-0.2200, valid loss-2.1684, acc-0.3616, test loss-2.1594, acc-0.3711\n",
      "Iter-17250, train loss-2.1512, acc-0.4800, valid loss-2.1684, acc-0.3616, test loss-2.1594, acc-0.3712\n",
      "Iter-17260, train loss-2.1276, acc-0.4200, valid loss-2.1683, acc-0.3618, test loss-2.1593, acc-0.3714\n",
      "Iter-17270, train loss-2.1917, acc-0.2000, valid loss-2.1682, acc-0.3620, test loss-2.1592, acc-0.3713\n",
      "Iter-17280, train loss-2.1776, acc-0.3800, valid loss-2.1682, acc-0.3620, test loss-2.1592, acc-0.3715\n",
      "Iter-17290, train loss-2.1687, acc-0.3400, valid loss-2.1681, acc-0.3622, test loss-2.1591, acc-0.3717\n",
      "Iter-17300, train loss-2.1559, acc-0.4400, valid loss-2.1680, acc-0.3624, test loss-2.1590, acc-0.3718\n",
      "Iter-17310, train loss-2.2069, acc-0.3000, valid loss-2.1680, acc-0.3620, test loss-2.1589, acc-0.3718\n",
      "Iter-17320, train loss-2.1742, acc-0.2800, valid loss-2.1679, acc-0.3624, test loss-2.1589, acc-0.3718\n",
      "Iter-17330, train loss-2.1659, acc-0.3600, valid loss-2.1678, acc-0.3624, test loss-2.1588, acc-0.3719\n",
      "Iter-17340, train loss-2.1874, acc-0.2600, valid loss-2.1678, acc-0.3628, test loss-2.1587, acc-0.3718\n",
      "Iter-17350, train loss-2.1639, acc-0.3800, valid loss-2.1677, acc-0.3620, test loss-2.1587, acc-0.3719\n",
      "Iter-17360, train loss-2.1747, acc-0.4000, valid loss-2.1677, acc-0.3628, test loss-2.1586, acc-0.3721\n",
      "Iter-17370, train loss-2.1692, acc-0.3400, valid loss-2.1676, acc-0.3630, test loss-2.1585, acc-0.3725\n",
      "Iter-17380, train loss-2.1726, acc-0.4200, valid loss-2.1675, acc-0.3634, test loss-2.1584, acc-0.3721\n",
      "Iter-17390, train loss-2.1879, acc-0.3800, valid loss-2.1675, acc-0.3634, test loss-2.1584, acc-0.3724\n",
      "Iter-17400, train loss-2.1507, acc-0.4000, valid loss-2.1674, acc-0.3638, test loss-2.1583, acc-0.3725\n",
      "Iter-17410, train loss-2.1689, acc-0.2400, valid loss-2.1673, acc-0.3634, test loss-2.1582, acc-0.3725\n",
      "Iter-17420, train loss-2.1842, acc-0.3200, valid loss-2.1673, acc-0.3638, test loss-2.1582, acc-0.3722\n",
      "Iter-17430, train loss-2.1471, acc-0.3800, valid loss-2.1672, acc-0.3638, test loss-2.1581, acc-0.3724\n",
      "Iter-17440, train loss-2.1468, acc-0.4000, valid loss-2.1672, acc-0.3642, test loss-2.1580, acc-0.3729\n",
      "Iter-17450, train loss-2.1966, acc-0.3400, valid loss-2.1671, acc-0.3642, test loss-2.1580, acc-0.3727\n",
      "Iter-17460, train loss-2.1566, acc-0.3000, valid loss-2.1670, acc-0.3646, test loss-2.1579, acc-0.3730\n",
      "Iter-17470, train loss-2.1284, acc-0.5000, valid loss-2.1670, acc-0.3646, test loss-2.1578, acc-0.3731\n",
      "Iter-17480, train loss-2.1562, acc-0.3400, valid loss-2.1669, acc-0.3646, test loss-2.1578, acc-0.3736\n",
      "Iter-17490, train loss-2.1466, acc-0.4200, valid loss-2.1668, acc-0.3646, test loss-2.1577, acc-0.3736\n",
      "Iter-17500, train loss-2.1555, acc-0.3600, valid loss-2.1668, acc-0.3644, test loss-2.1576, acc-0.3736\n",
      "Iter-17510, train loss-2.1721, acc-0.4000, valid loss-2.1667, acc-0.3650, test loss-2.1575, acc-0.3737\n",
      "Iter-17520, train loss-2.1388, acc-0.3800, valid loss-2.1667, acc-0.3650, test loss-2.1575, acc-0.3739\n",
      "Iter-17530, train loss-2.1441, acc-0.5200, valid loss-2.1666, acc-0.3650, test loss-2.1574, acc-0.3736\n",
      "Iter-17540, train loss-2.1374, acc-0.2800, valid loss-2.1665, acc-0.3650, test loss-2.1573, acc-0.3735\n",
      "Iter-17550, train loss-2.1974, acc-0.3400, valid loss-2.1665, acc-0.3654, test loss-2.1573, acc-0.3738\n",
      "Iter-17560, train loss-2.1391, acc-0.4400, valid loss-2.1664, acc-0.3654, test loss-2.1572, acc-0.3741\n",
      "Iter-17570, train loss-2.1355, acc-0.3800, valid loss-2.1663, acc-0.3652, test loss-2.1571, acc-0.3737\n",
      "Iter-17580, train loss-2.1378, acc-0.4400, valid loss-2.1663, acc-0.3656, test loss-2.1570, acc-0.3739\n",
      "Iter-17590, train loss-2.1523, acc-0.3200, valid loss-2.1662, acc-0.3654, test loss-2.1570, acc-0.3739\n",
      "Iter-17600, train loss-2.1741, acc-0.3000, valid loss-2.1661, acc-0.3652, test loss-2.1569, acc-0.3746\n",
      "Iter-17610, train loss-2.1388, acc-0.3400, valid loss-2.1661, acc-0.3656, test loss-2.1568, acc-0.3749\n",
      "Iter-17620, train loss-2.1640, acc-0.3600, valid loss-2.1660, acc-0.3654, test loss-2.1568, acc-0.3750\n",
      "Iter-17630, train loss-2.2294, acc-0.3200, valid loss-2.1660, acc-0.3660, test loss-2.1567, acc-0.3750\n",
      "Iter-17640, train loss-2.1698, acc-0.4000, valid loss-2.1659, acc-0.3658, test loss-2.1566, acc-0.3753\n",
      "Iter-17650, train loss-2.1677, acc-0.3800, valid loss-2.1658, acc-0.3656, test loss-2.1566, acc-0.3752\n",
      "Iter-17660, train loss-2.1347, acc-0.4400, valid loss-2.1658, acc-0.3662, test loss-2.1565, acc-0.3750\n",
      "Iter-17670, train loss-2.1607, acc-0.3600, valid loss-2.1657, acc-0.3664, test loss-2.1564, acc-0.3751\n",
      "Iter-17680, train loss-2.1571, acc-0.3200, valid loss-2.1656, acc-0.3674, test loss-2.1563, acc-0.3751\n",
      "Iter-17690, train loss-2.1412, acc-0.5400, valid loss-2.1656, acc-0.3672, test loss-2.1563, acc-0.3751\n",
      "Iter-17700, train loss-2.1701, acc-0.4000, valid loss-2.1655, acc-0.3670, test loss-2.1562, acc-0.3751\n",
      "Iter-17710, train loss-2.1507, acc-0.4000, valid loss-2.1655, acc-0.3670, test loss-2.1561, acc-0.3751\n",
      "Iter-17720, train loss-2.1493, acc-0.3200, valid loss-2.1654, acc-0.3674, test loss-2.1561, acc-0.3752\n",
      "Iter-17730, train loss-2.1737, acc-0.3800, valid loss-2.1653, acc-0.3676, test loss-2.1560, acc-0.3755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-17740, train loss-2.1781, acc-0.3200, valid loss-2.1653, acc-0.3674, test loss-2.1559, acc-0.3754\n",
      "Iter-17750, train loss-2.1549, acc-0.4200, valid loss-2.1652, acc-0.3678, test loss-2.1558, acc-0.3756\n",
      "Iter-17760, train loss-2.1774, acc-0.2800, valid loss-2.1651, acc-0.3674, test loss-2.1558, acc-0.3758\n",
      "Iter-17770, train loss-2.1328, acc-0.4400, valid loss-2.1651, acc-0.3672, test loss-2.1557, acc-0.3757\n",
      "Iter-17780, train loss-2.1516, acc-0.4600, valid loss-2.1650, acc-0.3672, test loss-2.1556, acc-0.3757\n",
      "Iter-17790, train loss-2.1605, acc-0.2800, valid loss-2.1649, acc-0.3672, test loss-2.1556, acc-0.3758\n",
      "Iter-17800, train loss-2.1729, acc-0.3200, valid loss-2.1649, acc-0.3672, test loss-2.1555, acc-0.3760\n",
      "Iter-17810, train loss-2.1219, acc-0.3400, valid loss-2.1648, acc-0.3668, test loss-2.1554, acc-0.3760\n",
      "Iter-17820, train loss-2.1196, acc-0.4400, valid loss-2.1647, acc-0.3664, test loss-2.1554, acc-0.3759\n",
      "Iter-17830, train loss-2.1844, acc-0.3200, valid loss-2.1647, acc-0.3666, test loss-2.1553, acc-0.3758\n",
      "Iter-17840, train loss-2.1545, acc-0.2600, valid loss-2.1646, acc-0.3668, test loss-2.1552, acc-0.3761\n",
      "Iter-17850, train loss-2.1459, acc-0.3800, valid loss-2.1646, acc-0.3672, test loss-2.1552, acc-0.3759\n",
      "Iter-17860, train loss-2.1441, acc-0.3600, valid loss-2.1645, acc-0.3668, test loss-2.1551, acc-0.3761\n",
      "Iter-17870, train loss-2.1317, acc-0.4600, valid loss-2.1644, acc-0.3674, test loss-2.1550, acc-0.3762\n",
      "Iter-17880, train loss-2.1251, acc-0.3800, valid loss-2.1644, acc-0.3676, test loss-2.1549, acc-0.3762\n",
      "Iter-17890, train loss-2.1482, acc-0.4400, valid loss-2.1643, acc-0.3672, test loss-2.1549, acc-0.3762\n",
      "Iter-17900, train loss-2.1944, acc-0.2600, valid loss-2.1642, acc-0.3678, test loss-2.1548, acc-0.3764\n",
      "Iter-17910, train loss-2.1753, acc-0.3000, valid loss-2.1642, acc-0.3680, test loss-2.1547, acc-0.3762\n",
      "Iter-17920, train loss-2.1273, acc-0.3600, valid loss-2.1641, acc-0.3684, test loss-2.1547, acc-0.3764\n",
      "Iter-17930, train loss-2.1958, acc-0.2000, valid loss-2.1640, acc-0.3682, test loss-2.1546, acc-0.3767\n",
      "Iter-17940, train loss-2.1772, acc-0.3400, valid loss-2.1640, acc-0.3682, test loss-2.1545, acc-0.3765\n",
      "Iter-17950, train loss-2.1700, acc-0.3600, valid loss-2.1639, acc-0.3686, test loss-2.1544, acc-0.3764\n",
      "Iter-17960, train loss-2.1289, acc-0.3400, valid loss-2.1638, acc-0.3684, test loss-2.1544, acc-0.3767\n",
      "Iter-17970, train loss-2.1242, acc-0.4000, valid loss-2.1638, acc-0.3686, test loss-2.1543, acc-0.3766\n",
      "Iter-17980, train loss-2.1780, acc-0.3200, valid loss-2.1637, acc-0.3688, test loss-2.1542, acc-0.3765\n",
      "Iter-17990, train loss-2.1875, acc-0.3000, valid loss-2.1637, acc-0.3686, test loss-2.1542, acc-0.3769\n",
      "Iter-18000, train loss-2.1632, acc-0.4400, valid loss-2.1636, acc-0.3686, test loss-2.1541, acc-0.3769\n",
      "Iter-18010, train loss-2.1393, acc-0.4800, valid loss-2.1635, acc-0.3690, test loss-2.1540, acc-0.3770\n",
      "Iter-18020, train loss-2.1481, acc-0.3400, valid loss-2.1635, acc-0.3690, test loss-2.1539, acc-0.3772\n",
      "Iter-18030, train loss-2.1882, acc-0.2600, valid loss-2.1634, acc-0.3696, test loss-2.1539, acc-0.3772\n",
      "Iter-18040, train loss-2.1534, acc-0.4400, valid loss-2.1633, acc-0.3692, test loss-2.1538, acc-0.3777\n",
      "Iter-18050, train loss-2.1964, acc-0.4000, valid loss-2.1633, acc-0.3690, test loss-2.1537, acc-0.3777\n",
      "Iter-18060, train loss-2.1430, acc-0.3600, valid loss-2.1632, acc-0.3690, test loss-2.1537, acc-0.3775\n",
      "Iter-18070, train loss-2.1787, acc-0.3000, valid loss-2.1631, acc-0.3694, test loss-2.1536, acc-0.3772\n",
      "Iter-18080, train loss-2.1793, acc-0.4200, valid loss-2.1631, acc-0.3694, test loss-2.1535, acc-0.3778\n",
      "Iter-18090, train loss-2.1825, acc-0.2800, valid loss-2.1630, acc-0.3694, test loss-2.1534, acc-0.3777\n",
      "Iter-18100, train loss-2.1425, acc-0.3600, valid loss-2.1629, acc-0.3694, test loss-2.1534, acc-0.3778\n",
      "Iter-18110, train loss-2.1536, acc-0.4000, valid loss-2.1629, acc-0.3694, test loss-2.1533, acc-0.3777\n",
      "Iter-18120, train loss-2.1341, acc-0.4000, valid loss-2.1628, acc-0.3698, test loss-2.1532, acc-0.3778\n",
      "Iter-18130, train loss-2.1664, acc-0.4000, valid loss-2.1627, acc-0.3706, test loss-2.1532, acc-0.3778\n",
      "Iter-18140, train loss-2.2054, acc-0.3000, valid loss-2.1627, acc-0.3708, test loss-2.1531, acc-0.3776\n",
      "Iter-18150, train loss-2.1748, acc-0.2600, valid loss-2.1626, acc-0.3708, test loss-2.1530, acc-0.3779\n",
      "Iter-18160, train loss-2.1655, acc-0.3600, valid loss-2.1625, acc-0.3708, test loss-2.1529, acc-0.3782\n",
      "Iter-18170, train loss-2.1622, acc-0.3200, valid loss-2.1625, acc-0.3708, test loss-2.1529, acc-0.3780\n",
      "Iter-18180, train loss-2.1705, acc-0.4200, valid loss-2.1624, acc-0.3708, test loss-2.1528, acc-0.3784\n",
      "Iter-18190, train loss-2.1440, acc-0.3800, valid loss-2.1624, acc-0.3710, test loss-2.1527, acc-0.3783\n",
      "Iter-18200, train loss-2.1392, acc-0.3000, valid loss-2.1623, acc-0.3712, test loss-2.1527, acc-0.3784\n",
      "Iter-18210, train loss-2.1388, acc-0.5000, valid loss-2.1622, acc-0.3712, test loss-2.1526, acc-0.3786\n",
      "Iter-18220, train loss-2.1621, acc-0.3800, valid loss-2.1622, acc-0.3712, test loss-2.1525, acc-0.3789\n",
      "Iter-18230, train loss-2.1424, acc-0.3600, valid loss-2.1621, acc-0.3712, test loss-2.1524, acc-0.3788\n",
      "Iter-18240, train loss-2.1729, acc-0.3000, valid loss-2.1620, acc-0.3716, test loss-2.1524, acc-0.3787\n",
      "Iter-18250, train loss-2.1830, acc-0.3200, valid loss-2.1620, acc-0.3714, test loss-2.1523, acc-0.3790\n",
      "Iter-18260, train loss-2.1362, acc-0.4000, valid loss-2.1619, acc-0.3714, test loss-2.1522, acc-0.3794\n",
      "Iter-18270, train loss-2.1887, acc-0.2200, valid loss-2.1619, acc-0.3714, test loss-2.1522, acc-0.3792\n",
      "Iter-18280, train loss-2.1360, acc-0.4000, valid loss-2.1618, acc-0.3716, test loss-2.1521, acc-0.3796\n",
      "Iter-18290, train loss-2.1671, acc-0.3800, valid loss-2.1617, acc-0.3718, test loss-2.1520, acc-0.3795\n",
      "Iter-18300, train loss-2.1942, acc-0.2400, valid loss-2.1617, acc-0.3720, test loss-2.1520, acc-0.3794\n",
      "Iter-18310, train loss-2.1769, acc-0.2400, valid loss-2.1616, acc-0.3724, test loss-2.1519, acc-0.3795\n",
      "Iter-18320, train loss-2.1333, acc-0.4600, valid loss-2.1615, acc-0.3722, test loss-2.1518, acc-0.3796\n",
      "Iter-18330, train loss-2.1530, acc-0.3000, valid loss-2.1615, acc-0.3718, test loss-2.1518, acc-0.3794\n",
      "Iter-18340, train loss-2.1640, acc-0.3600, valid loss-2.1614, acc-0.3720, test loss-2.1517, acc-0.3793\n",
      "Iter-18350, train loss-2.1248, acc-0.4800, valid loss-2.1613, acc-0.3720, test loss-2.1516, acc-0.3793\n",
      "Iter-18360, train loss-2.1282, acc-0.5000, valid loss-2.1613, acc-0.3720, test loss-2.1515, acc-0.3792\n",
      "Iter-18370, train loss-2.1070, acc-0.4400, valid loss-2.1612, acc-0.3728, test loss-2.1515, acc-0.3795\n",
      "Iter-18380, train loss-2.1674, acc-0.4200, valid loss-2.1612, acc-0.3728, test loss-2.1514, acc-0.3798\n",
      "Iter-18390, train loss-2.1293, acc-0.4800, valid loss-2.1611, acc-0.3732, test loss-2.1513, acc-0.3800\n",
      "Iter-18400, train loss-2.1678, acc-0.3600, valid loss-2.1610, acc-0.3726, test loss-2.1513, acc-0.3803\n",
      "Iter-18410, train loss-2.1670, acc-0.3400, valid loss-2.1610, acc-0.3730, test loss-2.1512, acc-0.3803\n",
      "Iter-18420, train loss-2.1558, acc-0.4000, valid loss-2.1609, acc-0.3732, test loss-2.1511, acc-0.3803\n",
      "Iter-18430, train loss-2.1401, acc-0.5200, valid loss-2.1608, acc-0.3732, test loss-2.1511, acc-0.3807\n",
      "Iter-18440, train loss-2.1934, acc-0.3600, valid loss-2.1608, acc-0.3732, test loss-2.1510, acc-0.3809\n",
      "Iter-18450, train loss-2.1166, acc-0.3400, valid loss-2.1607, acc-0.3736, test loss-2.1509, acc-0.3809\n",
      "Iter-18460, train loss-2.1550, acc-0.2800, valid loss-2.1606, acc-0.3732, test loss-2.1509, acc-0.3816\n",
      "Iter-18470, train loss-2.1838, acc-0.3200, valid loss-2.1606, acc-0.3732, test loss-2.1508, acc-0.3815\n",
      "Iter-18480, train loss-2.1498, acc-0.3400, valid loss-2.1605, acc-0.3734, test loss-2.1507, acc-0.3816\n",
      "Iter-18490, train loss-2.1861, acc-0.3400, valid loss-2.1604, acc-0.3732, test loss-2.1506, acc-0.3816\n",
      "Iter-18500, train loss-2.1672, acc-0.4000, valid loss-2.1604, acc-0.3736, test loss-2.1506, acc-0.3817\n",
      "Iter-18510, train loss-2.1566, acc-0.4200, valid loss-2.1603, acc-0.3734, test loss-2.1505, acc-0.3819\n",
      "Iter-18520, train loss-2.1480, acc-0.3200, valid loss-2.1603, acc-0.3736, test loss-2.1504, acc-0.3818\n",
      "Iter-18530, train loss-2.1722, acc-0.3400, valid loss-2.1602, acc-0.3740, test loss-2.1504, acc-0.3823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-18540, train loss-2.1549, acc-0.4000, valid loss-2.1601, acc-0.3738, test loss-2.1503, acc-0.3824\n",
      "Iter-18550, train loss-2.1542, acc-0.4000, valid loss-2.1601, acc-0.3740, test loss-2.1502, acc-0.3822\n",
      "Iter-18560, train loss-2.1431, acc-0.3600, valid loss-2.1600, acc-0.3742, test loss-2.1501, acc-0.3828\n",
      "Iter-18570, train loss-2.1027, acc-0.4400, valid loss-2.1600, acc-0.3742, test loss-2.1501, acc-0.3826\n",
      "Iter-18580, train loss-2.1578, acc-0.4200, valid loss-2.1599, acc-0.3742, test loss-2.1500, acc-0.3827\n",
      "Iter-18590, train loss-2.1085, acc-0.4400, valid loss-2.1598, acc-0.3742, test loss-2.1499, acc-0.3826\n",
      "Iter-18600, train loss-2.1516, acc-0.3600, valid loss-2.1598, acc-0.3746, test loss-2.1499, acc-0.3827\n",
      "Iter-18610, train loss-2.1926, acc-0.3600, valid loss-2.1597, acc-0.3746, test loss-2.1498, acc-0.3827\n",
      "Iter-18620, train loss-2.1657, acc-0.3200, valid loss-2.1597, acc-0.3746, test loss-2.1497, acc-0.3828\n",
      "Iter-18630, train loss-2.1332, acc-0.4000, valid loss-2.1596, acc-0.3746, test loss-2.1497, acc-0.3830\n",
      "Iter-18640, train loss-2.1334, acc-0.4200, valid loss-2.1595, acc-0.3748, test loss-2.1496, acc-0.3832\n",
      "Iter-18650, train loss-2.1491, acc-0.3800, valid loss-2.1595, acc-0.3750, test loss-2.1495, acc-0.3836\n",
      "Iter-18660, train loss-2.1755, acc-0.3600, valid loss-2.1594, acc-0.3750, test loss-2.1495, acc-0.3835\n",
      "Iter-18670, train loss-2.1445, acc-0.3200, valid loss-2.1593, acc-0.3748, test loss-2.1494, acc-0.3836\n",
      "Iter-18680, train loss-2.1615, acc-0.3400, valid loss-2.1593, acc-0.3750, test loss-2.1493, acc-0.3835\n",
      "Iter-18690, train loss-2.1648, acc-0.3400, valid loss-2.1592, acc-0.3750, test loss-2.1493, acc-0.3837\n",
      "Iter-18700, train loss-2.1843, acc-0.2800, valid loss-2.1592, acc-0.3752, test loss-2.1492, acc-0.3837\n",
      "Iter-18710, train loss-2.1515, acc-0.3400, valid loss-2.1591, acc-0.3750, test loss-2.1491, acc-0.3837\n",
      "Iter-18720, train loss-2.1646, acc-0.4600, valid loss-2.1590, acc-0.3752, test loss-2.1491, acc-0.3836\n",
      "Iter-18730, train loss-2.1410, acc-0.4200, valid loss-2.1590, acc-0.3758, test loss-2.1490, acc-0.3834\n",
      "Iter-18740, train loss-2.1562, acc-0.4800, valid loss-2.1589, acc-0.3758, test loss-2.1489, acc-0.3833\n",
      "Iter-18750, train loss-2.1231, acc-0.4400, valid loss-2.1589, acc-0.3758, test loss-2.1488, acc-0.3835\n",
      "Iter-18760, train loss-2.1852, acc-0.2800, valid loss-2.1588, acc-0.3758, test loss-2.1488, acc-0.3835\n",
      "Iter-18770, train loss-2.1683, acc-0.3200, valid loss-2.1587, acc-0.3756, test loss-2.1487, acc-0.3834\n",
      "Iter-18780, train loss-2.1529, acc-0.4000, valid loss-2.1587, acc-0.3758, test loss-2.1486, acc-0.3836\n",
      "Iter-18790, train loss-2.1388, acc-0.4200, valid loss-2.1586, acc-0.3756, test loss-2.1486, acc-0.3841\n",
      "Iter-18800, train loss-2.1325, acc-0.4200, valid loss-2.1585, acc-0.3758, test loss-2.1485, acc-0.3837\n",
      "Iter-18810, train loss-2.2176, acc-0.2800, valid loss-2.1585, acc-0.3758, test loss-2.1484, acc-0.3840\n",
      "Iter-18820, train loss-2.1527, acc-0.4200, valid loss-2.1584, acc-0.3760, test loss-2.1484, acc-0.3839\n",
      "Iter-18830, train loss-2.1587, acc-0.4200, valid loss-2.1584, acc-0.3760, test loss-2.1483, acc-0.3842\n",
      "Iter-18840, train loss-2.1509, acc-0.3600, valid loss-2.1583, acc-0.3760, test loss-2.1482, acc-0.3841\n",
      "Iter-18850, train loss-2.1928, acc-0.4000, valid loss-2.1582, acc-0.3756, test loss-2.1482, acc-0.3842\n",
      "Iter-18860, train loss-2.1729, acc-0.2800, valid loss-2.1582, acc-0.3760, test loss-2.1481, acc-0.3841\n",
      "Iter-18870, train loss-2.1813, acc-0.3200, valid loss-2.1581, acc-0.3760, test loss-2.1480, acc-0.3843\n",
      "Iter-18880, train loss-2.1450, acc-0.3600, valid loss-2.1581, acc-0.3764, test loss-2.1480, acc-0.3845\n",
      "Iter-18890, train loss-2.1598, acc-0.3600, valid loss-2.1580, acc-0.3758, test loss-2.1479, acc-0.3851\n",
      "Iter-18900, train loss-2.1458, acc-0.3200, valid loss-2.1579, acc-0.3760, test loss-2.1478, acc-0.3852\n",
      "Iter-18910, train loss-2.1681, acc-0.2800, valid loss-2.1579, acc-0.3760, test loss-2.1478, acc-0.3853\n",
      "Iter-18920, train loss-2.1353, acc-0.4800, valid loss-2.1578, acc-0.3760, test loss-2.1477, acc-0.3854\n",
      "Iter-18930, train loss-2.1537, acc-0.3400, valid loss-2.1577, acc-0.3760, test loss-2.1476, acc-0.3857\n",
      "Iter-18940, train loss-2.1623, acc-0.4000, valid loss-2.1577, acc-0.3766, test loss-2.1476, acc-0.3856\n",
      "Iter-18950, train loss-2.1821, acc-0.3400, valid loss-2.1576, acc-0.3770, test loss-2.1475, acc-0.3855\n",
      "Iter-18960, train loss-2.1010, acc-0.5000, valid loss-2.1576, acc-0.3772, test loss-2.1474, acc-0.3858\n",
      "Iter-18970, train loss-2.1539, acc-0.4600, valid loss-2.1575, acc-0.3772, test loss-2.1473, acc-0.3860\n",
      "Iter-18980, train loss-2.1274, acc-0.4200, valid loss-2.1574, acc-0.3768, test loss-2.1473, acc-0.3858\n",
      "Iter-18990, train loss-2.1723, acc-0.4400, valid loss-2.1574, acc-0.3772, test loss-2.1472, acc-0.3859\n",
      "Iter-19000, train loss-2.1732, acc-0.3200, valid loss-2.1573, acc-0.3772, test loss-2.1471, acc-0.3864\n",
      "Iter-19010, train loss-2.1572, acc-0.3600, valid loss-2.1572, acc-0.3774, test loss-2.1471, acc-0.3863\n",
      "Iter-19020, train loss-2.1803, acc-0.3200, valid loss-2.1572, acc-0.3774, test loss-2.1470, acc-0.3866\n",
      "Iter-19030, train loss-2.1911, acc-0.2800, valid loss-2.1571, acc-0.3770, test loss-2.1469, acc-0.3870\n",
      "Iter-19040, train loss-2.1302, acc-0.4200, valid loss-2.1571, acc-0.3772, test loss-2.1469, acc-0.3875\n",
      "Iter-19050, train loss-2.1707, acc-0.3200, valid loss-2.1570, acc-0.3772, test loss-2.1468, acc-0.3876\n",
      "Iter-19060, train loss-2.1500, acc-0.3400, valid loss-2.1569, acc-0.3772, test loss-2.1467, acc-0.3876\n",
      "Iter-19070, train loss-2.1425, acc-0.4600, valid loss-2.1569, acc-0.3772, test loss-2.1467, acc-0.3875\n",
      "Iter-19080, train loss-2.1335, acc-0.3400, valid loss-2.1568, acc-0.3774, test loss-2.1466, acc-0.3876\n",
      "Iter-19090, train loss-2.1877, acc-0.3000, valid loss-2.1567, acc-0.3780, test loss-2.1465, acc-0.3879\n",
      "Iter-19100, train loss-2.1607, acc-0.3200, valid loss-2.1567, acc-0.3784, test loss-2.1464, acc-0.3877\n",
      "Iter-19110, train loss-2.1674, acc-0.3600, valid loss-2.1566, acc-0.3782, test loss-2.1464, acc-0.3879\n",
      "Iter-19120, train loss-2.1464, acc-0.4200, valid loss-2.1566, acc-0.3782, test loss-2.1463, acc-0.3878\n",
      "Iter-19130, train loss-2.1604, acc-0.3800, valid loss-2.1565, acc-0.3782, test loss-2.1462, acc-0.3881\n",
      "Iter-19140, train loss-2.1709, acc-0.3400, valid loss-2.1564, acc-0.3782, test loss-2.1462, acc-0.3884\n",
      "Iter-19150, train loss-2.1634, acc-0.3000, valid loss-2.1564, acc-0.3782, test loss-2.1461, acc-0.3884\n",
      "Iter-19160, train loss-2.1688, acc-0.2600, valid loss-2.1563, acc-0.3786, test loss-2.1460, acc-0.3882\n",
      "Iter-19170, train loss-2.1607, acc-0.3400, valid loss-2.1563, acc-0.3782, test loss-2.1460, acc-0.3884\n",
      "Iter-19180, train loss-2.1433, acc-0.4400, valid loss-2.1562, acc-0.3780, test loss-2.1459, acc-0.3878\n",
      "Iter-19190, train loss-2.1668, acc-0.3800, valid loss-2.1561, acc-0.3778, test loss-2.1458, acc-0.3877\n",
      "Iter-19200, train loss-2.1428, acc-0.4600, valid loss-2.1561, acc-0.3780, test loss-2.1458, acc-0.3877\n",
      "Iter-19210, train loss-2.1252, acc-0.4200, valid loss-2.1560, acc-0.3780, test loss-2.1457, acc-0.3876\n",
      "Iter-19220, train loss-2.1594, acc-0.2400, valid loss-2.1559, acc-0.3782, test loss-2.1456, acc-0.3876\n",
      "Iter-19230, train loss-2.1903, acc-0.2600, valid loss-2.1559, acc-0.3788, test loss-2.1456, acc-0.3879\n",
      "Iter-19240, train loss-2.1604, acc-0.3400, valid loss-2.1558, acc-0.3788, test loss-2.1455, acc-0.3882\n",
      "Iter-19250, train loss-2.1609, acc-0.3800, valid loss-2.1558, acc-0.3790, test loss-2.1454, acc-0.3883\n",
      "Iter-19260, train loss-2.1139, acc-0.5800, valid loss-2.1557, acc-0.3786, test loss-2.1454, acc-0.3884\n",
      "Iter-19270, train loss-2.1169, acc-0.3800, valid loss-2.1556, acc-0.3790, test loss-2.1453, acc-0.3883\n",
      "Iter-19280, train loss-2.0954, acc-0.4600, valid loss-2.1556, acc-0.3790, test loss-2.1452, acc-0.3881\n",
      "Iter-19290, train loss-2.1738, acc-0.4000, valid loss-2.1555, acc-0.3796, test loss-2.1452, acc-0.3883\n",
      "Iter-19300, train loss-2.2010, acc-0.3600, valid loss-2.1554, acc-0.3794, test loss-2.1451, acc-0.3884\n",
      "Iter-19310, train loss-2.1619, acc-0.3800, valid loss-2.1554, acc-0.3796, test loss-2.1450, acc-0.3889\n",
      "Iter-19320, train loss-2.1682, acc-0.3400, valid loss-2.1553, acc-0.3798, test loss-2.1449, acc-0.3888\n",
      "Iter-19330, train loss-2.1998, acc-0.2400, valid loss-2.1553, acc-0.3796, test loss-2.1449, acc-0.3890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-19340, train loss-2.2073, acc-0.2400, valid loss-2.1552, acc-0.3796, test loss-2.1448, acc-0.3891\n",
      "Iter-19350, train loss-2.1102, acc-0.4600, valid loss-2.1551, acc-0.3794, test loss-2.1447, acc-0.3894\n",
      "Iter-19360, train loss-2.1572, acc-0.3800, valid loss-2.1551, acc-0.3798, test loss-2.1447, acc-0.3892\n",
      "Iter-19370, train loss-2.1164, acc-0.5200, valid loss-2.1550, acc-0.3798, test loss-2.1446, acc-0.3894\n",
      "Iter-19380, train loss-2.1337, acc-0.3200, valid loss-2.1549, acc-0.3798, test loss-2.1445, acc-0.3898\n",
      "Iter-19390, train loss-2.1629, acc-0.4000, valid loss-2.1549, acc-0.3800, test loss-2.1445, acc-0.3903\n",
      "Iter-19400, train loss-2.1508, acc-0.4600, valid loss-2.1548, acc-0.3800, test loss-2.1444, acc-0.3903\n",
      "Iter-19410, train loss-2.1503, acc-0.3600, valid loss-2.1547, acc-0.3802, test loss-2.1443, acc-0.3903\n",
      "Iter-19420, train loss-2.1178, acc-0.5000, valid loss-2.1547, acc-0.3802, test loss-2.1443, acc-0.3904\n",
      "Iter-19430, train loss-2.1908, acc-0.3400, valid loss-2.1546, acc-0.3804, test loss-2.1442, acc-0.3900\n",
      "Iter-19440, train loss-2.1707, acc-0.3000, valid loss-2.1546, acc-0.3808, test loss-2.1441, acc-0.3900\n",
      "Iter-19450, train loss-2.0835, acc-0.5800, valid loss-2.1545, acc-0.3812, test loss-2.1441, acc-0.3901\n",
      "Iter-19460, train loss-2.1359, acc-0.4200, valid loss-2.1544, acc-0.3806, test loss-2.1440, acc-0.3903\n",
      "Iter-19470, train loss-2.1236, acc-0.4000, valid loss-2.1544, acc-0.3812, test loss-2.1439, acc-0.3904\n",
      "Iter-19480, train loss-2.1154, acc-0.3400, valid loss-2.1543, acc-0.3810, test loss-2.1438, acc-0.3904\n",
      "Iter-19490, train loss-2.1617, acc-0.3600, valid loss-2.1542, acc-0.3812, test loss-2.1438, acc-0.3904\n",
      "Iter-19500, train loss-2.1419, acc-0.4200, valid loss-2.1542, acc-0.3816, test loss-2.1437, acc-0.3903\n",
      "Iter-19510, train loss-2.1495, acc-0.3800, valid loss-2.1541, acc-0.3812, test loss-2.1436, acc-0.3904\n",
      "Iter-19520, train loss-2.2094, acc-0.3400, valid loss-2.1541, acc-0.3814, test loss-2.1436, acc-0.3908\n",
      "Iter-19530, train loss-2.1267, acc-0.4000, valid loss-2.1540, acc-0.3812, test loss-2.1435, acc-0.3907\n",
      "Iter-19540, train loss-2.1357, acc-0.4400, valid loss-2.1539, acc-0.3812, test loss-2.1434, acc-0.3908\n",
      "Iter-19550, train loss-2.1407, acc-0.3200, valid loss-2.1539, acc-0.3816, test loss-2.1434, acc-0.3909\n",
      "Iter-19560, train loss-2.1303, acc-0.3600, valid loss-2.1538, acc-0.3822, test loss-2.1433, acc-0.3911\n",
      "Iter-19570, train loss-2.1410, acc-0.4000, valid loss-2.1537, acc-0.3820, test loss-2.1432, acc-0.3910\n",
      "Iter-19580, train loss-2.1720, acc-0.4200, valid loss-2.1537, acc-0.3822, test loss-2.1432, acc-0.3913\n",
      "Iter-19590, train loss-2.1215, acc-0.4400, valid loss-2.1536, acc-0.3822, test loss-2.1431, acc-0.3911\n",
      "Iter-19600, train loss-2.1684, acc-0.3200, valid loss-2.1536, acc-0.3818, test loss-2.1430, acc-0.3913\n",
      "Iter-19610, train loss-2.1561, acc-0.4200, valid loss-2.1535, acc-0.3824, test loss-2.1430, acc-0.3916\n",
      "Iter-19620, train loss-2.1498, acc-0.3800, valid loss-2.1534, acc-0.3828, test loss-2.1429, acc-0.3916\n",
      "Iter-19630, train loss-2.1253, acc-0.5200, valid loss-2.1534, acc-0.3828, test loss-2.1428, acc-0.3916\n",
      "Iter-19640, train loss-2.1383, acc-0.3600, valid loss-2.1533, acc-0.3828, test loss-2.1428, acc-0.3917\n",
      "Iter-19650, train loss-2.1256, acc-0.4200, valid loss-2.1533, acc-0.3834, test loss-2.1427, acc-0.3916\n",
      "Iter-19660, train loss-2.1337, acc-0.5400, valid loss-2.1532, acc-0.3840, test loss-2.1426, acc-0.3918\n",
      "Iter-19670, train loss-2.1182, acc-0.4600, valid loss-2.1531, acc-0.3834, test loss-2.1425, acc-0.3919\n",
      "Iter-19680, train loss-2.1351, acc-0.5400, valid loss-2.1531, acc-0.3838, test loss-2.1425, acc-0.3918\n",
      "Iter-19690, train loss-2.1018, acc-0.4400, valid loss-2.1530, acc-0.3836, test loss-2.1424, acc-0.3921\n",
      "Iter-19700, train loss-2.1438, acc-0.4600, valid loss-2.1529, acc-0.3838, test loss-2.1423, acc-0.3925\n",
      "Iter-19710, train loss-2.1482, acc-0.3400, valid loss-2.1529, acc-0.3838, test loss-2.1423, acc-0.3925\n",
      "Iter-19720, train loss-2.1429, acc-0.4200, valid loss-2.1528, acc-0.3842, test loss-2.1422, acc-0.3924\n",
      "Iter-19730, train loss-2.1452, acc-0.4200, valid loss-2.1528, acc-0.3842, test loss-2.1421, acc-0.3923\n",
      "Iter-19740, train loss-2.1710, acc-0.2800, valid loss-2.1527, acc-0.3844, test loss-2.1421, acc-0.3926\n",
      "Iter-19750, train loss-2.1467, acc-0.3400, valid loss-2.1526, acc-0.3844, test loss-2.1420, acc-0.3928\n",
      "Iter-19760, train loss-2.1985, acc-0.3000, valid loss-2.1526, acc-0.3842, test loss-2.1419, acc-0.3928\n",
      "Iter-19770, train loss-2.1678, acc-0.4400, valid loss-2.1525, acc-0.3844, test loss-2.1419, acc-0.3930\n",
      "Iter-19780, train loss-2.1338, acc-0.4000, valid loss-2.1524, acc-0.3846, test loss-2.1418, acc-0.3929\n",
      "Iter-19790, train loss-2.1453, acc-0.4400, valid loss-2.1524, acc-0.3848, test loss-2.1417, acc-0.3929\n",
      "Iter-19800, train loss-2.1452, acc-0.4600, valid loss-2.1523, acc-0.3848, test loss-2.1417, acc-0.3929\n",
      "Iter-19810, train loss-2.1646, acc-0.4200, valid loss-2.1523, acc-0.3844, test loss-2.1416, acc-0.3930\n",
      "Iter-19820, train loss-2.1282, acc-0.4000, valid loss-2.1522, acc-0.3848, test loss-2.1415, acc-0.3929\n",
      "Iter-19830, train loss-2.1600, acc-0.4400, valid loss-2.1521, acc-0.3856, test loss-2.1415, acc-0.3931\n",
      "Iter-19840, train loss-2.0887, acc-0.5600, valid loss-2.1521, acc-0.3856, test loss-2.1414, acc-0.3935\n",
      "Iter-19850, train loss-2.1184, acc-0.3600, valid loss-2.1520, acc-0.3854, test loss-2.1413, acc-0.3936\n",
      "Iter-19860, train loss-2.1508, acc-0.3200, valid loss-2.1520, acc-0.3852, test loss-2.1412, acc-0.3940\n",
      "Iter-19870, train loss-2.1341, acc-0.3600, valid loss-2.1519, acc-0.3856, test loss-2.1412, acc-0.3940\n",
      "Iter-19880, train loss-2.1338, acc-0.4200, valid loss-2.1518, acc-0.3856, test loss-2.1411, acc-0.3937\n",
      "Iter-19890, train loss-2.1547, acc-0.3600, valid loss-2.1518, acc-0.3858, test loss-2.1410, acc-0.3943\n",
      "Iter-19900, train loss-2.1436, acc-0.2800, valid loss-2.1517, acc-0.3860, test loss-2.1410, acc-0.3947\n",
      "Iter-19910, train loss-2.1617, acc-0.3200, valid loss-2.1517, acc-0.3864, test loss-2.1409, acc-0.3944\n",
      "Iter-19920, train loss-2.1685, acc-0.3400, valid loss-2.1516, acc-0.3864, test loss-2.1409, acc-0.3946\n",
      "Iter-19930, train loss-2.1412, acc-0.3400, valid loss-2.1515, acc-0.3862, test loss-2.1408, acc-0.3944\n",
      "Iter-19940, train loss-2.1832, acc-0.2400, valid loss-2.1515, acc-0.3866, test loss-2.1407, acc-0.3946\n",
      "Iter-19950, train loss-2.1479, acc-0.2400, valid loss-2.1514, acc-0.3864, test loss-2.1407, acc-0.3946\n",
      "Iter-19960, train loss-2.1318, acc-0.3600, valid loss-2.1514, acc-0.3866, test loss-2.1406, acc-0.3951\n",
      "Iter-19970, train loss-2.1269, acc-0.4200, valid loss-2.1513, acc-0.3860, test loss-2.1405, acc-0.3947\n",
      "Iter-19980, train loss-2.1277, acc-0.4200, valid loss-2.1512, acc-0.3864, test loss-2.1404, acc-0.3946\n",
      "Iter-19990, train loss-2.1178, acc-0.4000, valid loss-2.1512, acc-0.3868, test loss-2.1404, acc-0.3950\n",
      "Iter-20000, train loss-2.1320, acc-0.3600, valid loss-2.1511, acc-0.3870, test loss-2.1403, acc-0.3955\n",
      "Iter-20010, train loss-2.1612, acc-0.4000, valid loss-2.1510, acc-0.3874, test loss-2.1403, acc-0.3956\n",
      "Iter-20020, train loss-2.1531, acc-0.2800, valid loss-2.1510, acc-0.3864, test loss-2.1402, acc-0.3961\n",
      "Iter-20030, train loss-2.1475, acc-0.3800, valid loss-2.1509, acc-0.3864, test loss-2.1401, acc-0.3960\n",
      "Iter-20040, train loss-2.1196, acc-0.4800, valid loss-2.1509, acc-0.3870, test loss-2.1400, acc-0.3958\n",
      "Iter-20050, train loss-2.1784, acc-0.3000, valid loss-2.1508, acc-0.3872, test loss-2.1400, acc-0.3962\n",
      "Iter-20060, train loss-2.1781, acc-0.2400, valid loss-2.1507, acc-0.3870, test loss-2.1399, acc-0.3961\n",
      "Iter-20070, train loss-2.1151, acc-0.4600, valid loss-2.1507, acc-0.3872, test loss-2.1398, acc-0.3964\n",
      "Iter-20080, train loss-2.1828, acc-0.3400, valid loss-2.1506, acc-0.3874, test loss-2.1398, acc-0.3961\n",
      "Iter-20090, train loss-2.1617, acc-0.3600, valid loss-2.1505, acc-0.3872, test loss-2.1397, acc-0.3961\n",
      "Iter-20100, train loss-2.1402, acc-0.3400, valid loss-2.1505, acc-0.3872, test loss-2.1396, acc-0.3963\n",
      "Iter-20110, train loss-2.1767, acc-0.3000, valid loss-2.1504, acc-0.3872, test loss-2.1396, acc-0.3963\n",
      "Iter-20120, train loss-2.1384, acc-0.4400, valid loss-2.1503, acc-0.3874, test loss-2.1395, acc-0.3967\n",
      "Iter-20130, train loss-2.1622, acc-0.2800, valid loss-2.1503, acc-0.3876, test loss-2.1394, acc-0.3966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-20140, train loss-2.1399, acc-0.3200, valid loss-2.1502, acc-0.3876, test loss-2.1393, acc-0.3966\n",
      "Iter-20150, train loss-2.1583, acc-0.2800, valid loss-2.1502, acc-0.3878, test loss-2.1393, acc-0.3966\n",
      "Iter-20160, train loss-2.1589, acc-0.2800, valid loss-2.1501, acc-0.3876, test loss-2.1392, acc-0.3966\n",
      "Iter-20170, train loss-2.1657, acc-0.3000, valid loss-2.1500, acc-0.3878, test loss-2.1391, acc-0.3966\n",
      "Iter-20180, train loss-2.1316, acc-0.4200, valid loss-2.1500, acc-0.3880, test loss-2.1391, acc-0.3968\n",
      "Iter-20190, train loss-2.1666, acc-0.4400, valid loss-2.1499, acc-0.3880, test loss-2.1390, acc-0.3974\n",
      "Iter-20200, train loss-2.1391, acc-0.4200, valid loss-2.1498, acc-0.3874, test loss-2.1389, acc-0.3972\n",
      "Iter-20210, train loss-2.1563, acc-0.3800, valid loss-2.1498, acc-0.3880, test loss-2.1389, acc-0.3972\n",
      "Iter-20220, train loss-2.1626, acc-0.4400, valid loss-2.1497, acc-0.3880, test loss-2.1388, acc-0.3973\n",
      "Iter-20230, train loss-2.1091, acc-0.4200, valid loss-2.1497, acc-0.3882, test loss-2.1387, acc-0.3976\n",
      "Iter-20240, train loss-2.1422, acc-0.4000, valid loss-2.1496, acc-0.3880, test loss-2.1387, acc-0.3973\n",
      "Iter-20250, train loss-2.1028, acc-0.5000, valid loss-2.1495, acc-0.3882, test loss-2.1386, acc-0.3975\n",
      "Iter-20260, train loss-2.1567, acc-0.4200, valid loss-2.1495, acc-0.3884, test loss-2.1385, acc-0.3976\n",
      "Iter-20270, train loss-2.1813, acc-0.3400, valid loss-2.1494, acc-0.3880, test loss-2.1384, acc-0.3977\n",
      "Iter-20280, train loss-2.1096, acc-0.4200, valid loss-2.1493, acc-0.3886, test loss-2.1384, acc-0.3975\n",
      "Iter-20290, train loss-2.1039, acc-0.5600, valid loss-2.1493, acc-0.3884, test loss-2.1383, acc-0.3976\n",
      "Iter-20300, train loss-2.1302, acc-0.3600, valid loss-2.1492, acc-0.3886, test loss-2.1383, acc-0.3979\n",
      "Iter-20310, train loss-2.1660, acc-0.4600, valid loss-2.1492, acc-0.3882, test loss-2.1382, acc-0.3982\n",
      "Iter-20320, train loss-2.1462, acc-0.4400, valid loss-2.1491, acc-0.3884, test loss-2.1381, acc-0.3983\n",
      "Iter-20330, train loss-2.1604, acc-0.4000, valid loss-2.1490, acc-0.3880, test loss-2.1381, acc-0.3986\n",
      "Iter-20340, train loss-2.0920, acc-0.4400, valid loss-2.1490, acc-0.3888, test loss-2.1380, acc-0.3988\n",
      "Iter-20350, train loss-2.1343, acc-0.4000, valid loss-2.1489, acc-0.3880, test loss-2.1379, acc-0.3988\n",
      "Iter-20360, train loss-2.1447, acc-0.4400, valid loss-2.1489, acc-0.3878, test loss-2.1379, acc-0.3982\n",
      "Iter-20370, train loss-2.1198, acc-0.4200, valid loss-2.1488, acc-0.3882, test loss-2.1378, acc-0.3986\n",
      "Iter-20380, train loss-2.1840, acc-0.3600, valid loss-2.1487, acc-0.3882, test loss-2.1377, acc-0.3982\n",
      "Iter-20390, train loss-2.1426, acc-0.3800, valid loss-2.1487, acc-0.3890, test loss-2.1377, acc-0.3986\n",
      "Iter-20400, train loss-2.1305, acc-0.3400, valid loss-2.1486, acc-0.3886, test loss-2.1376, acc-0.3982\n",
      "Iter-20410, train loss-2.1024, acc-0.5000, valid loss-2.1486, acc-0.3888, test loss-2.1375, acc-0.3983\n",
      "Iter-20420, train loss-2.1457, acc-0.4000, valid loss-2.1485, acc-0.3888, test loss-2.1374, acc-0.3990\n",
      "Iter-20430, train loss-2.1087, acc-0.4600, valid loss-2.1484, acc-0.3888, test loss-2.1374, acc-0.3987\n",
      "Iter-20440, train loss-2.1144, acc-0.4200, valid loss-2.1484, acc-0.3890, test loss-2.1373, acc-0.3985\n",
      "Iter-20450, train loss-2.1913, acc-0.3200, valid loss-2.1483, acc-0.3888, test loss-2.1372, acc-0.3985\n",
      "Iter-20460, train loss-2.1646, acc-0.4000, valid loss-2.1482, acc-0.3894, test loss-2.1372, acc-0.3984\n",
      "Iter-20470, train loss-2.1300, acc-0.4000, valid loss-2.1482, acc-0.3898, test loss-2.1371, acc-0.3985\n",
      "Iter-20480, train loss-2.1958, acc-0.3600, valid loss-2.1481, acc-0.3894, test loss-2.1370, acc-0.3985\n",
      "Iter-20490, train loss-2.1488, acc-0.3600, valid loss-2.1481, acc-0.3900, test loss-2.1370, acc-0.3984\n",
      "Iter-20500, train loss-2.1164, acc-0.2800, valid loss-2.1480, acc-0.3898, test loss-2.1369, acc-0.3989\n",
      "Iter-20510, train loss-2.1731, acc-0.4000, valid loss-2.1479, acc-0.3898, test loss-2.1368, acc-0.3988\n",
      "Iter-20520, train loss-2.1142, acc-0.5400, valid loss-2.1479, acc-0.3898, test loss-2.1368, acc-0.3988\n",
      "Iter-20530, train loss-2.1647, acc-0.4000, valid loss-2.1478, acc-0.3900, test loss-2.1367, acc-0.3990\n",
      "Iter-20540, train loss-2.1627, acc-0.4200, valid loss-2.1478, acc-0.3898, test loss-2.1366, acc-0.3990\n",
      "Iter-20550, train loss-2.1644, acc-0.3800, valid loss-2.1477, acc-0.3904, test loss-2.1366, acc-0.3992\n",
      "Iter-20560, train loss-2.1351, acc-0.4600, valid loss-2.1476, acc-0.3900, test loss-2.1365, acc-0.3993\n",
      "Iter-20570, train loss-2.1476, acc-0.3200, valid loss-2.1476, acc-0.3900, test loss-2.1364, acc-0.3992\n",
      "Iter-20580, train loss-2.1136, acc-0.5000, valid loss-2.1475, acc-0.3904, test loss-2.1364, acc-0.3994\n",
      "Iter-20590, train loss-2.1114, acc-0.5600, valid loss-2.1475, acc-0.3906, test loss-2.1363, acc-0.3997\n",
      "Iter-20600, train loss-2.1209, acc-0.4200, valid loss-2.1474, acc-0.3904, test loss-2.1362, acc-0.3996\n",
      "Iter-20610, train loss-2.1554, acc-0.3600, valid loss-2.1473, acc-0.3906, test loss-2.1362, acc-0.4000\n",
      "Iter-20620, train loss-2.1652, acc-0.3800, valid loss-2.1473, acc-0.3906, test loss-2.1361, acc-0.3997\n",
      "Iter-20630, train loss-2.1538, acc-0.4200, valid loss-2.1472, acc-0.3910, test loss-2.1360, acc-0.4000\n",
      "Iter-20640, train loss-2.0991, acc-0.4400, valid loss-2.1472, acc-0.3910, test loss-2.1360, acc-0.4000\n",
      "Iter-20650, train loss-2.0851, acc-0.5200, valid loss-2.1471, acc-0.3910, test loss-2.1359, acc-0.4000\n",
      "Iter-20660, train loss-2.1114, acc-0.4400, valid loss-2.1470, acc-0.3908, test loss-2.1358, acc-0.4008\n",
      "Iter-20670, train loss-2.0844, acc-0.5000, valid loss-2.1470, acc-0.3906, test loss-2.1358, acc-0.4006\n",
      "Iter-20680, train loss-2.1626, acc-0.3800, valid loss-2.1469, acc-0.3910, test loss-2.1357, acc-0.4006\n",
      "Iter-20690, train loss-2.1367, acc-0.3800, valid loss-2.1469, acc-0.3908, test loss-2.1356, acc-0.4006\n",
      "Iter-20700, train loss-2.1512, acc-0.4000, valid loss-2.1468, acc-0.3908, test loss-2.1356, acc-0.4011\n",
      "Iter-20710, train loss-2.1385, acc-0.4000, valid loss-2.1467, acc-0.3910, test loss-2.1355, acc-0.4012\n",
      "Iter-20720, train loss-2.1337, acc-0.4000, valid loss-2.1467, acc-0.3908, test loss-2.1354, acc-0.4016\n",
      "Iter-20730, train loss-2.1312, acc-0.4800, valid loss-2.1466, acc-0.3910, test loss-2.1354, acc-0.4013\n",
      "Iter-20740, train loss-2.1306, acc-0.3200, valid loss-2.1465, acc-0.3908, test loss-2.1353, acc-0.4013\n",
      "Iter-20750, train loss-2.1086, acc-0.4800, valid loss-2.1465, acc-0.3906, test loss-2.1352, acc-0.4012\n",
      "Iter-20760, train loss-2.1230, acc-0.4600, valid loss-2.1464, acc-0.3908, test loss-2.1351, acc-0.4013\n",
      "Iter-20770, train loss-2.1538, acc-0.4600, valid loss-2.1463, acc-0.3910, test loss-2.1351, acc-0.4014\n",
      "Iter-20780, train loss-2.1477, acc-0.4200, valid loss-2.1463, acc-0.3910, test loss-2.1350, acc-0.4014\n",
      "Iter-20790, train loss-2.1808, acc-0.3400, valid loss-2.1462, acc-0.3908, test loss-2.1350, acc-0.4017\n",
      "Iter-20800, train loss-2.1403, acc-0.4400, valid loss-2.1462, acc-0.3908, test loss-2.1349, acc-0.4017\n",
      "Iter-20810, train loss-2.1628, acc-0.3600, valid loss-2.1461, acc-0.3912, test loss-2.1348, acc-0.4017\n",
      "Iter-20820, train loss-2.1331, acc-0.4400, valid loss-2.1460, acc-0.3912, test loss-2.1348, acc-0.4017\n",
      "Iter-20830, train loss-2.1260, acc-0.4800, valid loss-2.1460, acc-0.3912, test loss-2.1347, acc-0.4019\n",
      "Iter-20840, train loss-2.1280, acc-0.4200, valid loss-2.1459, acc-0.3916, test loss-2.1346, acc-0.4022\n",
      "Iter-20850, train loss-2.1766, acc-0.2800, valid loss-2.1459, acc-0.3912, test loss-2.1345, acc-0.4025\n",
      "Iter-20860, train loss-2.1648, acc-0.4000, valid loss-2.1458, acc-0.3916, test loss-2.1345, acc-0.4023\n",
      "Iter-20870, train loss-2.1446, acc-0.2600, valid loss-2.1457, acc-0.3918, test loss-2.1344, acc-0.4026\n",
      "Iter-20880, train loss-2.1469, acc-0.3400, valid loss-2.1457, acc-0.3916, test loss-2.1343, acc-0.4024\n",
      "Iter-20890, train loss-2.1336, acc-0.4400, valid loss-2.1456, acc-0.3916, test loss-2.1343, acc-0.4025\n",
      "Iter-20900, train loss-2.1709, acc-0.3200, valid loss-2.1456, acc-0.3918, test loss-2.1342, acc-0.4025\n",
      "Iter-20910, train loss-2.1620, acc-0.3200, valid loss-2.1455, acc-0.3918, test loss-2.1342, acc-0.4026\n",
      "Iter-20920, train loss-2.1233, acc-0.4000, valid loss-2.1454, acc-0.3918, test loss-2.1341, acc-0.4027\n",
      "Iter-20930, train loss-2.0993, acc-0.4800, valid loss-2.1454, acc-0.3920, test loss-2.1340, acc-0.4027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-20940, train loss-2.1608, acc-0.3400, valid loss-2.1453, acc-0.3924, test loss-2.1340, acc-0.4025\n",
      "Iter-20950, train loss-2.1342, acc-0.4800, valid loss-2.1453, acc-0.3930, test loss-2.1339, acc-0.4026\n",
      "Iter-20960, train loss-2.1575, acc-0.3800, valid loss-2.1452, acc-0.3930, test loss-2.1338, acc-0.4026\n",
      "Iter-20970, train loss-2.1769, acc-0.2800, valid loss-2.1451, acc-0.3930, test loss-2.1338, acc-0.4026\n",
      "Iter-20980, train loss-2.1562, acc-0.3200, valid loss-2.1451, acc-0.3928, test loss-2.1337, acc-0.4029\n",
      "Iter-20990, train loss-2.1393, acc-0.4400, valid loss-2.1450, acc-0.3928, test loss-2.1336, acc-0.4030\n",
      "Iter-21000, train loss-2.1523, acc-0.4800, valid loss-2.1450, acc-0.3928, test loss-2.1336, acc-0.4030\n",
      "Iter-21010, train loss-2.1459, acc-0.4800, valid loss-2.1449, acc-0.3938, test loss-2.1335, acc-0.4030\n",
      "Iter-21020, train loss-2.1560, acc-0.3600, valid loss-2.1448, acc-0.3936, test loss-2.1334, acc-0.4035\n",
      "Iter-21030, train loss-2.1212, acc-0.4800, valid loss-2.1448, acc-0.3934, test loss-2.1334, acc-0.4031\n",
      "Iter-21040, train loss-2.1201, acc-0.4200, valid loss-2.1447, acc-0.3936, test loss-2.1333, acc-0.4034\n",
      "Iter-21050, train loss-2.1722, acc-0.1800, valid loss-2.1446, acc-0.3938, test loss-2.1332, acc-0.4035\n",
      "Iter-21060, train loss-2.1580, acc-0.4200, valid loss-2.1446, acc-0.3936, test loss-2.1332, acc-0.4032\n",
      "Iter-21070, train loss-2.1469, acc-0.3400, valid loss-2.1445, acc-0.3934, test loss-2.1331, acc-0.4036\n",
      "Iter-21080, train loss-2.1522, acc-0.3200, valid loss-2.1444, acc-0.3936, test loss-2.1330, acc-0.4031\n",
      "Iter-21090, train loss-2.1298, acc-0.4200, valid loss-2.1444, acc-0.3938, test loss-2.1329, acc-0.4034\n",
      "Iter-21100, train loss-2.1646, acc-0.3800, valid loss-2.1443, acc-0.3936, test loss-2.1329, acc-0.4030\n",
      "Iter-21110, train loss-2.1353, acc-0.3400, valid loss-2.1443, acc-0.3934, test loss-2.1328, acc-0.4031\n",
      "Iter-21120, train loss-2.1135, acc-0.4800, valid loss-2.1442, acc-0.3934, test loss-2.1327, acc-0.4027\n",
      "Iter-21130, train loss-2.1532, acc-0.4200, valid loss-2.1441, acc-0.3934, test loss-2.1327, acc-0.4032\n",
      "Iter-21140, train loss-2.1019, acc-0.5400, valid loss-2.1441, acc-0.3936, test loss-2.1326, acc-0.4034\n",
      "Iter-21150, train loss-2.1067, acc-0.4600, valid loss-2.1440, acc-0.3938, test loss-2.1325, acc-0.4034\n",
      "Iter-21160, train loss-2.1318, acc-0.3600, valid loss-2.1439, acc-0.3932, test loss-2.1325, acc-0.4032\n",
      "Iter-21170, train loss-2.1387, acc-0.4200, valid loss-2.1439, acc-0.3938, test loss-2.1324, acc-0.4033\n",
      "Iter-21180, train loss-2.1491, acc-0.4600, valid loss-2.1438, acc-0.3938, test loss-2.1323, acc-0.4040\n",
      "Iter-21190, train loss-2.1612, acc-0.3400, valid loss-2.1437, acc-0.3940, test loss-2.1323, acc-0.4041\n",
      "Iter-21200, train loss-2.1308, acc-0.4000, valid loss-2.1437, acc-0.3944, test loss-2.1322, acc-0.4042\n",
      "Iter-21210, train loss-2.1284, acc-0.3600, valid loss-2.1436, acc-0.3944, test loss-2.1321, acc-0.4042\n",
      "Iter-21220, train loss-2.1181, acc-0.5200, valid loss-2.1436, acc-0.3948, test loss-2.1321, acc-0.4042\n",
      "Iter-21230, train loss-2.1276, acc-0.4000, valid loss-2.1435, acc-0.3948, test loss-2.1320, acc-0.4043\n",
      "Iter-21240, train loss-2.1369, acc-0.3800, valid loss-2.1434, acc-0.3948, test loss-2.1319, acc-0.4045\n",
      "Iter-21250, train loss-2.1241, acc-0.4200, valid loss-2.1434, acc-0.3948, test loss-2.1319, acc-0.4045\n",
      "Iter-21260, train loss-2.2071, acc-0.4000, valid loss-2.1433, acc-0.3948, test loss-2.1318, acc-0.4048\n",
      "Iter-21270, train loss-2.1141, acc-0.4000, valid loss-2.1433, acc-0.3948, test loss-2.1317, acc-0.4050\n",
      "Iter-21280, train loss-2.2059, acc-0.3000, valid loss-2.1432, acc-0.3950, test loss-2.1317, acc-0.4050\n",
      "Iter-21290, train loss-2.1224, acc-0.3000, valid loss-2.1431, acc-0.3952, test loss-2.1316, acc-0.4052\n",
      "Iter-21300, train loss-2.1231, acc-0.3600, valid loss-2.1431, acc-0.3952, test loss-2.1315, acc-0.4055\n",
      "Iter-21310, train loss-2.1466, acc-0.3600, valid loss-2.1430, acc-0.3952, test loss-2.1315, acc-0.4057\n",
      "Iter-21320, train loss-2.1467, acc-0.4000, valid loss-2.1430, acc-0.3952, test loss-2.1314, acc-0.4056\n",
      "Iter-21330, train loss-2.1402, acc-0.3800, valid loss-2.1429, acc-0.3950, test loss-2.1313, acc-0.4059\n",
      "Iter-21340, train loss-2.1567, acc-0.4000, valid loss-2.1428, acc-0.3950, test loss-2.1313, acc-0.4060\n",
      "Iter-21350, train loss-2.1546, acc-0.3400, valid loss-2.1428, acc-0.3948, test loss-2.1312, acc-0.4061\n",
      "Iter-21360, train loss-2.1078, acc-0.4800, valid loss-2.1427, acc-0.3950, test loss-2.1311, acc-0.4061\n",
      "Iter-21370, train loss-2.1565, acc-0.3800, valid loss-2.1427, acc-0.3948, test loss-2.1311, acc-0.4059\n",
      "Iter-21380, train loss-2.1475, acc-0.3600, valid loss-2.1426, acc-0.3950, test loss-2.1310, acc-0.4062\n",
      "Iter-21390, train loss-2.1296, acc-0.3400, valid loss-2.1425, acc-0.3948, test loss-2.1309, acc-0.4062\n",
      "Iter-21400, train loss-2.1444, acc-0.3600, valid loss-2.1425, acc-0.3948, test loss-2.1309, acc-0.4063\n",
      "Iter-21410, train loss-2.1066, acc-0.3800, valid loss-2.1424, acc-0.3950, test loss-2.1308, acc-0.4065\n",
      "Iter-21420, train loss-2.1211, acc-0.4400, valid loss-2.1424, acc-0.3954, test loss-2.1307, acc-0.4065\n",
      "Iter-21430, train loss-2.1465, acc-0.2400, valid loss-2.1423, acc-0.3958, test loss-2.1307, acc-0.4066\n",
      "Iter-21440, train loss-2.1536, acc-0.2800, valid loss-2.1422, acc-0.3960, test loss-2.1306, acc-0.4065\n",
      "Iter-21450, train loss-2.2080, acc-0.2400, valid loss-2.1422, acc-0.3960, test loss-2.1305, acc-0.4068\n",
      "Iter-21460, train loss-2.1404, acc-0.3600, valid loss-2.1421, acc-0.3958, test loss-2.1305, acc-0.4070\n",
      "Iter-21470, train loss-2.1575, acc-0.3000, valid loss-2.1421, acc-0.3960, test loss-2.1304, acc-0.4071\n",
      "Iter-21480, train loss-2.1517, acc-0.4200, valid loss-2.1420, acc-0.3962, test loss-2.1303, acc-0.4071\n",
      "Iter-21490, train loss-2.1764, acc-0.3800, valid loss-2.1419, acc-0.3960, test loss-2.1303, acc-0.4072\n",
      "Iter-21500, train loss-2.1243, acc-0.4600, valid loss-2.1419, acc-0.3958, test loss-2.1302, acc-0.4071\n",
      "Iter-21510, train loss-2.1508, acc-0.5000, valid loss-2.1418, acc-0.3960, test loss-2.1301, acc-0.4071\n",
      "Iter-21520, train loss-2.1588, acc-0.3000, valid loss-2.1417, acc-0.3964, test loss-2.1301, acc-0.4070\n",
      "Iter-21530, train loss-2.1165, acc-0.4200, valid loss-2.1417, acc-0.3962, test loss-2.1300, acc-0.4069\n",
      "Iter-21540, train loss-2.1412, acc-0.4600, valid loss-2.1416, acc-0.3960, test loss-2.1299, acc-0.4070\n",
      "Iter-21550, train loss-2.1336, acc-0.4000, valid loss-2.1416, acc-0.3960, test loss-2.1299, acc-0.4068\n",
      "Iter-21560, train loss-2.1950, acc-0.2800, valid loss-2.1415, acc-0.3966, test loss-2.1298, acc-0.4072\n",
      "Iter-21570, train loss-2.1138, acc-0.4200, valid loss-2.1414, acc-0.3960, test loss-2.1297, acc-0.4069\n",
      "Iter-21580, train loss-2.1136, acc-0.4200, valid loss-2.1414, acc-0.3960, test loss-2.1297, acc-0.4070\n",
      "Iter-21590, train loss-2.1180, acc-0.4400, valid loss-2.1413, acc-0.3960, test loss-2.1296, acc-0.4073\n",
      "Iter-21600, train loss-2.1447, acc-0.4200, valid loss-2.1413, acc-0.3966, test loss-2.1295, acc-0.4069\n",
      "Iter-21610, train loss-2.1314, acc-0.5400, valid loss-2.1412, acc-0.3970, test loss-2.1295, acc-0.4071\n",
      "Iter-21620, train loss-2.0777, acc-0.4600, valid loss-2.1411, acc-0.3970, test loss-2.1294, acc-0.4070\n",
      "Iter-21630, train loss-2.0993, acc-0.5000, valid loss-2.1411, acc-0.3970, test loss-2.1293, acc-0.4072\n",
      "Iter-21640, train loss-2.1141, acc-0.4400, valid loss-2.1410, acc-0.3970, test loss-2.1293, acc-0.4071\n",
      "Iter-21650, train loss-2.0881, acc-0.4600, valid loss-2.1409, acc-0.3972, test loss-2.1292, acc-0.4073\n",
      "Iter-21660, train loss-2.1277, acc-0.4000, valid loss-2.1409, acc-0.3964, test loss-2.1291, acc-0.4073\n",
      "Iter-21670, train loss-2.1127, acc-0.4000, valid loss-2.1408, acc-0.3968, test loss-2.1291, acc-0.4075\n",
      "Iter-21680, train loss-2.0918, acc-0.4800, valid loss-2.1408, acc-0.3966, test loss-2.1290, acc-0.4075\n",
      "Iter-21690, train loss-2.1817, acc-0.4400, valid loss-2.1407, acc-0.3972, test loss-2.1289, acc-0.4072\n",
      "Iter-21700, train loss-2.1295, acc-0.4200, valid loss-2.1406, acc-0.3970, test loss-2.1289, acc-0.4074\n",
      "Iter-21710, train loss-2.1518, acc-0.3400, valid loss-2.1406, acc-0.3972, test loss-2.1288, acc-0.4072\n",
      "Iter-21720, train loss-2.1943, acc-0.3200, valid loss-2.1405, acc-0.3972, test loss-2.1287, acc-0.4074\n",
      "Iter-21730, train loss-2.1410, acc-0.4400, valid loss-2.1405, acc-0.3978, test loss-2.1287, acc-0.4072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-21740, train loss-2.1455, acc-0.3600, valid loss-2.1404, acc-0.3976, test loss-2.1286, acc-0.4071\n",
      "Iter-21750, train loss-2.1499, acc-0.3600, valid loss-2.1403, acc-0.3978, test loss-2.1285, acc-0.4071\n",
      "Iter-21760, train loss-2.1105, acc-0.5000, valid loss-2.1403, acc-0.3974, test loss-2.1285, acc-0.4074\n",
      "Iter-21770, train loss-2.1559, acc-0.3600, valid loss-2.1402, acc-0.3976, test loss-2.1284, acc-0.4075\n",
      "Iter-21780, train loss-2.1509, acc-0.2800, valid loss-2.1402, acc-0.3976, test loss-2.1283, acc-0.4075\n",
      "Iter-21790, train loss-2.1610, acc-0.3400, valid loss-2.1401, acc-0.3976, test loss-2.1282, acc-0.4079\n",
      "Iter-21800, train loss-2.1147, acc-0.3600, valid loss-2.1400, acc-0.3976, test loss-2.1282, acc-0.4077\n",
      "Iter-21810, train loss-2.1186, acc-0.3800, valid loss-2.1400, acc-0.3980, test loss-2.1281, acc-0.4077\n",
      "Iter-21820, train loss-2.1264, acc-0.4800, valid loss-2.1399, acc-0.3980, test loss-2.1280, acc-0.4078\n",
      "Iter-21830, train loss-2.1675, acc-0.3200, valid loss-2.1399, acc-0.3986, test loss-2.1280, acc-0.4079\n",
      "Iter-21840, train loss-2.0927, acc-0.4800, valid loss-2.1398, acc-0.3986, test loss-2.1279, acc-0.4079\n",
      "Iter-21850, train loss-2.0667, acc-0.5600, valid loss-2.1397, acc-0.3988, test loss-2.1279, acc-0.4080\n",
      "Iter-21860, train loss-2.1028, acc-0.4600, valid loss-2.1397, acc-0.3988, test loss-2.1278, acc-0.4078\n",
      "Iter-21870, train loss-2.1528, acc-0.3200, valid loss-2.1396, acc-0.3986, test loss-2.1277, acc-0.4078\n",
      "Iter-21880, train loss-2.1142, acc-0.4200, valid loss-2.1396, acc-0.3988, test loss-2.1277, acc-0.4083\n",
      "Iter-21890, train loss-2.1371, acc-0.3600, valid loss-2.1395, acc-0.3984, test loss-2.1276, acc-0.4080\n",
      "Iter-21900, train loss-2.1287, acc-0.4600, valid loss-2.1394, acc-0.3982, test loss-2.1275, acc-0.4078\n",
      "Iter-21910, train loss-2.1328, acc-0.4000, valid loss-2.1394, acc-0.3984, test loss-2.1275, acc-0.4080\n",
      "Iter-21920, train loss-2.0894, acc-0.4800, valid loss-2.1393, acc-0.3984, test loss-2.1274, acc-0.4082\n",
      "Iter-21930, train loss-2.1205, acc-0.4000, valid loss-2.1393, acc-0.3984, test loss-2.1273, acc-0.4081\n",
      "Iter-21940, train loss-2.1190, acc-0.3600, valid loss-2.1392, acc-0.3982, test loss-2.1272, acc-0.4084\n",
      "Iter-21950, train loss-2.1257, acc-0.4400, valid loss-2.1392, acc-0.3984, test loss-2.1272, acc-0.4084\n",
      "Iter-21960, train loss-2.1235, acc-0.4000, valid loss-2.1391, acc-0.3982, test loss-2.1271, acc-0.4085\n",
      "Iter-21970, train loss-2.1298, acc-0.4600, valid loss-2.1390, acc-0.3980, test loss-2.1270, acc-0.4085\n",
      "Iter-21980, train loss-2.0981, acc-0.4600, valid loss-2.1390, acc-0.3978, test loss-2.1270, acc-0.4086\n",
      "Iter-21990, train loss-2.1200, acc-0.4600, valid loss-2.1389, acc-0.3978, test loss-2.1269, acc-0.4084\n",
      "Iter-22000, train loss-2.1224, acc-0.5200, valid loss-2.1389, acc-0.3978, test loss-2.1268, acc-0.4087\n",
      "Iter-22010, train loss-2.1227, acc-0.4800, valid loss-2.1388, acc-0.3980, test loss-2.1268, acc-0.4087\n",
      "Iter-22020, train loss-2.1235, acc-0.4000, valid loss-2.1387, acc-0.3988, test loss-2.1267, acc-0.4086\n",
      "Iter-22030, train loss-2.1175, acc-0.4200, valid loss-2.1387, acc-0.3984, test loss-2.1267, acc-0.4088\n",
      "Iter-22040, train loss-2.1152, acc-0.4600, valid loss-2.1386, acc-0.3982, test loss-2.1266, acc-0.4090\n",
      "Iter-22050, train loss-2.1165, acc-0.4400, valid loss-2.1386, acc-0.3984, test loss-2.1265, acc-0.4093\n",
      "Iter-22060, train loss-2.1275, acc-0.4400, valid loss-2.1385, acc-0.3986, test loss-2.1265, acc-0.4094\n",
      "Iter-22070, train loss-2.1275, acc-0.4200, valid loss-2.1384, acc-0.3982, test loss-2.1264, acc-0.4096\n",
      "Iter-22080, train loss-2.1257, acc-0.5000, valid loss-2.1384, acc-0.3986, test loss-2.1263, acc-0.4092\n",
      "Iter-22090, train loss-2.1171, acc-0.3400, valid loss-2.1383, acc-0.3986, test loss-2.1263, acc-0.4093\n",
      "Iter-22100, train loss-2.1314, acc-0.5000, valid loss-2.1383, acc-0.3988, test loss-2.1262, acc-0.4094\n",
      "Iter-22110, train loss-2.1340, acc-0.3400, valid loss-2.1382, acc-0.3990, test loss-2.1261, acc-0.4094\n",
      "Iter-22120, train loss-2.1501, acc-0.4400, valid loss-2.1382, acc-0.3990, test loss-2.1261, acc-0.4097\n",
      "Iter-22130, train loss-2.1528, acc-0.3800, valid loss-2.1381, acc-0.3992, test loss-2.1260, acc-0.4098\n",
      "Iter-22140, train loss-2.1242, acc-0.4200, valid loss-2.1380, acc-0.3992, test loss-2.1259, acc-0.4098\n",
      "Iter-22150, train loss-2.1004, acc-0.4200, valid loss-2.1380, acc-0.3992, test loss-2.1259, acc-0.4098\n",
      "Iter-22160, train loss-2.1062, acc-0.4200, valid loss-2.1379, acc-0.3994, test loss-2.1258, acc-0.4101\n",
      "Iter-22170, train loss-2.1093, acc-0.5600, valid loss-2.1378, acc-0.3996, test loss-2.1257, acc-0.4100\n",
      "Iter-22180, train loss-2.1092, acc-0.4200, valid loss-2.1378, acc-0.3992, test loss-2.1257, acc-0.4099\n",
      "Iter-22190, train loss-2.1060, acc-0.4000, valid loss-2.1377, acc-0.3992, test loss-2.1256, acc-0.4103\n",
      "Iter-22200, train loss-2.1061, acc-0.5000, valid loss-2.1377, acc-0.3992, test loss-2.1255, acc-0.4100\n",
      "Iter-22210, train loss-2.1161, acc-0.4600, valid loss-2.1376, acc-0.3990, test loss-2.1255, acc-0.4103\n",
      "Iter-22220, train loss-2.1310, acc-0.4600, valid loss-2.1375, acc-0.3992, test loss-2.1254, acc-0.4103\n",
      "Iter-22230, train loss-2.1024, acc-0.4600, valid loss-2.1375, acc-0.3998, test loss-2.1253, acc-0.4100\n",
      "Iter-22240, train loss-2.1046, acc-0.4800, valid loss-2.1374, acc-0.4000, test loss-2.1253, acc-0.4102\n",
      "Iter-22250, train loss-2.1148, acc-0.4400, valid loss-2.1374, acc-0.3998, test loss-2.1252, acc-0.4103\n",
      "Iter-22260, train loss-2.1241, acc-0.4000, valid loss-2.1373, acc-0.4000, test loss-2.1251, acc-0.4107\n",
      "Iter-22270, train loss-2.0787, acc-0.4800, valid loss-2.1372, acc-0.4000, test loss-2.1251, acc-0.4107\n",
      "Iter-22280, train loss-2.0961, acc-0.4600, valid loss-2.1372, acc-0.4002, test loss-2.1250, acc-0.4103\n",
      "Iter-22290, train loss-2.1414, acc-0.3000, valid loss-2.1371, acc-0.3998, test loss-2.1249, acc-0.4106\n",
      "Iter-22300, train loss-2.1307, acc-0.3600, valid loss-2.1371, acc-0.3996, test loss-2.1249, acc-0.4108\n",
      "Iter-22310, train loss-2.1407, acc-0.4400, valid loss-2.1370, acc-0.4002, test loss-2.1248, acc-0.4109\n",
      "Iter-22320, train loss-2.1415, acc-0.3800, valid loss-2.1369, acc-0.4006, test loss-2.1247, acc-0.4109\n",
      "Iter-22330, train loss-2.1661, acc-0.4000, valid loss-2.1369, acc-0.4008, test loss-2.1247, acc-0.4110\n",
      "Iter-22340, train loss-2.0851, acc-0.5400, valid loss-2.1368, acc-0.4002, test loss-2.1246, acc-0.4111\n",
      "Iter-22350, train loss-2.1180, acc-0.4200, valid loss-2.1368, acc-0.4002, test loss-2.1245, acc-0.4115\n",
      "Iter-22360, train loss-2.1333, acc-0.3200, valid loss-2.1367, acc-0.4004, test loss-2.1245, acc-0.4114\n",
      "Iter-22370, train loss-2.1365, acc-0.4000, valid loss-2.1367, acc-0.4008, test loss-2.1244, acc-0.4114\n",
      "Iter-22380, train loss-2.1264, acc-0.4000, valid loss-2.1366, acc-0.4008, test loss-2.1244, acc-0.4119\n",
      "Iter-22390, train loss-2.0993, acc-0.5200, valid loss-2.1365, acc-0.4004, test loss-2.1243, acc-0.4117\n",
      "Iter-22400, train loss-2.1115, acc-0.4400, valid loss-2.1365, acc-0.4010, test loss-2.1242, acc-0.4113\n",
      "Iter-22410, train loss-2.1098, acc-0.4600, valid loss-2.1364, acc-0.4012, test loss-2.1242, acc-0.4114\n",
      "Iter-22420, train loss-2.1477, acc-0.3400, valid loss-2.1364, acc-0.4014, test loss-2.1241, acc-0.4113\n",
      "Iter-22430, train loss-2.1152, acc-0.3000, valid loss-2.1363, acc-0.4012, test loss-2.1240, acc-0.4120\n",
      "Iter-22440, train loss-2.1631, acc-0.3800, valid loss-2.1362, acc-0.4016, test loss-2.1240, acc-0.4119\n",
      "Iter-22450, train loss-2.1216, acc-0.3200, valid loss-2.1362, acc-0.4008, test loss-2.1239, acc-0.4120\n",
      "Iter-22460, train loss-2.1523, acc-0.4200, valid loss-2.1361, acc-0.4014, test loss-2.1238, acc-0.4121\n",
      "Iter-22470, train loss-2.1468, acc-0.3400, valid loss-2.1361, acc-0.4016, test loss-2.1237, acc-0.4120\n",
      "Iter-22480, train loss-2.1615, acc-0.3400, valid loss-2.1360, acc-0.4014, test loss-2.1237, acc-0.4119\n",
      "Iter-22490, train loss-2.1578, acc-0.4600, valid loss-2.1360, acc-0.4016, test loss-2.1236, acc-0.4123\n",
      "Iter-22500, train loss-2.1174, acc-0.4200, valid loss-2.1359, acc-0.4018, test loss-2.1236, acc-0.4125\n",
      "Iter-22510, train loss-2.1458, acc-0.3800, valid loss-2.1358, acc-0.4016, test loss-2.1235, acc-0.4128\n",
      "Iter-22520, train loss-2.1677, acc-0.3600, valid loss-2.1358, acc-0.4024, test loss-2.1234, acc-0.4129\n",
      "Iter-22530, train loss-2.0937, acc-0.5000, valid loss-2.1357, acc-0.4022, test loss-2.1234, acc-0.4131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-22540, train loss-2.1628, acc-0.3200, valid loss-2.1357, acc-0.4022, test loss-2.1233, acc-0.4130\n",
      "Iter-22550, train loss-2.1089, acc-0.4800, valid loss-2.1356, acc-0.4016, test loss-2.1232, acc-0.4131\n",
      "Iter-22560, train loss-2.1367, acc-0.3400, valid loss-2.1355, acc-0.4024, test loss-2.1232, acc-0.4128\n",
      "Iter-22570, train loss-2.1028, acc-0.5400, valid loss-2.1355, acc-0.4026, test loss-2.1231, acc-0.4132\n",
      "Iter-22580, train loss-2.1032, acc-0.4200, valid loss-2.1354, acc-0.4030, test loss-2.1230, acc-0.4129\n",
      "Iter-22590, train loss-2.1003, acc-0.4000, valid loss-2.1354, acc-0.4036, test loss-2.1230, acc-0.4128\n",
      "Iter-22600, train loss-2.1425, acc-0.3800, valid loss-2.1353, acc-0.4034, test loss-2.1229, acc-0.4130\n",
      "Iter-22610, train loss-2.1331, acc-0.2800, valid loss-2.1353, acc-0.4036, test loss-2.1228, acc-0.4131\n",
      "Iter-22620, train loss-2.1448, acc-0.3600, valid loss-2.1352, acc-0.4038, test loss-2.1228, acc-0.4132\n",
      "Iter-22630, train loss-2.1625, acc-0.3600, valid loss-2.1351, acc-0.4038, test loss-2.1227, acc-0.4132\n",
      "Iter-22640, train loss-2.0821, acc-0.5600, valid loss-2.1351, acc-0.4038, test loss-2.1226, acc-0.4136\n",
      "Iter-22650, train loss-2.2034, acc-0.3200, valid loss-2.1350, acc-0.4040, test loss-2.1226, acc-0.4134\n",
      "Iter-22660, train loss-2.1110, acc-0.4000, valid loss-2.1350, acc-0.4040, test loss-2.1225, acc-0.4132\n",
      "Iter-22670, train loss-2.1475, acc-0.4600, valid loss-2.1349, acc-0.4040, test loss-2.1224, acc-0.4137\n",
      "Iter-22680, train loss-2.1342, acc-0.3600, valid loss-2.1348, acc-0.4044, test loss-2.1224, acc-0.4135\n",
      "Iter-22690, train loss-2.1493, acc-0.3800, valid loss-2.1348, acc-0.4042, test loss-2.1223, acc-0.4133\n",
      "Iter-22700, train loss-2.1231, acc-0.3600, valid loss-2.1347, acc-0.4044, test loss-2.1223, acc-0.4139\n",
      "Iter-22710, train loss-2.1538, acc-0.3400, valid loss-2.1347, acc-0.4044, test loss-2.1222, acc-0.4137\n",
      "Iter-22720, train loss-2.1261, acc-0.4000, valid loss-2.1346, acc-0.4044, test loss-2.1221, acc-0.4139\n",
      "Iter-22730, train loss-2.1351, acc-0.3200, valid loss-2.1345, acc-0.4044, test loss-2.1221, acc-0.4137\n",
      "Iter-22740, train loss-2.0932, acc-0.3800, valid loss-2.1345, acc-0.4044, test loss-2.1220, acc-0.4139\n",
      "Iter-22750, train loss-2.0999, acc-0.4000, valid loss-2.1344, acc-0.4044, test loss-2.1219, acc-0.4141\n",
      "Iter-22760, train loss-2.1088, acc-0.4000, valid loss-2.1344, acc-0.4050, test loss-2.1219, acc-0.4140\n",
      "Iter-22770, train loss-2.1468, acc-0.4400, valid loss-2.1343, acc-0.4048, test loss-2.1218, acc-0.4142\n",
      "Iter-22780, train loss-2.1332, acc-0.4200, valid loss-2.1342, acc-0.4048, test loss-2.1217, acc-0.4142\n",
      "Iter-22790, train loss-2.1327, acc-0.3600, valid loss-2.1342, acc-0.4056, test loss-2.1217, acc-0.4141\n",
      "Iter-22800, train loss-2.1277, acc-0.3800, valid loss-2.1341, acc-0.4054, test loss-2.1216, acc-0.4143\n",
      "Iter-22810, train loss-2.0709, acc-0.5000, valid loss-2.1341, acc-0.4054, test loss-2.1215, acc-0.4143\n",
      "Iter-22820, train loss-2.0991, acc-0.4600, valid loss-2.1340, acc-0.4052, test loss-2.1215, acc-0.4141\n",
      "Iter-22830, train loss-2.1151, acc-0.4400, valid loss-2.1339, acc-0.4052, test loss-2.1214, acc-0.4139\n",
      "Iter-22840, train loss-2.1236, acc-0.4400, valid loss-2.1339, acc-0.4052, test loss-2.1213, acc-0.4143\n",
      "Iter-22850, train loss-2.0824, acc-0.5200, valid loss-2.1338, acc-0.4052, test loss-2.1213, acc-0.4146\n",
      "Iter-22860, train loss-2.0811, acc-0.3800, valid loss-2.1338, acc-0.4056, test loss-2.1212, acc-0.4144\n",
      "Iter-22870, train loss-2.0984, acc-0.5600, valid loss-2.1337, acc-0.4056, test loss-2.1211, acc-0.4145\n",
      "Iter-22880, train loss-2.1221, acc-0.3600, valid loss-2.1336, acc-0.4056, test loss-2.1211, acc-0.4147\n",
      "Iter-22890, train loss-2.1447, acc-0.3400, valid loss-2.1336, acc-0.4050, test loss-2.1210, acc-0.4146\n",
      "Iter-22900, train loss-2.1195, acc-0.3400, valid loss-2.1335, acc-0.4054, test loss-2.1209, acc-0.4146\n",
      "Iter-22910, train loss-2.1137, acc-0.5000, valid loss-2.1335, acc-0.4056, test loss-2.1209, acc-0.4149\n",
      "Iter-22920, train loss-2.1170, acc-0.4800, valid loss-2.1334, acc-0.4058, test loss-2.1208, acc-0.4151\n",
      "Iter-22930, train loss-2.1377, acc-0.3000, valid loss-2.1334, acc-0.4056, test loss-2.1207, acc-0.4149\n",
      "Iter-22940, train loss-2.1454, acc-0.3000, valid loss-2.1333, acc-0.4062, test loss-2.1207, acc-0.4148\n",
      "Iter-22950, train loss-2.1142, acc-0.4400, valid loss-2.1332, acc-0.4060, test loss-2.1206, acc-0.4147\n",
      "Iter-22960, train loss-2.0939, acc-0.4800, valid loss-2.1332, acc-0.4062, test loss-2.1205, acc-0.4147\n",
      "Iter-22970, train loss-2.1218, acc-0.3800, valid loss-2.1331, acc-0.4058, test loss-2.1205, acc-0.4150\n",
      "Iter-22980, train loss-2.1004, acc-0.5000, valid loss-2.1331, acc-0.4056, test loss-2.1204, acc-0.4149\n",
      "Iter-22990, train loss-2.1290, acc-0.4200, valid loss-2.1330, acc-0.4058, test loss-2.1203, acc-0.4150\n",
      "Iter-23000, train loss-2.1007, acc-0.4400, valid loss-2.1329, acc-0.4062, test loss-2.1203, acc-0.4153\n",
      "Iter-23010, train loss-2.1634, acc-0.4000, valid loss-2.1329, acc-0.4058, test loss-2.1202, acc-0.4151\n",
      "Iter-23020, train loss-2.0964, acc-0.4000, valid loss-2.1328, acc-0.4058, test loss-2.1202, acc-0.4154\n",
      "Iter-23030, train loss-2.1332, acc-0.4600, valid loss-2.1328, acc-0.4062, test loss-2.1201, acc-0.4153\n",
      "Iter-23040, train loss-2.1047, acc-0.4400, valid loss-2.1327, acc-0.4060, test loss-2.1200, acc-0.4157\n",
      "Iter-23050, train loss-2.0986, acc-0.4600, valid loss-2.1326, acc-0.4056, test loss-2.1200, acc-0.4157\n",
      "Iter-23060, train loss-2.1313, acc-0.3600, valid loss-2.1326, acc-0.4058, test loss-2.1199, acc-0.4154\n",
      "Iter-23070, train loss-2.1292, acc-0.3400, valid loss-2.1325, acc-0.4058, test loss-2.1198, acc-0.4154\n",
      "Iter-23080, train loss-2.1052, acc-0.4400, valid loss-2.1325, acc-0.4060, test loss-2.1198, acc-0.4162\n",
      "Iter-23090, train loss-2.1395, acc-0.4400, valid loss-2.1324, acc-0.4062, test loss-2.1197, acc-0.4156\n",
      "Iter-23100, train loss-2.1388, acc-0.4800, valid loss-2.1323, acc-0.4062, test loss-2.1196, acc-0.4157\n",
      "Iter-23110, train loss-2.0339, acc-0.6000, valid loss-2.1323, acc-0.4060, test loss-2.1196, acc-0.4161\n",
      "Iter-23120, train loss-2.1618, acc-0.4600, valid loss-2.1322, acc-0.4060, test loss-2.1195, acc-0.4163\n",
      "Iter-23130, train loss-2.1571, acc-0.2600, valid loss-2.1322, acc-0.4062, test loss-2.1194, acc-0.4162\n",
      "Iter-23140, train loss-2.0779, acc-0.4600, valid loss-2.1321, acc-0.4062, test loss-2.1194, acc-0.4162\n",
      "Iter-23150, train loss-2.1077, acc-0.4600, valid loss-2.1321, acc-0.4064, test loss-2.1193, acc-0.4162\n",
      "Iter-23160, train loss-2.1607, acc-0.3600, valid loss-2.1320, acc-0.4066, test loss-2.1192, acc-0.4163\n",
      "Iter-23170, train loss-2.1042, acc-0.5000, valid loss-2.1319, acc-0.4070, test loss-2.1192, acc-0.4163\n",
      "Iter-23180, train loss-2.1954, acc-0.4200, valid loss-2.1319, acc-0.4068, test loss-2.1191, acc-0.4164\n",
      "Iter-23190, train loss-2.0944, acc-0.4000, valid loss-2.1318, acc-0.4072, test loss-2.1191, acc-0.4166\n",
      "Iter-23200, train loss-2.1131, acc-0.3800, valid loss-2.1318, acc-0.4072, test loss-2.1190, acc-0.4170\n",
      "Iter-23210, train loss-2.1361, acc-0.4800, valid loss-2.1317, acc-0.4072, test loss-2.1189, acc-0.4166\n",
      "Iter-23220, train loss-2.1098, acc-0.4400, valid loss-2.1316, acc-0.4072, test loss-2.1189, acc-0.4166\n",
      "Iter-23230, train loss-2.0932, acc-0.3800, valid loss-2.1316, acc-0.4074, test loss-2.1188, acc-0.4169\n",
      "Iter-23240, train loss-2.1430, acc-0.3200, valid loss-2.1315, acc-0.4072, test loss-2.1187, acc-0.4170\n",
      "Iter-23250, train loss-2.1144, acc-0.4200, valid loss-2.1315, acc-0.4072, test loss-2.1187, acc-0.4170\n",
      "Iter-23260, train loss-2.1085, acc-0.5000, valid loss-2.1314, acc-0.4072, test loss-2.1186, acc-0.4167\n",
      "Iter-23270, train loss-2.1531, acc-0.4600, valid loss-2.1313, acc-0.4072, test loss-2.1185, acc-0.4169\n",
      "Iter-23280, train loss-2.1357, acc-0.3800, valid loss-2.1313, acc-0.4078, test loss-2.1185, acc-0.4166\n",
      "Iter-23290, train loss-2.1790, acc-0.3200, valid loss-2.1312, acc-0.4078, test loss-2.1184, acc-0.4169\n",
      "Iter-23300, train loss-2.1796, acc-0.3600, valid loss-2.1312, acc-0.4076, test loss-2.1183, acc-0.4170\n",
      "Iter-23310, train loss-2.1196, acc-0.4200, valid loss-2.1311, acc-0.4078, test loss-2.1183, acc-0.4170\n",
      "Iter-23320, train loss-2.1316, acc-0.4200, valid loss-2.1311, acc-0.4076, test loss-2.1182, acc-0.4167\n",
      "Iter-23330, train loss-2.0907, acc-0.4600, valid loss-2.1310, acc-0.4080, test loss-2.1181, acc-0.4169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-23340, train loss-2.0834, acc-0.5600, valid loss-2.1309, acc-0.4078, test loss-2.1181, acc-0.4170\n",
      "Iter-23350, train loss-2.1504, acc-0.3800, valid loss-2.1309, acc-0.4082, test loss-2.1180, acc-0.4171\n",
      "Iter-23360, train loss-2.1292, acc-0.4200, valid loss-2.1308, acc-0.4082, test loss-2.1180, acc-0.4169\n",
      "Iter-23370, train loss-2.1349, acc-0.4000, valid loss-2.1308, acc-0.4082, test loss-2.1179, acc-0.4168\n",
      "Iter-23380, train loss-2.1448, acc-0.4200, valid loss-2.1307, acc-0.4080, test loss-2.1178, acc-0.4169\n",
      "Iter-23390, train loss-2.0705, acc-0.5000, valid loss-2.1307, acc-0.4080, test loss-2.1178, acc-0.4170\n",
      "Iter-23400, train loss-2.1308, acc-0.4600, valid loss-2.1306, acc-0.4080, test loss-2.1177, acc-0.4168\n",
      "Iter-23410, train loss-2.1338, acc-0.3600, valid loss-2.1305, acc-0.4078, test loss-2.1176, acc-0.4174\n",
      "Iter-23420, train loss-2.1430, acc-0.4200, valid loss-2.1305, acc-0.4078, test loss-2.1176, acc-0.4172\n",
      "Iter-23430, train loss-2.1203, acc-0.3000, valid loss-2.1304, acc-0.4078, test loss-2.1175, acc-0.4173\n",
      "Iter-23440, train loss-2.1248, acc-0.4000, valid loss-2.1304, acc-0.4078, test loss-2.1174, acc-0.4174\n",
      "Iter-23450, train loss-2.1391, acc-0.4200, valid loss-2.1303, acc-0.4078, test loss-2.1174, acc-0.4174\n",
      "Iter-23460, train loss-2.1215, acc-0.3800, valid loss-2.1302, acc-0.4080, test loss-2.1173, acc-0.4176\n",
      "Iter-23470, train loss-2.1014, acc-0.5000, valid loss-2.1302, acc-0.4080, test loss-2.1173, acc-0.4174\n",
      "Iter-23480, train loss-2.1352, acc-0.4000, valid loss-2.1301, acc-0.4082, test loss-2.1172, acc-0.4176\n",
      "Iter-23490, train loss-2.0972, acc-0.4200, valid loss-2.1301, acc-0.4086, test loss-2.1171, acc-0.4176\n",
      "Iter-23500, train loss-2.1445, acc-0.4400, valid loss-2.1300, acc-0.4086, test loss-2.1171, acc-0.4178\n",
      "Iter-23510, train loss-2.1163, acc-0.4000, valid loss-2.1300, acc-0.4084, test loss-2.1170, acc-0.4175\n",
      "Iter-23520, train loss-2.1432, acc-0.4800, valid loss-2.1299, acc-0.4090, test loss-2.1169, acc-0.4176\n",
      "Iter-23530, train loss-2.1459, acc-0.4200, valid loss-2.1298, acc-0.4088, test loss-2.1169, acc-0.4175\n",
      "Iter-23540, train loss-2.1386, acc-0.4000, valid loss-2.1298, acc-0.4088, test loss-2.1168, acc-0.4177\n",
      "Iter-23550, train loss-2.1402, acc-0.3600, valid loss-2.1297, acc-0.4086, test loss-2.1167, acc-0.4176\n",
      "Iter-23560, train loss-2.1216, acc-0.3400, valid loss-2.1297, acc-0.4090, test loss-2.1167, acc-0.4180\n",
      "Iter-23570, train loss-2.0928, acc-0.4600, valid loss-2.1296, acc-0.4088, test loss-2.1166, acc-0.4179\n",
      "Iter-23580, train loss-2.0931, acc-0.5000, valid loss-2.1296, acc-0.4086, test loss-2.1165, acc-0.4179\n",
      "Iter-23590, train loss-2.1072, acc-0.4000, valid loss-2.1295, acc-0.4088, test loss-2.1165, acc-0.4178\n",
      "Iter-23600, train loss-2.0994, acc-0.5000, valid loss-2.1294, acc-0.4090, test loss-2.1164, acc-0.4178\n",
      "Iter-23610, train loss-2.1424, acc-0.4800, valid loss-2.1294, acc-0.4092, test loss-2.1164, acc-0.4181\n",
      "Iter-23620, train loss-2.1278, acc-0.4800, valid loss-2.1293, acc-0.4090, test loss-2.1163, acc-0.4182\n",
      "Iter-23630, train loss-2.1400, acc-0.4600, valid loss-2.1293, acc-0.4092, test loss-2.1162, acc-0.4184\n",
      "Iter-23640, train loss-2.1884, acc-0.3600, valid loss-2.1292, acc-0.4094, test loss-2.1162, acc-0.4190\n",
      "Iter-23650, train loss-2.1090, acc-0.3600, valid loss-2.1292, acc-0.4090, test loss-2.1161, acc-0.4186\n",
      "Iter-23660, train loss-2.0811, acc-0.4800, valid loss-2.1291, acc-0.4092, test loss-2.1160, acc-0.4186\n",
      "Iter-23670, train loss-2.1442, acc-0.3000, valid loss-2.1290, acc-0.4094, test loss-2.1160, acc-0.4186\n",
      "Iter-23680, train loss-2.1253, acc-0.4000, valid loss-2.1290, acc-0.4094, test loss-2.1159, acc-0.4188\n",
      "Iter-23690, train loss-2.1237, acc-0.3800, valid loss-2.1289, acc-0.4094, test loss-2.1158, acc-0.4188\n",
      "Iter-23700, train loss-2.1004, acc-0.4600, valid loss-2.1289, acc-0.4094, test loss-2.1158, acc-0.4188\n",
      "Iter-23710, train loss-2.1096, acc-0.4000, valid loss-2.1288, acc-0.4100, test loss-2.1157, acc-0.4190\n",
      "Iter-23720, train loss-2.0793, acc-0.5600, valid loss-2.1288, acc-0.4098, test loss-2.1157, acc-0.4191\n",
      "Iter-23730, train loss-2.1272, acc-0.3600, valid loss-2.1287, acc-0.4098, test loss-2.1156, acc-0.4191\n",
      "Iter-23740, train loss-2.1062, acc-0.3600, valid loss-2.1286, acc-0.4098, test loss-2.1155, acc-0.4191\n",
      "Iter-23750, train loss-2.1239, acc-0.4600, valid loss-2.1286, acc-0.4096, test loss-2.1155, acc-0.4194\n",
      "Iter-23760, train loss-2.1123, acc-0.4600, valid loss-2.1285, acc-0.4096, test loss-2.1154, acc-0.4196\n",
      "Iter-23770, train loss-2.1253, acc-0.4800, valid loss-2.1285, acc-0.4094, test loss-2.1153, acc-0.4191\n",
      "Iter-23780, train loss-2.1161, acc-0.4200, valid loss-2.1284, acc-0.4096, test loss-2.1153, acc-0.4194\n",
      "Iter-23790, train loss-2.1208, acc-0.4800, valid loss-2.1284, acc-0.4102, test loss-2.1152, acc-0.4194\n",
      "Iter-23800, train loss-2.1444, acc-0.3000, valid loss-2.1283, acc-0.4098, test loss-2.1151, acc-0.4196\n",
      "Iter-23810, train loss-2.1112, acc-0.4600, valid loss-2.1282, acc-0.4100, test loss-2.1151, acc-0.4194\n",
      "Iter-23820, train loss-2.1363, acc-0.3400, valid loss-2.1282, acc-0.4102, test loss-2.1150, acc-0.4191\n",
      "Iter-23830, train loss-2.1022, acc-0.4400, valid loss-2.1281, acc-0.4102, test loss-2.1150, acc-0.4190\n",
      "Iter-23840, train loss-2.0683, acc-0.5200, valid loss-2.1281, acc-0.4102, test loss-2.1149, acc-0.4193\n",
      "Iter-23850, train loss-2.1331, acc-0.4000, valid loss-2.1280, acc-0.4102, test loss-2.1148, acc-0.4194\n",
      "Iter-23860, train loss-2.1162, acc-0.4200, valid loss-2.1279, acc-0.4100, test loss-2.1148, acc-0.4194\n",
      "Iter-23870, train loss-2.1183, acc-0.5000, valid loss-2.1279, acc-0.4102, test loss-2.1147, acc-0.4196\n",
      "Iter-23880, train loss-2.1295, acc-0.4000, valid loss-2.1278, acc-0.4102, test loss-2.1146, acc-0.4196\n",
      "Iter-23890, train loss-2.1209, acc-0.3600, valid loss-2.1278, acc-0.4104, test loss-2.1146, acc-0.4195\n",
      "Iter-23900, train loss-2.0924, acc-0.4400, valid loss-2.1277, acc-0.4104, test loss-2.1145, acc-0.4198\n",
      "Iter-23910, train loss-2.0959, acc-0.3400, valid loss-2.1277, acc-0.4106, test loss-2.1144, acc-0.4198\n",
      "Iter-23920, train loss-2.1230, acc-0.3600, valid loss-2.1276, acc-0.4106, test loss-2.1144, acc-0.4200\n",
      "Iter-23930, train loss-2.1271, acc-0.4400, valid loss-2.1275, acc-0.4104, test loss-2.1143, acc-0.4204\n",
      "Iter-23940, train loss-2.1730, acc-0.3400, valid loss-2.1275, acc-0.4104, test loss-2.1142, acc-0.4202\n",
      "Iter-23950, train loss-2.1098, acc-0.4000, valid loss-2.1274, acc-0.4104, test loss-2.1142, acc-0.4202\n",
      "Iter-23960, train loss-2.1342, acc-0.3200, valid loss-2.1274, acc-0.4104, test loss-2.1141, acc-0.4204\n",
      "Iter-23970, train loss-2.1269, acc-0.4200, valid loss-2.1273, acc-0.4108, test loss-2.1140, acc-0.4204\n",
      "Iter-23980, train loss-2.1208, acc-0.4200, valid loss-2.1272, acc-0.4104, test loss-2.1140, acc-0.4206\n",
      "Iter-23990, train loss-2.1639, acc-0.3200, valid loss-2.1272, acc-0.4106, test loss-2.1139, acc-0.4206\n",
      "Iter-24000, train loss-2.1647, acc-0.3200, valid loss-2.1271, acc-0.4108, test loss-2.1139, acc-0.4207\n",
      "Iter-24010, train loss-2.1292, acc-0.3600, valid loss-2.1271, acc-0.4100, test loss-2.1138, acc-0.4207\n",
      "Iter-24020, train loss-2.1478, acc-0.3600, valid loss-2.1270, acc-0.4106, test loss-2.1137, acc-0.4209\n",
      "Iter-24030, train loss-2.1848, acc-0.2400, valid loss-2.1270, acc-0.4104, test loss-2.1137, acc-0.4210\n",
      "Iter-24040, train loss-2.1404, acc-0.4600, valid loss-2.1269, acc-0.4102, test loss-2.1136, acc-0.4209\n",
      "Iter-24050, train loss-2.1245, acc-0.3600, valid loss-2.1268, acc-0.4108, test loss-2.1135, acc-0.4209\n",
      "Iter-24060, train loss-2.1037, acc-0.4800, valid loss-2.1268, acc-0.4108, test loss-2.1135, acc-0.4208\n",
      "Iter-24070, train loss-2.1483, acc-0.3600, valid loss-2.1267, acc-0.4106, test loss-2.1134, acc-0.4209\n",
      "Iter-24080, train loss-2.1411, acc-0.4600, valid loss-2.1267, acc-0.4108, test loss-2.1133, acc-0.4208\n",
      "Iter-24090, train loss-2.1535, acc-0.3800, valid loss-2.1266, acc-0.4106, test loss-2.1133, acc-0.4210\n",
      "Iter-24100, train loss-2.1028, acc-0.4200, valid loss-2.1266, acc-0.4108, test loss-2.1132, acc-0.4212\n",
      "Iter-24110, train loss-2.1284, acc-0.4400, valid loss-2.1265, acc-0.4106, test loss-2.1132, acc-0.4215\n",
      "Iter-24120, train loss-2.1463, acc-0.3000, valid loss-2.1264, acc-0.4108, test loss-2.1131, acc-0.4212\n",
      "Iter-24130, train loss-2.0923, acc-0.4800, valid loss-2.1264, acc-0.4106, test loss-2.1130, acc-0.4214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-24140, train loss-2.1332, acc-0.4400, valid loss-2.1263, acc-0.4106, test loss-2.1130, acc-0.4214\n",
      "Iter-24150, train loss-2.0765, acc-0.5000, valid loss-2.1263, acc-0.4106, test loss-2.1129, acc-0.4214\n",
      "Iter-24160, train loss-2.1306, acc-0.4000, valid loss-2.1262, acc-0.4106, test loss-2.1128, acc-0.4214\n",
      "Iter-24170, train loss-2.1065, acc-0.4400, valid loss-2.1262, acc-0.4108, test loss-2.1128, acc-0.4214\n",
      "Iter-24180, train loss-2.1046, acc-0.4400, valid loss-2.1261, acc-0.4106, test loss-2.1127, acc-0.4214\n",
      "Iter-24190, train loss-2.1281, acc-0.4400, valid loss-2.1260, acc-0.4106, test loss-2.1126, acc-0.4214\n",
      "Iter-24200, train loss-2.0775, acc-0.4800, valid loss-2.1260, acc-0.4108, test loss-2.1126, acc-0.4215\n",
      "Iter-24210, train loss-2.1398, acc-0.3800, valid loss-2.1259, acc-0.4106, test loss-2.1125, acc-0.4215\n",
      "Iter-24220, train loss-2.1446, acc-0.5000, valid loss-2.1259, acc-0.4108, test loss-2.1125, acc-0.4215\n",
      "Iter-24230, train loss-2.0963, acc-0.4800, valid loss-2.1258, acc-0.4108, test loss-2.1124, acc-0.4215\n",
      "Iter-24240, train loss-2.1457, acc-0.2400, valid loss-2.1257, acc-0.4110, test loss-2.1123, acc-0.4213\n",
      "Iter-24250, train loss-2.1283, acc-0.4600, valid loss-2.1257, acc-0.4108, test loss-2.1123, acc-0.4214\n",
      "Iter-24260, train loss-2.1553, acc-0.3400, valid loss-2.1256, acc-0.4104, test loss-2.1122, acc-0.4215\n",
      "Iter-24270, train loss-2.0806, acc-0.5000, valid loss-2.1256, acc-0.4110, test loss-2.1121, acc-0.4215\n",
      "Iter-24280, train loss-2.0974, acc-0.4200, valid loss-2.1255, acc-0.4106, test loss-2.1121, acc-0.4215\n",
      "Iter-24290, train loss-2.1454, acc-0.3400, valid loss-2.1255, acc-0.4104, test loss-2.1120, acc-0.4214\n",
      "Iter-24300, train loss-2.1158, acc-0.3800, valid loss-2.1254, acc-0.4106, test loss-2.1119, acc-0.4218\n",
      "Iter-24310, train loss-2.1212, acc-0.4600, valid loss-2.1253, acc-0.4106, test loss-2.1119, acc-0.4216\n",
      "Iter-24320, train loss-2.0898, acc-0.5400, valid loss-2.1253, acc-0.4108, test loss-2.1118, acc-0.4214\n",
      "Iter-24330, train loss-2.0702, acc-0.5200, valid loss-2.1252, acc-0.4106, test loss-2.1118, acc-0.4214\n",
      "Iter-24340, train loss-2.1405, acc-0.2800, valid loss-2.1252, acc-0.4106, test loss-2.1117, acc-0.4216\n",
      "Iter-24350, train loss-2.1017, acc-0.4800, valid loss-2.1251, acc-0.4108, test loss-2.1116, acc-0.4213\n",
      "Iter-24360, train loss-2.1210, acc-0.3800, valid loss-2.1250, acc-0.4106, test loss-2.1116, acc-0.4214\n",
      "Iter-24370, train loss-2.1420, acc-0.3600, valid loss-2.1250, acc-0.4108, test loss-2.1115, acc-0.4215\n",
      "Iter-24380, train loss-2.1209, acc-0.3800, valid loss-2.1249, acc-0.4108, test loss-2.1114, acc-0.4213\n",
      "Iter-24390, train loss-2.1581, acc-0.3000, valid loss-2.1249, acc-0.4106, test loss-2.1114, acc-0.4213\n",
      "Iter-24400, train loss-2.1353, acc-0.5000, valid loss-2.1248, acc-0.4112, test loss-2.1113, acc-0.4215\n",
      "Iter-24410, train loss-2.0929, acc-0.5000, valid loss-2.1248, acc-0.4106, test loss-2.1112, acc-0.4214\n",
      "Iter-24420, train loss-2.1332, acc-0.3400, valid loss-2.1247, acc-0.4108, test loss-2.1112, acc-0.4216\n",
      "Iter-24430, train loss-2.1271, acc-0.4000, valid loss-2.1246, acc-0.4106, test loss-2.1111, acc-0.4218\n",
      "Iter-24440, train loss-2.0964, acc-0.4400, valid loss-2.1246, acc-0.4108, test loss-2.1110, acc-0.4217\n",
      "Iter-24450, train loss-2.1265, acc-0.4000, valid loss-2.1245, acc-0.4110, test loss-2.1110, acc-0.4218\n",
      "Iter-24460, train loss-2.0943, acc-0.3800, valid loss-2.1245, acc-0.4116, test loss-2.1109, acc-0.4219\n",
      "Iter-24470, train loss-2.1141, acc-0.4000, valid loss-2.1244, acc-0.4116, test loss-2.1109, acc-0.4221\n",
      "Iter-24480, train loss-2.0986, acc-0.4600, valid loss-2.1243, acc-0.4116, test loss-2.1108, acc-0.4220\n",
      "Iter-24490, train loss-2.0918, acc-0.5000, valid loss-2.1243, acc-0.4116, test loss-2.1107, acc-0.4220\n",
      "Iter-24500, train loss-2.1116, acc-0.5200, valid loss-2.1242, acc-0.4114, test loss-2.1106, acc-0.4220\n",
      "Iter-24510, train loss-2.0535, acc-0.5400, valid loss-2.1242, acc-0.4114, test loss-2.1106, acc-0.4220\n",
      "Iter-24520, train loss-2.0876, acc-0.3800, valid loss-2.1241, acc-0.4114, test loss-2.1105, acc-0.4219\n",
      "Iter-24530, train loss-2.0971, acc-0.4400, valid loss-2.1240, acc-0.4116, test loss-2.1105, acc-0.4218\n",
      "Iter-24540, train loss-2.1550, acc-0.2600, valid loss-2.1240, acc-0.4114, test loss-2.1104, acc-0.4219\n",
      "Iter-24550, train loss-2.1204, acc-0.3600, valid loss-2.1239, acc-0.4116, test loss-2.1103, acc-0.4222\n",
      "Iter-24560, train loss-2.1010, acc-0.4200, valid loss-2.1239, acc-0.4116, test loss-2.1103, acc-0.4221\n",
      "Iter-24570, train loss-2.1299, acc-0.3800, valid loss-2.1238, acc-0.4114, test loss-2.1102, acc-0.4223\n",
      "Iter-24580, train loss-2.0798, acc-0.4800, valid loss-2.1238, acc-0.4116, test loss-2.1101, acc-0.4225\n",
      "Iter-24590, train loss-2.0991, acc-0.4200, valid loss-2.1237, acc-0.4118, test loss-2.1101, acc-0.4226\n",
      "Iter-24600, train loss-2.1396, acc-0.3800, valid loss-2.1236, acc-0.4120, test loss-2.1100, acc-0.4225\n",
      "Iter-24610, train loss-2.1739, acc-0.3600, valid loss-2.1236, acc-0.4118, test loss-2.1100, acc-0.4226\n",
      "Iter-24620, train loss-2.1345, acc-0.3400, valid loss-2.1235, acc-0.4116, test loss-2.1099, acc-0.4223\n",
      "Iter-24630, train loss-2.1079, acc-0.4400, valid loss-2.1235, acc-0.4116, test loss-2.1098, acc-0.4222\n",
      "Iter-24640, train loss-2.0803, acc-0.5600, valid loss-2.1234, acc-0.4120, test loss-2.1098, acc-0.4222\n",
      "Iter-24650, train loss-2.1235, acc-0.3200, valid loss-2.1234, acc-0.4124, test loss-2.1097, acc-0.4224\n",
      "Iter-24660, train loss-2.1240, acc-0.3200, valid loss-2.1233, acc-0.4126, test loss-2.1096, acc-0.4225\n",
      "Iter-24670, train loss-2.0932, acc-0.5600, valid loss-2.1232, acc-0.4126, test loss-2.1096, acc-0.4227\n",
      "Iter-24680, train loss-2.1157, acc-0.3600, valid loss-2.1232, acc-0.4126, test loss-2.1095, acc-0.4227\n",
      "Iter-24690, train loss-2.1189, acc-0.3800, valid loss-2.1231, acc-0.4126, test loss-2.1094, acc-0.4226\n",
      "Iter-24700, train loss-2.0342, acc-0.5200, valid loss-2.1231, acc-0.4128, test loss-2.1094, acc-0.4226\n",
      "Iter-24710, train loss-2.0866, acc-0.5400, valid loss-2.1230, acc-0.4130, test loss-2.1093, acc-0.4227\n",
      "Iter-24720, train loss-2.1074, acc-0.4600, valid loss-2.1229, acc-0.4128, test loss-2.1093, acc-0.4226\n",
      "Iter-24730, train loss-2.0789, acc-0.4600, valid loss-2.1229, acc-0.4124, test loss-2.1092, acc-0.4226\n",
      "Iter-24740, train loss-2.0963, acc-0.4600, valid loss-2.1228, acc-0.4126, test loss-2.1091, acc-0.4228\n",
      "Iter-24750, train loss-2.1101, acc-0.3600, valid loss-2.1228, acc-0.4124, test loss-2.1091, acc-0.4226\n",
      "Iter-24760, train loss-2.1305, acc-0.4200, valid loss-2.1227, acc-0.4122, test loss-2.1090, acc-0.4227\n",
      "Iter-24770, train loss-2.1278, acc-0.4600, valid loss-2.1226, acc-0.4128, test loss-2.1089, acc-0.4226\n",
      "Iter-24780, train loss-2.0980, acc-0.4400, valid loss-2.1226, acc-0.4128, test loss-2.1089, acc-0.4227\n",
      "Iter-24790, train loss-2.1646, acc-0.3400, valid loss-2.1225, acc-0.4132, test loss-2.1088, acc-0.4228\n",
      "Iter-24800, train loss-2.1096, acc-0.4000, valid loss-2.1225, acc-0.4134, test loss-2.1087, acc-0.4227\n",
      "Iter-24810, train loss-2.1373, acc-0.3400, valid loss-2.1224, acc-0.4134, test loss-2.1087, acc-0.4226\n",
      "Iter-24820, train loss-2.1207, acc-0.4400, valid loss-2.1224, acc-0.4134, test loss-2.1086, acc-0.4227\n",
      "Iter-24830, train loss-2.0876, acc-0.3400, valid loss-2.1223, acc-0.4132, test loss-2.1085, acc-0.4226\n",
      "Iter-24840, train loss-2.1052, acc-0.3800, valid loss-2.1222, acc-0.4132, test loss-2.1085, acc-0.4227\n",
      "Iter-24850, train loss-2.1092, acc-0.4000, valid loss-2.1222, acc-0.4136, test loss-2.1084, acc-0.4232\n",
      "Iter-24860, train loss-2.1136, acc-0.4000, valid loss-2.1221, acc-0.4136, test loss-2.1084, acc-0.4236\n",
      "Iter-24870, train loss-2.0920, acc-0.5400, valid loss-2.1221, acc-0.4134, test loss-2.1083, acc-0.4235\n",
      "Iter-24880, train loss-2.0853, acc-0.5400, valid loss-2.1220, acc-0.4134, test loss-2.1082, acc-0.4236\n",
      "Iter-24890, train loss-2.1507, acc-0.3200, valid loss-2.1219, acc-0.4138, test loss-2.1082, acc-0.4236\n",
      "Iter-24900, train loss-2.1145, acc-0.3600, valid loss-2.1219, acc-0.4134, test loss-2.1081, acc-0.4234\n",
      "Iter-24910, train loss-2.1332, acc-0.3400, valid loss-2.1218, acc-0.4134, test loss-2.1080, acc-0.4238\n",
      "Iter-24920, train loss-2.1034, acc-0.4200, valid loss-2.1218, acc-0.4134, test loss-2.1080, acc-0.4238\n",
      "Iter-24930, train loss-2.1022, acc-0.4600, valid loss-2.1217, acc-0.4134, test loss-2.1079, acc-0.4242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-24940, train loss-2.1458, acc-0.3400, valid loss-2.1217, acc-0.4138, test loss-2.1079, acc-0.4243\n",
      "Iter-24950, train loss-2.1302, acc-0.3800, valid loss-2.1216, acc-0.4138, test loss-2.1078, acc-0.4243\n",
      "Iter-24960, train loss-2.1575, acc-0.3800, valid loss-2.1216, acc-0.4142, test loss-2.1077, acc-0.4245\n",
      "Iter-24970, train loss-2.1185, acc-0.4400, valid loss-2.1215, acc-0.4140, test loss-2.1077, acc-0.4245\n",
      "Iter-24980, train loss-2.0965, acc-0.4200, valid loss-2.1215, acc-0.4138, test loss-2.1076, acc-0.4244\n",
      "Iter-24990, train loss-2.1192, acc-0.4200, valid loss-2.1214, acc-0.4146, test loss-2.1075, acc-0.4243\n",
      "Iter-25000, train loss-2.1618, acc-0.4000, valid loss-2.1213, acc-0.4144, test loss-2.1075, acc-0.4241\n",
      "Iter-25010, train loss-2.0869, acc-0.3800, valid loss-2.1213, acc-0.4146, test loss-2.1074, acc-0.4243\n",
      "Iter-25020, train loss-2.1640, acc-0.3600, valid loss-2.1212, acc-0.4144, test loss-2.1074, acc-0.4245\n",
      "Iter-25030, train loss-2.1409, acc-0.3600, valid loss-2.1212, acc-0.4146, test loss-2.1073, acc-0.4246\n",
      "Iter-25040, train loss-2.0416, acc-0.5000, valid loss-2.1211, acc-0.4144, test loss-2.1072, acc-0.4247\n",
      "Iter-25050, train loss-2.1071, acc-0.4000, valid loss-2.1211, acc-0.4146, test loss-2.1072, acc-0.4248\n",
      "Iter-25060, train loss-2.1160, acc-0.4000, valid loss-2.1210, acc-0.4150, test loss-2.1071, acc-0.4248\n",
      "Iter-25070, train loss-2.1073, acc-0.4600, valid loss-2.1209, acc-0.4148, test loss-2.1070, acc-0.4247\n",
      "Iter-25080, train loss-2.0719, acc-0.5000, valid loss-2.1209, acc-0.4152, test loss-2.1070, acc-0.4251\n",
      "Iter-25090, train loss-2.1291, acc-0.3600, valid loss-2.1208, acc-0.4148, test loss-2.1069, acc-0.4250\n",
      "Iter-25100, train loss-2.0924, acc-0.4000, valid loss-2.1208, acc-0.4148, test loss-2.1069, acc-0.4251\n",
      "Iter-25110, train loss-2.1022, acc-0.3800, valid loss-2.1207, acc-0.4148, test loss-2.1068, acc-0.4251\n",
      "Iter-25120, train loss-2.1194, acc-0.4400, valid loss-2.1206, acc-0.4146, test loss-2.1067, acc-0.4249\n",
      "Iter-25130, train loss-2.0924, acc-0.4400, valid loss-2.1206, acc-0.4142, test loss-2.1067, acc-0.4250\n",
      "Iter-25140, train loss-2.1512, acc-0.3600, valid loss-2.1205, acc-0.4148, test loss-2.1066, acc-0.4250\n",
      "Iter-25150, train loss-2.1276, acc-0.4000, valid loss-2.1205, acc-0.4144, test loss-2.1065, acc-0.4251\n",
      "Iter-25160, train loss-2.0976, acc-0.4000, valid loss-2.1204, acc-0.4148, test loss-2.1065, acc-0.4253\n",
      "Iter-25170, train loss-2.1128, acc-0.5000, valid loss-2.1204, acc-0.4148, test loss-2.1064, acc-0.4254\n",
      "Iter-25180, train loss-2.1042, acc-0.5000, valid loss-2.1203, acc-0.4146, test loss-2.1064, acc-0.4253\n",
      "Iter-25190, train loss-2.1188, acc-0.4600, valid loss-2.1203, acc-0.4148, test loss-2.1063, acc-0.4255\n",
      "Iter-25200, train loss-2.1127, acc-0.3800, valid loss-2.1202, acc-0.4146, test loss-2.1062, acc-0.4254\n",
      "Iter-25210, train loss-2.1122, acc-0.4600, valid loss-2.1201, acc-0.4148, test loss-2.1062, acc-0.4256\n",
      "Iter-25220, train loss-2.1096, acc-0.3800, valid loss-2.1201, acc-0.4152, test loss-2.1061, acc-0.4253\n",
      "Iter-25230, train loss-2.1509, acc-0.4200, valid loss-2.1200, acc-0.4154, test loss-2.1061, acc-0.4255\n",
      "Iter-25240, train loss-2.1214, acc-0.4200, valid loss-2.1200, acc-0.4158, test loss-2.1060, acc-0.4256\n",
      "Iter-25250, train loss-2.0682, acc-0.4800, valid loss-2.1199, acc-0.4158, test loss-2.1059, acc-0.4260\n",
      "Iter-25260, train loss-2.1722, acc-0.3000, valid loss-2.1198, acc-0.4160, test loss-2.1059, acc-0.4261\n",
      "Iter-25270, train loss-2.1081, acc-0.5000, valid loss-2.1198, acc-0.4160, test loss-2.1058, acc-0.4258\n",
      "Iter-25280, train loss-2.1305, acc-0.4200, valid loss-2.1197, acc-0.4162, test loss-2.1057, acc-0.4256\n",
      "Iter-25290, train loss-2.1548, acc-0.4400, valid loss-2.1197, acc-0.4162, test loss-2.1057, acc-0.4259\n",
      "Iter-25300, train loss-2.0911, acc-0.4400, valid loss-2.1196, acc-0.4160, test loss-2.1056, acc-0.4260\n",
      "Iter-25310, train loss-2.0869, acc-0.4600, valid loss-2.1196, acc-0.4164, test loss-2.1055, acc-0.4258\n",
      "Iter-25320, train loss-2.1378, acc-0.3600, valid loss-2.1195, acc-0.4162, test loss-2.1055, acc-0.4259\n",
      "Iter-25330, train loss-2.1196, acc-0.3800, valid loss-2.1194, acc-0.4162, test loss-2.1054, acc-0.4261\n",
      "Iter-25340, train loss-2.0892, acc-0.3800, valid loss-2.1194, acc-0.4166, test loss-2.1054, acc-0.4262\n",
      "Iter-25350, train loss-2.1300, acc-0.3400, valid loss-2.1193, acc-0.4164, test loss-2.1053, acc-0.4262\n",
      "Iter-25360, train loss-2.1171, acc-0.4400, valid loss-2.1193, acc-0.4164, test loss-2.1052, acc-0.4264\n",
      "Iter-25370, train loss-2.1100, acc-0.4400, valid loss-2.1192, acc-0.4164, test loss-2.1052, acc-0.4262\n",
      "Iter-25380, train loss-2.0828, acc-0.5000, valid loss-2.1192, acc-0.4164, test loss-2.1051, acc-0.4267\n",
      "Iter-25390, train loss-2.1229, acc-0.4000, valid loss-2.1191, acc-0.4168, test loss-2.1051, acc-0.4268\n",
      "Iter-25400, train loss-2.1274, acc-0.3600, valid loss-2.1190, acc-0.4166, test loss-2.1050, acc-0.4267\n",
      "Iter-25410, train loss-2.0547, acc-0.4800, valid loss-2.1190, acc-0.4174, test loss-2.1049, acc-0.4269\n",
      "Iter-25420, train loss-2.1272, acc-0.2800, valid loss-2.1189, acc-0.4172, test loss-2.1049, acc-0.4268\n",
      "Iter-25430, train loss-2.1381, acc-0.3600, valid loss-2.1189, acc-0.4174, test loss-2.1048, acc-0.4269\n",
      "Iter-25440, train loss-2.1118, acc-0.3200, valid loss-2.1188, acc-0.4176, test loss-2.1047, acc-0.4269\n",
      "Iter-25450, train loss-2.1097, acc-0.3800, valid loss-2.1188, acc-0.4178, test loss-2.1047, acc-0.4269\n",
      "Iter-25460, train loss-2.0899, acc-0.4600, valid loss-2.1187, acc-0.4178, test loss-2.1046, acc-0.4271\n",
      "Iter-25470, train loss-2.1416, acc-0.3400, valid loss-2.1187, acc-0.4178, test loss-2.1046, acc-0.4272\n",
      "Iter-25480, train loss-2.0783, acc-0.4800, valid loss-2.1186, acc-0.4176, test loss-2.1045, acc-0.4272\n",
      "Iter-25490, train loss-2.1248, acc-0.3400, valid loss-2.1186, acc-0.4174, test loss-2.1044, acc-0.4273\n",
      "Iter-25500, train loss-2.1056, acc-0.3800, valid loss-2.1185, acc-0.4178, test loss-2.1044, acc-0.4273\n",
      "Iter-25510, train loss-2.0910, acc-0.4600, valid loss-2.1184, acc-0.4178, test loss-2.1043, acc-0.4276\n",
      "Iter-25520, train loss-2.1478, acc-0.3600, valid loss-2.1184, acc-0.4178, test loss-2.1043, acc-0.4273\n",
      "Iter-25530, train loss-2.0695, acc-0.5000, valid loss-2.1183, acc-0.4182, test loss-2.1042, acc-0.4273\n",
      "Iter-25540, train loss-2.1470, acc-0.4800, valid loss-2.1183, acc-0.4180, test loss-2.1041, acc-0.4275\n",
      "Iter-25550, train loss-2.1059, acc-0.5000, valid loss-2.1182, acc-0.4180, test loss-2.1041, acc-0.4277\n",
      "Iter-25560, train loss-2.0500, acc-0.4800, valid loss-2.1182, acc-0.4182, test loss-2.1040, acc-0.4280\n",
      "Iter-25570, train loss-2.0951, acc-0.4200, valid loss-2.1181, acc-0.4180, test loss-2.1039, acc-0.4279\n",
      "Iter-25580, train loss-2.1586, acc-0.3400, valid loss-2.1180, acc-0.4180, test loss-2.1039, acc-0.4281\n",
      "Iter-25590, train loss-2.1434, acc-0.3400, valid loss-2.1180, acc-0.4178, test loss-2.1038, acc-0.4278\n",
      "Iter-25600, train loss-2.1095, acc-0.3000, valid loss-2.1179, acc-0.4176, test loss-2.1038, acc-0.4281\n",
      "Iter-25610, train loss-2.0967, acc-0.4200, valid loss-2.1179, acc-0.4170, test loss-2.1037, acc-0.4282\n",
      "Iter-25620, train loss-2.1053, acc-0.3200, valid loss-2.1178, acc-0.4170, test loss-2.1036, acc-0.4282\n",
      "Iter-25630, train loss-2.0643, acc-0.4400, valid loss-2.1178, acc-0.4176, test loss-2.1036, acc-0.4287\n",
      "Iter-25640, train loss-2.0773, acc-0.4600, valid loss-2.1177, acc-0.4176, test loss-2.1035, acc-0.4285\n",
      "Iter-25650, train loss-2.1325, acc-0.4400, valid loss-2.1177, acc-0.4178, test loss-2.1034, acc-0.4283\n",
      "Iter-25660, train loss-2.0866, acc-0.5000, valid loss-2.1176, acc-0.4180, test loss-2.1034, acc-0.4284\n",
      "Iter-25670, train loss-2.0768, acc-0.4400, valid loss-2.1175, acc-0.4182, test loss-2.1033, acc-0.4287\n",
      "Iter-25680, train loss-2.0972, acc-0.4000, valid loss-2.1175, acc-0.4184, test loss-2.1033, acc-0.4284\n",
      "Iter-25690, train loss-2.1180, acc-0.3800, valid loss-2.1174, acc-0.4180, test loss-2.1032, acc-0.4287\n",
      "Iter-25700, train loss-2.0673, acc-0.4800, valid loss-2.1174, acc-0.4178, test loss-2.1031, acc-0.4288\n",
      "Iter-25710, train loss-2.1244, acc-0.4000, valid loss-2.1173, acc-0.4184, test loss-2.1031, acc-0.4288\n",
      "Iter-25720, train loss-2.1204, acc-0.4400, valid loss-2.1173, acc-0.4184, test loss-2.1030, acc-0.4288\n",
      "Iter-25730, train loss-2.0924, acc-0.3800, valid loss-2.1172, acc-0.4186, test loss-2.1029, acc-0.4289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-25740, train loss-2.1504, acc-0.4600, valid loss-2.1172, acc-0.4188, test loss-2.1029, acc-0.4292\n",
      "Iter-25750, train loss-2.1180, acc-0.4000, valid loss-2.1171, acc-0.4180, test loss-2.1028, acc-0.4294\n",
      "Iter-25760, train loss-2.1139, acc-0.4800, valid loss-2.1171, acc-0.4186, test loss-2.1028, acc-0.4292\n",
      "Iter-25770, train loss-2.1327, acc-0.3800, valid loss-2.1170, acc-0.4190, test loss-2.1027, acc-0.4294\n",
      "Iter-25780, train loss-2.0839, acc-0.5200, valid loss-2.1169, acc-0.4190, test loss-2.1026, acc-0.4296\n",
      "Iter-25790, train loss-2.1079, acc-0.4000, valid loss-2.1169, acc-0.4190, test loss-2.1026, acc-0.4298\n",
      "Iter-25800, train loss-2.1148, acc-0.3400, valid loss-2.1168, acc-0.4188, test loss-2.1025, acc-0.4295\n",
      "Iter-25810, train loss-2.1276, acc-0.3800, valid loss-2.1168, acc-0.4190, test loss-2.1024, acc-0.4298\n",
      "Iter-25820, train loss-2.1072, acc-0.4200, valid loss-2.1167, acc-0.4188, test loss-2.1024, acc-0.4299\n",
      "Iter-25830, train loss-2.1133, acc-0.4200, valid loss-2.1166, acc-0.4190, test loss-2.1023, acc-0.4297\n",
      "Iter-25840, train loss-2.1449, acc-0.3000, valid loss-2.1166, acc-0.4190, test loss-2.1023, acc-0.4300\n",
      "Iter-25850, train loss-2.1139, acc-0.4000, valid loss-2.1165, acc-0.4190, test loss-2.1022, acc-0.4303\n",
      "Iter-25860, train loss-2.1250, acc-0.3800, valid loss-2.1165, acc-0.4190, test loss-2.1021, acc-0.4302\n",
      "Iter-25870, train loss-2.0958, acc-0.4200, valid loss-2.1164, acc-0.4188, test loss-2.1021, acc-0.4301\n",
      "Iter-25880, train loss-2.1125, acc-0.4200, valid loss-2.1164, acc-0.4190, test loss-2.1020, acc-0.4300\n",
      "Iter-25890, train loss-2.1083, acc-0.4800, valid loss-2.1163, acc-0.4192, test loss-2.1020, acc-0.4309\n",
      "Iter-25900, train loss-2.1197, acc-0.4400, valid loss-2.1163, acc-0.4190, test loss-2.1019, acc-0.4309\n",
      "Iter-25910, train loss-2.1390, acc-0.3200, valid loss-2.1162, acc-0.4192, test loss-2.1018, acc-0.4312\n",
      "Iter-25920, train loss-2.1458, acc-0.4000, valid loss-2.1161, acc-0.4194, test loss-2.1018, acc-0.4313\n",
      "Iter-25930, train loss-2.0648, acc-0.5400, valid loss-2.1161, acc-0.4192, test loss-2.1017, acc-0.4311\n",
      "Iter-25940, train loss-2.1085, acc-0.4000, valid loss-2.1160, acc-0.4198, test loss-2.1016, acc-0.4313\n",
      "Iter-25950, train loss-2.0690, acc-0.5000, valid loss-2.1160, acc-0.4198, test loss-2.1016, acc-0.4311\n",
      "Iter-25960, train loss-2.1376, acc-0.4000, valid loss-2.1159, acc-0.4198, test loss-2.1015, acc-0.4313\n",
      "Iter-25970, train loss-2.1117, acc-0.5000, valid loss-2.1159, acc-0.4200, test loss-2.1015, acc-0.4315\n",
      "Iter-25980, train loss-2.1195, acc-0.4600, valid loss-2.1158, acc-0.4202, test loss-2.1014, acc-0.4314\n",
      "Iter-25990, train loss-2.1215, acc-0.3800, valid loss-2.1158, acc-0.4200, test loss-2.1013, acc-0.4315\n",
      "Iter-26000, train loss-2.0703, acc-0.4600, valid loss-2.1157, acc-0.4200, test loss-2.1013, acc-0.4315\n",
      "Iter-26010, train loss-2.1161, acc-0.4200, valid loss-2.1156, acc-0.4202, test loss-2.1012, acc-0.4315\n",
      "Iter-26020, train loss-2.0893, acc-0.4600, valid loss-2.1156, acc-0.4202, test loss-2.1012, acc-0.4314\n",
      "Iter-26030, train loss-2.1220, acc-0.4400, valid loss-2.1155, acc-0.4206, test loss-2.1011, acc-0.4315\n",
      "Iter-26040, train loss-2.1003, acc-0.3800, valid loss-2.1155, acc-0.4206, test loss-2.1010, acc-0.4313\n",
      "Iter-26050, train loss-2.1251, acc-0.4600, valid loss-2.1154, acc-0.4208, test loss-2.1010, acc-0.4318\n",
      "Iter-26060, train loss-2.1230, acc-0.3400, valid loss-2.1154, acc-0.4208, test loss-2.1009, acc-0.4319\n",
      "Iter-26070, train loss-2.0762, acc-0.3600, valid loss-2.1153, acc-0.4208, test loss-2.1009, acc-0.4319\n",
      "Iter-26080, train loss-2.1092, acc-0.4200, valid loss-2.1153, acc-0.4208, test loss-2.1008, acc-0.4319\n",
      "Iter-26090, train loss-2.1130, acc-0.4600, valid loss-2.1152, acc-0.4206, test loss-2.1007, acc-0.4319\n",
      "Iter-26100, train loss-2.1542, acc-0.3800, valid loss-2.1151, acc-0.4208, test loss-2.1007, acc-0.4319\n",
      "Iter-26110, train loss-2.0899, acc-0.4800, valid loss-2.1151, acc-0.4204, test loss-2.1006, acc-0.4320\n",
      "Iter-26120, train loss-2.0981, acc-0.4400, valid loss-2.1150, acc-0.4204, test loss-2.1005, acc-0.4321\n",
      "Iter-26130, train loss-2.1131, acc-0.3000, valid loss-2.1150, acc-0.4198, test loss-2.1005, acc-0.4318\n",
      "Iter-26140, train loss-2.1189, acc-0.4000, valid loss-2.1149, acc-0.4202, test loss-2.1004, acc-0.4319\n",
      "Iter-26150, train loss-2.1192, acc-0.3800, valid loss-2.1149, acc-0.4202, test loss-2.1004, acc-0.4318\n",
      "Iter-26160, train loss-2.1126, acc-0.4600, valid loss-2.1148, acc-0.4206, test loss-2.1003, acc-0.4320\n",
      "Iter-26170, train loss-2.0963, acc-0.4600, valid loss-2.1148, acc-0.4204, test loss-2.1002, acc-0.4320\n",
      "Iter-26180, train loss-2.1002, acc-0.4200, valid loss-2.1147, acc-0.4204, test loss-2.1002, acc-0.4321\n",
      "Iter-26190, train loss-2.1042, acc-0.4400, valid loss-2.1146, acc-0.4202, test loss-2.1001, acc-0.4320\n",
      "Iter-26200, train loss-2.1003, acc-0.3800, valid loss-2.1146, acc-0.4204, test loss-2.1001, acc-0.4322\n",
      "Iter-26210, train loss-2.0739, acc-0.5400, valid loss-2.1145, acc-0.4208, test loss-2.1000, acc-0.4321\n",
      "Iter-26220, train loss-2.0791, acc-0.4400, valid loss-2.1145, acc-0.4206, test loss-2.0999, acc-0.4321\n",
      "Iter-26230, train loss-2.1249, acc-0.2400, valid loss-2.1144, acc-0.4210, test loss-2.0999, acc-0.4321\n",
      "Iter-26240, train loss-2.0966, acc-0.4000, valid loss-2.1144, acc-0.4206, test loss-2.0998, acc-0.4322\n",
      "Iter-26250, train loss-2.0948, acc-0.4600, valid loss-2.1143, acc-0.4204, test loss-2.0997, acc-0.4322\n",
      "Iter-26260, train loss-2.1167, acc-0.4000, valid loss-2.1142, acc-0.4204, test loss-2.0997, acc-0.4324\n",
      "Iter-26270, train loss-2.0953, acc-0.4400, valid loss-2.1142, acc-0.4202, test loss-2.0996, acc-0.4325\n",
      "Iter-26280, train loss-2.1369, acc-0.3200, valid loss-2.1141, acc-0.4206, test loss-2.0996, acc-0.4325\n",
      "Iter-26290, train loss-2.1254, acc-0.3400, valid loss-2.1141, acc-0.4204, test loss-2.0995, acc-0.4326\n",
      "Iter-26300, train loss-2.0786, acc-0.5600, valid loss-2.1140, acc-0.4204, test loss-2.0994, acc-0.4323\n",
      "Iter-26310, train loss-2.1351, acc-0.3800, valid loss-2.1140, acc-0.4206, test loss-2.0994, acc-0.4323\n",
      "Iter-26320, train loss-2.1712, acc-0.3000, valid loss-2.1139, acc-0.4208, test loss-2.0993, acc-0.4328\n",
      "Iter-26330, train loss-2.1267, acc-0.3200, valid loss-2.1138, acc-0.4208, test loss-2.0992, acc-0.4327\n",
      "Iter-26340, train loss-2.0862, acc-0.4800, valid loss-2.1138, acc-0.4208, test loss-2.0992, acc-0.4328\n",
      "Iter-26350, train loss-2.0784, acc-0.5000, valid loss-2.1137, acc-0.4210, test loss-2.0991, acc-0.4327\n",
      "Iter-26360, train loss-2.0813, acc-0.5000, valid loss-2.1137, acc-0.4212, test loss-2.0990, acc-0.4329\n",
      "Iter-26370, train loss-2.1016, acc-0.3000, valid loss-2.1136, acc-0.4214, test loss-2.0990, acc-0.4334\n",
      "Iter-26380, train loss-2.1156, acc-0.4000, valid loss-2.1136, acc-0.4212, test loss-2.0989, acc-0.4335\n",
      "Iter-26390, train loss-2.0851, acc-0.4200, valid loss-2.1135, acc-0.4214, test loss-2.0989, acc-0.4332\n",
      "Iter-26400, train loss-2.1092, acc-0.4000, valid loss-2.1134, acc-0.4216, test loss-2.0988, acc-0.4330\n",
      "Iter-26410, train loss-2.1199, acc-0.4000, valid loss-2.1134, acc-0.4216, test loss-2.0987, acc-0.4332\n",
      "Iter-26420, train loss-2.1009, acc-0.4800, valid loss-2.1133, acc-0.4216, test loss-2.0987, acc-0.4331\n",
      "Iter-26430, train loss-2.1314, acc-0.3200, valid loss-2.1133, acc-0.4220, test loss-2.0986, acc-0.4333\n",
      "Iter-26440, train loss-2.1118, acc-0.3800, valid loss-2.1132, acc-0.4218, test loss-2.0985, acc-0.4333\n",
      "Iter-26450, train loss-2.1165, acc-0.3800, valid loss-2.1132, acc-0.4218, test loss-2.0985, acc-0.4334\n",
      "Iter-26460, train loss-2.1367, acc-0.3600, valid loss-2.1131, acc-0.4216, test loss-2.0984, acc-0.4335\n",
      "Iter-26470, train loss-2.0725, acc-0.4200, valid loss-2.1130, acc-0.4214, test loss-2.0984, acc-0.4333\n",
      "Iter-26480, train loss-2.0843, acc-0.4400, valid loss-2.1130, acc-0.4210, test loss-2.0983, acc-0.4338\n",
      "Iter-26490, train loss-2.1069, acc-0.4000, valid loss-2.1129, acc-0.4214, test loss-2.0982, acc-0.4339\n",
      "Iter-26500, train loss-2.1154, acc-0.5000, valid loss-2.1129, acc-0.4212, test loss-2.0982, acc-0.4338\n",
      "Iter-26510, train loss-2.0911, acc-0.5400, valid loss-2.1128, acc-0.4210, test loss-2.0981, acc-0.4340\n",
      "Iter-26520, train loss-2.1925, acc-0.2200, valid loss-2.1128, acc-0.4210, test loss-2.0981, acc-0.4340\n",
      "Iter-26530, train loss-2.0731, acc-0.5000, valid loss-2.1127, acc-0.4214, test loss-2.0980, acc-0.4339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-26540, train loss-2.1050, acc-0.4200, valid loss-2.1127, acc-0.4216, test loss-2.0979, acc-0.4341\n",
      "Iter-26550, train loss-2.0726, acc-0.4200, valid loss-2.1126, acc-0.4218, test loss-2.0979, acc-0.4338\n",
      "Iter-26560, train loss-2.1107, acc-0.4000, valid loss-2.1125, acc-0.4218, test loss-2.0978, acc-0.4338\n",
      "Iter-26570, train loss-2.1389, acc-0.3000, valid loss-2.1125, acc-0.4218, test loss-2.0977, acc-0.4341\n",
      "Iter-26580, train loss-2.0586, acc-0.5400, valid loss-2.1124, acc-0.4218, test loss-2.0977, acc-0.4342\n",
      "Iter-26590, train loss-2.1186, acc-0.3800, valid loss-2.1124, acc-0.4218, test loss-2.0976, acc-0.4342\n",
      "Iter-26600, train loss-2.0533, acc-0.5400, valid loss-2.1123, acc-0.4216, test loss-2.0976, acc-0.4341\n",
      "Iter-26610, train loss-2.1154, acc-0.3800, valid loss-2.1123, acc-0.4218, test loss-2.0975, acc-0.4342\n",
      "Iter-26620, train loss-2.1135, acc-0.3400, valid loss-2.1122, acc-0.4212, test loss-2.0974, acc-0.4342\n",
      "Iter-26630, train loss-2.0854, acc-0.4200, valid loss-2.1121, acc-0.4216, test loss-2.0974, acc-0.4340\n",
      "Iter-26640, train loss-2.0820, acc-0.4000, valid loss-2.1121, acc-0.4220, test loss-2.0973, acc-0.4338\n",
      "Iter-26650, train loss-2.1039, acc-0.4800, valid loss-2.1120, acc-0.4218, test loss-2.0972, acc-0.4338\n",
      "Iter-26660, train loss-2.1130, acc-0.4600, valid loss-2.1120, acc-0.4216, test loss-2.0972, acc-0.4338\n",
      "Iter-26670, train loss-2.0872, acc-0.4000, valid loss-2.1119, acc-0.4216, test loss-2.0971, acc-0.4339\n",
      "Iter-26680, train loss-2.1136, acc-0.4200, valid loss-2.1119, acc-0.4214, test loss-2.0971, acc-0.4341\n",
      "Iter-26690, train loss-2.1170, acc-0.3800, valid loss-2.1118, acc-0.4218, test loss-2.0970, acc-0.4341\n",
      "Iter-26700, train loss-2.1134, acc-0.4200, valid loss-2.1117, acc-0.4214, test loss-2.0969, acc-0.4339\n",
      "Iter-26710, train loss-2.0712, acc-0.5200, valid loss-2.1117, acc-0.4212, test loss-2.0969, acc-0.4340\n",
      "Iter-26720, train loss-2.1266, acc-0.3600, valid loss-2.1116, acc-0.4216, test loss-2.0968, acc-0.4342\n",
      "Iter-26730, train loss-2.1296, acc-0.3400, valid loss-2.1116, acc-0.4216, test loss-2.0968, acc-0.4342\n",
      "Iter-26740, train loss-2.0846, acc-0.4000, valid loss-2.1115, acc-0.4214, test loss-2.0967, acc-0.4344\n",
      "Iter-26750, train loss-2.1386, acc-0.3800, valid loss-2.1115, acc-0.4214, test loss-2.0966, acc-0.4342\n",
      "Iter-26760, train loss-2.0985, acc-0.4800, valid loss-2.1114, acc-0.4216, test loss-2.0966, acc-0.4343\n",
      "Iter-26770, train loss-2.1058, acc-0.3800, valid loss-2.1114, acc-0.4218, test loss-2.0965, acc-0.4351\n",
      "Iter-26780, train loss-2.0847, acc-0.4400, valid loss-2.1113, acc-0.4220, test loss-2.0965, acc-0.4347\n",
      "Iter-26790, train loss-2.1157, acc-0.3400, valid loss-2.1113, acc-0.4220, test loss-2.0964, acc-0.4346\n",
      "Iter-26800, train loss-2.1328, acc-0.3600, valid loss-2.1112, acc-0.4220, test loss-2.0963, acc-0.4347\n",
      "Iter-26810, train loss-2.0685, acc-0.4000, valid loss-2.1112, acc-0.4222, test loss-2.0963, acc-0.4348\n",
      "Iter-26820, train loss-2.1142, acc-0.3800, valid loss-2.1111, acc-0.4226, test loss-2.0962, acc-0.4347\n",
      "Iter-26830, train loss-2.0756, acc-0.4800, valid loss-2.1110, acc-0.4228, test loss-2.0962, acc-0.4345\n",
      "Iter-26840, train loss-2.0404, acc-0.4800, valid loss-2.1110, acc-0.4234, test loss-2.0961, acc-0.4346\n",
      "Iter-26850, train loss-2.0914, acc-0.4400, valid loss-2.1109, acc-0.4230, test loss-2.0960, acc-0.4349\n",
      "Iter-26860, train loss-2.1630, acc-0.3800, valid loss-2.1109, acc-0.4224, test loss-2.0960, acc-0.4351\n",
      "Iter-26870, train loss-2.1143, acc-0.3000, valid loss-2.1108, acc-0.4224, test loss-2.0959, acc-0.4351\n",
      "Iter-26880, train loss-2.1139, acc-0.4200, valid loss-2.1108, acc-0.4222, test loss-2.0958, acc-0.4352\n",
      "Iter-26890, train loss-2.0817, acc-0.3600, valid loss-2.1107, acc-0.4226, test loss-2.0958, acc-0.4352\n",
      "Iter-26900, train loss-2.1171, acc-0.3800, valid loss-2.1106, acc-0.4226, test loss-2.0957, acc-0.4354\n",
      "Iter-26910, train loss-2.1155, acc-0.3800, valid loss-2.1106, acc-0.4228, test loss-2.0957, acc-0.4354\n",
      "Iter-26920, train loss-2.0855, acc-0.4600, valid loss-2.1105, acc-0.4226, test loss-2.0956, acc-0.4357\n",
      "Iter-26930, train loss-2.0914, acc-0.4000, valid loss-2.1105, acc-0.4224, test loss-2.0955, acc-0.4356\n",
      "Iter-26940, train loss-2.1657, acc-0.3000, valid loss-2.1104, acc-0.4228, test loss-2.0955, acc-0.4355\n",
      "Iter-26950, train loss-2.0945, acc-0.3800, valid loss-2.1104, acc-0.4236, test loss-2.0954, acc-0.4356\n",
      "Iter-26960, train loss-2.1653, acc-0.3400, valid loss-2.1103, acc-0.4234, test loss-2.0954, acc-0.4355\n",
      "Iter-26970, train loss-2.1050, acc-0.3800, valid loss-2.1103, acc-0.4232, test loss-2.0953, acc-0.4353\n",
      "Iter-26980, train loss-2.0709, acc-0.5000, valid loss-2.1102, acc-0.4232, test loss-2.0952, acc-0.4354\n",
      "Iter-26990, train loss-2.0893, acc-0.4200, valid loss-2.1102, acc-0.4234, test loss-2.0952, acc-0.4356\n",
      "Iter-27000, train loss-2.0897, acc-0.4200, valid loss-2.1101, acc-0.4228, test loss-2.0951, acc-0.4358\n",
      "Iter-27010, train loss-2.1360, acc-0.3800, valid loss-2.1101, acc-0.4230, test loss-2.0951, acc-0.4355\n",
      "Iter-27020, train loss-2.0752, acc-0.4000, valid loss-2.1100, acc-0.4234, test loss-2.0950, acc-0.4357\n",
      "Iter-27030, train loss-2.1570, acc-0.3800, valid loss-2.1099, acc-0.4236, test loss-2.0949, acc-0.4355\n",
      "Iter-27040, train loss-2.1264, acc-0.4000, valid loss-2.1099, acc-0.4238, test loss-2.0949, acc-0.4358\n",
      "Iter-27050, train loss-2.1106, acc-0.3800, valid loss-2.1098, acc-0.4238, test loss-2.0948, acc-0.4359\n",
      "Iter-27060, train loss-2.1341, acc-0.3600, valid loss-2.1098, acc-0.4240, test loss-2.0947, acc-0.4360\n",
      "Iter-27070, train loss-2.0885, acc-0.4800, valid loss-2.1097, acc-0.4242, test loss-2.0947, acc-0.4361\n",
      "Iter-27080, train loss-2.0736, acc-0.5200, valid loss-2.1096, acc-0.4240, test loss-2.0946, acc-0.4358\n",
      "Iter-27090, train loss-2.1432, acc-0.4000, valid loss-2.1096, acc-0.4238, test loss-2.0946, acc-0.4357\n",
      "Iter-27100, train loss-2.0679, acc-0.5600, valid loss-2.1095, acc-0.4240, test loss-2.0945, acc-0.4358\n",
      "Iter-27110, train loss-2.0951, acc-0.4000, valid loss-2.1095, acc-0.4238, test loss-2.0944, acc-0.4359\n",
      "Iter-27120, train loss-2.1180, acc-0.4400, valid loss-2.1094, acc-0.4240, test loss-2.0944, acc-0.4360\n",
      "Iter-27130, train loss-2.1356, acc-0.2400, valid loss-2.1094, acc-0.4242, test loss-2.0943, acc-0.4361\n",
      "Iter-27140, train loss-2.1077, acc-0.4400, valid loss-2.1093, acc-0.4240, test loss-2.0943, acc-0.4363\n",
      "Iter-27150, train loss-2.1251, acc-0.4400, valid loss-2.1093, acc-0.4240, test loss-2.0942, acc-0.4362\n",
      "Iter-27160, train loss-2.1275, acc-0.4200, valid loss-2.1092, acc-0.4244, test loss-2.0941, acc-0.4361\n",
      "Iter-27170, train loss-2.0828, acc-0.4400, valid loss-2.1092, acc-0.4246, test loss-2.0941, acc-0.4364\n",
      "Iter-27180, train loss-2.0649, acc-0.4400, valid loss-2.1091, acc-0.4250, test loss-2.0940, acc-0.4367\n",
      "Iter-27190, train loss-2.0858, acc-0.5000, valid loss-2.1090, acc-0.4254, test loss-2.0940, acc-0.4371\n",
      "Iter-27200, train loss-2.0980, acc-0.3800, valid loss-2.1090, acc-0.4252, test loss-2.0939, acc-0.4368\n",
      "Iter-27210, train loss-2.0938, acc-0.4000, valid loss-2.1089, acc-0.4254, test loss-2.0938, acc-0.4369\n",
      "Iter-27220, train loss-2.0273, acc-0.5800, valid loss-2.1089, acc-0.4252, test loss-2.0938, acc-0.4367\n",
      "Iter-27230, train loss-2.1369, acc-0.3400, valid loss-2.1088, acc-0.4250, test loss-2.0937, acc-0.4367\n",
      "Iter-27240, train loss-2.1084, acc-0.4400, valid loss-2.1088, acc-0.4252, test loss-2.0937, acc-0.4371\n",
      "Iter-27250, train loss-2.0750, acc-0.5400, valid loss-2.1087, acc-0.4250, test loss-2.0936, acc-0.4371\n",
      "Iter-27260, train loss-2.0794, acc-0.4800, valid loss-2.1087, acc-0.4252, test loss-2.0935, acc-0.4372\n",
      "Iter-27270, train loss-2.0635, acc-0.4600, valid loss-2.1086, acc-0.4256, test loss-2.0935, acc-0.4373\n",
      "Iter-27280, train loss-2.0722, acc-0.5000, valid loss-2.1086, acc-0.4254, test loss-2.0934, acc-0.4373\n",
      "Iter-27290, train loss-2.1060, acc-0.4600, valid loss-2.1085, acc-0.4256, test loss-2.0933, acc-0.4374\n",
      "Iter-27300, train loss-2.1204, acc-0.4000, valid loss-2.1084, acc-0.4252, test loss-2.0933, acc-0.4375\n",
      "Iter-27310, train loss-2.1099, acc-0.3600, valid loss-2.1084, acc-0.4256, test loss-2.0932, acc-0.4375\n",
      "Iter-27320, train loss-2.0895, acc-0.4600, valid loss-2.1083, acc-0.4254, test loss-2.0932, acc-0.4375\n",
      "Iter-27330, train loss-2.0795, acc-0.5400, valid loss-2.1083, acc-0.4258, test loss-2.0931, acc-0.4374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-27340, train loss-2.1079, acc-0.4200, valid loss-2.1082, acc-0.4260, test loss-2.0930, acc-0.4373\n",
      "Iter-27350, train loss-2.1169, acc-0.4200, valid loss-2.1082, acc-0.4260, test loss-2.0930, acc-0.4376\n",
      "Iter-27360, train loss-2.0969, acc-0.3600, valid loss-2.1081, acc-0.4264, test loss-2.0929, acc-0.4377\n",
      "Iter-27370, train loss-2.1263, acc-0.3400, valid loss-2.1081, acc-0.4262, test loss-2.0929, acc-0.4379\n",
      "Iter-27380, train loss-2.0933, acc-0.4400, valid loss-2.1080, acc-0.4264, test loss-2.0928, acc-0.4378\n",
      "Iter-27390, train loss-2.0910, acc-0.4400, valid loss-2.1080, acc-0.4260, test loss-2.0927, acc-0.4379\n",
      "Iter-27400, train loss-2.0526, acc-0.4600, valid loss-2.1079, acc-0.4262, test loss-2.0927, acc-0.4379\n",
      "Iter-27410, train loss-2.1585, acc-0.3200, valid loss-2.1078, acc-0.4262, test loss-2.0926, acc-0.4379\n",
      "Iter-27420, train loss-2.0892, acc-0.4200, valid loss-2.1078, acc-0.4264, test loss-2.0925, acc-0.4380\n",
      "Iter-27430, train loss-2.1416, acc-0.4000, valid loss-2.1077, acc-0.4264, test loss-2.0925, acc-0.4382\n",
      "Iter-27440, train loss-2.1277, acc-0.3600, valid loss-2.1077, acc-0.4266, test loss-2.0924, acc-0.4380\n",
      "Iter-27450, train loss-2.0478, acc-0.5600, valid loss-2.1076, acc-0.4262, test loss-2.0924, acc-0.4384\n",
      "Iter-27460, train loss-2.1023, acc-0.4600, valid loss-2.1076, acc-0.4268, test loss-2.0923, acc-0.4383\n",
      "Iter-27470, train loss-2.0372, acc-0.6200, valid loss-2.1075, acc-0.4268, test loss-2.0923, acc-0.4383\n",
      "Iter-27480, train loss-2.0580, acc-0.4600, valid loss-2.1075, acc-0.4264, test loss-2.0922, acc-0.4380\n",
      "Iter-27490, train loss-2.0967, acc-0.4200, valid loss-2.1074, acc-0.4266, test loss-2.0921, acc-0.4382\n",
      "Iter-27500, train loss-2.1048, acc-0.5600, valid loss-2.1074, acc-0.4268, test loss-2.0921, acc-0.4382\n",
      "Iter-27510, train loss-2.1713, acc-0.3200, valid loss-2.1073, acc-0.4270, test loss-2.0920, acc-0.4384\n",
      "Iter-27520, train loss-2.0652, acc-0.5400, valid loss-2.1072, acc-0.4270, test loss-2.0919, acc-0.4382\n",
      "Iter-27530, train loss-2.0861, acc-0.4200, valid loss-2.1072, acc-0.4272, test loss-2.0919, acc-0.4382\n",
      "Iter-27540, train loss-2.1121, acc-0.4800, valid loss-2.1071, acc-0.4276, test loss-2.0918, acc-0.4382\n",
      "Iter-27550, train loss-2.0473, acc-0.5000, valid loss-2.1071, acc-0.4274, test loss-2.0918, acc-0.4381\n",
      "Iter-27560, train loss-2.1434, acc-0.3600, valid loss-2.1070, acc-0.4278, test loss-2.0917, acc-0.4381\n",
      "Iter-27570, train loss-2.0708, acc-0.5400, valid loss-2.1070, acc-0.4278, test loss-2.0916, acc-0.4383\n",
      "Iter-27580, train loss-2.0735, acc-0.4800, valid loss-2.1069, acc-0.4274, test loss-2.0916, acc-0.4383\n",
      "Iter-27590, train loss-2.0927, acc-0.4800, valid loss-2.1069, acc-0.4274, test loss-2.0915, acc-0.4382\n",
      "Iter-27600, train loss-2.1145, acc-0.4000, valid loss-2.1068, acc-0.4274, test loss-2.0915, acc-0.4382\n",
      "Iter-27610, train loss-2.0587, acc-0.4400, valid loss-2.1068, acc-0.4274, test loss-2.0914, acc-0.4382\n",
      "Iter-27620, train loss-2.1159, acc-0.4200, valid loss-2.1067, acc-0.4276, test loss-2.0913, acc-0.4383\n",
      "Iter-27630, train loss-2.0323, acc-0.5200, valid loss-2.1067, acc-0.4274, test loss-2.0913, acc-0.4381\n",
      "Iter-27640, train loss-2.0954, acc-0.4600, valid loss-2.1066, acc-0.4278, test loss-2.0912, acc-0.4381\n",
      "Iter-27650, train loss-2.0858, acc-0.4000, valid loss-2.1065, acc-0.4278, test loss-2.0912, acc-0.4381\n",
      "Iter-27660, train loss-2.1058, acc-0.3600, valid loss-2.1065, acc-0.4280, test loss-2.0911, acc-0.4384\n",
      "Iter-27670, train loss-2.0976, acc-0.4800, valid loss-2.1064, acc-0.4276, test loss-2.0910, acc-0.4385\n",
      "Iter-27680, train loss-2.1327, acc-0.3200, valid loss-2.1064, acc-0.4278, test loss-2.0910, acc-0.4383\n",
      "Iter-27690, train loss-2.1257, acc-0.3400, valid loss-2.1063, acc-0.4280, test loss-2.0909, acc-0.4385\n",
      "Iter-27700, train loss-2.0766, acc-0.4000, valid loss-2.1063, acc-0.4280, test loss-2.0909, acc-0.4382\n",
      "Iter-27710, train loss-2.1044, acc-0.4200, valid loss-2.1062, acc-0.4282, test loss-2.0908, acc-0.4384\n",
      "Iter-27720, train loss-2.1217, acc-0.3600, valid loss-2.1062, acc-0.4276, test loss-2.0907, acc-0.4384\n",
      "Iter-27730, train loss-2.0765, acc-0.4200, valid loss-2.1061, acc-0.4280, test loss-2.0907, acc-0.4382\n",
      "Iter-27740, train loss-2.1183, acc-0.4400, valid loss-2.1060, acc-0.4278, test loss-2.0906, acc-0.4382\n",
      "Iter-27750, train loss-2.0940, acc-0.5000, valid loss-2.1060, acc-0.4278, test loss-2.0905, acc-0.4384\n",
      "Iter-27760, train loss-2.1387, acc-0.3400, valid loss-2.1059, acc-0.4278, test loss-2.0905, acc-0.4383\n",
      "Iter-27770, train loss-2.0714, acc-0.5600, valid loss-2.1059, acc-0.4280, test loss-2.0904, acc-0.4383\n",
      "Iter-27780, train loss-2.1208, acc-0.3800, valid loss-2.1058, acc-0.4280, test loss-2.0904, acc-0.4385\n",
      "Iter-27790, train loss-2.0476, acc-0.5800, valid loss-2.1058, acc-0.4276, test loss-2.0903, acc-0.4386\n",
      "Iter-27800, train loss-2.0966, acc-0.4400, valid loss-2.1057, acc-0.4276, test loss-2.0902, acc-0.4386\n",
      "Iter-27810, train loss-2.1159, acc-0.3400, valid loss-2.1057, acc-0.4276, test loss-2.0902, acc-0.4386\n",
      "Iter-27820, train loss-2.0951, acc-0.4200, valid loss-2.1056, acc-0.4280, test loss-2.0901, acc-0.4387\n",
      "Iter-27830, train loss-2.0729, acc-0.4800, valid loss-2.1055, acc-0.4278, test loss-2.0901, acc-0.4387\n",
      "Iter-27840, train loss-2.1077, acc-0.3200, valid loss-2.1055, acc-0.4280, test loss-2.0900, acc-0.4386\n",
      "Iter-27850, train loss-2.0936, acc-0.4400, valid loss-2.1054, acc-0.4280, test loss-2.0899, acc-0.4385\n",
      "Iter-27860, train loss-2.1432, acc-0.4400, valid loss-2.1054, acc-0.4284, test loss-2.0899, acc-0.4388\n",
      "Iter-27870, train loss-2.0991, acc-0.3800, valid loss-2.1053, acc-0.4284, test loss-2.0898, acc-0.4386\n",
      "Iter-27880, train loss-2.0351, acc-0.5200, valid loss-2.1053, acc-0.4286, test loss-2.0898, acc-0.4387\n",
      "Iter-27890, train loss-2.1273, acc-0.3600, valid loss-2.1052, acc-0.4288, test loss-2.0897, acc-0.4389\n",
      "Iter-27900, train loss-2.0952, acc-0.2600, valid loss-2.1052, acc-0.4286, test loss-2.0896, acc-0.4389\n",
      "Iter-27910, train loss-1.9933, acc-0.6000, valid loss-2.1051, acc-0.4288, test loss-2.0896, acc-0.4390\n",
      "Iter-27920, train loss-2.1312, acc-0.3400, valid loss-2.1051, acc-0.4288, test loss-2.0895, acc-0.4391\n",
      "Iter-27930, train loss-2.1021, acc-0.4000, valid loss-2.1050, acc-0.4282, test loss-2.0895, acc-0.4390\n",
      "Iter-27940, train loss-2.0275, acc-0.5000, valid loss-2.1049, acc-0.4286, test loss-2.0894, acc-0.4389\n",
      "Iter-27950, train loss-2.1199, acc-0.4200, valid loss-2.1049, acc-0.4288, test loss-2.0893, acc-0.4388\n",
      "Iter-27960, train loss-2.0985, acc-0.5000, valid loss-2.1048, acc-0.4286, test loss-2.0893, acc-0.4389\n",
      "Iter-27970, train loss-2.0647, acc-0.5200, valid loss-2.1048, acc-0.4286, test loss-2.0892, acc-0.4389\n",
      "Iter-27980, train loss-2.0766, acc-0.5400, valid loss-2.1047, acc-0.4288, test loss-2.0892, acc-0.4389\n",
      "Iter-27990, train loss-2.0955, acc-0.3400, valid loss-2.1047, acc-0.4288, test loss-2.0891, acc-0.4391\n",
      "Iter-28000, train loss-2.0779, acc-0.3800, valid loss-2.1046, acc-0.4288, test loss-2.0890, acc-0.4390\n",
      "Iter-28010, train loss-2.0228, acc-0.5600, valid loss-2.1046, acc-0.4286, test loss-2.0890, acc-0.4391\n",
      "Iter-28020, train loss-2.0528, acc-0.4600, valid loss-2.1045, acc-0.4286, test loss-2.0889, acc-0.4391\n",
      "Iter-28030, train loss-2.0971, acc-0.4400, valid loss-2.1045, acc-0.4288, test loss-2.0889, acc-0.4392\n",
      "Iter-28040, train loss-2.0637, acc-0.4400, valid loss-2.1044, acc-0.4288, test loss-2.0888, acc-0.4394\n",
      "Iter-28050, train loss-2.1047, acc-0.4200, valid loss-2.1043, acc-0.4288, test loss-2.0887, acc-0.4393\n",
      "Iter-28060, train loss-2.1172, acc-0.4600, valid loss-2.1043, acc-0.4290, test loss-2.0887, acc-0.4393\n",
      "Iter-28070, train loss-2.0696, acc-0.5000, valid loss-2.1042, acc-0.4288, test loss-2.0886, acc-0.4394\n",
      "Iter-28080, train loss-2.0727, acc-0.5600, valid loss-2.1042, acc-0.4288, test loss-2.0885, acc-0.4395\n",
      "Iter-28090, train loss-2.1044, acc-0.4000, valid loss-2.1041, acc-0.4288, test loss-2.0885, acc-0.4395\n",
      "Iter-28100, train loss-2.0530, acc-0.5400, valid loss-2.1041, acc-0.4288, test loss-2.0884, acc-0.4394\n",
      "Iter-28110, train loss-2.0827, acc-0.5000, valid loss-2.1040, acc-0.4286, test loss-2.0884, acc-0.4395\n",
      "Iter-28120, train loss-2.0929, acc-0.3400, valid loss-2.1040, acc-0.4286, test loss-2.0883, acc-0.4395\n",
      "Iter-28130, train loss-2.0945, acc-0.4800, valid loss-2.1039, acc-0.4286, test loss-2.0882, acc-0.4396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-28140, train loss-2.0934, acc-0.4800, valid loss-2.1039, acc-0.4292, test loss-2.0882, acc-0.4397\n",
      "Iter-28150, train loss-2.1170, acc-0.4200, valid loss-2.1038, acc-0.4286, test loss-2.0881, acc-0.4395\n",
      "Iter-28160, train loss-2.0994, acc-0.4200, valid loss-2.1037, acc-0.4290, test loss-2.0881, acc-0.4398\n",
      "Iter-28170, train loss-2.1033, acc-0.4400, valid loss-2.1037, acc-0.4286, test loss-2.0880, acc-0.4400\n",
      "Iter-28180, train loss-2.0752, acc-0.4800, valid loss-2.1036, acc-0.4286, test loss-2.0880, acc-0.4399\n",
      "Iter-28190, train loss-2.0876, acc-0.4000, valid loss-2.1036, acc-0.4288, test loss-2.0879, acc-0.4399\n",
      "Iter-28200, train loss-2.0905, acc-0.5400, valid loss-2.1035, acc-0.4288, test loss-2.0878, acc-0.4399\n",
      "Iter-28210, train loss-2.0214, acc-0.5400, valid loss-2.1035, acc-0.4288, test loss-2.0878, acc-0.4399\n",
      "Iter-28220, train loss-2.0882, acc-0.4600, valid loss-2.1034, acc-0.4292, test loss-2.0877, acc-0.4397\n",
      "Iter-28230, train loss-2.1140, acc-0.3200, valid loss-2.1034, acc-0.4294, test loss-2.0877, acc-0.4399\n",
      "Iter-28240, train loss-2.0706, acc-0.4400, valid loss-2.1033, acc-0.4288, test loss-2.0876, acc-0.4400\n",
      "Iter-28250, train loss-2.1064, acc-0.4600, valid loss-2.1033, acc-0.4290, test loss-2.0875, acc-0.4401\n",
      "Iter-28260, train loss-2.0797, acc-0.3800, valid loss-2.1032, acc-0.4290, test loss-2.0875, acc-0.4402\n",
      "Iter-28270, train loss-2.1146, acc-0.3400, valid loss-2.1031, acc-0.4290, test loss-2.0874, acc-0.4400\n",
      "Iter-28280, train loss-2.0953, acc-0.4400, valid loss-2.1031, acc-0.4292, test loss-2.0874, acc-0.4406\n",
      "Iter-28290, train loss-2.0768, acc-0.4600, valid loss-2.1030, acc-0.4294, test loss-2.0873, acc-0.4406\n",
      "Iter-28300, train loss-2.1183, acc-0.4400, valid loss-2.1030, acc-0.4294, test loss-2.0872, acc-0.4404\n",
      "Iter-28310, train loss-2.0723, acc-0.4600, valid loss-2.1029, acc-0.4298, test loss-2.0872, acc-0.4408\n",
      "Iter-28320, train loss-2.1047, acc-0.3400, valid loss-2.1029, acc-0.4294, test loss-2.0871, acc-0.4407\n",
      "Iter-28330, train loss-2.0958, acc-0.5000, valid loss-2.1028, acc-0.4294, test loss-2.0871, acc-0.4407\n",
      "Iter-28340, train loss-2.0871, acc-0.4000, valid loss-2.1028, acc-0.4296, test loss-2.0870, acc-0.4408\n",
      "Iter-28350, train loss-2.1323, acc-0.3600, valid loss-2.1027, acc-0.4296, test loss-2.0869, acc-0.4409\n",
      "Iter-28360, train loss-2.0659, acc-0.4800, valid loss-2.1027, acc-0.4296, test loss-2.0869, acc-0.4409\n",
      "Iter-28370, train loss-2.1020, acc-0.3800, valid loss-2.1026, acc-0.4296, test loss-2.0868, acc-0.4409\n",
      "Iter-28380, train loss-2.1136, acc-0.3800, valid loss-2.1026, acc-0.4296, test loss-2.0868, acc-0.4409\n",
      "Iter-28390, train loss-2.0233, acc-0.4400, valid loss-2.1025, acc-0.4298, test loss-2.0867, acc-0.4410\n",
      "Iter-28400, train loss-2.0743, acc-0.5600, valid loss-2.1024, acc-0.4298, test loss-2.0866, acc-0.4410\n",
      "Iter-28410, train loss-2.0935, acc-0.4000, valid loss-2.1024, acc-0.4298, test loss-2.0866, acc-0.4408\n",
      "Iter-28420, train loss-2.0488, acc-0.4800, valid loss-2.1023, acc-0.4300, test loss-2.0865, acc-0.4409\n",
      "Iter-28430, train loss-2.0845, acc-0.4400, valid loss-2.1023, acc-0.4298, test loss-2.0865, acc-0.4408\n",
      "Iter-28440, train loss-2.0995, acc-0.3600, valid loss-2.1022, acc-0.4298, test loss-2.0864, acc-0.4407\n",
      "Iter-28450, train loss-2.0762, acc-0.3800, valid loss-2.1022, acc-0.4304, test loss-2.0863, acc-0.4408\n",
      "Iter-28460, train loss-2.1094, acc-0.4800, valid loss-2.1021, acc-0.4298, test loss-2.0863, acc-0.4408\n",
      "Iter-28470, train loss-2.0489, acc-0.4800, valid loss-2.1021, acc-0.4300, test loss-2.0862, acc-0.4409\n",
      "Iter-28480, train loss-2.1416, acc-0.3800, valid loss-2.1020, acc-0.4300, test loss-2.0862, acc-0.4407\n",
      "Iter-28490, train loss-2.1022, acc-0.4000, valid loss-2.1019, acc-0.4302, test loss-2.0861, acc-0.4408\n",
      "Iter-28500, train loss-2.1261, acc-0.3600, valid loss-2.1019, acc-0.4308, test loss-2.0860, acc-0.4408\n",
      "Iter-28510, train loss-2.1062, acc-0.4200, valid loss-2.1018, acc-0.4308, test loss-2.0860, acc-0.4409\n",
      "Iter-28520, train loss-2.0848, acc-0.5400, valid loss-2.1018, acc-0.4308, test loss-2.0859, acc-0.4408\n",
      "Iter-28530, train loss-2.0811, acc-0.3800, valid loss-2.1017, acc-0.4308, test loss-2.0859, acc-0.4408\n",
      "Iter-28540, train loss-2.0660, acc-0.4200, valid loss-2.1017, acc-0.4302, test loss-2.0858, acc-0.4408\n",
      "Iter-28550, train loss-2.0804, acc-0.4200, valid loss-2.1016, acc-0.4304, test loss-2.0857, acc-0.4407\n",
      "Iter-28560, train loss-2.0957, acc-0.4800, valid loss-2.1016, acc-0.4304, test loss-2.0857, acc-0.4413\n",
      "Iter-28570, train loss-2.0925, acc-0.3800, valid loss-2.1015, acc-0.4308, test loss-2.0856, acc-0.4412\n",
      "Iter-28580, train loss-2.1458, acc-0.3200, valid loss-2.1015, acc-0.4308, test loss-2.0856, acc-0.4410\n",
      "Iter-28590, train loss-2.1171, acc-0.4400, valid loss-2.1014, acc-0.4312, test loss-2.0855, acc-0.4414\n",
      "Iter-28600, train loss-2.0436, acc-0.4400, valid loss-2.1014, acc-0.4312, test loss-2.0854, acc-0.4409\n",
      "Iter-28610, train loss-2.0672, acc-0.4600, valid loss-2.1013, acc-0.4310, test loss-2.0854, acc-0.4410\n",
      "Iter-28620, train loss-2.0523, acc-0.5000, valid loss-2.1012, acc-0.4310, test loss-2.0853, acc-0.4409\n",
      "Iter-28630, train loss-2.1290, acc-0.3400, valid loss-2.1012, acc-0.4312, test loss-2.0853, acc-0.4414\n",
      "Iter-28640, train loss-2.0877, acc-0.3800, valid loss-2.1011, acc-0.4314, test loss-2.0852, acc-0.4413\n",
      "Iter-28650, train loss-2.1101, acc-0.4200, valid loss-2.1011, acc-0.4314, test loss-2.0851, acc-0.4414\n",
      "Iter-28660, train loss-2.0957, acc-0.3800, valid loss-2.1010, acc-0.4312, test loss-2.0851, acc-0.4412\n",
      "Iter-28670, train loss-2.1395, acc-0.4600, valid loss-2.1010, acc-0.4312, test loss-2.0850, acc-0.4412\n",
      "Iter-28680, train loss-2.0795, acc-0.4000, valid loss-2.1009, acc-0.4314, test loss-2.0850, acc-0.4413\n",
      "Iter-28690, train loss-2.1264, acc-0.3600, valid loss-2.1009, acc-0.4310, test loss-2.0849, acc-0.4415\n",
      "Iter-28700, train loss-2.1084, acc-0.4000, valid loss-2.1008, acc-0.4312, test loss-2.0848, acc-0.4412\n",
      "Iter-28710, train loss-2.0722, acc-0.4800, valid loss-2.1008, acc-0.4314, test loss-2.0848, acc-0.4413\n",
      "Iter-28720, train loss-2.0710, acc-0.4600, valid loss-2.1007, acc-0.4316, test loss-2.0847, acc-0.4416\n",
      "Iter-28730, train loss-2.0373, acc-0.5400, valid loss-2.1007, acc-0.4320, test loss-2.0847, acc-0.4416\n",
      "Iter-28740, train loss-2.0586, acc-0.5600, valid loss-2.1006, acc-0.4320, test loss-2.0846, acc-0.4416\n",
      "Iter-28750, train loss-2.1270, acc-0.3600, valid loss-2.1005, acc-0.4316, test loss-2.0845, acc-0.4412\n",
      "Iter-28760, train loss-2.1378, acc-0.3400, valid loss-2.1005, acc-0.4318, test loss-2.0845, acc-0.4414\n",
      "Iter-28770, train loss-2.0966, acc-0.4400, valid loss-2.1004, acc-0.4320, test loss-2.0844, acc-0.4415\n",
      "Iter-28780, train loss-2.0392, acc-0.4800, valid loss-2.1004, acc-0.4318, test loss-2.0844, acc-0.4417\n",
      "Iter-28790, train loss-2.1426, acc-0.3200, valid loss-2.1003, acc-0.4318, test loss-2.0843, acc-0.4417\n",
      "Iter-28800, train loss-2.1509, acc-0.3200, valid loss-2.1003, acc-0.4320, test loss-2.0843, acc-0.4415\n",
      "Iter-28810, train loss-2.0843, acc-0.4200, valid loss-2.1002, acc-0.4322, test loss-2.0842, acc-0.4418\n",
      "Iter-28820, train loss-2.0497, acc-0.5200, valid loss-2.1002, acc-0.4322, test loss-2.0841, acc-0.4419\n",
      "Iter-28830, train loss-2.0612, acc-0.4400, valid loss-2.1001, acc-0.4320, test loss-2.0841, acc-0.4420\n",
      "Iter-28840, train loss-2.0575, acc-0.5000, valid loss-2.1001, acc-0.4320, test loss-2.0840, acc-0.4421\n",
      "Iter-28850, train loss-2.0873, acc-0.4800, valid loss-2.1000, acc-0.4318, test loss-2.0840, acc-0.4416\n",
      "Iter-28860, train loss-2.0566, acc-0.4600, valid loss-2.1000, acc-0.4322, test loss-2.0839, acc-0.4417\n",
      "Iter-28870, train loss-2.1030, acc-0.3400, valid loss-2.0999, acc-0.4322, test loss-2.0838, acc-0.4418\n",
      "Iter-28880, train loss-2.0916, acc-0.4400, valid loss-2.0999, acc-0.4322, test loss-2.0838, acc-0.4417\n",
      "Iter-28890, train loss-2.0911, acc-0.4400, valid loss-2.0998, acc-0.4316, test loss-2.0837, acc-0.4417\n",
      "Iter-28900, train loss-2.0675, acc-0.3600, valid loss-2.0997, acc-0.4320, test loss-2.0836, acc-0.4417\n",
      "Iter-28910, train loss-2.1026, acc-0.3800, valid loss-2.0997, acc-0.4322, test loss-2.0836, acc-0.4420\n",
      "Iter-28920, train loss-2.0742, acc-0.4800, valid loss-2.0996, acc-0.4322, test loss-2.0835, acc-0.4420\n",
      "Iter-28930, train loss-2.0728, acc-0.4400, valid loss-2.0996, acc-0.4324, test loss-2.0835, acc-0.4420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-28940, train loss-2.1035, acc-0.4400, valid loss-2.0995, acc-0.4326, test loss-2.0834, acc-0.4422\n",
      "Iter-28950, train loss-2.0910, acc-0.4400, valid loss-2.0995, acc-0.4326, test loss-2.0834, acc-0.4421\n",
      "Iter-28960, train loss-2.0690, acc-0.4800, valid loss-2.0994, acc-0.4326, test loss-2.0833, acc-0.4422\n",
      "Iter-28970, train loss-2.0785, acc-0.5600, valid loss-2.0994, acc-0.4328, test loss-2.0832, acc-0.4422\n",
      "Iter-28980, train loss-2.1061, acc-0.3800, valid loss-2.0993, acc-0.4328, test loss-2.0832, acc-0.4423\n",
      "Iter-28990, train loss-2.0817, acc-0.5200, valid loss-2.0993, acc-0.4328, test loss-2.0831, acc-0.4422\n",
      "Iter-29000, train loss-2.0979, acc-0.4200, valid loss-2.0992, acc-0.4328, test loss-2.0831, acc-0.4424\n",
      "Iter-29010, train loss-2.1092, acc-0.3600, valid loss-2.0991, acc-0.4328, test loss-2.0830, acc-0.4423\n",
      "Iter-29020, train loss-2.0964, acc-0.4800, valid loss-2.0991, acc-0.4330, test loss-2.0829, acc-0.4427\n",
      "Iter-29030, train loss-2.0287, acc-0.5200, valid loss-2.0990, acc-0.4330, test loss-2.0829, acc-0.4427\n",
      "Iter-29040, train loss-2.1233, acc-0.4200, valid loss-2.0990, acc-0.4330, test loss-2.0828, acc-0.4427\n",
      "Iter-29050, train loss-2.0719, acc-0.4400, valid loss-2.0989, acc-0.4330, test loss-2.0827, acc-0.4426\n",
      "Iter-29060, train loss-2.0841, acc-0.4600, valid loss-2.0989, acc-0.4330, test loss-2.0827, acc-0.4426\n",
      "Iter-29070, train loss-2.0525, acc-0.6000, valid loss-2.0988, acc-0.4330, test loss-2.0826, acc-0.4426\n",
      "Iter-29080, train loss-2.0624, acc-0.5200, valid loss-2.0988, acc-0.4330, test loss-2.0826, acc-0.4423\n",
      "Iter-29090, train loss-2.0911, acc-0.3600, valid loss-2.0987, acc-0.4330, test loss-2.0825, acc-0.4421\n",
      "Iter-29100, train loss-2.0886, acc-0.4600, valid loss-2.0987, acc-0.4330, test loss-2.0825, acc-0.4422\n",
      "Iter-29110, train loss-2.0987, acc-0.4400, valid loss-2.0986, acc-0.4326, test loss-2.0824, acc-0.4423\n",
      "Iter-29120, train loss-2.0773, acc-0.4200, valid loss-2.0985, acc-0.4332, test loss-2.0823, acc-0.4423\n",
      "Iter-29130, train loss-2.1057, acc-0.5200, valid loss-2.0985, acc-0.4334, test loss-2.0823, acc-0.4423\n",
      "Iter-29140, train loss-2.0914, acc-0.4400, valid loss-2.0984, acc-0.4330, test loss-2.0822, acc-0.4424\n",
      "Iter-29150, train loss-2.1104, acc-0.4000, valid loss-2.0984, acc-0.4332, test loss-2.0822, acc-0.4425\n",
      "Iter-29160, train loss-2.1144, acc-0.3800, valid loss-2.0983, acc-0.4332, test loss-2.0821, acc-0.4428\n",
      "Iter-29170, train loss-2.0883, acc-0.5000, valid loss-2.0983, acc-0.4330, test loss-2.0820, acc-0.4427\n",
      "Iter-29180, train loss-2.0512, acc-0.4800, valid loss-2.0982, acc-0.4330, test loss-2.0820, acc-0.4427\n",
      "Iter-29190, train loss-2.1113, acc-0.4000, valid loss-2.0982, acc-0.4326, test loss-2.0819, acc-0.4425\n",
      "Iter-29200, train loss-2.0871, acc-0.4400, valid loss-2.0981, acc-0.4326, test loss-2.0819, acc-0.4427\n",
      "Iter-29210, train loss-2.1028, acc-0.4600, valid loss-2.0981, acc-0.4324, test loss-2.0818, acc-0.4427\n",
      "Iter-29220, train loss-2.0543, acc-0.4400, valid loss-2.0980, acc-0.4326, test loss-2.0817, acc-0.4424\n",
      "Iter-29230, train loss-2.1301, acc-0.3200, valid loss-2.0979, acc-0.4326, test loss-2.0817, acc-0.4424\n",
      "Iter-29240, train loss-2.1221, acc-0.2800, valid loss-2.0979, acc-0.4330, test loss-2.0816, acc-0.4424\n",
      "Iter-29250, train loss-2.0330, acc-0.5200, valid loss-2.0978, acc-0.4328, test loss-2.0816, acc-0.4423\n",
      "Iter-29260, train loss-2.0999, acc-0.4400, valid loss-2.0978, acc-0.4328, test loss-2.0815, acc-0.4423\n",
      "Iter-29270, train loss-2.0910, acc-0.5400, valid loss-2.0977, acc-0.4328, test loss-2.0814, acc-0.4424\n",
      "Iter-29280, train loss-2.0432, acc-0.5200, valid loss-2.0977, acc-0.4330, test loss-2.0814, acc-0.4424\n",
      "Iter-29290, train loss-2.1309, acc-0.3600, valid loss-2.0976, acc-0.4330, test loss-2.0813, acc-0.4423\n",
      "Iter-29300, train loss-2.0638, acc-0.3800, valid loss-2.0976, acc-0.4332, test loss-2.0812, acc-0.4425\n",
      "Iter-29310, train loss-2.0831, acc-0.4200, valid loss-2.0975, acc-0.4332, test loss-2.0812, acc-0.4426\n",
      "Iter-29320, train loss-2.0943, acc-0.4000, valid loss-2.0975, acc-0.4332, test loss-2.0811, acc-0.4425\n",
      "Iter-29330, train loss-2.0596, acc-0.4200, valid loss-2.0974, acc-0.4334, test loss-2.0811, acc-0.4425\n",
      "Iter-29340, train loss-2.0504, acc-0.5400, valid loss-2.0974, acc-0.4338, test loss-2.0810, acc-0.4426\n",
      "Iter-29350, train loss-2.0930, acc-0.5000, valid loss-2.0973, acc-0.4336, test loss-2.0810, acc-0.4426\n",
      "Iter-29360, train loss-2.1760, acc-0.3600, valid loss-2.0973, acc-0.4338, test loss-2.0809, acc-0.4425\n",
      "Iter-29370, train loss-2.1229, acc-0.4200, valid loss-2.0972, acc-0.4332, test loss-2.0808, acc-0.4423\n",
      "Iter-29380, train loss-2.0282, acc-0.5000, valid loss-2.0971, acc-0.4334, test loss-2.0808, acc-0.4422\n",
      "Iter-29390, train loss-2.0369, acc-0.5000, valid loss-2.0971, acc-0.4338, test loss-2.0807, acc-0.4425\n",
      "Iter-29400, train loss-2.0688, acc-0.4200, valid loss-2.0970, acc-0.4340, test loss-2.0807, acc-0.4425\n",
      "Iter-29410, train loss-2.1005, acc-0.2800, valid loss-2.0970, acc-0.4340, test loss-2.0806, acc-0.4426\n",
      "Iter-29420, train loss-2.0593, acc-0.4600, valid loss-2.0969, acc-0.4336, test loss-2.0805, acc-0.4424\n",
      "Iter-29430, train loss-2.0836, acc-0.4400, valid loss-2.0969, acc-0.4336, test loss-2.0805, acc-0.4426\n",
      "Iter-29440, train loss-2.0953, acc-0.5400, valid loss-2.0968, acc-0.4336, test loss-2.0804, acc-0.4425\n",
      "Iter-29450, train loss-2.1521, acc-0.4400, valid loss-2.0968, acc-0.4336, test loss-2.0804, acc-0.4427\n",
      "Iter-29460, train loss-2.1664, acc-0.3000, valid loss-2.0967, acc-0.4336, test loss-2.0803, acc-0.4429\n",
      "Iter-29470, train loss-2.0873, acc-0.5200, valid loss-2.0967, acc-0.4334, test loss-2.0802, acc-0.4428\n",
      "Iter-29480, train loss-2.0933, acc-0.4800, valid loss-2.0966, acc-0.4338, test loss-2.0802, acc-0.4428\n",
      "Iter-29490, train loss-2.0912, acc-0.4200, valid loss-2.0966, acc-0.4336, test loss-2.0801, acc-0.4428\n",
      "Iter-29500, train loss-2.0799, acc-0.4200, valid loss-2.0965, acc-0.4340, test loss-2.0801, acc-0.4429\n",
      "Iter-29510, train loss-2.0775, acc-0.5000, valid loss-2.0965, acc-0.4338, test loss-2.0800, acc-0.4428\n",
      "Iter-29520, train loss-2.1022, acc-0.4200, valid loss-2.0964, acc-0.4338, test loss-2.0799, acc-0.4429\n",
      "Iter-29530, train loss-2.0882, acc-0.4600, valid loss-2.0964, acc-0.4338, test loss-2.0799, acc-0.4429\n",
      "Iter-29540, train loss-2.1105, acc-0.4600, valid loss-2.0963, acc-0.4340, test loss-2.0798, acc-0.4429\n",
      "Iter-29550, train loss-2.1150, acc-0.3600, valid loss-2.0963, acc-0.4344, test loss-2.0798, acc-0.4429\n",
      "Iter-29560, train loss-2.0244, acc-0.5800, valid loss-2.0962, acc-0.4342, test loss-2.0797, acc-0.4430\n",
      "Iter-29570, train loss-2.0943, acc-0.4200, valid loss-2.0961, acc-0.4342, test loss-2.0797, acc-0.4428\n",
      "Iter-29580, train loss-2.0987, acc-0.4400, valid loss-2.0961, acc-0.4342, test loss-2.0796, acc-0.4426\n",
      "Iter-29590, train loss-2.1203, acc-0.2800, valid loss-2.0960, acc-0.4340, test loss-2.0795, acc-0.4425\n",
      "Iter-29600, train loss-2.0763, acc-0.4400, valid loss-2.0960, acc-0.4340, test loss-2.0795, acc-0.4425\n",
      "Iter-29610, train loss-2.0914, acc-0.3800, valid loss-2.0959, acc-0.4342, test loss-2.0794, acc-0.4423\n",
      "Iter-29620, train loss-2.0918, acc-0.3400, valid loss-2.0959, acc-0.4346, test loss-2.0794, acc-0.4427\n",
      "Iter-29630, train loss-2.1091, acc-0.4600, valid loss-2.0958, acc-0.4342, test loss-2.0793, acc-0.4427\n",
      "Iter-29640, train loss-2.1117, acc-0.4000, valid loss-2.0958, acc-0.4344, test loss-2.0792, acc-0.4427\n",
      "Iter-29650, train loss-2.0781, acc-0.4400, valid loss-2.0957, acc-0.4344, test loss-2.0792, acc-0.4433\n",
      "Iter-29660, train loss-2.1268, acc-0.5000, valid loss-2.0957, acc-0.4342, test loss-2.0791, acc-0.4431\n",
      "Iter-29670, train loss-2.1079, acc-0.4400, valid loss-2.0956, acc-0.4336, test loss-2.0791, acc-0.4432\n",
      "Iter-29680, train loss-2.0601, acc-0.4600, valid loss-2.0956, acc-0.4336, test loss-2.0790, acc-0.4432\n",
      "Iter-29690, train loss-2.1054, acc-0.4200, valid loss-2.0955, acc-0.4340, test loss-2.0790, acc-0.4433\n",
      "Iter-29700, train loss-2.0739, acc-0.4800, valid loss-2.0955, acc-0.4340, test loss-2.0789, acc-0.4434\n",
      "Iter-29710, train loss-2.0858, acc-0.4400, valid loss-2.0954, acc-0.4342, test loss-2.0789, acc-0.4434\n",
      "Iter-29720, train loss-2.0500, acc-0.4600, valid loss-2.0954, acc-0.4338, test loss-2.0788, acc-0.4432\n",
      "Iter-29730, train loss-2.0800, acc-0.4400, valid loss-2.0953, acc-0.4346, test loss-2.0787, acc-0.4434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-29740, train loss-2.0775, acc-0.4400, valid loss-2.0953, acc-0.4340, test loss-2.0787, acc-0.4435\n",
      "Iter-29750, train loss-2.0972, acc-0.5000, valid loss-2.0952, acc-0.4344, test loss-2.0786, acc-0.4434\n",
      "Iter-29760, train loss-2.0990, acc-0.4400, valid loss-2.0951, acc-0.4344, test loss-2.0786, acc-0.4434\n",
      "Iter-29770, train loss-2.1076, acc-0.4800, valid loss-2.0951, acc-0.4348, test loss-2.0785, acc-0.4437\n",
      "Iter-29780, train loss-2.0704, acc-0.5000, valid loss-2.0950, acc-0.4346, test loss-2.0784, acc-0.4435\n",
      "Iter-29790, train loss-2.0472, acc-0.4200, valid loss-2.0950, acc-0.4342, test loss-2.0784, acc-0.4434\n",
      "Iter-29800, train loss-2.0579, acc-0.4000, valid loss-2.0949, acc-0.4342, test loss-2.0783, acc-0.4435\n",
      "Iter-29810, train loss-2.1135, acc-0.4000, valid loss-2.0949, acc-0.4342, test loss-2.0783, acc-0.4433\n",
      "Iter-29820, train loss-2.1747, acc-0.2600, valid loss-2.0948, acc-0.4344, test loss-2.0782, acc-0.4434\n",
      "Iter-29830, train loss-2.0784, acc-0.4600, valid loss-2.0948, acc-0.4344, test loss-2.0781, acc-0.4431\n",
      "Iter-29840, train loss-2.0731, acc-0.4400, valid loss-2.0947, acc-0.4344, test loss-2.0781, acc-0.4431\n",
      "Iter-29850, train loss-2.0643, acc-0.4600, valid loss-2.0946, acc-0.4346, test loss-2.0780, acc-0.4432\n",
      "Iter-29860, train loss-2.0314, acc-0.5600, valid loss-2.0946, acc-0.4348, test loss-2.0780, acc-0.4433\n",
      "Iter-29870, train loss-2.1296, acc-0.4000, valid loss-2.0945, acc-0.4348, test loss-2.0779, acc-0.4432\n",
      "Iter-29880, train loss-2.0734, acc-0.4400, valid loss-2.0945, acc-0.4350, test loss-2.0778, acc-0.4433\n",
      "Iter-29890, train loss-2.1393, acc-0.3600, valid loss-2.0944, acc-0.4352, test loss-2.0778, acc-0.4434\n",
      "Iter-29900, train loss-2.0744, acc-0.4800, valid loss-2.0944, acc-0.4346, test loss-2.0777, acc-0.4433\n",
      "Iter-29910, train loss-2.1124, acc-0.4000, valid loss-2.0943, acc-0.4350, test loss-2.0777, acc-0.4435\n",
      "Iter-29920, train loss-2.0703, acc-0.4600, valid loss-2.0943, acc-0.4348, test loss-2.0776, acc-0.4435\n",
      "Iter-29930, train loss-2.0472, acc-0.4600, valid loss-2.0942, acc-0.4352, test loss-2.0776, acc-0.4435\n",
      "Iter-29940, train loss-2.0725, acc-0.4800, valid loss-2.0942, acc-0.4352, test loss-2.0775, acc-0.4434\n",
      "Iter-29950, train loss-2.1150, acc-0.4200, valid loss-2.0941, acc-0.4352, test loss-2.0774, acc-0.4434\n",
      "Iter-29960, train loss-2.0902, acc-0.4400, valid loss-2.0941, acc-0.4354, test loss-2.0774, acc-0.4432\n",
      "Iter-29970, train loss-2.0973, acc-0.4200, valid loss-2.0940, acc-0.4350, test loss-2.0773, acc-0.4436\n",
      "Iter-29980, train loss-2.1078, acc-0.4200, valid loss-2.0940, acc-0.4352, test loss-2.0773, acc-0.4435\n",
      "Iter-29990, train loss-2.0759, acc-0.5000, valid loss-2.0939, acc-0.4356, test loss-2.0772, acc-0.4437\n",
      "Iter-30000, train loss-2.0815, acc-0.4600, valid loss-2.0939, acc-0.4356, test loss-2.0771, acc-0.4437\n",
      "Iter-30010, train loss-2.0750, acc-0.4200, valid loss-2.0938, acc-0.4358, test loss-2.0771, acc-0.4440\n",
      "Iter-30020, train loss-2.1114, acc-0.3200, valid loss-2.0938, acc-0.4358, test loss-2.0770, acc-0.4437\n",
      "Iter-30030, train loss-2.1512, acc-0.3600, valid loss-2.0937, acc-0.4358, test loss-2.0770, acc-0.4439\n",
      "Iter-30040, train loss-2.0407, acc-0.5000, valid loss-2.0936, acc-0.4358, test loss-2.0769, acc-0.4441\n",
      "Iter-30050, train loss-2.1406, acc-0.3800, valid loss-2.0936, acc-0.4360, test loss-2.0768, acc-0.4441\n",
      "Iter-30060, train loss-2.0703, acc-0.4800, valid loss-2.0935, acc-0.4358, test loss-2.0768, acc-0.4444\n",
      "Iter-30070, train loss-2.0526, acc-0.5200, valid loss-2.0935, acc-0.4356, test loss-2.0767, acc-0.4443\n",
      "Iter-30080, train loss-2.0617, acc-0.5400, valid loss-2.0934, acc-0.4354, test loss-2.0767, acc-0.4442\n",
      "Iter-30090, train loss-2.0791, acc-0.5200, valid loss-2.0934, acc-0.4354, test loss-2.0766, acc-0.4441\n",
      "Iter-30100, train loss-2.0456, acc-0.4200, valid loss-2.0933, acc-0.4354, test loss-2.0765, acc-0.4442\n",
      "Iter-30110, train loss-2.0403, acc-0.5000, valid loss-2.0933, acc-0.4354, test loss-2.0765, acc-0.4440\n",
      "Iter-30120, train loss-2.1470, acc-0.3200, valid loss-2.0932, acc-0.4356, test loss-2.0764, acc-0.4442\n",
      "Iter-30130, train loss-2.0713, acc-0.4600, valid loss-2.0932, acc-0.4352, test loss-2.0764, acc-0.4442\n",
      "Iter-30140, train loss-2.1023, acc-0.3800, valid loss-2.0931, acc-0.4354, test loss-2.0763, acc-0.4443\n",
      "Iter-30150, train loss-2.0609, acc-0.3800, valid loss-2.0930, acc-0.4354, test loss-2.0762, acc-0.4443\n",
      "Iter-30160, train loss-2.0293, acc-0.4400, valid loss-2.0930, acc-0.4352, test loss-2.0762, acc-0.4445\n",
      "Iter-30170, train loss-2.1013, acc-0.4400, valid loss-2.0929, acc-0.4354, test loss-2.0761, acc-0.4446\n",
      "Iter-30180, train loss-2.0644, acc-0.4600, valid loss-2.0929, acc-0.4350, test loss-2.0761, acc-0.4445\n",
      "Iter-30190, train loss-2.0477, acc-0.5000, valid loss-2.0928, acc-0.4348, test loss-2.0760, acc-0.4446\n",
      "Iter-30200, train loss-2.1231, acc-0.3800, valid loss-2.0928, acc-0.4352, test loss-2.0760, acc-0.4445\n",
      "Iter-30210, train loss-2.1406, acc-0.4000, valid loss-2.0927, acc-0.4348, test loss-2.0759, acc-0.4445\n",
      "Iter-30220, train loss-2.1159, acc-0.3200, valid loss-2.0927, acc-0.4350, test loss-2.0758, acc-0.4443\n",
      "Iter-30230, train loss-2.0639, acc-0.5000, valid loss-2.0926, acc-0.4352, test loss-2.0758, acc-0.4444\n",
      "Iter-30240, train loss-2.0392, acc-0.5200, valid loss-2.0926, acc-0.4352, test loss-2.0757, acc-0.4443\n",
      "Iter-30250, train loss-2.0951, acc-0.4800, valid loss-2.0925, acc-0.4348, test loss-2.0756, acc-0.4447\n",
      "Iter-30260, train loss-2.0485, acc-0.5800, valid loss-2.0924, acc-0.4348, test loss-2.0756, acc-0.4446\n",
      "Iter-30270, train loss-2.0746, acc-0.4200, valid loss-2.0924, acc-0.4350, test loss-2.0755, acc-0.4446\n",
      "Iter-30280, train loss-2.0723, acc-0.4200, valid loss-2.0923, acc-0.4350, test loss-2.0755, acc-0.4448\n",
      "Iter-30290, train loss-2.1625, acc-0.2600, valid loss-2.0923, acc-0.4354, test loss-2.0754, acc-0.4448\n",
      "Iter-30300, train loss-2.1023, acc-0.4600, valid loss-2.0922, acc-0.4352, test loss-2.0754, acc-0.4448\n",
      "Iter-30310, train loss-2.0757, acc-0.4000, valid loss-2.0922, acc-0.4356, test loss-2.0753, acc-0.4446\n",
      "Iter-30320, train loss-2.1052, acc-0.4200, valid loss-2.0921, acc-0.4354, test loss-2.0752, acc-0.4449\n",
      "Iter-30330, train loss-2.0564, acc-0.5000, valid loss-2.0921, acc-0.4350, test loss-2.0752, acc-0.4448\n",
      "Iter-30340, train loss-2.0574, acc-0.4600, valid loss-2.0920, acc-0.4358, test loss-2.0751, acc-0.4448\n",
      "Iter-30350, train loss-2.0749, acc-0.5000, valid loss-2.0920, acc-0.4356, test loss-2.0751, acc-0.4449\n",
      "Iter-30360, train loss-2.0902, acc-0.3600, valid loss-2.0919, acc-0.4356, test loss-2.0750, acc-0.4449\n",
      "Iter-30370, train loss-2.0804, acc-0.4600, valid loss-2.0919, acc-0.4356, test loss-2.0749, acc-0.4450\n",
      "Iter-30380, train loss-2.0198, acc-0.4800, valid loss-2.0918, acc-0.4354, test loss-2.0749, acc-0.4450\n",
      "Iter-30390, train loss-2.0606, acc-0.5000, valid loss-2.0918, acc-0.4356, test loss-2.0748, acc-0.4451\n",
      "Iter-30400, train loss-2.1087, acc-0.3800, valid loss-2.0917, acc-0.4356, test loss-2.0748, acc-0.4452\n",
      "Iter-30410, train loss-2.0469, acc-0.4400, valid loss-2.0917, acc-0.4356, test loss-2.0747, acc-0.4450\n",
      "Iter-30420, train loss-2.0645, acc-0.5000, valid loss-2.0916, acc-0.4356, test loss-2.0747, acc-0.4454\n",
      "Iter-30430, train loss-2.1190, acc-0.3000, valid loss-2.0915, acc-0.4358, test loss-2.0746, acc-0.4453\n",
      "Iter-30440, train loss-2.1120, acc-0.4800, valid loss-2.0915, acc-0.4358, test loss-2.0745, acc-0.4452\n",
      "Iter-30450, train loss-2.0538, acc-0.5000, valid loss-2.0914, acc-0.4356, test loss-2.0745, acc-0.4453\n",
      "Iter-30460, train loss-2.1332, acc-0.4000, valid loss-2.0914, acc-0.4354, test loss-2.0744, acc-0.4454\n",
      "Iter-30470, train loss-2.1246, acc-0.3000, valid loss-2.0913, acc-0.4352, test loss-2.0744, acc-0.4452\n",
      "Iter-30480, train loss-2.0524, acc-0.4600, valid loss-2.0913, acc-0.4358, test loss-2.0743, acc-0.4451\n",
      "Iter-30490, train loss-2.1451, acc-0.2800, valid loss-2.0912, acc-0.4360, test loss-2.0743, acc-0.4452\n",
      "Iter-30500, train loss-2.0933, acc-0.4600, valid loss-2.0912, acc-0.4362, test loss-2.0742, acc-0.4452\n",
      "Iter-30510, train loss-2.0984, acc-0.4400, valid loss-2.0911, acc-0.4366, test loss-2.0741, acc-0.4454\n",
      "Iter-30520, train loss-2.0971, acc-0.4800, valid loss-2.0911, acc-0.4366, test loss-2.0741, acc-0.4453\n",
      "Iter-30530, train loss-2.0533, acc-0.4800, valid loss-2.0910, acc-0.4366, test loss-2.0740, acc-0.4453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-30540, train loss-2.0731, acc-0.3800, valid loss-2.0910, acc-0.4368, test loss-2.0740, acc-0.4455\n",
      "Iter-30550, train loss-2.1733, acc-0.3600, valid loss-2.0909, acc-0.4370, test loss-2.0739, acc-0.4454\n",
      "Iter-30560, train loss-2.0720, acc-0.4200, valid loss-2.0909, acc-0.4368, test loss-2.0739, acc-0.4455\n",
      "Iter-30570, train loss-2.0653, acc-0.4200, valid loss-2.0908, acc-0.4366, test loss-2.0738, acc-0.4453\n",
      "Iter-30580, train loss-2.0688, acc-0.4400, valid loss-2.0907, acc-0.4366, test loss-2.0737, acc-0.4453\n",
      "Iter-30590, train loss-2.0776, acc-0.5200, valid loss-2.0907, acc-0.4372, test loss-2.0737, acc-0.4452\n",
      "Iter-30600, train loss-2.0975, acc-0.4400, valid loss-2.0906, acc-0.4368, test loss-2.0736, acc-0.4453\n",
      "Iter-30610, train loss-2.0583, acc-0.4800, valid loss-2.0906, acc-0.4366, test loss-2.0736, acc-0.4452\n",
      "Iter-30620, train loss-2.0309, acc-0.5200, valid loss-2.0905, acc-0.4364, test loss-2.0735, acc-0.4452\n",
      "Iter-30630, train loss-2.0885, acc-0.4800, valid loss-2.0905, acc-0.4360, test loss-2.0735, acc-0.4451\n",
      "Iter-30640, train loss-2.1289, acc-0.3800, valid loss-2.0904, acc-0.4368, test loss-2.0734, acc-0.4452\n",
      "Iter-30650, train loss-2.0697, acc-0.4000, valid loss-2.0904, acc-0.4370, test loss-2.0733, acc-0.4451\n",
      "Iter-30660, train loss-2.0761, acc-0.3400, valid loss-2.0903, acc-0.4364, test loss-2.0733, acc-0.4450\n",
      "Iter-30670, train loss-2.1151, acc-0.3800, valid loss-2.0903, acc-0.4364, test loss-2.0732, acc-0.4450\n",
      "Iter-30680, train loss-2.0975, acc-0.5200, valid loss-2.0902, acc-0.4364, test loss-2.0732, acc-0.4449\n",
      "Iter-30690, train loss-2.1276, acc-0.3800, valid loss-2.0902, acc-0.4362, test loss-2.0731, acc-0.4451\n",
      "Iter-30700, train loss-2.0279, acc-0.5800, valid loss-2.0901, acc-0.4370, test loss-2.0731, acc-0.4453\n",
      "Iter-30710, train loss-2.1263, acc-0.4000, valid loss-2.0901, acc-0.4368, test loss-2.0730, acc-0.4453\n",
      "Iter-30720, train loss-2.0474, acc-0.5400, valid loss-2.0900, acc-0.4372, test loss-2.0729, acc-0.4456\n",
      "Iter-30730, train loss-2.0381, acc-0.4200, valid loss-2.0900, acc-0.4372, test loss-2.0729, acc-0.4457\n",
      "Iter-30740, train loss-2.0545, acc-0.5200, valid loss-2.0899, acc-0.4374, test loss-2.0728, acc-0.4457\n",
      "Iter-30750, train loss-2.0518, acc-0.5000, valid loss-2.0899, acc-0.4372, test loss-2.0728, acc-0.4457\n",
      "Iter-30760, train loss-2.0817, acc-0.4400, valid loss-2.0898, acc-0.4372, test loss-2.0727, acc-0.4460\n",
      "Iter-30770, train loss-2.0308, acc-0.5400, valid loss-2.0898, acc-0.4372, test loss-2.0726, acc-0.4458\n",
      "Iter-30780, train loss-2.0949, acc-0.4400, valid loss-2.0897, acc-0.4370, test loss-2.0726, acc-0.4460\n",
      "Iter-30790, train loss-2.1060, acc-0.4600, valid loss-2.0896, acc-0.4366, test loss-2.0725, acc-0.4460\n",
      "Iter-30800, train loss-2.1103, acc-0.4200, valid loss-2.0896, acc-0.4370, test loss-2.0725, acc-0.4461\n",
      "Iter-30810, train loss-2.0788, acc-0.4200, valid loss-2.0895, acc-0.4372, test loss-2.0724, acc-0.4460\n",
      "Iter-30820, train loss-2.0326, acc-0.5000, valid loss-2.0895, acc-0.4372, test loss-2.0724, acc-0.4457\n",
      "Iter-30830, train loss-2.0976, acc-0.3800, valid loss-2.0894, acc-0.4374, test loss-2.0723, acc-0.4460\n",
      "Iter-30840, train loss-2.0442, acc-0.4600, valid loss-2.0894, acc-0.4372, test loss-2.0722, acc-0.4460\n",
      "Iter-30850, train loss-2.1554, acc-0.4200, valid loss-2.0893, acc-0.4370, test loss-2.0722, acc-0.4459\n",
      "Iter-30860, train loss-2.0317, acc-0.5000, valid loss-2.0893, acc-0.4370, test loss-2.0721, acc-0.4460\n",
      "Iter-30870, train loss-2.0736, acc-0.4600, valid loss-2.0892, acc-0.4370, test loss-2.0721, acc-0.4463\n",
      "Iter-30880, train loss-2.0731, acc-0.4600, valid loss-2.0892, acc-0.4374, test loss-2.0720, acc-0.4464\n",
      "Iter-30890, train loss-2.0663, acc-0.5200, valid loss-2.0891, acc-0.4372, test loss-2.0719, acc-0.4462\n",
      "Iter-30900, train loss-2.0568, acc-0.5000, valid loss-2.0891, acc-0.4372, test loss-2.0719, acc-0.4462\n",
      "Iter-30910, train loss-2.0794, acc-0.4800, valid loss-2.0890, acc-0.4372, test loss-2.0718, acc-0.4459\n",
      "Iter-30920, train loss-2.0893, acc-0.4600, valid loss-2.0889, acc-0.4372, test loss-2.0718, acc-0.4459\n",
      "Iter-30930, train loss-2.1020, acc-0.4400, valid loss-2.0889, acc-0.4364, test loss-2.0717, acc-0.4460\n",
      "Iter-30940, train loss-2.1226, acc-0.2600, valid loss-2.0888, acc-0.4366, test loss-2.0717, acc-0.4460\n",
      "Iter-30950, train loss-2.0203, acc-0.4800, valid loss-2.0888, acc-0.4370, test loss-2.0716, acc-0.4457\n",
      "Iter-30960, train loss-2.0385, acc-0.5200, valid loss-2.0887, acc-0.4370, test loss-2.0715, acc-0.4458\n",
      "Iter-30970, train loss-2.0704, acc-0.4800, valid loss-2.0887, acc-0.4372, test loss-2.0715, acc-0.4461\n",
      "Iter-30980, train loss-2.0879, acc-0.4200, valid loss-2.0886, acc-0.4372, test loss-2.0714, acc-0.4463\n",
      "Iter-30990, train loss-2.0843, acc-0.4200, valid loss-2.0886, acc-0.4366, test loss-2.0714, acc-0.4463\n",
      "Iter-31000, train loss-2.0842, acc-0.4800, valid loss-2.0885, acc-0.4366, test loss-2.0713, acc-0.4463\n",
      "Iter-31010, train loss-2.0945, acc-0.4000, valid loss-2.0885, acc-0.4374, test loss-2.0713, acc-0.4462\n",
      "Iter-31020, train loss-2.0720, acc-0.4400, valid loss-2.0884, acc-0.4374, test loss-2.0712, acc-0.4461\n",
      "Iter-31030, train loss-2.0798, acc-0.5200, valid loss-2.0884, acc-0.4374, test loss-2.0711, acc-0.4459\n",
      "Iter-31040, train loss-2.1648, acc-0.2800, valid loss-2.0883, acc-0.4374, test loss-2.0711, acc-0.4460\n",
      "Iter-31050, train loss-2.0669, acc-0.4600, valid loss-2.0883, acc-0.4372, test loss-2.0710, acc-0.4456\n",
      "Iter-31060, train loss-2.0894, acc-0.4000, valid loss-2.0882, acc-0.4370, test loss-2.0710, acc-0.4460\n",
      "Iter-31070, train loss-2.1094, acc-0.4600, valid loss-2.0882, acc-0.4372, test loss-2.0709, acc-0.4461\n",
      "Iter-31080, train loss-2.0645, acc-0.5200, valid loss-2.0881, acc-0.4374, test loss-2.0709, acc-0.4460\n",
      "Iter-31090, train loss-2.0866, acc-0.3400, valid loss-2.0881, acc-0.4376, test loss-2.0708, acc-0.4462\n",
      "Iter-31100, train loss-2.1403, acc-0.3800, valid loss-2.0880, acc-0.4376, test loss-2.0707, acc-0.4460\n",
      "Iter-31110, train loss-2.1019, acc-0.3400, valid loss-2.0880, acc-0.4376, test loss-2.0707, acc-0.4461\n",
      "Iter-31120, train loss-2.0747, acc-0.5000, valid loss-2.0879, acc-0.4374, test loss-2.0706, acc-0.4462\n",
      "Iter-31130, train loss-2.1010, acc-0.4400, valid loss-2.0879, acc-0.4372, test loss-2.0706, acc-0.4462\n",
      "Iter-31140, train loss-2.0615, acc-0.4600, valid loss-2.0878, acc-0.4374, test loss-2.0705, acc-0.4463\n",
      "Iter-31150, train loss-2.1001, acc-0.4200, valid loss-2.0878, acc-0.4372, test loss-2.0704, acc-0.4460\n",
      "Iter-31160, train loss-2.0610, acc-0.5200, valid loss-2.0877, acc-0.4372, test loss-2.0704, acc-0.4460\n",
      "Iter-31170, train loss-2.0604, acc-0.4400, valid loss-2.0876, acc-0.4372, test loss-2.0703, acc-0.4460\n",
      "Iter-31180, train loss-2.0255, acc-0.4800, valid loss-2.0876, acc-0.4374, test loss-2.0703, acc-0.4457\n",
      "Iter-31190, train loss-2.0936, acc-0.4800, valid loss-2.0875, acc-0.4372, test loss-2.0702, acc-0.4457\n",
      "Iter-31200, train loss-2.1373, acc-0.3400, valid loss-2.0875, acc-0.4374, test loss-2.0702, acc-0.4462\n",
      "Iter-31210, train loss-2.0917, acc-0.4000, valid loss-2.0874, acc-0.4374, test loss-2.0701, acc-0.4464\n",
      "Iter-31220, train loss-2.1051, acc-0.3200, valid loss-2.0874, acc-0.4372, test loss-2.0700, acc-0.4462\n",
      "Iter-31230, train loss-2.0700, acc-0.4400, valid loss-2.0873, acc-0.4364, test loss-2.0700, acc-0.4468\n",
      "Iter-31240, train loss-2.0959, acc-0.4800, valid loss-2.0873, acc-0.4364, test loss-2.0699, acc-0.4465\n",
      "Iter-31250, train loss-2.0967, acc-0.4400, valid loss-2.0872, acc-0.4366, test loss-2.0699, acc-0.4467\n",
      "Iter-31260, train loss-2.1178, acc-0.4400, valid loss-2.0872, acc-0.4366, test loss-2.0698, acc-0.4465\n",
      "Iter-31270, train loss-2.0938, acc-0.3600, valid loss-2.0871, acc-0.4366, test loss-2.0698, acc-0.4465\n",
      "Iter-31280, train loss-2.1297, acc-0.3600, valid loss-2.0871, acc-0.4362, test loss-2.0697, acc-0.4468\n",
      "Iter-31290, train loss-2.0518, acc-0.5200, valid loss-2.0870, acc-0.4366, test loss-2.0696, acc-0.4467\n",
      "Iter-31300, train loss-2.0764, acc-0.4000, valid loss-2.0870, acc-0.4366, test loss-2.0696, acc-0.4469\n",
      "Iter-31310, train loss-2.0570, acc-0.4800, valid loss-2.0869, acc-0.4366, test loss-2.0695, acc-0.4471\n",
      "Iter-31320, train loss-2.1149, acc-0.4000, valid loss-2.0869, acc-0.4370, test loss-2.0695, acc-0.4471\n",
      "Iter-31330, train loss-2.0425, acc-0.4400, valid loss-2.0868, acc-0.4370, test loss-2.0694, acc-0.4470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-31340, train loss-2.1186, acc-0.3200, valid loss-2.0868, acc-0.4366, test loss-2.0693, acc-0.4472\n",
      "Iter-31350, train loss-2.0833, acc-0.4800, valid loss-2.0867, acc-0.4366, test loss-2.0693, acc-0.4473\n",
      "Iter-31360, train loss-2.0820, acc-0.4800, valid loss-2.0867, acc-0.4366, test loss-2.0692, acc-0.4476\n",
      "Iter-31370, train loss-2.1147, acc-0.4000, valid loss-2.0866, acc-0.4370, test loss-2.0692, acc-0.4478\n",
      "Iter-31380, train loss-2.0660, acc-0.4400, valid loss-2.0865, acc-0.4366, test loss-2.0691, acc-0.4477\n",
      "Iter-31390, train loss-2.0669, acc-0.5000, valid loss-2.0865, acc-0.4368, test loss-2.0691, acc-0.4477\n",
      "Iter-31400, train loss-2.0931, acc-0.4600, valid loss-2.0864, acc-0.4372, test loss-2.0690, acc-0.4477\n",
      "Iter-31410, train loss-2.0402, acc-0.4600, valid loss-2.0864, acc-0.4372, test loss-2.0689, acc-0.4476\n",
      "Iter-31420, train loss-2.0697, acc-0.4800, valid loss-2.0863, acc-0.4370, test loss-2.0689, acc-0.4475\n",
      "Iter-31430, train loss-2.1034, acc-0.4400, valid loss-2.0863, acc-0.4368, test loss-2.0688, acc-0.4477\n",
      "Iter-31440, train loss-2.0809, acc-0.4200, valid loss-2.0862, acc-0.4366, test loss-2.0688, acc-0.4474\n",
      "Iter-31450, train loss-2.0508, acc-0.4400, valid loss-2.0862, acc-0.4368, test loss-2.0687, acc-0.4480\n",
      "Iter-31460, train loss-2.0531, acc-0.5400, valid loss-2.0861, acc-0.4370, test loss-2.0687, acc-0.4480\n",
      "Iter-31470, train loss-2.1056, acc-0.3600, valid loss-2.0861, acc-0.4370, test loss-2.0686, acc-0.4480\n",
      "Iter-31480, train loss-2.0708, acc-0.3600, valid loss-2.0860, acc-0.4366, test loss-2.0686, acc-0.4481\n",
      "Iter-31490, train loss-2.0420, acc-0.4200, valid loss-2.0860, acc-0.4366, test loss-2.0685, acc-0.4481\n",
      "Iter-31500, train loss-2.0255, acc-0.5200, valid loss-2.0859, acc-0.4368, test loss-2.0684, acc-0.4480\n",
      "Iter-31510, train loss-2.0616, acc-0.5200, valid loss-2.0859, acc-0.4364, test loss-2.0684, acc-0.4482\n",
      "Iter-31520, train loss-2.0317, acc-0.5000, valid loss-2.0858, acc-0.4364, test loss-2.0683, acc-0.4480\n",
      "Iter-31530, train loss-2.0563, acc-0.4400, valid loss-2.0858, acc-0.4366, test loss-2.0683, acc-0.4479\n",
      "Iter-31540, train loss-2.1105, acc-0.3800, valid loss-2.0857, acc-0.4364, test loss-2.0682, acc-0.4481\n",
      "Iter-31550, train loss-2.1567, acc-0.3800, valid loss-2.0857, acc-0.4366, test loss-2.0681, acc-0.4481\n",
      "Iter-31560, train loss-2.1524, acc-0.3800, valid loss-2.0856, acc-0.4366, test loss-2.0681, acc-0.4482\n",
      "Iter-31570, train loss-2.1203, acc-0.4000, valid loss-2.0856, acc-0.4368, test loss-2.0680, acc-0.4481\n",
      "Iter-31580, train loss-2.0559, acc-0.4400, valid loss-2.0855, acc-0.4372, test loss-2.0680, acc-0.4484\n",
      "Iter-31590, train loss-2.0889, acc-0.3600, valid loss-2.0855, acc-0.4366, test loss-2.0679, acc-0.4484\n",
      "Iter-31600, train loss-2.0342, acc-0.6200, valid loss-2.0854, acc-0.4370, test loss-2.0679, acc-0.4484\n",
      "Iter-31610, train loss-2.1554, acc-0.3200, valid loss-2.0854, acc-0.4372, test loss-2.0678, acc-0.4483\n",
      "Iter-31620, train loss-2.1197, acc-0.4400, valid loss-2.0853, acc-0.4366, test loss-2.0677, acc-0.4481\n",
      "Iter-31630, train loss-2.0527, acc-0.4400, valid loss-2.0853, acc-0.4366, test loss-2.0677, acc-0.4482\n",
      "Iter-31640, train loss-2.1438, acc-0.3400, valid loss-2.0852, acc-0.4370, test loss-2.0676, acc-0.4482\n",
      "Iter-31650, train loss-2.0395, acc-0.5400, valid loss-2.0852, acc-0.4368, test loss-2.0676, acc-0.4482\n",
      "Iter-31660, train loss-2.0567, acc-0.3600, valid loss-2.0851, acc-0.4374, test loss-2.0675, acc-0.4483\n",
      "Iter-31670, train loss-2.1587, acc-0.2800, valid loss-2.0851, acc-0.4372, test loss-2.0675, acc-0.4486\n",
      "Iter-31680, train loss-2.1370, acc-0.4000, valid loss-2.0850, acc-0.4376, test loss-2.0674, acc-0.4490\n",
      "Iter-31690, train loss-2.0731, acc-0.4000, valid loss-2.0850, acc-0.4376, test loss-2.0674, acc-0.4487\n",
      "Iter-31700, train loss-2.0482, acc-0.4400, valid loss-2.0849, acc-0.4374, test loss-2.0673, acc-0.4488\n",
      "Iter-31710, train loss-2.0526, acc-0.5000, valid loss-2.0848, acc-0.4376, test loss-2.0672, acc-0.4489\n",
      "Iter-31720, train loss-2.0278, acc-0.5600, valid loss-2.0848, acc-0.4374, test loss-2.0672, acc-0.4490\n",
      "Iter-31730, train loss-2.0320, acc-0.5600, valid loss-2.0847, acc-0.4374, test loss-2.0671, acc-0.4491\n",
      "Iter-31740, train loss-2.0986, acc-0.3200, valid loss-2.0847, acc-0.4378, test loss-2.0671, acc-0.4488\n",
      "Iter-31750, train loss-2.0226, acc-0.4800, valid loss-2.0846, acc-0.4380, test loss-2.0670, acc-0.4486\n",
      "Iter-31760, train loss-2.0975, acc-0.3000, valid loss-2.0846, acc-0.4380, test loss-2.0669, acc-0.4489\n",
      "Iter-31770, train loss-2.0920, acc-0.4200, valid loss-2.0845, acc-0.4382, test loss-2.0669, acc-0.4487\n",
      "Iter-31780, train loss-2.0579, acc-0.4800, valid loss-2.0845, acc-0.4382, test loss-2.0668, acc-0.4487\n",
      "Iter-31790, train loss-2.0713, acc-0.4200, valid loss-2.0844, acc-0.4378, test loss-2.0668, acc-0.4488\n",
      "Iter-31800, train loss-2.1773, acc-0.2600, valid loss-2.0844, acc-0.4382, test loss-2.0667, acc-0.4488\n",
      "Iter-31810, train loss-2.0426, acc-0.4800, valid loss-2.0843, acc-0.4384, test loss-2.0667, acc-0.4489\n",
      "Iter-31820, train loss-2.0644, acc-0.4800, valid loss-2.0843, acc-0.4378, test loss-2.0666, acc-0.4489\n",
      "Iter-31830, train loss-2.0348, acc-0.5400, valid loss-2.0842, acc-0.4378, test loss-2.0666, acc-0.4492\n",
      "Iter-31840, train loss-2.0783, acc-0.4400, valid loss-2.0842, acc-0.4378, test loss-2.0665, acc-0.4490\n",
      "Iter-31850, train loss-2.0222, acc-0.5400, valid loss-2.0841, acc-0.4382, test loss-2.0664, acc-0.4485\n",
      "Iter-31860, train loss-2.0567, acc-0.4600, valid loss-2.0841, acc-0.4384, test loss-2.0664, acc-0.4488\n",
      "Iter-31870, train loss-2.1180, acc-0.2800, valid loss-2.0840, acc-0.4384, test loss-2.0663, acc-0.4488\n",
      "Iter-31880, train loss-2.0741, acc-0.5000, valid loss-2.0840, acc-0.4388, test loss-2.0663, acc-0.4487\n",
      "Iter-31890, train loss-2.0922, acc-0.3800, valid loss-2.0839, acc-0.4388, test loss-2.0662, acc-0.4490\n",
      "Iter-31900, train loss-2.0623, acc-0.5200, valid loss-2.0839, acc-0.4388, test loss-2.0662, acc-0.4488\n",
      "Iter-31910, train loss-2.0973, acc-0.3800, valid loss-2.0838, acc-0.4388, test loss-2.0661, acc-0.4488\n",
      "Iter-31920, train loss-2.0500, acc-0.4400, valid loss-2.0838, acc-0.4384, test loss-2.0660, acc-0.4487\n",
      "Iter-31930, train loss-2.0835, acc-0.5000, valid loss-2.0837, acc-0.4384, test loss-2.0660, acc-0.4492\n",
      "Iter-31940, train loss-2.0959, acc-0.4200, valid loss-2.0837, acc-0.4384, test loss-2.0659, acc-0.4489\n",
      "Iter-31950, train loss-2.0769, acc-0.5200, valid loss-2.0836, acc-0.4386, test loss-2.0659, acc-0.4494\n",
      "Iter-31960, train loss-2.0595, acc-0.4400, valid loss-2.0835, acc-0.4384, test loss-2.0658, acc-0.4494\n",
      "Iter-31970, train loss-2.0236, acc-0.5600, valid loss-2.0835, acc-0.4386, test loss-2.0657, acc-0.4494\n",
      "Iter-31980, train loss-2.0512, acc-0.5400, valid loss-2.0834, acc-0.4386, test loss-2.0657, acc-0.4496\n",
      "Iter-31990, train loss-2.0891, acc-0.4000, valid loss-2.0834, acc-0.4386, test loss-2.0656, acc-0.4495\n",
      "Iter-32000, train loss-2.0784, acc-0.4800, valid loss-2.0833, acc-0.4384, test loss-2.0656, acc-0.4493\n",
      "Iter-32010, train loss-2.0746, acc-0.4200, valid loss-2.0833, acc-0.4386, test loss-2.0655, acc-0.4494\n",
      "Iter-32020, train loss-2.0871, acc-0.4800, valid loss-2.0832, acc-0.4386, test loss-2.0655, acc-0.4492\n",
      "Iter-32030, train loss-2.1115, acc-0.4400, valid loss-2.0832, acc-0.4384, test loss-2.0654, acc-0.4493\n",
      "Iter-32040, train loss-2.1246, acc-0.4400, valid loss-2.0831, acc-0.4386, test loss-2.0653, acc-0.4497\n",
      "Iter-32050, train loss-2.0731, acc-0.4000, valid loss-2.0831, acc-0.4384, test loss-2.0653, acc-0.4497\n",
      "Iter-32060, train loss-2.0554, acc-0.5200, valid loss-2.0830, acc-0.4386, test loss-2.0652, acc-0.4496\n",
      "Iter-32070, train loss-2.0977, acc-0.3400, valid loss-2.0830, acc-0.4382, test loss-2.0652, acc-0.4496\n",
      "Iter-32080, train loss-2.0128, acc-0.5200, valid loss-2.0829, acc-0.4390, test loss-2.0651, acc-0.4497\n",
      "Iter-32090, train loss-2.0530, acc-0.4200, valid loss-2.0829, acc-0.4386, test loss-2.0651, acc-0.4497\n",
      "Iter-32100, train loss-2.0221, acc-0.5000, valid loss-2.0828, acc-0.4392, test loss-2.0650, acc-0.4498\n",
      "Iter-32110, train loss-2.0754, acc-0.4400, valid loss-2.0828, acc-0.4390, test loss-2.0650, acc-0.4496\n",
      "Iter-32120, train loss-2.0489, acc-0.5200, valid loss-2.0827, acc-0.4388, test loss-2.0649, acc-0.4497\n",
      "Iter-32130, train loss-2.0940, acc-0.4400, valid loss-2.0827, acc-0.4386, test loss-2.0648, acc-0.4498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-32140, train loss-2.1451, acc-0.4200, valid loss-2.0826, acc-0.4386, test loss-2.0648, acc-0.4495\n",
      "Iter-32150, train loss-2.1055, acc-0.5000, valid loss-2.0826, acc-0.4386, test loss-2.0647, acc-0.4496\n",
      "Iter-32160, train loss-2.1325, acc-0.3600, valid loss-2.0825, acc-0.4388, test loss-2.0647, acc-0.4499\n",
      "Iter-32170, train loss-2.1291, acc-0.3400, valid loss-2.0825, acc-0.4388, test loss-2.0646, acc-0.4502\n",
      "Iter-32180, train loss-2.0227, acc-0.4600, valid loss-2.0824, acc-0.4388, test loss-2.0646, acc-0.4503\n",
      "Iter-32190, train loss-2.0500, acc-0.4800, valid loss-2.0824, acc-0.4388, test loss-2.0645, acc-0.4501\n",
      "Iter-32200, train loss-2.1188, acc-0.4600, valid loss-2.0823, acc-0.4388, test loss-2.0644, acc-0.4499\n",
      "Iter-32210, train loss-2.0742, acc-0.4200, valid loss-2.0823, acc-0.4388, test loss-2.0644, acc-0.4498\n",
      "Iter-32220, train loss-2.0859, acc-0.4400, valid loss-2.0822, acc-0.4388, test loss-2.0643, acc-0.4502\n",
      "Iter-32230, train loss-2.0840, acc-0.3800, valid loss-2.0822, acc-0.4386, test loss-2.0643, acc-0.4503\n",
      "Iter-32240, train loss-2.1087, acc-0.3800, valid loss-2.0821, acc-0.4386, test loss-2.0642, acc-0.4504\n",
      "Iter-32250, train loss-2.0725, acc-0.4600, valid loss-2.0821, acc-0.4384, test loss-2.0642, acc-0.4505\n",
      "Iter-32260, train loss-2.0814, acc-0.4400, valid loss-2.0820, acc-0.4392, test loss-2.0641, acc-0.4505\n",
      "Iter-32270, train loss-2.1070, acc-0.3800, valid loss-2.0820, acc-0.4390, test loss-2.0641, acc-0.4506\n",
      "Iter-32280, train loss-2.0571, acc-0.4600, valid loss-2.0819, acc-0.4390, test loss-2.0640, acc-0.4503\n",
      "Iter-32290, train loss-2.0628, acc-0.3800, valid loss-2.0819, acc-0.4392, test loss-2.0640, acc-0.4506\n",
      "Iter-32300, train loss-2.0509, acc-0.4800, valid loss-2.0818, acc-0.4392, test loss-2.0639, acc-0.4506\n",
      "Iter-32310, train loss-2.0767, acc-0.4000, valid loss-2.0818, acc-0.4392, test loss-2.0638, acc-0.4507\n",
      "Iter-32320, train loss-1.9927, acc-0.6000, valid loss-2.0817, acc-0.4392, test loss-2.0638, acc-0.4505\n",
      "Iter-32330, train loss-2.0512, acc-0.4800, valid loss-2.0817, acc-0.4390, test loss-2.0637, acc-0.4507\n",
      "Iter-32340, train loss-2.0321, acc-0.4000, valid loss-2.0816, acc-0.4390, test loss-2.0637, acc-0.4505\n",
      "Iter-32350, train loss-2.0907, acc-0.4800, valid loss-2.0816, acc-0.4392, test loss-2.0636, acc-0.4505\n",
      "Iter-32360, train loss-2.0897, acc-0.4600, valid loss-2.0815, acc-0.4394, test loss-2.0635, acc-0.4506\n",
      "Iter-32370, train loss-2.0517, acc-0.4600, valid loss-2.0814, acc-0.4392, test loss-2.0635, acc-0.4506\n",
      "Iter-32380, train loss-2.0581, acc-0.4400, valid loss-2.0814, acc-0.4394, test loss-2.0634, acc-0.4507\n",
      "Iter-32390, train loss-2.1262, acc-0.3400, valid loss-2.0813, acc-0.4390, test loss-2.0634, acc-0.4509\n",
      "Iter-32400, train loss-2.0876, acc-0.4000, valid loss-2.0813, acc-0.4392, test loss-2.0633, acc-0.4510\n",
      "Iter-32410, train loss-2.0659, acc-0.4000, valid loss-2.0812, acc-0.4386, test loss-2.0633, acc-0.4508\n",
      "Iter-32420, train loss-2.0884, acc-0.4800, valid loss-2.0812, acc-0.4388, test loss-2.0632, acc-0.4507\n",
      "Iter-32430, train loss-2.0701, acc-0.3800, valid loss-2.0811, acc-0.4390, test loss-2.0632, acc-0.4512\n",
      "Iter-32440, train loss-2.0502, acc-0.5200, valid loss-2.0811, acc-0.4390, test loss-2.0631, acc-0.4512\n",
      "Iter-32450, train loss-2.1455, acc-0.3000, valid loss-2.0810, acc-0.4390, test loss-2.0630, acc-0.4512\n",
      "Iter-32460, train loss-2.0352, acc-0.4600, valid loss-2.0810, acc-0.4394, test loss-2.0630, acc-0.4513\n",
      "Iter-32470, train loss-2.0181, acc-0.6200, valid loss-2.0809, acc-0.4396, test loss-2.0629, acc-0.4512\n",
      "Iter-32480, train loss-2.0684, acc-0.3600, valid loss-2.0809, acc-0.4392, test loss-2.0629, acc-0.4514\n",
      "Iter-32490, train loss-2.0630, acc-0.4600, valid loss-2.0808, acc-0.4390, test loss-2.0628, acc-0.4514\n",
      "Iter-32500, train loss-2.1591, acc-0.4000, valid loss-2.0808, acc-0.4396, test loss-2.0628, acc-0.4514\n",
      "Iter-32510, train loss-2.0822, acc-0.4800, valid loss-2.0807, acc-0.4398, test loss-2.0627, acc-0.4515\n",
      "Iter-32520, train loss-2.0696, acc-0.4600, valid loss-2.0807, acc-0.4392, test loss-2.0626, acc-0.4517\n",
      "Iter-32530, train loss-2.0746, acc-0.4200, valid loss-2.0806, acc-0.4400, test loss-2.0626, acc-0.4517\n",
      "Iter-32540, train loss-2.0721, acc-0.3800, valid loss-2.0806, acc-0.4400, test loss-2.0625, acc-0.4519\n",
      "Iter-32550, train loss-2.0554, acc-0.4600, valid loss-2.0805, acc-0.4400, test loss-2.0625, acc-0.4518\n",
      "Iter-32560, train loss-2.0852, acc-0.4200, valid loss-2.0805, acc-0.4400, test loss-2.0624, acc-0.4518\n",
      "Iter-32570, train loss-2.0944, acc-0.4200, valid loss-2.0804, acc-0.4400, test loss-2.0624, acc-0.4517\n",
      "Iter-32580, train loss-2.1245, acc-0.3200, valid loss-2.0804, acc-0.4398, test loss-2.0623, acc-0.4517\n",
      "Iter-32590, train loss-2.0670, acc-0.4000, valid loss-2.0803, acc-0.4402, test loss-2.0622, acc-0.4518\n",
      "Iter-32600, train loss-2.0395, acc-0.5000, valid loss-2.0803, acc-0.4402, test loss-2.0622, acc-0.4516\n",
      "Iter-32610, train loss-2.1240, acc-0.3200, valid loss-2.0802, acc-0.4400, test loss-2.0621, acc-0.4517\n",
      "Iter-32620, train loss-2.0598, acc-0.3600, valid loss-2.0802, acc-0.4402, test loss-2.0621, acc-0.4517\n",
      "Iter-32630, train loss-2.1217, acc-0.3200, valid loss-2.0801, acc-0.4402, test loss-2.0620, acc-0.4518\n",
      "Iter-32640, train loss-2.0968, acc-0.4400, valid loss-2.0801, acc-0.4402, test loss-2.0620, acc-0.4519\n",
      "Iter-32650, train loss-2.0908, acc-0.4600, valid loss-2.0800, acc-0.4404, test loss-2.0619, acc-0.4520\n",
      "Iter-32660, train loss-2.0563, acc-0.3600, valid loss-2.0800, acc-0.4404, test loss-2.0618, acc-0.4519\n",
      "Iter-32670, train loss-2.0449, acc-0.4800, valid loss-2.0799, acc-0.4406, test loss-2.0618, acc-0.4519\n",
      "Iter-32680, train loss-2.0232, acc-0.5000, valid loss-2.0799, acc-0.4406, test loss-2.0617, acc-0.4520\n",
      "Iter-32690, train loss-2.1308, acc-0.3600, valid loss-2.0798, acc-0.4406, test loss-2.0617, acc-0.4522\n",
      "Iter-32700, train loss-2.0741, acc-0.4400, valid loss-2.0798, acc-0.4404, test loss-2.0616, acc-0.4523\n",
      "Iter-32710, train loss-2.1097, acc-0.4000, valid loss-2.0797, acc-0.4408, test loss-2.0616, acc-0.4522\n",
      "Iter-32720, train loss-2.0569, acc-0.4000, valid loss-2.0797, acc-0.4406, test loss-2.0615, acc-0.4520\n",
      "Iter-32730, train loss-2.0352, acc-0.4200, valid loss-2.0796, acc-0.4408, test loss-2.0615, acc-0.4522\n",
      "Iter-32740, train loss-2.1033, acc-0.3800, valid loss-2.0796, acc-0.4410, test loss-2.0614, acc-0.4522\n",
      "Iter-32750, train loss-2.0828, acc-0.3600, valid loss-2.0795, acc-0.4410, test loss-2.0613, acc-0.4521\n",
      "Iter-32760, train loss-2.0617, acc-0.4200, valid loss-2.0795, acc-0.4410, test loss-2.0613, acc-0.4521\n",
      "Iter-32770, train loss-2.0384, acc-0.5000, valid loss-2.0794, acc-0.4410, test loss-2.0612, acc-0.4521\n",
      "Iter-32780, train loss-2.1159, acc-0.4400, valid loss-2.0794, acc-0.4414, test loss-2.0612, acc-0.4522\n",
      "Iter-32790, train loss-2.0806, acc-0.4200, valid loss-2.0793, acc-0.4416, test loss-2.0611, acc-0.4524\n",
      "Iter-32800, train loss-2.1210, acc-0.4000, valid loss-2.0793, acc-0.4414, test loss-2.0611, acc-0.4519\n",
      "Iter-32810, train loss-2.0732, acc-0.4200, valid loss-2.0792, acc-0.4412, test loss-2.0610, acc-0.4523\n",
      "Iter-32820, train loss-2.0694, acc-0.4600, valid loss-2.0792, acc-0.4414, test loss-2.0610, acc-0.4521\n",
      "Iter-32830, train loss-2.0724, acc-0.5600, valid loss-2.0791, acc-0.4414, test loss-2.0609, acc-0.4521\n",
      "Iter-32840, train loss-2.0884, acc-0.3600, valid loss-2.0791, acc-0.4414, test loss-2.0608, acc-0.4523\n",
      "Iter-32850, train loss-2.0869, acc-0.3400, valid loss-2.0790, acc-0.4414, test loss-2.0608, acc-0.4523\n",
      "Iter-32860, train loss-2.0450, acc-0.4600, valid loss-2.0790, acc-0.4414, test loss-2.0607, acc-0.4524\n",
      "Iter-32870, train loss-2.1257, acc-0.4200, valid loss-2.0789, acc-0.4416, test loss-2.0607, acc-0.4524\n",
      "Iter-32880, train loss-2.1176, acc-0.3400, valid loss-2.0789, acc-0.4418, test loss-2.0606, acc-0.4524\n",
      "Iter-32890, train loss-2.0254, acc-0.5400, valid loss-2.0788, acc-0.4416, test loss-2.0606, acc-0.4525\n",
      "Iter-32900, train loss-2.1245, acc-0.3800, valid loss-2.0788, acc-0.4420, test loss-2.0605, acc-0.4527\n",
      "Iter-32910, train loss-2.0662, acc-0.5200, valid loss-2.0787, acc-0.4420, test loss-2.0604, acc-0.4528\n",
      "Iter-32920, train loss-2.0498, acc-0.5600, valid loss-2.0787, acc-0.4418, test loss-2.0604, acc-0.4526\n",
      "Iter-32930, train loss-2.0612, acc-0.4600, valid loss-2.0786, acc-0.4418, test loss-2.0603, acc-0.4525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-32940, train loss-2.1472, acc-0.3600, valid loss-2.0786, acc-0.4420, test loss-2.0603, acc-0.4527\n",
      "Iter-32950, train loss-2.0823, acc-0.4200, valid loss-2.0785, acc-0.4422, test loss-2.0602, acc-0.4526\n",
      "Iter-32960, train loss-2.1040, acc-0.3200, valid loss-2.0785, acc-0.4418, test loss-2.0602, acc-0.4529\n",
      "Iter-32970, train loss-2.0622, acc-0.5000, valid loss-2.0784, acc-0.4420, test loss-2.0601, acc-0.4530\n",
      "Iter-32980, train loss-2.0401, acc-0.4000, valid loss-2.0783, acc-0.4422, test loss-2.0600, acc-0.4530\n",
      "Iter-32990, train loss-2.0058, acc-0.4800, valid loss-2.0783, acc-0.4422, test loss-2.0600, acc-0.4531\n",
      "Iter-33000, train loss-2.0447, acc-0.5400, valid loss-2.0782, acc-0.4424, test loss-2.0599, acc-0.4532\n",
      "Iter-33010, train loss-2.0431, acc-0.5200, valid loss-2.0782, acc-0.4426, test loss-2.0599, acc-0.4531\n",
      "Iter-33020, train loss-2.1053, acc-0.4600, valid loss-2.0781, acc-0.4426, test loss-2.0598, acc-0.4530\n",
      "Iter-33030, train loss-2.0651, acc-0.5000, valid loss-2.0781, acc-0.4428, test loss-2.0598, acc-0.4532\n",
      "Iter-33040, train loss-2.0702, acc-0.3800, valid loss-2.0780, acc-0.4434, test loss-2.0597, acc-0.4535\n",
      "Iter-33050, train loss-2.0719, acc-0.4800, valid loss-2.0780, acc-0.4436, test loss-2.0597, acc-0.4535\n",
      "Iter-33060, train loss-2.0584, acc-0.3200, valid loss-2.0779, acc-0.4434, test loss-2.0596, acc-0.4536\n",
      "Iter-33070, train loss-2.0779, acc-0.4800, valid loss-2.0779, acc-0.4436, test loss-2.0595, acc-0.4537\n",
      "Iter-33080, train loss-2.1105, acc-0.4000, valid loss-2.0778, acc-0.4436, test loss-2.0595, acc-0.4537\n",
      "Iter-33090, train loss-2.0445, acc-0.5000, valid loss-2.0778, acc-0.4434, test loss-2.0594, acc-0.4539\n",
      "Iter-33100, train loss-2.0381, acc-0.5000, valid loss-2.0777, acc-0.4430, test loss-2.0594, acc-0.4538\n",
      "Iter-33110, train loss-2.0281, acc-0.5200, valid loss-2.0777, acc-0.4432, test loss-2.0593, acc-0.4538\n",
      "Iter-33120, train loss-2.0916, acc-0.3400, valid loss-2.0776, acc-0.4430, test loss-2.0593, acc-0.4540\n",
      "Iter-33130, train loss-2.0991, acc-0.5000, valid loss-2.0776, acc-0.4434, test loss-2.0592, acc-0.4539\n",
      "Iter-33140, train loss-2.0822, acc-0.4400, valid loss-2.0775, acc-0.4434, test loss-2.0591, acc-0.4543\n",
      "Iter-33150, train loss-2.0720, acc-0.4800, valid loss-2.0775, acc-0.4432, test loss-2.0591, acc-0.4543\n",
      "Iter-33160, train loss-2.1108, acc-0.4600, valid loss-2.0774, acc-0.4436, test loss-2.0590, acc-0.4542\n",
      "Iter-33170, train loss-2.0110, acc-0.5400, valid loss-2.0774, acc-0.4438, test loss-2.0590, acc-0.4543\n",
      "Iter-33180, train loss-2.0904, acc-0.4000, valid loss-2.0773, acc-0.4436, test loss-2.0589, acc-0.4545\n",
      "Iter-33190, train loss-2.1770, acc-0.2400, valid loss-2.0773, acc-0.4438, test loss-2.0589, acc-0.4544\n",
      "Iter-33200, train loss-2.0655, acc-0.3200, valid loss-2.0772, acc-0.4436, test loss-2.0588, acc-0.4543\n",
      "Iter-33210, train loss-2.0774, acc-0.3800, valid loss-2.0772, acc-0.4436, test loss-2.0588, acc-0.4544\n",
      "Iter-33220, train loss-2.0193, acc-0.5800, valid loss-2.0771, acc-0.4434, test loss-2.0587, acc-0.4545\n",
      "Iter-33230, train loss-2.0790, acc-0.4400, valid loss-2.0771, acc-0.4434, test loss-2.0586, acc-0.4546\n",
      "Iter-33240, train loss-2.0532, acc-0.4600, valid loss-2.0770, acc-0.4432, test loss-2.0586, acc-0.4547\n",
      "Iter-33250, train loss-2.0842, acc-0.3800, valid loss-2.0770, acc-0.4432, test loss-2.0585, acc-0.4548\n",
      "Iter-33260, train loss-2.0647, acc-0.5000, valid loss-2.0769, acc-0.4432, test loss-2.0585, acc-0.4548\n",
      "Iter-33270, train loss-2.0577, acc-0.5000, valid loss-2.0769, acc-0.4432, test loss-2.0584, acc-0.4548\n",
      "Iter-33280, train loss-2.0415, acc-0.4400, valid loss-2.0768, acc-0.4432, test loss-2.0584, acc-0.4549\n",
      "Iter-33290, train loss-2.0912, acc-0.5000, valid loss-2.0768, acc-0.4434, test loss-2.0583, acc-0.4551\n",
      "Iter-33300, train loss-2.0664, acc-0.4800, valid loss-2.0767, acc-0.4434, test loss-2.0582, acc-0.4553\n",
      "Iter-33310, train loss-2.0525, acc-0.4000, valid loss-2.0767, acc-0.4434, test loss-2.0582, acc-0.4553\n",
      "Iter-33320, train loss-1.9715, acc-0.6200, valid loss-2.0766, acc-0.4434, test loss-2.0581, acc-0.4553\n",
      "Iter-33330, train loss-2.0109, acc-0.4200, valid loss-2.0766, acc-0.4436, test loss-2.0581, acc-0.4554\n",
      "Iter-33340, train loss-2.1424, acc-0.3600, valid loss-2.0765, acc-0.4436, test loss-2.0580, acc-0.4554\n",
      "Iter-33350, train loss-2.0544, acc-0.4800, valid loss-2.0765, acc-0.4436, test loss-2.0580, acc-0.4554\n",
      "Iter-33360, train loss-2.1055, acc-0.3400, valid loss-2.0764, acc-0.4436, test loss-2.0579, acc-0.4553\n",
      "Iter-33370, train loss-2.0682, acc-0.4200, valid loss-2.0763, acc-0.4438, test loss-2.0579, acc-0.4554\n",
      "Iter-33380, train loss-2.0459, acc-0.4800, valid loss-2.0763, acc-0.4438, test loss-2.0578, acc-0.4556\n",
      "Iter-33390, train loss-2.1135, acc-0.3600, valid loss-2.0762, acc-0.4434, test loss-2.0577, acc-0.4555\n",
      "Iter-33400, train loss-2.0656, acc-0.4200, valid loss-2.0762, acc-0.4434, test loss-2.0577, acc-0.4556\n",
      "Iter-33410, train loss-2.1402, acc-0.3200, valid loss-2.0762, acc-0.4438, test loss-2.0576, acc-0.4559\n",
      "Iter-33420, train loss-2.1105, acc-0.3800, valid loss-2.0761, acc-0.4444, test loss-2.0576, acc-0.4559\n",
      "Iter-33430, train loss-2.1119, acc-0.2600, valid loss-2.0761, acc-0.4448, test loss-2.0575, acc-0.4557\n",
      "Iter-33440, train loss-2.0983, acc-0.4000, valid loss-2.0760, acc-0.4446, test loss-2.0575, acc-0.4557\n",
      "Iter-33450, train loss-2.0832, acc-0.4600, valid loss-2.0760, acc-0.4446, test loss-2.0574, acc-0.4558\n",
      "Iter-33460, train loss-2.0727, acc-0.4600, valid loss-2.0759, acc-0.4446, test loss-2.0573, acc-0.4556\n",
      "Iter-33470, train loss-2.0944, acc-0.4400, valid loss-2.0759, acc-0.4444, test loss-2.0573, acc-0.4557\n",
      "Iter-33480, train loss-2.0668, acc-0.3400, valid loss-2.0758, acc-0.4448, test loss-2.0572, acc-0.4558\n",
      "Iter-33490, train loss-2.0820, acc-0.4600, valid loss-2.0758, acc-0.4450, test loss-2.0572, acc-0.4557\n",
      "Iter-33500, train loss-2.0552, acc-0.5000, valid loss-2.0757, acc-0.4446, test loss-2.0571, acc-0.4557\n",
      "Iter-33510, train loss-2.0403, acc-0.4000, valid loss-2.0757, acc-0.4448, test loss-2.0571, acc-0.4558\n",
      "Iter-33520, train loss-2.0531, acc-0.5000, valid loss-2.0756, acc-0.4448, test loss-2.0570, acc-0.4558\n",
      "Iter-33530, train loss-2.0111, acc-0.5800, valid loss-2.0755, acc-0.4448, test loss-2.0570, acc-0.4556\n",
      "Iter-33540, train loss-2.0879, acc-0.4400, valid loss-2.0755, acc-0.4446, test loss-2.0569, acc-0.4556\n",
      "Iter-33550, train loss-2.0459, acc-0.5400, valid loss-2.0755, acc-0.4446, test loss-2.0569, acc-0.4555\n",
      "Iter-33560, train loss-2.0817, acc-0.4200, valid loss-2.0754, acc-0.4442, test loss-2.0568, acc-0.4557\n",
      "Iter-33570, train loss-2.0830, acc-0.4600, valid loss-2.0753, acc-0.4444, test loss-2.0567, acc-0.4556\n",
      "Iter-33580, train loss-2.0790, acc-0.4000, valid loss-2.0753, acc-0.4444, test loss-2.0567, acc-0.4557\n",
      "Iter-33590, train loss-2.1081, acc-0.4600, valid loss-2.0752, acc-0.4444, test loss-2.0566, acc-0.4559\n",
      "Iter-33600, train loss-2.0391, acc-0.5000, valid loss-2.0752, acc-0.4444, test loss-2.0566, acc-0.4561\n",
      "Iter-33610, train loss-2.0935, acc-0.4800, valid loss-2.0751, acc-0.4442, test loss-2.0565, acc-0.4560\n",
      "Iter-33620, train loss-2.0599, acc-0.4800, valid loss-2.0751, acc-0.4442, test loss-2.0565, acc-0.4560\n",
      "Iter-33630, train loss-2.0196, acc-0.6800, valid loss-2.0750, acc-0.4444, test loss-2.0564, acc-0.4559\n",
      "Iter-33640, train loss-2.0975, acc-0.3200, valid loss-2.0750, acc-0.4438, test loss-2.0563, acc-0.4561\n",
      "Iter-33650, train loss-2.0519, acc-0.5400, valid loss-2.0749, acc-0.4444, test loss-2.0563, acc-0.4560\n",
      "Iter-33660, train loss-2.1141, acc-0.3800, valid loss-2.0749, acc-0.4448, test loss-2.0562, acc-0.4562\n",
      "Iter-33670, train loss-2.0569, acc-0.5600, valid loss-2.0748, acc-0.4446, test loss-2.0562, acc-0.4558\n",
      "Iter-33680, train loss-2.0477, acc-0.5000, valid loss-2.0748, acc-0.4446, test loss-2.0561, acc-0.4561\n",
      "Iter-33690, train loss-2.1160, acc-0.3400, valid loss-2.0747, acc-0.4448, test loss-2.0561, acc-0.4563\n",
      "Iter-33700, train loss-2.0800, acc-0.4600, valid loss-2.0747, acc-0.4450, test loss-2.0560, acc-0.4562\n",
      "Iter-33710, train loss-2.0650, acc-0.4200, valid loss-2.0746, acc-0.4448, test loss-2.0559, acc-0.4559\n",
      "Iter-33720, train loss-2.1284, acc-0.3800, valid loss-2.0746, acc-0.4450, test loss-2.0559, acc-0.4560\n",
      "Iter-33730, train loss-2.0953, acc-0.3400, valid loss-2.0745, acc-0.4456, test loss-2.0558, acc-0.4563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-33740, train loss-2.1122, acc-0.3600, valid loss-2.0745, acc-0.4456, test loss-2.0558, acc-0.4560\n",
      "Iter-33750, train loss-2.0670, acc-0.4000, valid loss-2.0744, acc-0.4454, test loss-2.0557, acc-0.4562\n",
      "Iter-33760, train loss-2.0817, acc-0.4200, valid loss-2.0744, acc-0.4452, test loss-2.0557, acc-0.4562\n",
      "Iter-33770, train loss-2.0930, acc-0.4200, valid loss-2.0744, acc-0.4456, test loss-2.0556, acc-0.4561\n",
      "Iter-33780, train loss-2.0404, acc-0.3200, valid loss-2.0743, acc-0.4456, test loss-2.0556, acc-0.4562\n",
      "Iter-33790, train loss-2.0696, acc-0.3800, valid loss-2.0743, acc-0.4454, test loss-2.0555, acc-0.4564\n",
      "Iter-33800, train loss-2.0647, acc-0.4000, valid loss-2.0742, acc-0.4454, test loss-2.0555, acc-0.4564\n",
      "Iter-33810, train loss-2.0601, acc-0.4000, valid loss-2.0741, acc-0.4456, test loss-2.0554, acc-0.4565\n",
      "Iter-33820, train loss-2.0189, acc-0.4600, valid loss-2.0741, acc-0.4452, test loss-2.0554, acc-0.4565\n",
      "Iter-33830, train loss-2.0805, acc-0.4200, valid loss-2.0741, acc-0.4452, test loss-2.0553, acc-0.4565\n",
      "Iter-33840, train loss-2.0955, acc-0.4600, valid loss-2.0740, acc-0.4452, test loss-2.0552, acc-0.4566\n",
      "Iter-33850, train loss-2.0274, acc-0.4600, valid loss-2.0740, acc-0.4452, test loss-2.0552, acc-0.4570\n",
      "Iter-33860, train loss-2.0483, acc-0.4600, valid loss-2.0739, acc-0.4454, test loss-2.0551, acc-0.4570\n",
      "Iter-33870, train loss-2.0336, acc-0.4200, valid loss-2.0739, acc-0.4454, test loss-2.0551, acc-0.4568\n",
      "Iter-33880, train loss-2.0054, acc-0.6200, valid loss-2.0738, acc-0.4452, test loss-2.0550, acc-0.4571\n",
      "Iter-33890, train loss-2.0885, acc-0.2800, valid loss-2.0738, acc-0.4452, test loss-2.0550, acc-0.4568\n",
      "Iter-33900, train loss-2.0472, acc-0.6200, valid loss-2.0737, acc-0.4456, test loss-2.0549, acc-0.4568\n",
      "Iter-33910, train loss-2.0140, acc-0.4800, valid loss-2.0737, acc-0.4454, test loss-2.0548, acc-0.4571\n",
      "Iter-33920, train loss-2.0661, acc-0.4800, valid loss-2.0736, acc-0.4452, test loss-2.0548, acc-0.4571\n",
      "Iter-33930, train loss-2.1294, acc-0.3800, valid loss-2.0736, acc-0.4456, test loss-2.0547, acc-0.4571\n",
      "Iter-33940, train loss-2.1229, acc-0.4400, valid loss-2.0735, acc-0.4454, test loss-2.0547, acc-0.4572\n",
      "Iter-33950, train loss-2.1077, acc-0.3400, valid loss-2.0734, acc-0.4454, test loss-2.0546, acc-0.4571\n",
      "Iter-33960, train loss-2.0272, acc-0.5200, valid loss-2.0734, acc-0.4450, test loss-2.0546, acc-0.4573\n",
      "Iter-33970, train loss-2.0649, acc-0.3800, valid loss-2.0733, acc-0.4454, test loss-2.0545, acc-0.4575\n",
      "Iter-33980, train loss-2.0573, acc-0.5200, valid loss-2.0733, acc-0.4454, test loss-2.0545, acc-0.4577\n",
      "Iter-33990, train loss-2.0252, acc-0.5600, valid loss-2.0732, acc-0.4452, test loss-2.0544, acc-0.4577\n",
      "Iter-34000, train loss-2.0776, acc-0.4800, valid loss-2.0732, acc-0.4454, test loss-2.0543, acc-0.4581\n",
      "Iter-34010, train loss-2.0865, acc-0.3000, valid loss-2.0731, acc-0.4452, test loss-2.0543, acc-0.4579\n",
      "Iter-34020, train loss-2.0543, acc-0.4000, valid loss-2.0731, acc-0.4456, test loss-2.0542, acc-0.4579\n",
      "Iter-34030, train loss-2.1101, acc-0.3400, valid loss-2.0731, acc-0.4458, test loss-2.0542, acc-0.4579\n",
      "Iter-34040, train loss-2.0573, acc-0.4600, valid loss-2.0730, acc-0.4460, test loss-2.0541, acc-0.4579\n",
      "Iter-34050, train loss-2.0446, acc-0.5000, valid loss-2.0730, acc-0.4460, test loss-2.0541, acc-0.4579\n",
      "Iter-34060, train loss-2.1047, acc-0.4000, valid loss-2.0729, acc-0.4460, test loss-2.0540, acc-0.4577\n",
      "Iter-34070, train loss-2.0966, acc-0.3600, valid loss-2.0729, acc-0.4460, test loss-2.0540, acc-0.4576\n",
      "Iter-34080, train loss-2.0676, acc-0.3600, valid loss-2.0728, acc-0.4460, test loss-2.0539, acc-0.4577\n",
      "Iter-34090, train loss-2.0093, acc-0.5000, valid loss-2.0728, acc-0.4460, test loss-2.0539, acc-0.4576\n",
      "Iter-34100, train loss-2.0449, acc-0.5000, valid loss-2.0727, acc-0.4460, test loss-2.0538, acc-0.4576\n",
      "Iter-34110, train loss-2.0322, acc-0.4800, valid loss-2.0727, acc-0.4460, test loss-2.0537, acc-0.4575\n",
      "Iter-34120, train loss-2.0161, acc-0.5400, valid loss-2.0726, acc-0.4464, test loss-2.0537, acc-0.4574\n",
      "Iter-34130, train loss-2.0687, acc-0.4400, valid loss-2.0726, acc-0.4466, test loss-2.0536, acc-0.4572\n",
      "Iter-34140, train loss-2.0481, acc-0.4000, valid loss-2.0725, acc-0.4464, test loss-2.0536, acc-0.4574\n",
      "Iter-34150, train loss-2.1168, acc-0.3600, valid loss-2.0725, acc-0.4464, test loss-2.0535, acc-0.4572\n",
      "Iter-34160, train loss-2.1794, acc-0.3400, valid loss-2.0724, acc-0.4468, test loss-2.0535, acc-0.4574\n",
      "Iter-34170, train loss-2.0456, acc-0.4600, valid loss-2.0724, acc-0.4464, test loss-2.0534, acc-0.4571\n",
      "Iter-34180, train loss-2.0438, acc-0.4800, valid loss-2.0723, acc-0.4468, test loss-2.0534, acc-0.4571\n",
      "Iter-34190, train loss-2.0315, acc-0.4400, valid loss-2.0723, acc-0.4468, test loss-2.0533, acc-0.4570\n",
      "Iter-34200, train loss-2.0564, acc-0.5200, valid loss-2.0722, acc-0.4466, test loss-2.0532, acc-0.4573\n",
      "Iter-34210, train loss-2.0599, acc-0.5200, valid loss-2.0722, acc-0.4468, test loss-2.0532, acc-0.4572\n",
      "Iter-34220, train loss-2.0706, acc-0.4000, valid loss-2.0721, acc-0.4468, test loss-2.0531, acc-0.4572\n",
      "Iter-34230, train loss-2.0387, acc-0.3600, valid loss-2.0721, acc-0.4468, test loss-2.0531, acc-0.4576\n",
      "Iter-34240, train loss-2.1084, acc-0.3600, valid loss-2.0720, acc-0.4470, test loss-2.0530, acc-0.4579\n",
      "Iter-34250, train loss-2.0548, acc-0.4800, valid loss-2.0720, acc-0.4470, test loss-2.0530, acc-0.4578\n",
      "Iter-34260, train loss-2.0403, acc-0.5200, valid loss-2.0719, acc-0.4470, test loss-2.0529, acc-0.4578\n",
      "Iter-34270, train loss-2.0889, acc-0.3000, valid loss-2.0719, acc-0.4468, test loss-2.0529, acc-0.4576\n",
      "Iter-34280, train loss-2.0454, acc-0.4800, valid loss-2.0718, acc-0.4470, test loss-2.0528, acc-0.4577\n",
      "Iter-34290, train loss-2.0537, acc-0.4800, valid loss-2.0718, acc-0.4472, test loss-2.0527, acc-0.4579\n",
      "Iter-34300, train loss-2.0896, acc-0.4400, valid loss-2.0717, acc-0.4474, test loss-2.0527, acc-0.4581\n",
      "Iter-34310, train loss-2.1000, acc-0.4000, valid loss-2.0717, acc-0.4474, test loss-2.0526, acc-0.4582\n",
      "Iter-34320, train loss-2.0059, acc-0.5400, valid loss-2.0716, acc-0.4474, test loss-2.0526, acc-0.4582\n",
      "Iter-34330, train loss-2.0886, acc-0.4000, valid loss-2.0716, acc-0.4474, test loss-2.0525, acc-0.4583\n",
      "Iter-34340, train loss-2.0233, acc-0.5000, valid loss-2.0715, acc-0.4472, test loss-2.0525, acc-0.4584\n",
      "Iter-34350, train loss-2.0164, acc-0.5600, valid loss-2.0714, acc-0.4474, test loss-2.0524, acc-0.4583\n",
      "Iter-34360, train loss-2.0691, acc-0.4400, valid loss-2.0714, acc-0.4476, test loss-2.0524, acc-0.4583\n",
      "Iter-34370, train loss-2.0961, acc-0.4200, valid loss-2.0713, acc-0.4474, test loss-2.0523, acc-0.4584\n",
      "Iter-34380, train loss-2.0383, acc-0.4400, valid loss-2.0713, acc-0.4474, test loss-2.0522, acc-0.4584\n",
      "Iter-34390, train loss-2.0764, acc-0.4800, valid loss-2.0712, acc-0.4478, test loss-2.0522, acc-0.4586\n",
      "Iter-34400, train loss-2.0781, acc-0.4400, valid loss-2.0712, acc-0.4478, test loss-2.0521, acc-0.4587\n",
      "Iter-34410, train loss-2.0456, acc-0.4400, valid loss-2.0711, acc-0.4476, test loss-2.0521, acc-0.4586\n",
      "Iter-34420, train loss-2.0994, acc-0.3200, valid loss-2.0711, acc-0.4474, test loss-2.0520, acc-0.4586\n",
      "Iter-34430, train loss-2.0598, acc-0.5200, valid loss-2.0711, acc-0.4474, test loss-2.0520, acc-0.4585\n",
      "Iter-34440, train loss-2.1023, acc-0.5200, valid loss-2.0710, acc-0.4474, test loss-2.0519, acc-0.4583\n",
      "Iter-34450, train loss-2.0882, acc-0.4600, valid loss-2.0710, acc-0.4476, test loss-2.0519, acc-0.4583\n",
      "Iter-34460, train loss-2.0876, acc-0.4200, valid loss-2.0709, acc-0.4474, test loss-2.0518, acc-0.4583\n",
      "Iter-34470, train loss-2.0357, acc-0.4600, valid loss-2.0709, acc-0.4474, test loss-2.0518, acc-0.4583\n",
      "Iter-34480, train loss-2.1058, acc-0.4400, valid loss-2.0708, acc-0.4480, test loss-2.0517, acc-0.4583\n",
      "Iter-34490, train loss-2.0671, acc-0.4200, valid loss-2.0708, acc-0.4480, test loss-2.0516, acc-0.4586\n",
      "Iter-34500, train loss-2.0791, acc-0.5400, valid loss-2.0707, acc-0.4476, test loss-2.0516, acc-0.4586\n",
      "Iter-34510, train loss-2.0675, acc-0.3400, valid loss-2.0707, acc-0.4476, test loss-2.0515, acc-0.4587\n",
      "Iter-34520, train loss-2.0370, acc-0.4800, valid loss-2.0706, acc-0.4474, test loss-2.0515, acc-0.4587\n",
      "Iter-34530, train loss-2.0132, acc-0.5200, valid loss-2.0706, acc-0.4476, test loss-2.0514, acc-0.4588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-34540, train loss-2.0302, acc-0.5600, valid loss-2.0705, acc-0.4476, test loss-2.0514, acc-0.4589\n",
      "Iter-34550, train loss-2.0226, acc-0.5000, valid loss-2.0705, acc-0.4474, test loss-2.0513, acc-0.4589\n",
      "Iter-34560, train loss-2.0381, acc-0.4600, valid loss-2.0704, acc-0.4474, test loss-2.0513, acc-0.4588\n",
      "Iter-34570, train loss-2.0612, acc-0.5000, valid loss-2.0704, acc-0.4474, test loss-2.0512, acc-0.4589\n",
      "Iter-34580, train loss-2.0377, acc-0.5200, valid loss-2.0703, acc-0.4474, test loss-2.0511, acc-0.4591\n",
      "Iter-34590, train loss-2.0208, acc-0.4800, valid loss-2.0703, acc-0.4484, test loss-2.0511, acc-0.4592\n",
      "Iter-34600, train loss-2.0741, acc-0.4200, valid loss-2.0702, acc-0.4474, test loss-2.0510, acc-0.4592\n",
      "Iter-34610, train loss-2.0747, acc-0.4000, valid loss-2.0702, acc-0.4484, test loss-2.0510, acc-0.4591\n",
      "Iter-34620, train loss-2.0664, acc-0.4400, valid loss-2.0701, acc-0.4478, test loss-2.0509, acc-0.4591\n",
      "Iter-34630, train loss-2.0357, acc-0.4600, valid loss-2.0701, acc-0.4476, test loss-2.0509, acc-0.4590\n",
      "Iter-34640, train loss-2.0769, acc-0.5400, valid loss-2.0700, acc-0.4478, test loss-2.0508, acc-0.4592\n",
      "Iter-34650, train loss-2.0540, acc-0.4400, valid loss-2.0700, acc-0.4488, test loss-2.0508, acc-0.4594\n",
      "Iter-34660, train loss-2.0121, acc-0.5600, valid loss-2.0699, acc-0.4488, test loss-2.0507, acc-0.4596\n",
      "Iter-34670, train loss-2.0840, acc-0.3600, valid loss-2.0699, acc-0.4484, test loss-2.0506, acc-0.4596\n",
      "Iter-34680, train loss-2.0485, acc-0.5400, valid loss-2.0698, acc-0.4486, test loss-2.0506, acc-0.4596\n",
      "Iter-34690, train loss-2.0639, acc-0.4600, valid loss-2.0698, acc-0.4486, test loss-2.0505, acc-0.4597\n",
      "Iter-34700, train loss-2.0652, acc-0.4200, valid loss-2.0697, acc-0.4486, test loss-2.0505, acc-0.4596\n",
      "Iter-34710, train loss-2.0513, acc-0.4800, valid loss-2.0697, acc-0.4488, test loss-2.0504, acc-0.4598\n",
      "Iter-34720, train loss-2.0657, acc-0.3600, valid loss-2.0696, acc-0.4486, test loss-2.0504, acc-0.4602\n",
      "Iter-34730, train loss-2.0086, acc-0.5200, valid loss-2.0696, acc-0.4486, test loss-2.0503, acc-0.4601\n",
      "Iter-34740, train loss-2.0860, acc-0.5000, valid loss-2.0695, acc-0.4486, test loss-2.0503, acc-0.4598\n",
      "Iter-34750, train loss-2.0563, acc-0.4400, valid loss-2.0695, acc-0.4490, test loss-2.0502, acc-0.4601\n",
      "Iter-34760, train loss-2.0351, acc-0.4400, valid loss-2.0694, acc-0.4490, test loss-2.0502, acc-0.4598\n",
      "Iter-34770, train loss-2.1652, acc-0.3600, valid loss-2.0694, acc-0.4490, test loss-2.0501, acc-0.4599\n",
      "Iter-34780, train loss-2.0453, acc-0.5200, valid loss-2.0693, acc-0.4486, test loss-2.0500, acc-0.4599\n",
      "Iter-34790, train loss-2.0545, acc-0.4600, valid loss-2.0693, acc-0.4486, test loss-2.0500, acc-0.4602\n",
      "Iter-34800, train loss-2.0189, acc-0.5400, valid loss-2.0692, acc-0.4488, test loss-2.0499, acc-0.4601\n",
      "Iter-34810, train loss-2.0404, acc-0.3400, valid loss-2.0692, acc-0.4488, test loss-2.0499, acc-0.4602\n",
      "Iter-34820, train loss-2.0012, acc-0.4800, valid loss-2.0691, acc-0.4490, test loss-2.0498, acc-0.4601\n",
      "Iter-34830, train loss-2.0459, acc-0.4800, valid loss-2.0691, acc-0.4490, test loss-2.0498, acc-0.4603\n",
      "Iter-34840, train loss-2.0362, acc-0.4000, valid loss-2.0690, acc-0.4490, test loss-2.0497, acc-0.4601\n",
      "Iter-34850, train loss-2.0710, acc-0.3400, valid loss-2.0690, acc-0.4488, test loss-2.0497, acc-0.4603\n",
      "Iter-34860, train loss-2.0946, acc-0.3800, valid loss-2.0689, acc-0.4492, test loss-2.0496, acc-0.4606\n",
      "Iter-34870, train loss-2.0567, acc-0.4800, valid loss-2.0689, acc-0.4488, test loss-2.0496, acc-0.4602\n",
      "Iter-34880, train loss-2.0542, acc-0.4000, valid loss-2.0688, acc-0.4488, test loss-2.0495, acc-0.4599\n",
      "Iter-34890, train loss-2.0454, acc-0.4400, valid loss-2.0688, acc-0.4486, test loss-2.0495, acc-0.4599\n",
      "Iter-34900, train loss-2.0346, acc-0.5000, valid loss-2.0687, acc-0.4488, test loss-2.0494, acc-0.4600\n",
      "Iter-34910, train loss-2.0840, acc-0.4200, valid loss-2.0687, acc-0.4488, test loss-2.0493, acc-0.4603\n",
      "Iter-34920, train loss-2.0446, acc-0.4400, valid loss-2.0686, acc-0.4488, test loss-2.0493, acc-0.4600\n",
      "Iter-34930, train loss-2.0522, acc-0.4400, valid loss-2.0686, acc-0.4480, test loss-2.0492, acc-0.4601\n",
      "Iter-34940, train loss-2.0559, acc-0.5400, valid loss-2.0685, acc-0.4480, test loss-2.0492, acc-0.4601\n",
      "Iter-34950, train loss-2.0292, acc-0.4800, valid loss-2.0685, acc-0.4480, test loss-2.0491, acc-0.4599\n",
      "Iter-34960, train loss-2.0124, acc-0.4400, valid loss-2.0684, acc-0.4484, test loss-2.0491, acc-0.4602\n",
      "Iter-34970, train loss-2.0522, acc-0.4800, valid loss-2.0684, acc-0.4484, test loss-2.0490, acc-0.4600\n",
      "Iter-34980, train loss-2.0717, acc-0.3600, valid loss-2.0683, acc-0.4482, test loss-2.0490, acc-0.4597\n",
      "Iter-34990, train loss-2.1007, acc-0.4800, valid loss-2.0683, acc-0.4484, test loss-2.0489, acc-0.4597\n",
      "Iter-35000, train loss-2.0786, acc-0.3400, valid loss-2.0682, acc-0.4482, test loss-2.0489, acc-0.4598\n",
      "Iter-35010, train loss-2.0929, acc-0.4000, valid loss-2.0682, acc-0.4482, test loss-2.0488, acc-0.4599\n",
      "Iter-35020, train loss-2.1048, acc-0.3800, valid loss-2.0681, acc-0.4484, test loss-2.0487, acc-0.4601\n",
      "Iter-35030, train loss-2.1484, acc-0.2800, valid loss-2.0681, acc-0.4484, test loss-2.0487, acc-0.4600\n",
      "Iter-35040, train loss-2.0619, acc-0.5600, valid loss-2.0680, acc-0.4488, test loss-2.0486, acc-0.4601\n",
      "Iter-35050, train loss-2.0387, acc-0.4600, valid loss-2.0680, acc-0.4486, test loss-2.0486, acc-0.4600\n",
      "Iter-35060, train loss-2.0500, acc-0.4600, valid loss-2.0680, acc-0.4488, test loss-2.0485, acc-0.4604\n",
      "Iter-35070, train loss-2.0528, acc-0.3800, valid loss-2.0679, acc-0.4486, test loss-2.0485, acc-0.4606\n",
      "Iter-35080, train loss-2.0678, acc-0.4800, valid loss-2.0679, acc-0.4484, test loss-2.0484, acc-0.4603\n",
      "Iter-35090, train loss-2.0587, acc-0.4800, valid loss-2.0678, acc-0.4490, test loss-2.0484, acc-0.4604\n",
      "Iter-35100, train loss-2.0291, acc-0.5000, valid loss-2.0678, acc-0.4488, test loss-2.0483, acc-0.4606\n",
      "Iter-35110, train loss-2.0092, acc-0.4800, valid loss-2.0677, acc-0.4490, test loss-2.0483, acc-0.4603\n",
      "Iter-35120, train loss-2.0635, acc-0.4200, valid loss-2.0677, acc-0.4488, test loss-2.0482, acc-0.4605\n",
      "Iter-35130, train loss-2.0301, acc-0.4600, valid loss-2.0676, acc-0.4488, test loss-2.0481, acc-0.4604\n",
      "Iter-35140, train loss-2.0380, acc-0.5000, valid loss-2.0675, acc-0.4488, test loss-2.0481, acc-0.4606\n",
      "Iter-35150, train loss-2.0512, acc-0.5200, valid loss-2.0675, acc-0.4486, test loss-2.0480, acc-0.4605\n",
      "Iter-35160, train loss-2.0529, acc-0.5000, valid loss-2.0674, acc-0.4488, test loss-2.0480, acc-0.4604\n",
      "Iter-35170, train loss-2.0442, acc-0.5000, valid loss-2.0674, acc-0.4490, test loss-2.0479, acc-0.4606\n",
      "Iter-35180, train loss-1.9912, acc-0.4800, valid loss-2.0673, acc-0.4494, test loss-2.0479, acc-0.4608\n",
      "Iter-35190, train loss-2.0391, acc-0.5600, valid loss-2.0673, acc-0.4494, test loss-2.0478, acc-0.4604\n",
      "Iter-35200, train loss-1.9943, acc-0.5200, valid loss-2.0672, acc-0.4492, test loss-2.0478, acc-0.4602\n",
      "Iter-35210, train loss-2.0013, acc-0.5800, valid loss-2.0672, acc-0.4494, test loss-2.0477, acc-0.4603\n",
      "Iter-35220, train loss-2.0634, acc-0.4600, valid loss-2.0671, acc-0.4492, test loss-2.0476, acc-0.4605\n",
      "Iter-35230, train loss-2.0211, acc-0.5000, valid loss-2.0671, acc-0.4490, test loss-2.0476, acc-0.4603\n",
      "Iter-35240, train loss-2.0625, acc-0.4000, valid loss-2.0670, acc-0.4492, test loss-2.0475, acc-0.4606\n",
      "Iter-35250, train loss-2.0884, acc-0.4200, valid loss-2.0670, acc-0.4494, test loss-2.0475, acc-0.4603\n",
      "Iter-35260, train loss-2.0805, acc-0.5200, valid loss-2.0669, acc-0.4494, test loss-2.0474, acc-0.4604\n",
      "Iter-35270, train loss-2.0850, acc-0.3800, valid loss-2.0669, acc-0.4494, test loss-2.0474, acc-0.4606\n",
      "Iter-35280, train loss-2.0236, acc-0.5400, valid loss-2.0668, acc-0.4494, test loss-2.0473, acc-0.4604\n",
      "Iter-35290, train loss-2.1031, acc-0.3800, valid loss-2.0668, acc-0.4492, test loss-2.0473, acc-0.4606\n",
      "Iter-35300, train loss-2.0534, acc-0.3600, valid loss-2.0667, acc-0.4494, test loss-2.0472, acc-0.4608\n",
      "Iter-35310, train loss-2.0768, acc-0.3800, valid loss-2.0667, acc-0.4492, test loss-2.0471, acc-0.4606\n",
      "Iter-35320, train loss-2.0803, acc-0.4400, valid loss-2.0666, acc-0.4490, test loss-2.0471, acc-0.4605\n",
      "Iter-35330, train loss-2.0075, acc-0.5000, valid loss-2.0666, acc-0.4494, test loss-2.0470, acc-0.4607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-35340, train loss-2.0888, acc-0.2800, valid loss-2.0665, acc-0.4492, test loss-2.0470, acc-0.4603\n",
      "Iter-35350, train loss-2.1081, acc-0.3800, valid loss-2.0665, acc-0.4488, test loss-2.0469, acc-0.4603\n",
      "Iter-35360, train loss-2.0638, acc-0.4200, valid loss-2.0664, acc-0.4492, test loss-2.0469, acc-0.4606\n",
      "Iter-35370, train loss-2.0326, acc-0.4400, valid loss-2.0664, acc-0.4490, test loss-2.0468, acc-0.4604\n",
      "Iter-35380, train loss-2.0243, acc-0.4800, valid loss-2.0663, acc-0.4490, test loss-2.0468, acc-0.4605\n",
      "Iter-35390, train loss-2.0534, acc-0.5200, valid loss-2.0663, acc-0.4490, test loss-2.0467, acc-0.4606\n",
      "Iter-35400, train loss-2.0319, acc-0.5200, valid loss-2.0662, acc-0.4490, test loss-2.0467, acc-0.4605\n",
      "Iter-35410, train loss-2.0400, acc-0.4600, valid loss-2.0662, acc-0.4488, test loss-2.0466, acc-0.4604\n",
      "Iter-35420, train loss-2.0931, acc-0.4200, valid loss-2.0661, acc-0.4488, test loss-2.0465, acc-0.4607\n",
      "Iter-35430, train loss-2.0729, acc-0.4000, valid loss-2.0661, acc-0.4492, test loss-2.0465, acc-0.4607\n",
      "Iter-35440, train loss-2.0226, acc-0.5600, valid loss-2.0660, acc-0.4492, test loss-2.0464, acc-0.4609\n",
      "Iter-35450, train loss-2.0429, acc-0.4200, valid loss-2.0660, acc-0.4498, test loss-2.0464, acc-0.4611\n",
      "Iter-35460, train loss-2.0243, acc-0.5400, valid loss-2.0660, acc-0.4494, test loss-2.0463, acc-0.4611\n",
      "Iter-35470, train loss-2.0476, acc-0.4600, valid loss-2.0659, acc-0.4490, test loss-2.0463, acc-0.4609\n",
      "Iter-35480, train loss-2.0865, acc-0.3800, valid loss-2.0659, acc-0.4490, test loss-2.0462, acc-0.4609\n",
      "Iter-35490, train loss-2.0519, acc-0.4200, valid loss-2.0658, acc-0.4490, test loss-2.0462, acc-0.4608\n",
      "Iter-35500, train loss-2.1045, acc-0.3600, valid loss-2.0658, acc-0.4492, test loss-2.0461, acc-0.4612\n",
      "Iter-35510, train loss-2.0472, acc-0.4600, valid loss-2.0657, acc-0.4492, test loss-2.0461, acc-0.4612\n",
      "Iter-35520, train loss-2.0754, acc-0.4800, valid loss-2.0657, acc-0.4492, test loss-2.0460, acc-0.4611\n",
      "Iter-35530, train loss-2.0777, acc-0.4600, valid loss-2.0656, acc-0.4492, test loss-2.0459, acc-0.4609\n",
      "Iter-35540, train loss-2.1185, acc-0.3600, valid loss-2.0656, acc-0.4496, test loss-2.0459, acc-0.4610\n",
      "Iter-35550, train loss-2.1162, acc-0.4400, valid loss-2.0655, acc-0.4496, test loss-2.0458, acc-0.4610\n",
      "Iter-35560, train loss-2.0366, acc-0.3800, valid loss-2.0655, acc-0.4492, test loss-2.0458, acc-0.4609\n",
      "Iter-35570, train loss-2.0883, acc-0.5000, valid loss-2.0654, acc-0.4494, test loss-2.0457, acc-0.4608\n",
      "Iter-35580, train loss-2.0865, acc-0.3800, valid loss-2.0654, acc-0.4496, test loss-2.0457, acc-0.4611\n",
      "Iter-35590, train loss-2.0802, acc-0.4000, valid loss-2.0653, acc-0.4494, test loss-2.0456, acc-0.4615\n",
      "Iter-35600, train loss-2.1043, acc-0.4200, valid loss-2.0653, acc-0.4498, test loss-2.0456, acc-0.4615\n",
      "Iter-35610, train loss-1.9956, acc-0.5800, valid loss-2.0652, acc-0.4496, test loss-2.0455, acc-0.4614\n",
      "Iter-35620, train loss-2.0816, acc-0.5400, valid loss-2.0652, acc-0.4498, test loss-2.0455, acc-0.4618\n",
      "Iter-35630, train loss-2.0414, acc-0.5000, valid loss-2.0651, acc-0.4496, test loss-2.0454, acc-0.4619\n",
      "Iter-35640, train loss-2.1450, acc-0.3000, valid loss-2.0651, acc-0.4500, test loss-2.0453, acc-0.4618\n",
      "Iter-35650, train loss-2.0848, acc-0.4800, valid loss-2.0650, acc-0.4502, test loss-2.0453, acc-0.4620\n",
      "Iter-35660, train loss-2.0695, acc-0.4600, valid loss-2.0650, acc-0.4504, test loss-2.0452, acc-0.4621\n",
      "Iter-35670, train loss-2.0365, acc-0.5000, valid loss-2.0649, acc-0.4504, test loss-2.0452, acc-0.4620\n",
      "Iter-35680, train loss-2.0571, acc-0.4800, valid loss-2.0649, acc-0.4504, test loss-2.0451, acc-0.4623\n",
      "Iter-35690, train loss-2.0495, acc-0.4600, valid loss-2.0648, acc-0.4504, test loss-2.0451, acc-0.4623\n",
      "Iter-35700, train loss-2.0280, acc-0.4000, valid loss-2.0648, acc-0.4502, test loss-2.0450, acc-0.4621\n",
      "Iter-35710, train loss-2.0323, acc-0.5000, valid loss-2.0647, acc-0.4506, test loss-2.0450, acc-0.4623\n",
      "Iter-35720, train loss-2.0580, acc-0.4400, valid loss-2.0647, acc-0.4500, test loss-2.0449, acc-0.4623\n",
      "Iter-35730, train loss-2.0590, acc-0.4800, valid loss-2.0646, acc-0.4498, test loss-2.0449, acc-0.4624\n",
      "Iter-35740, train loss-2.1475, acc-0.3200, valid loss-2.0646, acc-0.4500, test loss-2.0448, acc-0.4623\n",
      "Iter-35750, train loss-2.0732, acc-0.3000, valid loss-2.0645, acc-0.4502, test loss-2.0448, acc-0.4623\n",
      "Iter-35760, train loss-2.0218, acc-0.5400, valid loss-2.0645, acc-0.4500, test loss-2.0447, acc-0.4623\n",
      "Iter-35770, train loss-2.0667, acc-0.4200, valid loss-2.0644, acc-0.4500, test loss-2.0446, acc-0.4623\n",
      "Iter-35780, train loss-2.0827, acc-0.4000, valid loss-2.0644, acc-0.4502, test loss-2.0446, acc-0.4621\n",
      "Iter-35790, train loss-1.9675, acc-0.5400, valid loss-2.0643, acc-0.4504, test loss-2.0445, acc-0.4622\n",
      "Iter-35800, train loss-2.1119, acc-0.3600, valid loss-2.0643, acc-0.4506, test loss-2.0445, acc-0.4624\n",
      "Iter-35810, train loss-2.0857, acc-0.4600, valid loss-2.0642, acc-0.4502, test loss-2.0444, acc-0.4624\n",
      "Iter-35820, train loss-2.0881, acc-0.4000, valid loss-2.0642, acc-0.4502, test loss-2.0444, acc-0.4624\n",
      "Iter-35830, train loss-2.0198, acc-0.5600, valid loss-2.0641, acc-0.4502, test loss-2.0443, acc-0.4624\n",
      "Iter-35840, train loss-2.0502, acc-0.4200, valid loss-2.0641, acc-0.4500, test loss-2.0443, acc-0.4623\n",
      "Iter-35850, train loss-2.0187, acc-0.4800, valid loss-2.0640, acc-0.4502, test loss-2.0442, acc-0.4624\n",
      "Iter-35860, train loss-2.0426, acc-0.4600, valid loss-2.0640, acc-0.4506, test loss-2.0442, acc-0.4626\n",
      "Iter-35870, train loss-2.0336, acc-0.4200, valid loss-2.0639, acc-0.4506, test loss-2.0441, acc-0.4622\n",
      "Iter-35880, train loss-2.0384, acc-0.4600, valid loss-2.0639, acc-0.4506, test loss-2.0440, acc-0.4626\n",
      "Iter-35890, train loss-2.0766, acc-0.5200, valid loss-2.0638, acc-0.4508, test loss-2.0440, acc-0.4625\n",
      "Iter-35900, train loss-2.1010, acc-0.4600, valid loss-2.0638, acc-0.4508, test loss-2.0439, acc-0.4625\n",
      "Iter-35910, train loss-2.1080, acc-0.3200, valid loss-2.0638, acc-0.4508, test loss-2.0439, acc-0.4626\n",
      "Iter-35920, train loss-2.0506, acc-0.5200, valid loss-2.0637, acc-0.4514, test loss-2.0438, acc-0.4627\n",
      "Iter-35930, train loss-2.1123, acc-0.3000, valid loss-2.0637, acc-0.4516, test loss-2.0438, acc-0.4627\n",
      "Iter-35940, train loss-2.0824, acc-0.4000, valid loss-2.0636, acc-0.4516, test loss-2.0437, acc-0.4629\n",
      "Iter-35950, train loss-2.0243, acc-0.6200, valid loss-2.0636, acc-0.4518, test loss-2.0437, acc-0.4627\n",
      "Iter-35960, train loss-2.0475, acc-0.4800, valid loss-2.0635, acc-0.4514, test loss-2.0436, acc-0.4628\n",
      "Iter-35970, train loss-2.0533, acc-0.5400, valid loss-2.0635, acc-0.4510, test loss-2.0436, acc-0.4627\n",
      "Iter-35980, train loss-2.0713, acc-0.4600, valid loss-2.0634, acc-0.4510, test loss-2.0435, acc-0.4628\n",
      "Iter-35990, train loss-2.0802, acc-0.4200, valid loss-2.0634, acc-0.4512, test loss-2.0435, acc-0.4628\n",
      "Iter-36000, train loss-2.0932, acc-0.3800, valid loss-2.0633, acc-0.4514, test loss-2.0434, acc-0.4627\n",
      "Iter-36010, train loss-2.0374, acc-0.4800, valid loss-2.0633, acc-0.4514, test loss-2.0434, acc-0.4628\n",
      "Iter-36020, train loss-2.1157, acc-0.3600, valid loss-2.0632, acc-0.4514, test loss-2.0433, acc-0.4627\n",
      "Iter-36030, train loss-2.0152, acc-0.5000, valid loss-2.0632, acc-0.4516, test loss-2.0432, acc-0.4628\n",
      "Iter-36040, train loss-2.0882, acc-0.4400, valid loss-2.0631, acc-0.4512, test loss-2.0432, acc-0.4630\n",
      "Iter-36050, train loss-2.0606, acc-0.4000, valid loss-2.0631, acc-0.4512, test loss-2.0431, acc-0.4631\n",
      "Iter-36060, train loss-2.0813, acc-0.3600, valid loss-2.0630, acc-0.4512, test loss-2.0431, acc-0.4632\n",
      "Iter-36070, train loss-2.0557, acc-0.5200, valid loss-2.0630, acc-0.4510, test loss-2.0430, acc-0.4632\n",
      "Iter-36080, train loss-2.0854, acc-0.4400, valid loss-2.0629, acc-0.4510, test loss-2.0430, acc-0.4630\n",
      "Iter-36090, train loss-2.0683, acc-0.4000, valid loss-2.0629, acc-0.4508, test loss-2.0429, acc-0.4630\n",
      "Iter-36100, train loss-2.1027, acc-0.3800, valid loss-2.0628, acc-0.4510, test loss-2.0429, acc-0.4632\n",
      "Iter-36110, train loss-2.0342, acc-0.4400, valid loss-2.0628, acc-0.4510, test loss-2.0428, acc-0.4633\n",
      "Iter-36120, train loss-2.0663, acc-0.4200, valid loss-2.0627, acc-0.4510, test loss-2.0428, acc-0.4632\n",
      "Iter-36130, train loss-2.0765, acc-0.4000, valid loss-2.0627, acc-0.4512, test loss-2.0427, acc-0.4631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-36140, train loss-2.0379, acc-0.4600, valid loss-2.0626, acc-0.4514, test loss-2.0427, acc-0.4634\n",
      "Iter-36150, train loss-2.0428, acc-0.4600, valid loss-2.0626, acc-0.4514, test loss-2.0426, acc-0.4634\n",
      "Iter-36160, train loss-2.0331, acc-0.5000, valid loss-2.0625, acc-0.4514, test loss-2.0426, acc-0.4634\n",
      "Iter-36170, train loss-2.0156, acc-0.4000, valid loss-2.0625, acc-0.4508, test loss-2.0425, acc-0.4635\n",
      "Iter-36180, train loss-2.0435, acc-0.4800, valid loss-2.0624, acc-0.4510, test loss-2.0424, acc-0.4638\n",
      "Iter-36190, train loss-2.0339, acc-0.5000, valid loss-2.0624, acc-0.4510, test loss-2.0424, acc-0.4638\n",
      "Iter-36200, train loss-2.0722, acc-0.4200, valid loss-2.0623, acc-0.4514, test loss-2.0423, acc-0.4640\n",
      "Iter-36210, train loss-2.0981, acc-0.3200, valid loss-2.0623, acc-0.4516, test loss-2.0423, acc-0.4638\n",
      "Iter-36220, train loss-2.0408, acc-0.4400, valid loss-2.0622, acc-0.4514, test loss-2.0422, acc-0.4638\n",
      "Iter-36230, train loss-1.9945, acc-0.5800, valid loss-2.0622, acc-0.4516, test loss-2.0422, acc-0.4636\n",
      "Iter-36240, train loss-2.0687, acc-0.4400, valid loss-2.0621, acc-0.4514, test loss-2.0421, acc-0.4640\n",
      "Iter-36250, train loss-2.0462, acc-0.4200, valid loss-2.0621, acc-0.4514, test loss-2.0421, acc-0.4641\n",
      "Iter-36260, train loss-2.0384, acc-0.4400, valid loss-2.0620, acc-0.4514, test loss-2.0420, acc-0.4640\n",
      "Iter-36270, train loss-2.0369, acc-0.5400, valid loss-2.0620, acc-0.4516, test loss-2.0419, acc-0.4641\n",
      "Iter-36280, train loss-2.0436, acc-0.4400, valid loss-2.0619, acc-0.4514, test loss-2.0419, acc-0.4643\n",
      "Iter-36290, train loss-2.0628, acc-0.3800, valid loss-2.0619, acc-0.4520, test loss-2.0418, acc-0.4643\n",
      "Iter-36300, train loss-2.0819, acc-0.4400, valid loss-2.0618, acc-0.4514, test loss-2.0418, acc-0.4641\n",
      "Iter-36310, train loss-2.0558, acc-0.5000, valid loss-2.0618, acc-0.4516, test loss-2.0417, acc-0.4638\n",
      "Iter-36320, train loss-2.0230, acc-0.5800, valid loss-2.0617, acc-0.4516, test loss-2.0417, acc-0.4638\n",
      "Iter-36330, train loss-2.0587, acc-0.4400, valid loss-2.0617, acc-0.4514, test loss-2.0416, acc-0.4637\n",
      "Iter-36340, train loss-2.0365, acc-0.4000, valid loss-2.0616, acc-0.4514, test loss-2.0416, acc-0.4636\n",
      "Iter-36350, train loss-2.0169, acc-0.5000, valid loss-2.0616, acc-0.4516, test loss-2.0415, acc-0.4637\n",
      "Iter-36360, train loss-2.0377, acc-0.4400, valid loss-2.0615, acc-0.4506, test loss-2.0415, acc-0.4638\n",
      "Iter-36370, train loss-2.0274, acc-0.4600, valid loss-2.0615, acc-0.4508, test loss-2.0414, acc-0.4639\n",
      "Iter-36380, train loss-2.0395, acc-0.4400, valid loss-2.0614, acc-0.4508, test loss-2.0414, acc-0.4640\n",
      "Iter-36390, train loss-2.0491, acc-0.4800, valid loss-2.0614, acc-0.4508, test loss-2.0413, acc-0.4641\n",
      "Iter-36400, train loss-2.0198, acc-0.4400, valid loss-2.0614, acc-0.4508, test loss-2.0413, acc-0.4640\n",
      "Iter-36410, train loss-2.0811, acc-0.4000, valid loss-2.0613, acc-0.4508, test loss-2.0412, acc-0.4641\n",
      "Iter-36420, train loss-2.0351, acc-0.4800, valid loss-2.0613, acc-0.4506, test loss-2.0412, acc-0.4641\n",
      "Iter-36430, train loss-1.9833, acc-0.5800, valid loss-2.0612, acc-0.4508, test loss-2.0411, acc-0.4640\n",
      "Iter-36440, train loss-1.9674, acc-0.5600, valid loss-2.0612, acc-0.4508, test loss-2.0411, acc-0.4640\n",
      "Iter-36450, train loss-2.0421, acc-0.5000, valid loss-2.0611, acc-0.4512, test loss-2.0410, acc-0.4643\n",
      "Iter-36460, train loss-2.0572, acc-0.3400, valid loss-2.0611, acc-0.4512, test loss-2.0409, acc-0.4646\n",
      "Iter-36470, train loss-2.0207, acc-0.4400, valid loss-2.0610, acc-0.4508, test loss-2.0409, acc-0.4643\n",
      "Iter-36480, train loss-2.1038, acc-0.3800, valid loss-2.0610, acc-0.4508, test loss-2.0408, acc-0.4642\n",
      "Iter-36490, train loss-2.0213, acc-0.5600, valid loss-2.0609, acc-0.4510, test loss-2.0408, acc-0.4642\n",
      "Iter-36500, train loss-2.0642, acc-0.3800, valid loss-2.0609, acc-0.4512, test loss-2.0407, acc-0.4646\n",
      "Iter-36510, train loss-2.0523, acc-0.5000, valid loss-2.0608, acc-0.4508, test loss-2.0407, acc-0.4642\n",
      "Iter-36520, train loss-2.1199, acc-0.4400, valid loss-2.0608, acc-0.4510, test loss-2.0406, acc-0.4647\n",
      "Iter-36530, train loss-2.0388, acc-0.4000, valid loss-2.0607, acc-0.4512, test loss-2.0406, acc-0.4649\n",
      "Iter-36540, train loss-2.0126, acc-0.6000, valid loss-2.0607, acc-0.4512, test loss-2.0405, acc-0.4648\n",
      "Iter-36550, train loss-2.0604, acc-0.3800, valid loss-2.0606, acc-0.4510, test loss-2.0405, acc-0.4648\n",
      "Iter-36560, train loss-2.1295, acc-0.3200, valid loss-2.0606, acc-0.4510, test loss-2.0404, acc-0.4648\n",
      "Iter-36570, train loss-2.0724, acc-0.4400, valid loss-2.0606, acc-0.4512, test loss-2.0404, acc-0.4649\n",
      "Iter-36580, train loss-2.0313, acc-0.4800, valid loss-2.0605, acc-0.4516, test loss-2.0403, acc-0.4647\n",
      "Iter-36590, train loss-2.0263, acc-0.5200, valid loss-2.0605, acc-0.4516, test loss-2.0402, acc-0.4651\n",
      "Iter-36600, train loss-2.0597, acc-0.4000, valid loss-2.0604, acc-0.4516, test loss-2.0402, acc-0.4648\n",
      "Iter-36610, train loss-2.0958, acc-0.4200, valid loss-2.0604, acc-0.4516, test loss-2.0401, acc-0.4651\n",
      "Iter-36620, train loss-1.9985, acc-0.5400, valid loss-2.0603, acc-0.4514, test loss-2.0401, acc-0.4656\n",
      "Iter-36630, train loss-2.0837, acc-0.3800, valid loss-2.0603, acc-0.4514, test loss-2.0400, acc-0.4655\n",
      "Iter-36640, train loss-1.9908, acc-0.4600, valid loss-2.0602, acc-0.4514, test loss-2.0400, acc-0.4656\n",
      "Iter-36650, train loss-2.0815, acc-0.4600, valid loss-2.0602, acc-0.4514, test loss-2.0399, acc-0.4656\n",
      "Iter-36660, train loss-2.0342, acc-0.3800, valid loss-2.0601, acc-0.4518, test loss-2.0399, acc-0.4658\n",
      "Iter-36670, train loss-2.0776, acc-0.4200, valid loss-2.0601, acc-0.4514, test loss-2.0398, acc-0.4658\n",
      "Iter-36680, train loss-2.0282, acc-0.5400, valid loss-2.0600, acc-0.4518, test loss-2.0398, acc-0.4658\n",
      "Iter-36690, train loss-1.9929, acc-0.6000, valid loss-2.0600, acc-0.4518, test loss-2.0397, acc-0.4659\n",
      "Iter-36700, train loss-2.0595, acc-0.4200, valid loss-2.0599, acc-0.4518, test loss-2.0397, acc-0.4656\n",
      "Iter-36710, train loss-2.0157, acc-0.4800, valid loss-2.0599, acc-0.4520, test loss-2.0396, acc-0.4658\n",
      "Iter-36720, train loss-2.0164, acc-0.4400, valid loss-2.0598, acc-0.4520, test loss-2.0396, acc-0.4655\n",
      "Iter-36730, train loss-2.0273, acc-0.5400, valid loss-2.0598, acc-0.4520, test loss-2.0395, acc-0.4658\n",
      "Iter-36740, train loss-2.0657, acc-0.3800, valid loss-2.0597, acc-0.4518, test loss-2.0394, acc-0.4657\n",
      "Iter-36750, train loss-2.0493, acc-0.4600, valid loss-2.0597, acc-0.4518, test loss-2.0394, acc-0.4656\n",
      "Iter-36760, train loss-2.0367, acc-0.5000, valid loss-2.0596, acc-0.4522, test loss-2.0393, acc-0.4659\n",
      "Iter-36770, train loss-2.0800, acc-0.4200, valid loss-2.0596, acc-0.4520, test loss-2.0393, acc-0.4657\n",
      "Iter-36780, train loss-2.0588, acc-0.4000, valid loss-2.0595, acc-0.4522, test loss-2.0392, acc-0.4658\n",
      "Iter-36790, train loss-2.0491, acc-0.4600, valid loss-2.0595, acc-0.4520, test loss-2.0392, acc-0.4657\n",
      "Iter-36800, train loss-2.0156, acc-0.5400, valid loss-2.0594, acc-0.4520, test loss-2.0391, acc-0.4657\n",
      "Iter-36810, train loss-2.0646, acc-0.4600, valid loss-2.0594, acc-0.4524, test loss-2.0391, acc-0.4658\n",
      "Iter-36820, train loss-2.0685, acc-0.4000, valid loss-2.0593, acc-0.4524, test loss-2.0390, acc-0.4661\n",
      "Iter-36830, train loss-2.0859, acc-0.4800, valid loss-2.0593, acc-0.4528, test loss-2.0389, acc-0.4662\n",
      "Iter-36840, train loss-2.0553, acc-0.5200, valid loss-2.0592, acc-0.4528, test loss-2.0389, acc-0.4662\n",
      "Iter-36850, train loss-1.9974, acc-0.5600, valid loss-2.0592, acc-0.4528, test loss-2.0388, acc-0.4662\n",
      "Iter-36860, train loss-2.0487, acc-0.5000, valid loss-2.0591, acc-0.4524, test loss-2.0388, acc-0.4661\n",
      "Iter-36870, train loss-2.1079, acc-0.3600, valid loss-2.0591, acc-0.4522, test loss-2.0387, acc-0.4663\n",
      "Iter-36880, train loss-2.0413, acc-0.4600, valid loss-2.0590, acc-0.4526, test loss-2.0387, acc-0.4663\n",
      "Iter-36890, train loss-2.1048, acc-0.4000, valid loss-2.0590, acc-0.4530, test loss-2.0386, acc-0.4662\n",
      "Iter-36900, train loss-2.0169, acc-0.5400, valid loss-2.0589, acc-0.4528, test loss-2.0386, acc-0.4664\n",
      "Iter-36910, train loss-2.0210, acc-0.5600, valid loss-2.0589, acc-0.4526, test loss-2.0385, acc-0.4664\n",
      "Iter-36920, train loss-2.0310, acc-0.5600, valid loss-2.0589, acc-0.4524, test loss-2.0385, acc-0.4663\n",
      "Iter-36930, train loss-2.0576, acc-0.5000, valid loss-2.0588, acc-0.4526, test loss-2.0384, acc-0.4664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-36940, train loss-1.9920, acc-0.5600, valid loss-2.0587, acc-0.4532, test loss-2.0384, acc-0.4663\n",
      "Iter-36950, train loss-2.0666, acc-0.3800, valid loss-2.0587, acc-0.4528, test loss-2.0383, acc-0.4663\n",
      "Iter-36960, train loss-2.1252, acc-0.3800, valid loss-2.0587, acc-0.4530, test loss-2.0383, acc-0.4665\n",
      "Iter-36970, train loss-1.9939, acc-0.5400, valid loss-2.0586, acc-0.4530, test loss-2.0382, acc-0.4668\n",
      "Iter-36980, train loss-2.0513, acc-0.4800, valid loss-2.0585, acc-0.4530, test loss-2.0381, acc-0.4667\n",
      "Iter-36990, train loss-2.0902, acc-0.3400, valid loss-2.0585, acc-0.4528, test loss-2.0381, acc-0.4668\n",
      "Iter-37000, train loss-2.0624, acc-0.5000, valid loss-2.0584, acc-0.4530, test loss-2.0380, acc-0.4668\n",
      "Iter-37010, train loss-2.0681, acc-0.4200, valid loss-2.0584, acc-0.4530, test loss-2.0380, acc-0.4668\n",
      "Iter-37020, train loss-2.1349, acc-0.3800, valid loss-2.0584, acc-0.4540, test loss-2.0379, acc-0.4671\n",
      "Iter-37030, train loss-2.0469, acc-0.4800, valid loss-2.0583, acc-0.4538, test loss-2.0379, acc-0.4669\n",
      "Iter-37040, train loss-2.0448, acc-0.4600, valid loss-2.0583, acc-0.4538, test loss-2.0378, acc-0.4672\n",
      "Iter-37050, train loss-2.0205, acc-0.4600, valid loss-2.0582, acc-0.4538, test loss-2.0378, acc-0.4673\n",
      "Iter-37060, train loss-2.0470, acc-0.4000, valid loss-2.0582, acc-0.4538, test loss-2.0377, acc-0.4668\n",
      "Iter-37070, train loss-2.0649, acc-0.3400, valid loss-2.0581, acc-0.4538, test loss-2.0377, acc-0.4667\n",
      "Iter-37080, train loss-1.9796, acc-0.6000, valid loss-2.0581, acc-0.4538, test loss-2.0376, acc-0.4672\n",
      "Iter-37090, train loss-2.0614, acc-0.4200, valid loss-2.0580, acc-0.4538, test loss-2.0376, acc-0.4672\n",
      "Iter-37100, train loss-2.0155, acc-0.5400, valid loss-2.0580, acc-0.4538, test loss-2.0375, acc-0.4672\n",
      "Iter-37110, train loss-2.0668, acc-0.4600, valid loss-2.0579, acc-0.4538, test loss-2.0375, acc-0.4673\n",
      "Iter-37120, train loss-2.0503, acc-0.5000, valid loss-2.0579, acc-0.4540, test loss-2.0374, acc-0.4672\n",
      "Iter-37130, train loss-2.0677, acc-0.4800, valid loss-2.0578, acc-0.4540, test loss-2.0374, acc-0.4672\n",
      "Iter-37140, train loss-2.0653, acc-0.3000, valid loss-2.0578, acc-0.4540, test loss-2.0373, acc-0.4672\n",
      "Iter-37150, train loss-2.0522, acc-0.4400, valid loss-2.0577, acc-0.4540, test loss-2.0372, acc-0.4670\n",
      "Iter-37160, train loss-2.1253, acc-0.3400, valid loss-2.0577, acc-0.4542, test loss-2.0372, acc-0.4672\n",
      "Iter-37170, train loss-1.9934, acc-0.5200, valid loss-2.0576, acc-0.4542, test loss-2.0371, acc-0.4673\n",
      "Iter-37180, train loss-2.0625, acc-0.4000, valid loss-2.0576, acc-0.4544, test loss-2.0371, acc-0.4673\n",
      "Iter-37190, train loss-2.0355, acc-0.4800, valid loss-2.0575, acc-0.4544, test loss-2.0370, acc-0.4672\n",
      "Iter-37200, train loss-2.1164, acc-0.2800, valid loss-2.0575, acc-0.4546, test loss-2.0370, acc-0.4672\n",
      "Iter-37210, train loss-2.0579, acc-0.5600, valid loss-2.0575, acc-0.4544, test loss-2.0369, acc-0.4673\n",
      "Iter-37220, train loss-2.1061, acc-0.3600, valid loss-2.0574, acc-0.4540, test loss-2.0369, acc-0.4674\n",
      "Iter-37230, train loss-2.0291, acc-0.4400, valid loss-2.0574, acc-0.4538, test loss-2.0368, acc-0.4675\n",
      "Iter-37240, train loss-2.0587, acc-0.5000, valid loss-2.0573, acc-0.4536, test loss-2.0368, acc-0.4676\n",
      "Iter-37250, train loss-2.0370, acc-0.4400, valid loss-2.0573, acc-0.4536, test loss-2.0367, acc-0.4676\n",
      "Iter-37260, train loss-2.0327, acc-0.4400, valid loss-2.0572, acc-0.4538, test loss-2.0367, acc-0.4674\n",
      "Iter-37270, train loss-2.0364, acc-0.5000, valid loss-2.0572, acc-0.4536, test loss-2.0366, acc-0.4675\n",
      "Iter-37280, train loss-2.0584, acc-0.4000, valid loss-2.0571, acc-0.4536, test loss-2.0366, acc-0.4675\n",
      "Iter-37290, train loss-2.0007, acc-0.4600, valid loss-2.0571, acc-0.4536, test loss-2.0365, acc-0.4676\n",
      "Iter-37300, train loss-2.0686, acc-0.4400, valid loss-2.0570, acc-0.4536, test loss-2.0364, acc-0.4676\n",
      "Iter-37310, train loss-2.0459, acc-0.4200, valid loss-2.0570, acc-0.4538, test loss-2.0364, acc-0.4676\n",
      "Iter-37320, train loss-2.0627, acc-0.5000, valid loss-2.0569, acc-0.4540, test loss-2.0363, acc-0.4678\n",
      "Iter-37330, train loss-2.0212, acc-0.4600, valid loss-2.0569, acc-0.4540, test loss-2.0363, acc-0.4677\n",
      "Iter-37340, train loss-1.9977, acc-0.5200, valid loss-2.0568, acc-0.4540, test loss-2.0362, acc-0.4676\n",
      "Iter-37350, train loss-2.0040, acc-0.5200, valid loss-2.0568, acc-0.4540, test loss-2.0362, acc-0.4679\n",
      "Iter-37360, train loss-2.0428, acc-0.4800, valid loss-2.0567, acc-0.4540, test loss-2.0361, acc-0.4678\n",
      "Iter-37370, train loss-2.0377, acc-0.5000, valid loss-2.0567, acc-0.4538, test loss-2.0361, acc-0.4678\n",
      "Iter-37380, train loss-2.0328, acc-0.5200, valid loss-2.0566, acc-0.4540, test loss-2.0360, acc-0.4677\n",
      "Iter-37390, train loss-2.0694, acc-0.4800, valid loss-2.0566, acc-0.4538, test loss-2.0360, acc-0.4677\n",
      "Iter-37400, train loss-2.0698, acc-0.4600, valid loss-2.0565, acc-0.4540, test loss-2.0359, acc-0.4676\n",
      "Iter-37410, train loss-2.0436, acc-0.4600, valid loss-2.0565, acc-0.4540, test loss-2.0359, acc-0.4676\n",
      "Iter-37420, train loss-2.0947, acc-0.3600, valid loss-2.0564, acc-0.4538, test loss-2.0358, acc-0.4678\n",
      "Iter-37430, train loss-2.0781, acc-0.4600, valid loss-2.0564, acc-0.4540, test loss-2.0358, acc-0.4676\n",
      "Iter-37440, train loss-1.9848, acc-0.5200, valid loss-2.0563, acc-0.4540, test loss-2.0357, acc-0.4676\n",
      "Iter-37450, train loss-2.0039, acc-0.4200, valid loss-2.0563, acc-0.4538, test loss-2.0357, acc-0.4672\n",
      "Iter-37460, train loss-2.0699, acc-0.5000, valid loss-2.0562, acc-0.4536, test loss-2.0356, acc-0.4672\n",
      "Iter-37470, train loss-2.0828, acc-0.3600, valid loss-2.0562, acc-0.4536, test loss-2.0355, acc-0.4674\n",
      "Iter-37480, train loss-2.0834, acc-0.3400, valid loss-2.0561, acc-0.4534, test loss-2.0355, acc-0.4676\n",
      "Iter-37490, train loss-2.0665, acc-0.4000, valid loss-2.0561, acc-0.4536, test loss-2.0354, acc-0.4675\n",
      "Iter-37500, train loss-2.0349, acc-0.4600, valid loss-2.0561, acc-0.4536, test loss-2.0354, acc-0.4677\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "n_iter = 100000 # number of epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "mb_size = 50 # 2**10==1024 # width, timestep for sequential data or minibatch size\n",
    "print_after = 10 # n_iter//10 # print loss for train, valid, and test\n",
    "num_hidden_units = 32 # number of kernels/ filters in each layer\n",
    "num_input_units = X_train.shape[1] # noise added at the input lavel as input noise we can use dX or for more improvement\n",
    "num_output_units = y_train.max() + 1 # number of classes in this classification problem\n",
    "num_layers = 2 # depth \n",
    "\n",
    "# Build the model/NN and learn it: running session.\n",
    "nn = FFNN(C=num_output_units, D=num_input_units, H=num_hidden_units, L=num_layers)\n",
    "\n",
    "nn.sgd(train_set=(X_train, y_train), val_set=(X_val, y_val), mb_size=mb_size, alpha=alpha, \n",
    "           n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(nn.losses['train'], label='Train loss')\n",
    "plt.plot(nn.losses['valid'], label='Valid loss')\n",
    "plt.plot(nn.losses['test'], label='Test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nn.losses['train_acc'], label='Train accuracy')\n",
    "plt.plot(nn.losses['valid_acc'], label='Valid accuracy')\n",
    "plt.plot(nn.losses['test_acc'], label='Test accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
