{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "with open('data/text_data/japan.txt', 'r') as f:\n",
    "    txt = f.read()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    char_to_idx = {char: i for i, char in enumerate(set(txt))}\n",
    "    idx_to_char = {i: char for i, char in enumerate(set(txt))}\n",
    "    \n",
    "    X = [char_to_idx[x] for x in txt]\n",
    "    X = np.array(X)\n",
    "    y = [char_to_idx[x] for x in txt[1:]]\n",
    "    y.append(char_to_idx['.'])\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l\n",
    "\n",
    "class RNN:\n",
    "\n",
    "    def __init__(self, D, H, C, L, p_dropout):\n",
    "        self.L = L\n",
    "        self.H = H\n",
    "        self.D = D\n",
    "        self.losses = {'train':[], 'smooth train':[]}\n",
    "        self.p_dropout = p_dropout\n",
    "        \n",
    "        # Input layer\n",
    "        m_in = dict(\n",
    "            Wx=np.random.randn(D, H) / np.sqrt(D / 2.),\n",
    "            bx=np.zeros((1, H))\n",
    "            )\n",
    "\n",
    "        # Hidden layers\n",
    "        m_h = dict(\n",
    "            Wxh=np.random.randn(H, H) / np.sqrt(H / 2.),\n",
    "            Whh=np.random.randn(H, H) / np.sqrt(H / 2.),\n",
    "            Wx=np.random.randn(H, H) / np.sqrt(H / 2.),\n",
    "            Wh=np.random.randn(H, H) / np.sqrt(H / 2.),\n",
    "            bxh=np.zeros((1, H)),\n",
    "            bx=np.zeros((1, H)),\n",
    "            bh=np.zeros((1, H))\n",
    "            )\n",
    "            \n",
    "        # Output layer\n",
    "        m_out = dict(\n",
    "            Wy=np.random.randn(H, C) / np.sqrt(H / 2.),\n",
    "            by=np.zeros((1, C))\n",
    "            )\n",
    "        \n",
    "        # Model parameters\n",
    "        self.model = []\n",
    "        self.model.append(m_in) # input layer: layer == 0\n",
    "        for _ in range(self.L): # hidden layer: layer == 1:self.L\n",
    "            self.model.append(m_h)\n",
    "        self.model.append(m_out) # output layer: layer == self.L\n",
    "                \n",
    "    def initial_state(self):\n",
    "        return np.zeros((1, self.H))\n",
    "\n",
    "    def selu_forward(self, X):\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        out = scale * np.where(X>=0.0, X, alpha * (np.exp(X)-1))\n",
    "        cache = X\n",
    "        return out, cache\n",
    "\n",
    "    def selu_backward(self, dout, cache):\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        X = cache\n",
    "        dX_pos = dout.copy()\n",
    "        dX_pos[X<0] = 0\n",
    "        dX_neg = dout.copy()\n",
    "        dX_neg[X>0] = 0\n",
    "        dX = scale * np.where(X>=0.0, dX_pos, dX_neg * alpha * np.exp(X))\n",
    "        return dX\n",
    "\n",
    "    # p_dropout = keep_prob in this case! \n",
    "    # Is this true in other cases as well?\n",
    "    def alpha_dropout_fwd(self, h, q):\n",
    "        '''h is activation, q is keep probability: q=1-p, p=p_dropout, and q=keep_prob'''\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        alpha_p = -scale * alpha\n",
    "        mask = np.random.binomial(1, q, size=h.shape)\n",
    "        dropped = (mask * h) + ((1 - mask) * alpha_p)\n",
    "        a = 1. / np.sqrt(q + (alpha_p ** 2 * q  * (1 - q)))\n",
    "        b = -a * (1 - q) * alpha_p\n",
    "        out = (a * dropped) + b\n",
    "        cache = (a, mask)\n",
    "        return out, cache\n",
    "\n",
    "    def alpha_dropout_bwd(self, dout, cache):\n",
    "        a, mask = cache\n",
    "        d_dropped = dout * a\n",
    "        dh = d_dropped * mask\n",
    "        return dh\n",
    "    \n",
    "    def forward(self, X, h, m):\n",
    "        Wxh, Whh, bxh = m['Wxh'], m['Whh'], m['bxh']\n",
    "        Xh = (X @ Wxh) + (h @ Whh) + bxh\n",
    "        Xh, Xh_nl_cache = l.tanh_forward(Xh)\n",
    "        # Xh, Xh_nl_cache = self.selu_forward(Xh)\n",
    "        \n",
    "        Wx, bx = m['Wx'], m['bx']\n",
    "        X_in = X.copy()\n",
    "        # X = (X @ Wx) + bx\n",
    "        X, X_fc_cache = l.fc_forward(X, Wx, bx)\n",
    "        X, X_nl_cache = l.tanh_forward(X)\n",
    "        # X, X_nl_cache = self.selu_forward(X)\n",
    "        X += X_in\n",
    "        \n",
    "        Wh, bh = m['Wh'], m['bh']\n",
    "        h_in = h.copy()\n",
    "        # h = (h @ Wh) + bh\n",
    "        h, h_fc_cache = l.fc_forward(h, Wh, bh)\n",
    "        h, h_nl_cache = l.tanh_forward(h)\n",
    "        # h, h_nl_cache = self.selu_forward(h)\n",
    "        h += h_in\n",
    "        \n",
    "        h = Xh + h\n",
    "        y = Xh + X\n",
    "\n",
    "        h, h_selu_nl_cache = self.selu_forward(h)\n",
    "        h, h_selu_do_cache = self.alpha_dropout_fwd(h, self.p_dropout)\n",
    "        \n",
    "        y, y_selu_nl_cache = self.selu_forward(y)\n",
    "        y, y_selu_do_cache = self.alpha_dropout_fwd(y, self.p_dropout)\n",
    "        \n",
    "        cache = (X_in, h_in, Wxh, Whh, Xh_nl_cache, X_fc_cache, X_nl_cache, h_fc_cache, h_nl_cache, h_selu_nl_cache, h_selu_do_cache, y_selu_nl_cache, y_selu_do_cache)\n",
    "\n",
    "        return y, h, cache\n",
    "\n",
    "    def backward(self, dy, dh, cache):\n",
    "        (X_in, h_in, Wxh, Whh, Xh_nl_cache, X_fc_cache, X_nl_cache, h_fc_cache, h_nl_cache, h_selu_nl_cache, h_selu_do_cache, y_selu_nl_cache, y_selu_do_cache) = cache\n",
    "         \n",
    "        dh = self.alpha_dropout_bwd(dh, h_selu_do_cache)\n",
    "        dh = self.selu_backward(dh, h_selu_nl_cache)\n",
    "        \n",
    "        dy = self.alpha_dropout_bwd(dy, y_selu_do_cache)\n",
    "        dy = self.selu_backward(dy, y_selu_nl_cache)\n",
    "\n",
    "        dh_out = dh.copy()\n",
    "        # dh = self.selu_backward(dh, h_nl_cache)\n",
    "        dh = l.tanh_backward(dh, h_nl_cache)\n",
    "        dh, dWh, dbh = l.fc_backward(dh, h_fc_cache)\n",
    "        dh += dh_out\n",
    "        #         dWh = h_in.T @ dh # nxh = nx1 @ 1xh\n",
    "        #         dbh = dh * 1.0\n",
    "        #         dh = dh @ Wh.T # 1xn = 1xh @ hxn\n",
    "\n",
    "        dX = dy.copy()\n",
    "        # dX = self.selu_backward(dX, X_nl_cache)\n",
    "        dX = l.tanh_backward(dX, X_nl_cache)\n",
    "        dX, dWx, dbx = l.fc_backward(dX, X_fc_cache)\n",
    "        dX += dy\n",
    "        #         dWx = X_in.T @ dX # nxh = nx1 @ 1xh\n",
    "        #         dbx = dX * 1.0\n",
    "        #         dX = dX @ Wx.T # 1xn = 1xh @ hxn\n",
    "\n",
    "        dXh = dy + dh        \n",
    "        # dXh = self.selu_backward(dXh, Xh_nl_cache)\n",
    "        dXh = l.tanh_backward(dXh, Xh_nl_cache)\n",
    "        dbxh = dXh * 1.0\n",
    "        dWhh = h_in.T @ dXh\n",
    "        dWxh = X_in.T @ dXh\n",
    "        dX += dXh @ Wxh.T # 1xn = 1xh @ hxn\n",
    "        dh += dXh @ Whh.T # 1xn = 1xh @ hxn\n",
    "\n",
    "        grad = dict(Wxh=dWxh, Whh=dWhh, bxh=dbxh, Wx=dWx, bx=dbx, Wh=dWh, bh=dbh)\n",
    "        \n",
    "        return dX, dh, grad\n",
    "\n",
    "    def train_forward(self, X_train, h):\n",
    "        # Input (1), hidden (L), and output layers (1)\n",
    "        caches = []\n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        # Hidden layers and cells connections\n",
    "        for _ in range(self.L + 2):\n",
    "            h.append(h_init.copy())\n",
    "            caches.append([])\n",
    "            \n",
    "        # Hidden layers    \n",
    "        for layer in range(self.L + 2):\n",
    "            if layer == 0: # input layer\n",
    "                ys = []\n",
    "                for X in X_train:\n",
    "                    X_one_hot = np.zeros(self.D)\n",
    "                    X_one_hot[X] = 1.\n",
    "                    X = X_one_hot.reshape(1, -1)\n",
    "                    y, cache = l.fc_forward(X, self.model[layer]['Wx'], self.model[layer]['bx'])\n",
    "                    # print(y.shape, X.shape)\n",
    "                    caches[layer].append(cache)\n",
    "                    ys.append(y)\n",
    "            if (layer > 0) and (layer < self.L + 1): # hidden layers\n",
    "                Xs = ys.copy()\n",
    "                ys = []\n",
    "                for X in Xs:\n",
    "                    y, h[layer], cache = self.forward(X, h[layer], self.model[layer])\n",
    "                    caches[layer].append(cache)\n",
    "                    ys.append(y)\n",
    "            if layer == self.L + 1: # output layer\n",
    "                Xs = ys.copy()\n",
    "                ys = []\n",
    "                for X in Xs:\n",
    "                    y, cache = l.fc_forward(X, self.model[layer]['Wy'], self.model[layer]['by'])\n",
    "                    caches[layer].append(cache)\n",
    "                    ys.append(y)\n",
    "\n",
    "        return ys, caches\n",
    "\n",
    "    def cross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(prob[range(m), y_train])\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        grad_y = l.softmax(y_pred)\n",
    "        grad_y[range(m), y_train] -= 1.0\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "    \n",
    "    def loss_function(self, y_train, ys):\n",
    "        loss, dys = 0.0, []\n",
    "\n",
    "        for y_pred, y in zip(ys, y_train):\n",
    "            loss += self.cross_entropy(y_pred, y)\n",
    "            dy = self.dcross_entropy(y_pred, y)\n",
    "            dys.append(dy)\n",
    "            \n",
    "        return loss, dys\n",
    "    \n",
    "    def train_backward(self, dys, caches):\n",
    "        dh, grad, grads = [], [], []\n",
    "        for layer in range(self.L + 2):\n",
    "            dh.append(np.zeros((1, self.H)))\n",
    "            grad.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            grads.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "         \n",
    "        for layer in reversed(range(self.L + 2)):\n",
    "            if layer == (self.L + 1):  # Output layer\n",
    "                dXs = []\n",
    "                for t in reversed(range(len(dys))):\n",
    "                    dy = dys[t]\n",
    "                    dX, dWy, dby = l.fc_backward(dy, caches[layer][t])\n",
    "                    grads[layer]['Wy'] += dWy\n",
    "                    grads[layer]['by'] += dby\n",
    "                    dXs.append(dX)\n",
    "            if (layer > 0) and (layer < (self.L + 1)): # Middle layers\n",
    "                dys = dXs.copy()\n",
    "                dXs = []\n",
    "                for t in reversed(range(len(dys))):\n",
    "                    dy = dys[t]\n",
    "                    dX, dh[layer], grad[layer] = self.backward(dy, dh[layer], caches[layer][t])\n",
    "                    for key in grad[layer].keys():\n",
    "                        grads[layer][key] += grad[layer][key]\n",
    "                    dXs.append(dX)\n",
    "            if layer == 0: # Input-Output layer\n",
    "                dys = dXs.copy()\n",
    "                dXs = []\n",
    "                for t in reversed(range(len(dys))):\n",
    "                    dy = dys[t]\n",
    "                    dX, dWx, dbx = l.fc_backward(dy, caches[layer][t])\n",
    "                    grads[layer]['Wx'] += dWx\n",
    "                    grads[layer]['bx'] += dbx\n",
    "                    dXs.append(dX)\n",
    "                \n",
    "        return dXs, grads\n",
    "    \n",
    "    #     def test(self, X_seed, h, size):\n",
    "    #         chars = [self.idx2char[X_seed]]\n",
    "    #         idx_list = list(range(self.vocab_size))\n",
    "    #         X = X_seed\n",
    "\n",
    "    #         h_init = h.copy()\n",
    "    #         h = []\n",
    "    #         for _ in range(self.L):\n",
    "    #             h.append(h_init.copy())\n",
    "\n",
    "    #         # Test is different than train since y[t+1] is related to y[t] \n",
    "    #         for _ in range(size):\n",
    "    #             X_one_hot = np.zeros(self.D)\n",
    "    #             X_one_hot[X] = 1.\n",
    "    #             X = X_one_hot.reshape(1, -1)\n",
    "    #             for layer in range(self.L): # start, stop, step\n",
    "    #                 y, h[layer], _ = self.forward(X, h[layer], self.model[layer], train=False)\n",
    "    #                 if layer == self.L-1: # this is the last layer\n",
    "    #                     y_logit = y\n",
    "    #                 else: \n",
    "    #                     X = y # y: output for this layer, X: input for this layer\n",
    "    #             y_prob = l.softmax(y_logit)\n",
    "    #             idx = np.random.choice(idx_list, p=y_prob.ravel())\n",
    "    #             chars.append(self.idx2char[idx])\n",
    "    #             X = idx\n",
    "\n",
    "    #         return ''.join(chars)\n",
    "\n",
    "    def get_minibatch(self, X, y, minibatch_size, shuffle):\n",
    "        minibatches = []\n",
    "\n",
    "        # for i in range(0, X.shape[0] - minibatch_size +1, 1):\n",
    "        for i in range(0, X.shape[0], minibatch_size):\n",
    "            X_mini = X[i:i + minibatch_size]\n",
    "            y_mini = y[i:i + minibatch_size]\n",
    "            minibatches.append((X_mini, y_mini))\n",
    "\n",
    "        return minibatches\n",
    "\n",
    "    def adam_rnn(self, X_train, y_train, alpha, mb_size, n_iter, print_after):\n",
    "        M, R = [], []\n",
    "         \n",
    "        # Hidden layers\n",
    "        for layer in range(nn.L + 2):\n",
    "            M.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            R.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "         \n",
    "        beta1 = .99\n",
    "        beta2 = .999\n",
    "        eps = 1e-8\n",
    "        state = self.initial_state()\n",
    "        smooth_loss = 1.0\n",
    "        minibatches = self.get_minibatch(X_train, y_train, mb_size, shuffle=False)\n",
    "\n",
    "        # Epochs\n",
    "        for iter in range(1, n_iter + 1):\n",
    "\n",
    "            # Minibacthes\n",
    "            for idx in range(len(minibatches)):\n",
    "                X_mini, y_mini = minibatches[idx]\n",
    "                ys, caches = self.train_forward(X_mini, state)\n",
    "                loss, dys = self.loss_function(y_train=y_mini, ys=ys)\n",
    "                _, grads = self.train_backward(dys, caches)\n",
    "                self.losses['train'].append(loss)\n",
    "                smooth_loss = (0.999 * smooth_loss) + (0.001 * loss)\n",
    "                self.losses['smooth train'].append(smooth_loss)\n",
    "\n",
    "                for layer in range(nn.L + 2):\n",
    "                    for key in grads[layer].keys(): #key, value: items\n",
    "                        M[layer][key] = l.exp_running_avg(M[layer][key], grads[layer][key], beta1)\n",
    "                        R[layer][key] = l.exp_running_avg(R[layer][key], grads[layer][key]**2, beta2)\n",
    "\n",
    "                        m_k_hat = M[layer][key] / (1. - (beta1**(iter)))\n",
    "                        r_k_hat = R[layer][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                        self.model[layer][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + eps)\n",
    "\n",
    "            # Print loss and test sample\n",
    "            if iter % print_after == 0:\n",
    "                print('Iter-{} loss: {:.4f}'.format(iter, loss))\n",
    "                #                 sample = self.test(X_mini[0], state, size=100)\n",
    "                #                 print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1 loss: 124.9617\n",
      "Iter-2 loss: 80.8457\n",
      "Iter-3 loss: 82.2547\n",
      "Iter-4 loss: 90.4658\n",
      "Iter-5 loss: 113.3202\n",
      "Iter-6 loss: 76.0658\n",
      "Iter-7 loss: 60.8807\n",
      "Iter-8 loss: 83.7895\n",
      "Iter-9 loss: 103.7940\n",
      "Iter-10 loss: 94.5512\n",
      "Iter-11 loss: 75.5367\n",
      "Iter-12 loss: 67.7846\n",
      "Iter-13 loss: 88.8661\n",
      "Iter-14 loss: 92.9699\n",
      "Iter-15 loss: 75.2957\n",
      "Iter-16 loss: 63.8795\n",
      "Iter-17 loss: 68.5055\n",
      "Iter-18 loss: 81.3137\n",
      "Iter-19 loss: 59.5472\n",
      "Iter-20 loss: 68.4197\n",
      "Iter-21 loss: 73.5178\n",
      "Iter-22 loss: 72.3798\n",
      "Iter-23 loss: 93.7848\n",
      "Iter-24 loss: 98.5489\n",
      "Iter-25 loss: 61.6901\n",
      "Iter-26 loss: 68.2607\n",
      "Iter-27 loss: 84.7870\n",
      "Iter-28 loss: 81.7685\n",
      "Iter-29 loss: 74.7123\n",
      "Iter-30 loss: 63.2221\n",
      "Iter-31 loss: 69.6617\n",
      "Iter-32 loss: 56.3860\n",
      "Iter-33 loss: 56.1530\n",
      "Iter-34 loss: 56.1813\n",
      "Iter-35 loss: 63.4077\n",
      "Iter-36 loss: 62.8782\n",
      "Iter-37 loss: 49.7926\n",
      "Iter-38 loss: 62.2414\n",
      "Iter-39 loss: 65.9033\n",
      "Iter-40 loss: 66.5275\n",
      "Iter-41 loss: 54.3236\n",
      "Iter-42 loss: 67.1705\n",
      "Iter-43 loss: 54.2267\n",
      "Iter-44 loss: 53.0472\n",
      "Iter-45 loss: 62.2217\n",
      "Iter-46 loss: 72.0668\n",
      "Iter-47 loss: 65.7058\n",
      "Iter-48 loss: 57.2086\n",
      "Iter-49 loss: 56.2324\n",
      "Iter-50 loss: 63.4889\n",
      "Iter-51 loss: 66.3422\n",
      "Iter-52 loss: 51.9038\n",
      "Iter-53 loss: 57.8266\n",
      "Iter-54 loss: 55.7976\n",
      "Iter-55 loss: 35.8282\n",
      "Iter-56 loss: 58.3537\n",
      "Iter-57 loss: 53.6306\n",
      "Iter-58 loss: 60.3994\n",
      "Iter-59 loss: 55.1388\n",
      "Iter-60 loss: 53.1599\n",
      "Iter-61 loss: 52.4243\n",
      "Iter-62 loss: 55.7638\n",
      "Iter-63 loss: 50.0827\n",
      "Iter-64 loss: 56.0372\n",
      "Iter-65 loss: 44.6454\n",
      "Iter-66 loss: 57.4127\n",
      "Iter-67 loss: 55.6522\n",
      "Iter-68 loss: 47.7458\n",
      "Iter-69 loss: 59.6677\n",
      "Iter-70 loss: 56.2716\n",
      "Iter-71 loss: 50.9232\n",
      "Iter-72 loss: 51.8844\n",
      "Iter-73 loss: 46.3813\n",
      "Iter-74 loss: 55.9513\n",
      "Iter-75 loss: 52.1723\n",
      "Iter-76 loss: 42.2953\n",
      "Iter-77 loss: 46.1833\n",
      "Iter-78 loss: 49.8769\n",
      "Iter-79 loss: 57.0560\n",
      "Iter-80 loss: 50.9006\n",
      "Iter-81 loss: 43.2445\n",
      "Iter-82 loss: 47.7318\n",
      "Iter-83 loss: 46.0859\n",
      "Iter-84 loss: 42.0964\n",
      "Iter-85 loss: 49.2324\n",
      "Iter-86 loss: 58.6868\n",
      "Iter-87 loss: 53.1420\n",
      "Iter-88 loss: 57.1847\n",
      "Iter-89 loss: 51.9465\n",
      "Iter-90 loss: 43.1664\n",
      "Iter-91 loss: 43.9706\n",
      "Iter-92 loss: 39.5422\n",
      "Iter-93 loss: 47.4285\n",
      "Iter-94 loss: 55.3188\n",
      "Iter-95 loss: 37.9521\n",
      "Iter-96 loss: 46.6469\n",
      "Iter-97 loss: 49.1603\n",
      "Iter-98 loss: 54.1437\n",
      "Iter-99 loss: 54.9274\n",
      "Iter-100 loss: 46.8433\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110904588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "time_step = 10 # width, minibatch size and test sample size as well\n",
    "num_layers = 10 # depth\n",
    "n_iter = 100 # epochs\n",
    "alpha = 1e-4 # learning_rate\n",
    "p_dropout = 0.95 # q=1-p, q=keep_prob and p=dropout.\n",
    "print_after = n_iter//100 # print training loss, valid, and test\n",
    "num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "num_input_units = len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "num_output_units = len(char_to_idx)\n",
    "\n",
    "# Build the network and learning it or optimizing it using SGD\n",
    "nn = RNN(D=num_input_units, H=num_hidden_units, C=num_output_units, L=num_layers, p_dropout=p_dropout)\n",
    "\n",
    "# Start learning using BP-SGD-ADAM\n",
    "nn.adam_rnn(X_train=X, y_train=y, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)\n",
    "\n",
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(nn.losses['train'], label='Train loss')\n",
    "plt.plot(nn.losses['smooth train'], label='Train smooth loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
