{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "with open('data/text_data/japan.txt', 'r') as f:\n",
    "    txt = f.read()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    char_to_idx = {char: i for i, char in enumerate(set(txt))}\n",
    "    idx_to_char = {i: char for i, char in enumerate(set(txt))}\n",
    "    \n",
    "    X = [char_to_idx[x] for x in txt]\n",
    "    X = np.array(X)\n",
    "    y = [char_to_idx[x] for x in txt[1:]]\n",
    "    y.append(char_to_idx['.'])\n",
    "    y = np.array(y)\n",
    "\n",
    "# # Data exploration\n",
    "# X.shape, y.shape, X, y, txt.split()[:2], \n",
    "# # set(txt), \n",
    "# # for val, key in enumerate(set(txt)):\n",
    "# #     print(val, key)\n",
    "# val2char = {val: key for val, key in enumerate(set(txt))}\n",
    "# # val2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l\n",
    "\n",
    "class RNN:\n",
    "\n",
    "    def __init__(self, D, H, L, char2idx, idx2char, p_dropout):\n",
    "        self.D = D\n",
    "        self.H = H\n",
    "        self.L = L\n",
    "        self.char2idx = char2idx\n",
    "        self.idx2char = idx2char\n",
    "        self.vocab_size = len(char2idx)\n",
    "        self.losses = {'train':[], 'train2':[]}\n",
    "        self.p_dropout = p_dropout\n",
    "        \n",
    "        # model parameters\n",
    "        m = dict(\n",
    "            Wxh=np.random.randn(D, H) / np.sqrt(D / 2.),\n",
    "            Whh=np.random.randn(H, H) / np.sqrt(H / 2.),\n",
    "            Why=np.random.randn(H, D) / np.sqrt(H / 2.),\n",
    "            bh=np.zeros((1, H)),\n",
    "            by=np.zeros((1, D))\n",
    "            )\n",
    "        self.model = []\n",
    "        for _ in range(self.L):\n",
    "            self.model.append(m)\n",
    "            \n",
    "    def initial_state(self):\n",
    "        return np.zeros((1, self.H))\n",
    "\n",
    "    def forward(self, X, h, m):\n",
    "        Wxh, Whh, Why = m['Wxh'], m['Whh'], m['Why']\n",
    "        bh, by = m['bh'], m['by']\n",
    "\n",
    "        hprev = h.copy()\n",
    "    \n",
    "        h = (X @ Wxh) + (hprev @ Whh) + bh\n",
    "        h, h_cache = l.tanh_forward(h)\n",
    "\n",
    "        y, y_cache = l.fc_forward(h, Why, by)\n",
    "        y, nl_cache = self.selu_forward(y)\n",
    "        y, do_cache = self.alpha_dropout_fwd(h=y, q=1.0-self.p_dropout) # q=1-p, 1=keep_prob\n",
    "        #         y, do_cache = self.dropout_forward(X=y, p_dropout=self.p_dropout)\n",
    "\n",
    "        cache = (X, hprev, Wxh, Whh, h_cache, y_cache, nl_cache, do_cache)\n",
    "\n",
    "        return y, h, cache\n",
    "\n",
    "    def backward(self, dy, dh, cache):\n",
    "        X, hprev, Wxh, Whh, h_cache, y_cache, nl_cache, do_cache = cache\n",
    "\n",
    "        dh_next = dh.copy()\n",
    "        \n",
    "        #         dy = self.dropout_backward(dout=dy, cache=do_cache)\n",
    "        dy = self.alpha_dropout_bwd(dout=dy, cache=do_cache)\n",
    "        dy = self.selu_backward(dy, nl_cache)\n",
    "        dh, dWhy, dby = l.fc_backward(dy, y_cache)\n",
    "        dh += dh_next\n",
    "        dby = dby.reshape((1, -1))\n",
    "\n",
    "        dh = l.tanh_backward(dh, h_cache)\n",
    "        dbh = dh * 1.0\n",
    "        dWhh = hprev.T @ dh\n",
    "        dWxh = X.T @ dh\n",
    "        dX = dh @ Wxh.T\n",
    "        dh = dh @ Whh.T\n",
    "\n",
    "        grad = dict(Wxh=dWxh, Whh=dWhh, Why=dWhy, bh=dbh, by=dby)\n",
    "        \n",
    "        return dX, dh, grad\n",
    "\n",
    "    # keep_prob = 1 - p_dropout, q = 1 - p\n",
    "    def dropout_forward(self, X, p_dropout):\n",
    "        u = np.random.binomial(1, p_dropout, size=X.shape) / p_dropout\n",
    "        out = X * u\n",
    "        cache = u\n",
    "        return out, cache\n",
    "\n",
    "    def dropout_backward(self, dout, cache):\n",
    "        u = cache\n",
    "        dX = dout * u\n",
    "        return dX\n",
    "\n",
    "    def selu_forward(self, X):\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        out = scale * np.where(X>=0.0, X, alpha * (np.exp(X)-1))\n",
    "        cache = X\n",
    "        return out, cache\n",
    "\n",
    "    def selu_backward(self, dout, cache):\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        X = cache\n",
    "        dX_pos = dout.copy()\n",
    "        dX_pos[X<0] = 0\n",
    "        dX_neg = dout.copy()\n",
    "        dX_neg[X>0] = 0\n",
    "        dX = scale * np.where(X>=0.0, dX_pos, dX_neg * alpha * np.exp(X))\n",
    "        return dX\n",
    "    \n",
    "    def alpha_dropout_fwd(self, h, q):\n",
    "        '''h is activation, q is keep probability: q=1-p, p=p_dropout, and q=keep_prob'''\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        alpha_p = -scale * alpha\n",
    "        mask = np.random.binomial(1, q, size=h.shape)\n",
    "        dropped = mask * h + (1 - mask) * alpha_p\n",
    "        a = 1. / np.sqrt(q + alpha_p ** 2 * q  * (1 - q))\n",
    "        b = -a * (1 - q) * alpha_p\n",
    "        out = a * dropped + b\n",
    "        cache = (a, mask)\n",
    "        return out, cache\n",
    "\n",
    "    def alpha_dropout_bwd(self, dout, cache):\n",
    "        a, mask = cache\n",
    "        d_dropped = dout * a\n",
    "        dh = d_dropped * mask\n",
    "        return dh\n",
    "    \n",
    "    def train_forward(self, X_train, h):\n",
    "        ys, caches = [], []\n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "            caches.append([])\n",
    "            \n",
    "        for X in X_train:\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.0\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], cache = self.forward(y, h[layer], self.model[layer])\n",
    "                caches[layer].append(cache)\n",
    "                \n",
    "            ys.append(y)\n",
    "            \n",
    "        return ys, caches\n",
    "    \n",
    "    def cross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(prob[range(m), y_train])\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        grad_y = l.softmax(y_pred)\n",
    "        grad_y[range(m), y_train] -= 1.0\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "\n",
    "    def loss_function(self, y_train, ys):\n",
    "        loss, dys = 0.0, []\n",
    "\n",
    "        for y_pred, y in zip(ys, y_train):\n",
    "            loss += self.cross_entropy(y_pred, y)/ y_train.shape[0]\n",
    "            dy = self.dcross_entropy(y_pred, y)\n",
    "            dys.append(dy)\n",
    "            \n",
    "        return loss, dys\n",
    "\n",
    "    def train_backward(self, dys, caches):\n",
    "        dh, grad, grads = [], [], []\n",
    "        for layer in range(self.L):\n",
    "            dh.append(np.zeros((1, self.H)))\n",
    "            grad.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            grads.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "\n",
    "        for t in reversed(range(len(dys))):\n",
    "            dX = dys[t]\n",
    "            for layer in reversed(range(self.L)):\n",
    "                dX, dh[layer], grad[layer] = self.backward(dX, dh[layer], caches[layer][t])\n",
    "                for k in grad[0].keys():\n",
    "                    grads[layer][k] += grad[layer][k]\n",
    "                \n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X_seed, h, size):\n",
    "        chars = [self.idx2char[X_seed]]\n",
    "        idx_list = list(range(self.vocab_size))\n",
    "        X = X_seed\n",
    "        \n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "\n",
    "        for _ in range(size): # range(start, stop, step)\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.0\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], _ = self.forward(y, h[layer], self.model[layer])\n",
    "                \n",
    "            prob = l.softmax(y)\n",
    "            idx = np.random.choice(idx_list, p=prob.ravel())\n",
    "            chars.append(self.idx2char[idx])\n",
    "            X = idx\n",
    "\n",
    "        return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "def get_minibatch(X, y, minibatch_size, shuffle=True):\n",
    "    minibatches = []\n",
    "\n",
    "    if shuffle:\n",
    "        X, y = skshuffle(X, y)\n",
    "\n",
    "    for i in range(0, X.shape[0], minibatch_size):\n",
    "        X_mini = X[i:i + minibatch_size]\n",
    "        y_mini = y[i:i + minibatch_size]\n",
    "        minibatches.append((X_mini, y_mini))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "def adam_rnn(nn, X_train, y_train, alpha, mb_size, n_iter, print_after):\n",
    "    minibatches = get_minibatch(X_train, y_train, mb_size, shuffle=False)\n",
    "\n",
    "    M, R = [], []\n",
    "    for layer in range(nn.L):\n",
    "        M.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()}) # dict={items, key:val, word:ID}\n",
    "        R.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        \n",
    "    beta1 = .99 # 0.9 to 0.99\n",
    "    beta2 = .999\n",
    "    state = nn.initial_state()\n",
    "    \n",
    "    #     import impl.constant as c, c.eps\n",
    "    eps = 1e-8 # constant\n",
    "\n",
    "    # Epochs\n",
    "    for iter in range(1, n_iter + 1): # range(start, stop, step=1 by default)\n",
    "\n",
    "        # No batches or other files available\n",
    "        # Minibatches\n",
    "        for idx in range(len(minibatches)):\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            ys, caches = nn.train_forward(X_mini, state)\n",
    "            loss, dys = nn.loss_function(y_mini, ys)\n",
    "            dX, grads = nn.train_backward(dys, caches)\n",
    "            \n",
    "            nn.losses['train'].append(loss)\n",
    "\n",
    "            for layer in range(nn.L):\n",
    "                for key in grads[layer].keys(): #key, value: items for dict={}\n",
    "                    M[layer][key] = l.exp_running_avg(M[layer][key], grads[layer][key], beta1)\n",
    "                    R[layer][key] = l.exp_running_avg(R[layer][key], grads[layer][key]**2, beta2)\n",
    "\n",
    "                    m_k_hat = M[layer][key] / (1. - (beta1**(iter)))\n",
    "                    r_k_hat = R[layer][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                    nn.model[layer][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + eps)\n",
    "                \n",
    "        # Print training loss and predicted samping for testing the model\n",
    "        if iter % print_after == 0:\n",
    "            print('Iter-{} training loss: {:.4f}'.format(iter, loss))\n",
    "            sample = nn.test(X_mini[0], state, size=100)\n",
    "            print(sample)\n",
    "    \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-130 training loss: 4.2627\n",
      "e8Ke–GapAbz0jWIB4%%DT'H%Ezkn72yJ0h1D0jrKwW9omlvK2IA–e0.KmESW-7zoB'wdDhg2p8;F7.6NUOdCoy9本v;;D6l本xgdvBF\n",
      "Iter-260 training loss: 4.2627\n",
      "eF,pC4DORlkoP:JInbAygAzc22Dx0GdNLoReb eGs;0'-OC.HW–yy't:c55,o日i.h.ldj1.jRgC25hctvM2aNdbgIz65R7kCW,M.T\n",
      "Iter-390 training loss: 4.2627\n",
      "eGe5jH0i%6hip本Psi08pTGitxUWx1-日eemNCLghFw6O2M3ak3pACrze:eKN(jlPgvzokuCrhpifvUoJGcISv6ro6thJp日4KHg0ltJ\n",
      "Iter-520 training loss: 4.2627\n",
      "er0SRy3\n",
      "8x,v7xT4'4LLe–wDSwLi;ki日s2%0Ro9R KHhw9l ESnBee3LzrRB1,18,6fC,xxa5OzP%u4212vLoB-kRpD日1AHzHec-m\n",
      "Iter-650 training loss: 4.2627\n",
      "efkuaC1日zWljT4P7–Un–W(3日本EEgs-nzTMH%LPmf%91b6TDC3dEvWo,'P日0bbR–Ru.jJUhI5s-60本G.;2vWz)4Dw2wbkzg0)RMaDL\n",
      "Iter-780 training loss: 4.2627\n",
      "e:)3j3Nv-,k2cA735R\"cLKLLcz80%GzCpN(\n",
      "EHmSz\"79yT31impgm;DTPR:M-hR,:2Htj%cn;E-be;72Dz9bhEeR6hzE3KaJRyMO\"\n",
      "Iter-910 training loss: 4.2627\n",
      "e3HD)nUNBKDRUGRJv4n–c'5c5;gzKJdkwWs;Uc\"T24B'–amj4D,R-PW%Ut\"e%bUG:8ySuOx,b.WE3.Mw,L6hux'3)cBt\n",
      "ry9LrRKv\n",
      "Iter-1040 training loss: 4.2627\n",
      "eCS4xyenONd%R\n",
      " \"UIgf,H0zpMsIW(bB\"日f'r5B1b4–he–9tU4k C0t0k%e(jUjDUW,uy'191b6bej5日nstCi\"Iv)aLK9-,:p本DDN\n",
      "Iter-1170 training loss: 4.2627\n",
      "e日47,Ihs1JS85j–j–Obg17MNL Fj;K62yJIvaPz-A5%hR,l-rguRGAml so-2B%.:Js\"a\"–e1Dy g\"APu6l4N5Gahf本R– N(43TjM\n",
      "Iter-1300 training loss: 4.2627\n",
      "eHevMwrHD-wfDnivCwACT%n6Fmc(iOzt80hj8W7y 08日vu–'%L0zUm:c,a%eHjf%rU6p6OFO–59(2Jl\n",
      "gizxk z1e本(–N4,0%b)rt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.RNN at 0x110c5c908>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyper-parameters\n",
    "n_iter = 1300 # epochs\n",
    "print_after = n_iter//10 # print loss, valid, and test\n",
    "time_step = 100 # width\n",
    "alpha = 1/time_step #1e-3 # learning_rate\n",
    "num_layers = 2 # depth\n",
    "num_hidden_units = 64 # hidden layer\n",
    "num_input_units = len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "p_dropout = 0.95 # keep_prob=1.0-p_dropout, q=1-p, 5% to 10% noise is recommanded for p_dropout\n",
    "\n",
    "net = RNN(D=num_input_units, H=num_hidden_units, L=num_layers, char2idx=char_to_idx, idx2char=idx_to_char, \n",
    "          p_dropout=p_dropout)\n",
    "\n",
    "adam_rnn(nn=net, X_train=X, y_train=y, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11093cf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(net.losses['train'], label='Train loss')\n",
    "# plt.plot(net.losses['train2'], label='Train loss 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
