{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "\n",
    "with open('data/text_data/japan.txt', 'r') as f:\n",
    "    txt = f.read()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    char_to_idx = {char: i for i, char in enumerate(set(txt))}\n",
    "    idx_to_char = {i: char for i, char in enumerate(set(txt))}\n",
    "\n",
    "    X = np.array([char_to_idx[x] for x in txt])\n",
    "    y = [char_to_idx[x] for x in txt[1:]]\n",
    "    y.append(char_to_idx['.'])\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model or Network\n",
    "import impl.layer as l\n",
    "\n",
    "class GRU:\n",
    "\n",
    "    def __init__(self, D, H, L, char2idx, idx2char, p_dropout):\n",
    "        self.D = D\n",
    "        self.H = H\n",
    "        self.L = L\n",
    "        self.char2idx = char2idx\n",
    "        self.idx2char = idx2char\n",
    "        self.vocab_size = len(char2idx)\n",
    "        self.losses = {'train':[], 'smooth train':[]}\n",
    "        self.p_dropout = p_dropout\n",
    "        \n",
    "        # Model parameters weights and biases\n",
    "        Z = H + D\n",
    "        m = dict(\n",
    "            Wz=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wr=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wh=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wy=np.random.randn(H, D) / np.sqrt(H / 2.),\n",
    "            bz=np.zeros((1, H)),\n",
    "            br=np.zeros((1, H)),\n",
    "            bh=np.zeros((1, H)),\n",
    "            by=np.zeros((1, D))\n",
    "        )\n",
    "\n",
    "        self.model = []\n",
    "        for _ in range(self.L):\n",
    "            self.model.append(m)\n",
    "\n",
    "    def initial_state(self):\n",
    "        return np.zeros((1, self.H))\n",
    "\n",
    "    def forward(self, X, h, m, train):\n",
    "        Wz, Wr, Wh, Wy = m['Wz'], m['Wr'], m['Wh'], m['Wy']\n",
    "        bz, br, bh, by = m['bz'], m['br'], m['bh'], m['by']\n",
    "\n",
    "        X_one_hot = X.copy()\n",
    "        h_old = h.copy()\n",
    "\n",
    "        X = np.column_stack((h_old, X_one_hot))\n",
    "\n",
    "        hz, hz_cache = l.fc_forward(X, Wz, bz)\n",
    "        hz, hz_sigm_cache = l.sigmoid_forward(hz)\n",
    "\n",
    "        hr, hr_cache = l.fc_forward(X, Wr, br)\n",
    "        hr, hr_sigm_cache = l.sigmoid_forward(hr)\n",
    "\n",
    "        X_prime = np.column_stack((hr * h_old, X_one_hot))\n",
    "        hh, hh_cache = l.fc_forward(X_prime, Wh, bh)\n",
    "        hh, hh_tanh_cache = l.tanh_forward(hh)\n",
    "\n",
    "        h = (1. - hz) * h_old + hz * hh\n",
    "        y, y_cache = l.fc_forward(h, Wy, by)\n",
    "        if train: \n",
    "            y, do_cache = self.dropout_forward(X=y, p_dropout=self.p_dropout)\n",
    "            cache = (X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, \n",
    "                     hh_tanh_cache, y_cache, do_cache)\n",
    "        else: # not train but test\n",
    "            cache = (X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, \n",
    "                     hh_tanh_cache, y_cache)\n",
    "\n",
    "        return y, h, cache\n",
    "\n",
    "    def backward(self, dy, dh, cache, train):\n",
    "        if train: # include dropout_cache/do_cache\n",
    "            X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache, do_cache = cache\n",
    "            dy = self.dropout_backward(dout=dy, cache=do_cache)\n",
    "        else: # not train but test\n",
    "            X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache = cache\n",
    "        \n",
    "        dh_next = dh.copy()\n",
    "        \n",
    "        dh, dWy, dby = l.fc_backward(dy, y_cache)\n",
    "        dh += dh_next\n",
    "\n",
    "        dhh = hz * dh\n",
    "        dh_old1 = (1. - hz) * dh\n",
    "        dhz = hh * dh - h_old * dh\n",
    "\n",
    "        dhh = l.tanh_backward(dhh, hh_tanh_cache)\n",
    "        dX_prime, dWh, dbh = l.fc_backward(dhh, hh_cache)\n",
    "\n",
    "        dh_prime = dX_prime[:, :self.H]\n",
    "        dh_old2 = hr * dh_prime\n",
    "\n",
    "        dhr = h_old * dh_prime\n",
    "        dhr = l.sigmoid_backward(dhr, hr_sigm_cache)\n",
    "        dXr, dWr, dbr = l.fc_backward(dhr, hr_cache)\n",
    "\n",
    "        dhz = l.sigmoid_backward(dhz, hz_sigm_cache)\n",
    "        dXz, dWz, dbz = l.fc_backward(dhz, hz_cache)\n",
    "\n",
    "        dX = dXr + dXz\n",
    "        dh_old3 = dX[:, :self.H]\n",
    "\n",
    "        dh = dh_old1 + dh_old2 + dh_old3\n",
    "        dX = dX[:, self.H:]\n",
    "\n",
    "        grad = dict(Wz=dWz, Wr=dWr, Wh=dWh, Wy=dWy, bz=dbz, br=dbr, bh=dbh, by=dby)\n",
    "        \n",
    "        return dX, dh, grad\n",
    "\n",
    "    def dropout_forward(self, X, p_dropout):\n",
    "        u = np.random.binomial(1, p_dropout, size=X.shape) / p_dropout\n",
    "        #         q = 1-p_dropout\n",
    "        #         u = np.random.binomial(1, q, size=X.shape)\n",
    "        out = X * u\n",
    "        cache = u\n",
    "        return out, cache\n",
    "\n",
    "    def dropout_backward(self, dout, cache):\n",
    "        dX = dout * cache\n",
    "        return dX\n",
    "\n",
    "    def train_forward(self, X_train, h):\n",
    "        ys, caches = [], []\n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "            caches.append([])\n",
    "\n",
    "        # Layer first and then lateral or recurrency\n",
    "        for X in X_train:\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], cache = self.forward(y, h[layer], self.model[layer], train=True)\n",
    "                caches[layer].append(cache)\n",
    "            ys.append(y)\n",
    "\n",
    "#         # Recurrency first and then layer\n",
    "#         for layer in range(self.L):\n",
    "#             # for X in X_train:\n",
    "#             for t in range(len(X_train)):\n",
    "#                 X = X_train[t]\n",
    "#                 if layer == 0:\n",
    "#                     X_one_hot = np.zeros(self.D)\n",
    "#                     X_one_hot[X] = 1.\n",
    "#                     y = X_one_hot.reshape(1, -1)\n",
    "#                 else:\n",
    "#                     y = X\n",
    "#                 y, h[layer], cache = self.forward(y, h[layer], self.model[layer], train=True)\n",
    "#                 caches[layer].append(cache)\n",
    "#                 ys.append(y)\n",
    "#             X_train = ys\n",
    "            \n",
    "        return ys, caches\n",
    "\n",
    "    def cross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(prob[range(m), y_train])\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        grad_y = l.softmax(y_pred)\n",
    "        grad_y[range(m), y_train] -= 1.0\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "    \n",
    "    def loss_function(self, y_train, ys):\n",
    "        loss, dys = 0.0, []\n",
    "\n",
    "        for y_pred, y in zip(ys, y_train):\n",
    "            loss += self.cross_entropy(y_pred, y)\n",
    "            dy = self.dcross_entropy(y_pred, y)\n",
    "            dys.append(dy)\n",
    "            \n",
    "        return loss, dys\n",
    "    \n",
    "    def train_backward(self, dys, caches):\n",
    "        dh, grad, grads = [], [], []\n",
    "        for layer in range(self.L):\n",
    "            dh.append(np.zeros((1, self.H)))\n",
    "            grad.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            grads.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "        \n",
    "        # layer 1st and then recurrency\n",
    "        for t in reversed(range(len(dys))):\n",
    "            dX = dys[t]\n",
    "            for layer in reversed(range(self.L)):\n",
    "                dX, dh[layer], grad[layer] = self.backward(dX, dh[layer], caches[layer][t], train=True)\n",
    "                for key in grad[0].keys():\n",
    "                    grads[layer][key] += grad[layer][key]\n",
    "                \n",
    "#         # rec 1st and then layer\n",
    "#         dXs = []\n",
    "#         for layer in reversed(range(self.L)):\n",
    "#             for t in reversed(range(len(dys))):\n",
    "#                 dX = dys[t]\n",
    "#                 dX, dh[layer], grad[layer] = self.backward(dX, dh[layer], caches[layer][t], train=True)\n",
    "#                 dXs.append(dX)\n",
    "#                 for key in grad[0].keys():\n",
    "#                     grads[layer][key] += grad[layer][key]\n",
    "#             dys = dXs\n",
    "            \n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X_seed, h, size):\n",
    "        chars = [self.idx2char[X_seed]]\n",
    "        idx_list = list(range(self.vocab_size))\n",
    "        X = X_seed\n",
    "        \n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "\n",
    "        for _ in range(size):\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], _ = self.forward(y, h[layer], self.model[layer], train=False)\n",
    "                \n",
    "            prob = l.softmax(y)\n",
    "            idx = np.random.choice(idx_list, p=prob.ravel())\n",
    "            chars.append(self.idx2char[idx])\n",
    "            X = idx\n",
    "\n",
    "        return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backprop\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "def get_minibatch(X, y, minibatch_size, shuffle):\n",
    "    minibatches = []\n",
    "\n",
    "    if shuffle:\n",
    "        X, y = skshuffle(X, y)\n",
    "\n",
    "    #     for i in range(0, X.shape[0], minibatch_size):\n",
    "    for i in range(0, X.shape[0] - minibatch_size +1, 1):\n",
    "        X_mini = X[i:i + minibatch_size]\n",
    "        y_mini = y[i:i + minibatch_size]\n",
    "        minibatches.append((X_mini, y_mini))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "def adam_rnn(nn, X_train, y_train, alpha, mb_size, n_iter, print_after):\n",
    "    M, R = [], []\n",
    "    for layer in range(nn.L):\n",
    "        M.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        R.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        \n",
    "    beta1 = .99\n",
    "    beta2 = .999\n",
    "    # import impl.constant as c\n",
    "    eps = 1e-8\n",
    "    state = nn.initial_state()\n",
    "    smooth_loss = 1.0\n",
    "\n",
    "    # Epochs\n",
    "    for iter in range(1, n_iter + 1):\n",
    "\n",
    "        # No batches/ full batches/ batch files\n",
    "        # Minibacthes\n",
    "        minibatches = get_minibatch(X_train, y_train, mb_size, shuffle=False)\n",
    "        for idx in range(len(minibatches)):\n",
    "            \n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            ys, caches = nn.train_forward(X_mini, state)\n",
    "            loss, dys = nn.loss_function(y_mini, ys)\n",
    "            dX, grads = nn.train_backward(dys, caches)\n",
    "            nn.losses['train'].append(loss)\n",
    "            smooth_loss = (0.999 * smooth_loss) + (0.001 * loss)\n",
    "            nn.losses['smooth train'].append(smooth_loss)\n",
    "        \n",
    "            for layer in range(nn.L):\n",
    "                for key in grads[0].keys(): #key, value: items\n",
    "                    M[layer][key] = l.exp_running_avg(M[layer][key], grads[layer][key], beta1)\n",
    "                    R[layer][key] = l.exp_running_avg(R[layer][key], grads[layer][key]**2, beta2)\n",
    "\n",
    "                    m_k_hat = M[layer][key] / (1. - (beta1**(iter)))\n",
    "                    r_k_hat = R[layer][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                    nn.model[layer][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + eps)\n",
    "                \n",
    "        # Print loss and test sample\n",
    "        if iter % print_after == 0:\n",
    "            print('Iter-{} loss: {:.4f}'.format(iter, loss))\n",
    "            sample = nn.test(X_mini[0], state, size=100)\n",
    "            print(sample)\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1 loss: 47.4783\n",
      "ioaBoso1nt1\n",
      "Iter-2 loss: 47.2149\n",
      "io  ta5an  \n",
      "Iter-3 loss: 45.3685\n",
      "ixyi cs    \n",
      "Iter-4 loss: 44.5191\n",
      "ilkbn  sd n\n",
      "Iter-5 loss: 45.2146\n",
      "ius btaenhu\n",
      "Iter-6 loss: 45.4403\n",
      "if  ,nbts s\n",
      "Iter-7 loss: 45.5019\n",
      "i Rn a n ut\n",
      "Iter-8 loss: 45.1328\n",
      "ionettthvP \n",
      "Iter-9 loss: 38.2199\n",
      "ii ed  y a2\n",
      "Iter-10 loss: 44.9147\n",
      "ise0ropacIt\n",
      "Iter-11 loss: 44.8637\n",
      "ianroed bkh\n",
      "Iter-12 loss: 38.2357\n",
      "i b iae  rt\n",
      "Iter-13 loss: 45.4569\n",
      "it b a pi o\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.GRU at 0x10fcae320>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "time_step = 10 # width, minibatch size and test sample size as well\n",
    "num_layers = 2 # depth\n",
    "n_iter = 13 # epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "p_dropout = 0.95 # q=1-p, q=keep_prob and p=dropout.\n",
    "print_after = n_iter//10 # print training loss, valid, and test\n",
    "num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "num_input_units = len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "\n",
    "# Build the network and learning it or optimizing it using SGD\n",
    "net = GRU(D=num_input_units, H=num_hidden_units, L=num_layers, char2idx=char_to_idx, idx2char=idx_to_char, \n",
    "          p_dropout=p_dropout)\n",
    "\n",
    "# Start learning using BP-SGD-ADAM\n",
    "adam_rnn(nn=net, X_train=X, y_train=y, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1108a65c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(net.losses['train'], label='Train loss')\n",
    "plt.plot(net.losses['smooth train'], label='Smooth train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
