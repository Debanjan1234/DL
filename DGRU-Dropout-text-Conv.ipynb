{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "\n",
    "with open('data/text_data/japan.txt', 'r') as f:\n",
    "    txt = f.read()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    char_to_idx = {char: i for i, char in enumerate(set(txt))}\n",
    "    idx_to_char = {i: char for i, char in enumerate(set(txt))}\n",
    "\n",
    "    X = np.array([char_to_idx[x] for x in txt])\n",
    "    y = [char_to_idx[x] for x in txt[1:]]\n",
    "    y.append(char_to_idx['.'])\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model or Network\n",
    "import impl.layer as l\n",
    "\n",
    "class GRU:\n",
    "\n",
    "    def __init__(self, D, H, L, char2idx, idx2char, p_dropout):\n",
    "        self.D = D\n",
    "        self.H = H\n",
    "        self.L = L\n",
    "        self.char2idx = char2idx\n",
    "        self.idx2char = idx2char\n",
    "        self.vocab_size = len(char2idx)\n",
    "        self.losses = {'train':[], 'smooth train':[]}\n",
    "        self.p_dropout = p_dropout\n",
    "        \n",
    "        # Model parameters weights and biases\n",
    "        Z = H + D\n",
    "        m = dict(\n",
    "            Wz=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wr=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wh=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wy=np.random.randn(H, D) / np.sqrt(H / 2.),\n",
    "            bz=np.zeros((1, H)),\n",
    "            br=np.zeros((1, H)),\n",
    "            bh=np.zeros((1, H)),\n",
    "            by=np.zeros((1, D))\n",
    "        )\n",
    "\n",
    "        self.model = []\n",
    "        for _ in range(self.L):\n",
    "            self.model.append(m)\n",
    "\n",
    "    def initial_state(self):\n",
    "        return np.zeros((1, self.H))\n",
    "\n",
    "    def forward(self, X, h, m, train):\n",
    "        Wz, Wr, Wh, Wy = m['Wz'], m['Wr'], m['Wh'], m['Wy']\n",
    "        bz, br, bh, by = m['bz'], m['br'], m['bh'], m['by']\n",
    "\n",
    "        X_one_hot = X.copy()\n",
    "        h_old = h.copy()\n",
    "\n",
    "        X = np.column_stack((h_old, X_one_hot))\n",
    "\n",
    "        hz, hz_cache = l.fc_forward(X, Wz, bz)\n",
    "        hz, hz_sigm_cache = l.sigmoid_forward(hz)\n",
    "\n",
    "        hr, hr_cache = l.fc_forward(X, Wr, br)\n",
    "        hr, hr_sigm_cache = l.sigmoid_forward(hr)\n",
    "\n",
    "        X_prime = np.column_stack((hr * h_old, X_one_hot))\n",
    "        hh, hh_cache = l.fc_forward(X_prime, Wh, bh)\n",
    "        hh, hh_tanh_cache = l.tanh_forward(hh)\n",
    "\n",
    "        h = (1. - hz) * h_old + hz * hh\n",
    "        y, y_cache = l.fc_forward(h, Wy, by)\n",
    "        if train: \n",
    "            y, do_cache = self.dropout_forward(X=y, p_dropout=self.p_dropout)\n",
    "            cache = (X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, \n",
    "                     hh_tanh_cache, y_cache, do_cache)\n",
    "        else: # not train but test\n",
    "            cache = (X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, \n",
    "                     hh_tanh_cache, y_cache)\n",
    "\n",
    "        return y, h, cache\n",
    "\n",
    "    def backward(self, dy, dh, cache, train):\n",
    "        if train: # include dropout_cache/do_cache\n",
    "            X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache, do_cache = cache\n",
    "            dy = self.dropout_backward(dout=dy, cache=do_cache)\n",
    "        else: # not train but test\n",
    "            X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache = cache\n",
    "        \n",
    "        dh_next = dh.copy()\n",
    "        \n",
    "        dh, dWy, dby = l.fc_backward(dy, y_cache)\n",
    "        dh += dh_next\n",
    "\n",
    "        dhh = hz * dh\n",
    "        dh_old1 = (1. - hz) * dh\n",
    "        dhz = (hh * dh) - (h_old * dh)\n",
    "\n",
    "        dhh = l.tanh_backward(dhh, hh_tanh_cache)\n",
    "        dX_prime, dWh, dbh = l.fc_backward(dhh, hh_cache)\n",
    "\n",
    "        dh_prime = dX_prime[:, :self.H]\n",
    "        dh_old2 = hr * dh_prime\n",
    "\n",
    "        dhr = h_old * dh_prime\n",
    "        dhr = l.sigmoid_backward(dhr, hr_sigm_cache)\n",
    "        dXr, dWr, dbr = l.fc_backward(dhr, hr_cache)\n",
    "\n",
    "        dhz = l.sigmoid_backward(dhz, hz_sigm_cache)\n",
    "        dXz, dWz, dbz = l.fc_backward(dhz, hz_cache)\n",
    "\n",
    "        dX = dXr + dXz\n",
    "\n",
    "        dh_old3 = dX[:, :self.H]\n",
    "        dh = dh_old1 + dh_old2 + dh_old3\n",
    "        \n",
    "        dX = dX[:, self.H:] + dX_prime[:, self.H:]\n",
    "\n",
    "        grad = dict(Wz=dWz, Wr=dWr, Wh=dWh, Wy=dWy, bz=dbz, br=dbr, bh=dbh, by=dby)\n",
    "        \n",
    "        return dX, dh, grad\n",
    "\n",
    "    def dropout_forward(self, X, p_dropout):\n",
    "        u = np.random.binomial(1, p_dropout, size=X.shape) / p_dropout\n",
    "        #         q = 1-p_dropout\n",
    "        #         u = np.random.binomial(1, q, size=X.shape)\n",
    "        out = X * u\n",
    "        cache = u\n",
    "        return out, cache\n",
    "\n",
    "    def dropout_backward(self, dout, cache):\n",
    "        dX = dout * cache\n",
    "        return dX\n",
    "\n",
    "    def train_forward(self, X_train, h):\n",
    "        ys, caches = [], []\n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "            caches.append([])\n",
    "\n",
    "        layer = 0 # self.L = 1\n",
    "        for X in X_train:\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            X = X_one_hot.reshape(1, -1)\n",
    "            y, h[layer], cache = self.forward(X, h[layer], self.model[layer], train=True)\n",
    "            caches[layer].append(cache)\n",
    "            ys.append(y)\n",
    "            \n",
    "        for layer in range(1, self.L):\n",
    "            X_train = ys.copy()\n",
    "            ys = []\n",
    "            for X in X_train:\n",
    "                y, h[layer], cache = self.forward(X, h[layer], self.model[layer], train=True)\n",
    "                caches[layer].append(cache)\n",
    "                ys.append(y)\n",
    "\n",
    "        return ys, caches\n",
    "\n",
    "    def cross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(prob[range(m), y_train])\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        grad_y = l.softmax(y_pred)\n",
    "        grad_y[range(m), y_train] -= 1.0\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "    \n",
    "    def loss_function(self, y_train, ys):\n",
    "        loss, dys = 0.0, []\n",
    "\n",
    "        for y_pred, y in zip(ys, y_train):\n",
    "            loss += self.cross_entropy(y_pred, y)\n",
    "            dy = self.dcross_entropy(y_pred, y)\n",
    "            dys.append(dy)\n",
    "            \n",
    "        return loss, dys\n",
    "    \n",
    "    def train_backward(self, dys, caches):\n",
    "        dh, grad, grads = [], [], []\n",
    "        for layer in range(self.L):\n",
    "            dh.append(np.zeros((1, self.H)))\n",
    "            grad.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            grads.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "        \n",
    "        for layer in reversed(range(self.L)):\n",
    "            if layer < (self.L - 1): dys = dXs.copy()\n",
    "            dXs = []\n",
    "            for t in reversed(range(len(dys))):\n",
    "                dX = dys[t]\n",
    "                dX, dh[layer], grad[layer] = self.backward(dX, dh[layer], caches[layer][t], train=True)\n",
    "                for key in grad[0].keys():\n",
    "                    grads[layer][key] += grad[layer][key]\n",
    "                dXs.append(dX)\n",
    "                \n",
    "        return dXs, grads\n",
    "    \n",
    "    def test(self, X_seed, h, size):\n",
    "        chars = [self.idx2char[X_seed]]\n",
    "        idx_list = list(range(self.vocab_size))\n",
    "        X = X_seed\n",
    "        \n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "\n",
    "        for _ in range(size):\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], _ = self.forward(y, h[layer], self.model[layer], train=False)\n",
    "                \n",
    "            prob = l.softmax(y)\n",
    "            idx = np.random.choice(idx_list, p=prob.ravel())\n",
    "            chars.append(self.idx2char[idx])\n",
    "            X = idx\n",
    "\n",
    "        return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backprop\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "def get_minibatch(X, y, minibatch_size, shuffle):\n",
    "    minibatches = []\n",
    "\n",
    "    if shuffle:\n",
    "        X, y = skshuffle(X, y)\n",
    "\n",
    "    #     for i in range(0, X.shape[0], minibatch_size):\n",
    "    for i in range(0, X.shape[0] - minibatch_size +1, 1):\n",
    "        X_mini = X[i:i + minibatch_size]\n",
    "        y_mini = y[i:i + minibatch_size]\n",
    "        minibatches.append((X_mini, y_mini))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "def adam_rnn(nn, X_train, y_train, alpha, mb_size, n_iter, print_after):\n",
    "    M, R = [], []\n",
    "    for layer in range(nn.L):\n",
    "        M.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        R.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        \n",
    "    beta1 = .99\n",
    "    beta2 = .999\n",
    "    eps = 1e-8\n",
    "    state = nn.initial_state()\n",
    "    smooth_loss = 1.0\n",
    "    minibatches = get_minibatch(X_train, y_train, mb_size, shuffle=False)\n",
    "\n",
    "    # Epochs\n",
    "    for iter in range(1, n_iter + 1):\n",
    "\n",
    "        # No batches/ full batches/ batch files\n",
    "        # Minibacthes\n",
    "        for idx in range(len(minibatches)):\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            ys, caches = nn.train_forward(X_mini, state)\n",
    "            loss, dys = nn.loss_function(y_train=y_mini, ys=ys)\n",
    "            _, grads = nn.train_backward(dys, caches)\n",
    "            nn.losses['train'].append(loss)\n",
    "            smooth_loss = (0.999 * smooth_loss) + (0.001 * loss)\n",
    "            nn.losses['smooth train'].append(smooth_loss)\n",
    "        \n",
    "            for layer in range(nn.L):\n",
    "                for key in grads[layer].keys(): #key, value: items\n",
    "                    M[layer][key] = l.exp_running_avg(M[layer][key], grads[layer][key], beta1)\n",
    "                    R[layer][key] = l.exp_running_avg(R[layer][key], grads[layer][key]**2, beta2)\n",
    "\n",
    "                    m_k_hat = M[layer][key] / (1. - (beta1**(iter)))\n",
    "                    r_k_hat = R[layer][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                    nn.model[layer][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + eps)\n",
    "                \n",
    "        # Print loss and test sample\n",
    "        if iter % print_after == 0:\n",
    "            print('Iter-{} loss: {:.4f}'.format(iter, loss))\n",
    "            sample = nn.test(X_mini[0], state, size=100)\n",
    "            print(sample)\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-10 loss: 156.7607\n",
      " Worghst in Japan toe dimatefrigg Japan is for the world's rcecay pirtrze. whish of eabonemb livu cin\n",
      "Iter-20 loss: 121.2539\n",
      " as 1941, following first of momited is the is the highest life expectures inse of mailld'seandexts a\n",
      "Iter-30 loss: 104.1452\n",
      " Chinas han tof Nogat of Japan's tht 19th an Emperor and an extand eargest exporter and fountry is th\n",
      "Iter-40 loss: 74.3782\n",
      " in the namly the Meiji Emperor as a country in the Global Corestion of the hagion in the Worrd'st ar\n",
      "Iter-50 loss: 74.5275\n",
      " power parity. It is also the world's largest city in the world's the fihted restion of inound an ene\n",
      "Iter-60 loss: 63.1969\n",
      " Sino-Japaneae world's letry te 1941, and the G20 and is considnred into a long perind in 1853 whes t\n",
      "Iter-70 loss: 80.2076\n",
      " Japan to expand its revised constitution in 1947, Japan has officially renounced its right to declar\n",
      "Iter-80 loss: 57.9856\n",
      " an legiclloty by colithinalSea and Russsaion expanded Japan tatente 19th and enjoys rinji Emperor an\n",
      "Iter-90 loss: 51.8141\n",
      " Tokyo Asia. Located in the 1uth anju emprited States fleet pressured Japan to open to the West. Near\n",
      "Iter-100 loss: 49.3057\n",
      " conymf or Niht reved the highest-ranked Asian country in the Global Phecearly from the Sea and the a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.GRU at 0x10bf42e10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "time_step = 100 # width, minibatch size and test sample size as well\n",
    "num_layers = 1 # depth\n",
    "n_iter = 100 # epochs\n",
    "alpha = 1e-4 # learning_rate\n",
    "p_dropout = 0.95 # q=1-p, q=keep_prob and p=dropout.\n",
    "print_after = n_iter//10 # print training loss, valid, and test\n",
    "num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "num_input_units = len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "\n",
    "# Build the network and learning it or optimizing it using SGD\n",
    "net = GRU(D=num_input_units, H=num_hidden_units, L=num_layers, char2idx=char_to_idx, idx2char=idx_to_char, \n",
    "          p_dropout=p_dropout)\n",
    "\n",
    "# Start learning using BP-SGD-ADAM\n",
    "adam_rnn(nn=net, X_train=X, y_train=y, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIBYcjDHGBPl/3yqS7rSpE2sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110dade48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(net.losses['train'], label='Train loss')\n",
    "plt.plot(net.losses['smooth train'], label='Smooth train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
