{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10000,), (5000,), (55000,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import impl.layer as l\n",
    "\n",
    "# Dataset preparation and pre-processing\n",
    "mnist = input_data.read_data_sets('data/MNIST_data/', one_hot=False)\n",
    "\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "y_test.shape, y_val.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "def prepro(X_train, X_val, X_test):\n",
    "    mean = np.mean(X_train)\n",
    "    # scale = 255. - mean # std or sqrt(var), 255 == 2**8 or 8 bit grayscale\n",
    "    # return (X_train - mean)/ scale, (X_val - mean)/ scale, (X_test - mean) / scale\n",
    "    return X_train - mean, X_val - mean, X_test - mean\n",
    "\n",
    "def selu_forward(X):\n",
    "    alpha = 1.6732632423543772848170429916717\n",
    "    scale = 1.0507009873554804934193349852946\n",
    "    out = scale * np.where(X>=0.0, X, alpha * (np.exp(X)-1))\n",
    "    cache = X\n",
    "    return out, cache\n",
    "\n",
    "def selu_backward(dout, cache):\n",
    "    alpha = 1.6732632423543772848170429916717\n",
    "    scale = 1.0507009873554804934193349852946\n",
    "    X = cache\n",
    "    dX_pos = dout.copy()\n",
    "    dX_pos[X<0] = 0\n",
    "    dX_neg = dout.copy()\n",
    "    dX_neg[X>0] = 0\n",
    "    dX = scale * np.where(X>=0.0, dX_pos, dX_neg * alpha * np.exp(X))\n",
    "    return dX\n",
    "\n",
    "# p_dropout = keep_prob\n",
    "def selu_dropout_forward(h, q):\n",
    "    '''h is activation, q is keep probability: q=1-p, p=p_dropout, and q=keep_prob'''\n",
    "    alpha = 1.6732632423543772848170429916717\n",
    "    scale = 1.0507009873554804934193349852946\n",
    "    alpha_p = -scale * alpha\n",
    "    mask = np.random.binomial(1, q, size=h.shape)\n",
    "    dropped = (mask * h) + ((1 - mask) * alpha_p)\n",
    "    a = 1. / np.sqrt(q + (alpha_p ** 2 * q  * (1 - q)))\n",
    "    b = -a * (1 - q) * alpha_p\n",
    "    out = (a * dropped) + b\n",
    "    cache = (a, mask)\n",
    "    return out, cache\n",
    "\n",
    "def selu_dropout_backward(dout, cache):\n",
    "    a, mask = cache\n",
    "    d_dropped = dout * a\n",
    "    dh = d_dropped * mask\n",
    "    return dh\n",
    "\n",
    "X_train, X_val, X_test = prepro(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l # or from impl.layer import *\n",
    "from impl.loss import * # import all functions from impl.loss file # import impl.loss as loss_func\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "class FFNN:\n",
    "\n",
    "    def __init__(self, D, C, H, L, p_dropout):\n",
    "#         self.mode = 'classification'\n",
    "        self.L = L # number of layers or depth\n",
    "#         self.p_dropout = p_dropout\n",
    "        self.losses = {'train':[], 'smooth train':[], 'valid':[], 'valid_acc':[]}\n",
    "        \n",
    "        # The adaptive/learnable/updatable random feedforward\n",
    "        self.model = []\n",
    "        \n",
    "        # Input layer\n",
    "        m = dict(W=np.random.randn(D, H) / np.sqrt(D / 2.),\n",
    "                 b=np.zeros((1, H)))\n",
    "        self.model.append(m)\n",
    "\n",
    "        # Hidden layers\n",
    "        m = dict(W=np.random.randn(H, H) / np.sqrt(H / 2.),\n",
    "                 b=np.zeros((1, H)))\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m_L.append(m)\n",
    "        self.model.append(m_L)\n",
    "        \n",
    "        # Output layer\n",
    "        m = dict(W=np.random.randn(H, C) / np.sqrt(H / 2.),\n",
    "                 b=np.zeros((1, C)))\n",
    "        self.model.append(m)\n",
    "        \n",
    "    def fc_forward(self, X, W, b):\n",
    "        out = (X @ W) + b\n",
    "        cache = (W, X)\n",
    "        return out, cache\n",
    "\n",
    "    def fc_backward(self, dout, cache):\n",
    "        W, h = cache\n",
    "\n",
    "        dW = h.T @ dout\n",
    "        db = np.sum(dout, axis=0).reshape(1, -1) # db_1xn\n",
    "#         print('db.shape', db.shape)\n",
    "        dX = dout @ W.T # Backprop\n",
    "\n",
    "        return dX, dW, db\n",
    "\n",
    "    def train_forward(self, X):\n",
    "        caches = []\n",
    "        \n",
    "        # Input layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[0]['W'], b=self.model[0]['b']) # X_1xD, y_1xc\n",
    "        y, nl_cache = selu_forward(X=y)\n",
    "        X = y.copy() # pass the previous output to the next layer\n",
    "        caches.append((fc_cache, nl_cache)) # caches[0]\n",
    "        \n",
    "        # Hidden layers\n",
    "        fc_caches, nl_caches = [], []\n",
    "        for layer in range(self.L):\n",
    "            y, fc_cache = self.fc_forward(X=X, W=self.model[1][layer]['W'], b=self.model[1][layer]['b'])\n",
    "            y, nl_cache = selu_forward(X=y)\n",
    "            X = y.copy() # pass to next layer\n",
    "            fc_caches.append(fc_cache)\n",
    "            nl_caches.append(nl_cache)\n",
    "        caches.append((fc_caches, nl_caches)) # caches[1]\n",
    "        \n",
    "        # Output layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[2]['W'], b=self.model[2]['b'])\n",
    "        caches.append(fc_cache) # caches[2]\n",
    "\n",
    "        return y, caches\n",
    "\n",
    "    def loss_function(self, y, y_train):\n",
    "        \n",
    "        loss = cross_entropy(y, y_train) # softmax is included\n",
    "        dy = dcross_entropy(y, y_train) # dsoftmax is included\n",
    "        \n",
    "        return loss, dy\n",
    "    \n",
    "    def train_backward(self, dy, caches):\n",
    "#         grads = self.model.copy()\n",
    "#         print('dy.shape', dy.shape)\n",
    "        grads = []\n",
    "\n",
    "        # Input layer\n",
    "        grads.append({key: np.zeros_like(val) for key, val in self.model[0].items()})\n",
    "        \n",
    "        # Hidden layer\n",
    "        grad = []\n",
    "        for layer in range(self.L):\n",
    "            grad.append({key: np.zeros_like(val) for key, val in self.model[1][layer].items()})\n",
    "        grads.append(grad)\n",
    "\n",
    "        # Outout layer\n",
    "        grads.append({key: np.zeros_like(val) for key, val in self.model[2].items()})\n",
    "\n",
    "        # Input layer\n",
    "        fc_cache = caches[2]\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache)\n",
    "        dy = dX.copy() # pass it to the previous layer\n",
    "        grads[2]['W'] = dW\n",
    "        grads[2]['b'] = db\n",
    "#         print('''grads[2]['W'].shape, grads[2]['b'].shape''', grads[2]['W'].shape, grads[2]['b'].shape)\n",
    "\n",
    "        # Hidden layer\n",
    "        fc_caches, nl_caches = caches[1]\n",
    "        for layer in reversed(range(self.L)):\n",
    "            dy = selu_backward(dout=dy, cache=nl_caches[layer])\n",
    "            dX, dW, db = self.fc_backward(dout=dy, cache=fc_caches[layer])\n",
    "            dy = dX.copy()\n",
    "            grads[1][layer]['W'] = dW\n",
    "            grads[1][layer]['b'] = db\n",
    "#             print('''grads[1][]layer['W'].shape, grads[1][layer]['b'].shape''', grads[1][layer]['W'].shape, \n",
    "#                   grads[1][layer]['b'].shape)\n",
    "\n",
    "        \n",
    "        # Input layer\n",
    "        fc_cache, nl_cache = caches[0]\n",
    "        dy = selu_backward(dout=dy, cache=nl_cache)\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache)\n",
    "        grads[0]['W'] = dW\n",
    "        grads[0]['b'] = db\n",
    "#         print('''grads[0]['W'].shape, grads[0]['b'].shape''', grads[0]['W'].shape, grads[0]['b'].shape)\n",
    "\n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X):\n",
    "        y_logit, _ = self.train_forward(X)\n",
    "        \n",
    "        # if self.mode == 'classification':\n",
    "        y_prob = l.softmax(y_logit) # for accuracy== acc\n",
    "        y_pred = np.argmax(y_prob, axis=1) # for loss==err\n",
    "        \n",
    "        return y_pred, y_logit\n",
    "        \n",
    "    def get_minibatch(self, X, y, minibatch_size, shuffle):\n",
    "        minibatches = []\n",
    "\n",
    "        if shuffle:\n",
    "            X, y = skshuffle(X, y)\n",
    "\n",
    "        for i in range(0, X.shape[0], minibatch_size):\n",
    "            X_mini = X[i:i + minibatch_size]\n",
    "            y_mini = y[i:i + minibatch_size]\n",
    "            minibatches.append((X_mini, y_mini))\n",
    "\n",
    "        return minibatches\n",
    "\n",
    "    def adam(self, train_set, val_set, alpha, mb_size, n_iter, print_after):\n",
    "        X_train, y_train = train_set\n",
    "        X_val, y_val = val_set\n",
    "\n",
    "        # Momentums\n",
    "        M, R = [], []\n",
    "\n",
    "        # Input layer momentums\n",
    "        M.append({key: np.zeros_like(val) for key, val in self.model[0].items()})\n",
    "        R.append({key: np.zeros_like(val) for key, val in self.model[0].items()})\n",
    "\n",
    "        # Hidden layers momentum\n",
    "        M_, R_ = [], []\n",
    "        for layer in range(self.L):\n",
    "            M_.append({key: np.zeros_like(val) for key, val in self.model[1][layer].items()})\n",
    "            R_.append({key: np.zeros_like(val) for key, val in self.model[1][layer].items()})\n",
    "        M.append(M_)\n",
    "        R.append(R_)\n",
    "\n",
    "        # Output layer momentums\n",
    "        M.append({key: np.zeros_like(val) for key, val in self.model[2].items()})\n",
    "        R.append({key: np.zeros_like(val) for key, val in self.model[2].items()})\n",
    " \n",
    "        # Learning decay\n",
    "        beta1 = .9\n",
    "        beta2 = .99\n",
    "        smooth_train = 1.\n",
    "\n",
    "        # Epochs\n",
    "        for iter in range(1, n_iter + 1):\n",
    "\n",
    "            # Minibatches\n",
    "            #         \"\"\"\n",
    "            #         Single training step over minibatch: forward, loss, backprop\n",
    "            #         \"\"\"\n",
    "            # Shuffle for each epochs/ stochasticity/ randomly choosing\n",
    "            #             for idx in range(len(minibatches)):\n",
    "            #             for _ in range(10):\n",
    "            # Shuffle in every iteration\n",
    "            # The dataset is static and non-sequentiol: no time-dependency or temporal pattern\n",
    "            minibatches = self.get_minibatch(X_train, y_train, mb_size, shuffle=True)\n",
    "            idx = np.random.randint(0, len(minibatches))\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            \n",
    "            # Train the model\n",
    "            y, caches = self.train_forward(X_mini)\n",
    "            loss, dy = self.loss_function(y, y_mini)\n",
    "            _, grads = self.train_backward(dy, caches)\n",
    "            self.losses['train'].append(loss)\n",
    "            smooth_train = (0.999 * smooth_train) + (0.001 * loss)\n",
    "            self.losses['smooth train'].append(smooth_train)\n",
    "            \n",
    "            # Update the model for input layer\n",
    "            for key in grads[0].keys():\n",
    "                M[0][key] = l.exp_running_avg(M[0][key], grads[0][key], beta1)\n",
    "                R[0][key] = l.exp_running_avg(R[0][key], grads[0][key]**2, beta2)\n",
    "                m_k_hat = M[0][key] / (1. - (beta1**(iter)))\n",
    "                r_k_hat = R[0][key] / (1. - (beta2**(iter)))\n",
    "                self.model[0][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + l.eps)\n",
    "\n",
    "            # Update the model for the hidden layers\n",
    "            for layer in range(self.L):\n",
    "                for key in grads[1][layer].keys():\n",
    "                    M[1][layer][key] = l.exp_running_avg(M[1][layer][key], grads[1][layer][key], beta1)\n",
    "                    R[1][layer][key] = l.exp_running_avg(R[1][layer][key], grads[1][layer][key]**2, beta2)\n",
    "                    m_k_hat = M[1][layer][key] / (1. - (beta1**(iter)))\n",
    "                    r_k_hat = R[1][layer][key] / (1. - (beta2**(iter)))\n",
    "                    self.model[1][layer][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + l.eps)\n",
    "\n",
    "            # Update the model for output layer\n",
    "            for key in grads[2].keys():\n",
    "                M[2][key] = l.exp_running_avg(M[2][key], grads[2][key], beta1)\n",
    "                R[2][key] = l.exp_running_avg(R[2][key], grads[2][key]**2, beta2)\n",
    "                m_k_hat = M[2][key] / (1. - (beta1**(iter)))\n",
    "                r_k_hat = R[2][key] / (1. - (beta2**(iter)))\n",
    "                self.model[2][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + l.eps)\n",
    "\n",
    "            # Validate the updated model\n",
    "            y_pred, y_logit = self.test(X_val)\n",
    "            valid_loss, _ = self.loss_function(y_logit, y_val) # softmax is included in entropy loss function\n",
    "            self.losses['valid'].append(valid_loss)\n",
    "            valid_acc = np.mean(y_pred == y_val)\n",
    "            self.losses['valid_acc'].append(valid_acc)\n",
    "            \n",
    "            # Print the model info: loss & accuracy or err & acc\n",
    "            if iter % print_after == 0:\n",
    "                print('Iter-{} train loss: {:.4f} valid loss: {:.4f}, valid accuracy: {:.4f}'.format(\n",
    "                    iter, loss, valid_loss, valid_acc))\n",
    "\n",
    "        # Test the final model\n",
    "        y_pred, y_logit = nn.test(X_test)\n",
    "        loss, _ = self.loss_function(y_logit, y_test) # softmax is included in entropy loss function\n",
    "        acc = np.mean(y_pred == y_test)\n",
    "        print('Last iteration - Test accuracy mean: {:.4f}, std: {:.4f}, loss: {:.4f}'.format(\n",
    "            acc.mean(), acc.std(), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-10 train loss: 2.6951 valid loss: 2.6985, valid accuracy: 0.1166\n",
      "Iter-20 train loss: 2.5007 valid loss: 2.5272, valid accuracy: 0.1520\n",
      "Iter-30 train loss: 2.4107 valid loss: 2.3778, valid accuracy: 0.1798\n",
      "Iter-40 train loss: 2.1465 valid loss: 2.2550, valid accuracy: 0.2198\n",
      "Iter-50 train loss: 2.2753 valid loss: 2.1440, valid accuracy: 0.2586\n",
      "Iter-60 train loss: 2.1922 valid loss: 2.0451, valid accuracy: 0.3000\n",
      "Iter-70 train loss: 2.0151 valid loss: 1.9579, valid accuracy: 0.3332\n",
      "Iter-80 train loss: 1.8910 valid loss: 1.8816, valid accuracy: 0.3670\n",
      "Iter-90 train loss: 1.7170 valid loss: 1.8152, valid accuracy: 0.3962\n",
      "Iter-100 train loss: 1.7580 valid loss: 1.7499, valid accuracy: 0.4194\n",
      "Iter-110 train loss: 1.7241 valid loss: 1.6878, valid accuracy: 0.4348\n",
      "Iter-120 train loss: 1.5926 valid loss: 1.6296, valid accuracy: 0.4578\n",
      "Iter-130 train loss: 1.5763 valid loss: 1.5769, valid accuracy: 0.4828\n",
      "Iter-140 train loss: 1.5157 valid loss: 1.5303, valid accuracy: 0.5016\n",
      "Iter-150 train loss: 1.4847 valid loss: 1.4888, valid accuracy: 0.5196\n",
      "Iter-160 train loss: 1.4580 valid loss: 1.4477, valid accuracy: 0.5376\n",
      "Iter-170 train loss: 1.5043 valid loss: 1.4078, valid accuracy: 0.5574\n",
      "Iter-180 train loss: 1.3599 valid loss: 1.3691, valid accuracy: 0.5734\n",
      "Iter-190 train loss: 1.3653 valid loss: 1.3360, valid accuracy: 0.5904\n",
      "Iter-200 train loss: 1.3005 valid loss: 1.3046, valid accuracy: 0.6042\n",
      "Iter-210 train loss: 1.3401 valid loss: 1.2727, valid accuracy: 0.6200\n",
      "Iter-220 train loss: 1.2955 valid loss: 1.2436, valid accuracy: 0.6356\n",
      "Iter-230 train loss: 1.0664 valid loss: 1.2159, valid accuracy: 0.6470\n",
      "Iter-240 train loss: 1.1801 valid loss: 1.1893, valid accuracy: 0.6576\n",
      "Iter-250 train loss: 1.3429 valid loss: 1.1645, valid accuracy: 0.6672\n",
      "Iter-260 train loss: 1.2610 valid loss: 1.1418, valid accuracy: 0.6756\n",
      "Iter-270 train loss: 1.1435 valid loss: 1.1194, valid accuracy: 0.6824\n",
      "Iter-280 train loss: 1.0605 valid loss: 1.0979, valid accuracy: 0.6914\n",
      "Iter-290 train loss: 1.0453 valid loss: 1.0789, valid accuracy: 0.6942\n",
      "Iter-300 train loss: 0.9480 valid loss: 1.0595, valid accuracy: 0.7024\n",
      "Iter-310 train loss: 1.0323 valid loss: 1.0416, valid accuracy: 0.7134\n",
      "Iter-320 train loss: 1.3810 valid loss: 1.0235, valid accuracy: 0.7174\n",
      "Iter-330 train loss: 1.0742 valid loss: 1.0049, valid accuracy: 0.7258\n",
      "Iter-340 train loss: 1.0986 valid loss: 0.9886, valid accuracy: 0.7326\n",
      "Iter-350 train loss: 0.8846 valid loss: 0.9726, valid accuracy: 0.7370\n",
      "Iter-360 train loss: 1.0860 valid loss: 0.9576, valid accuracy: 0.7414\n",
      "Iter-370 train loss: 0.9936 valid loss: 0.9437, valid accuracy: 0.7460\n",
      "Iter-380 train loss: 0.8030 valid loss: 0.9307, valid accuracy: 0.7526\n",
      "Iter-390 train loss: 1.0307 valid loss: 0.9174, valid accuracy: 0.7556\n",
      "Iter-400 train loss: 0.8237 valid loss: 0.9056, valid accuracy: 0.7602\n",
      "Iter-410 train loss: 0.7867 valid loss: 0.8915, valid accuracy: 0.7632\n",
      "Iter-420 train loss: 0.7304 valid loss: 0.8782, valid accuracy: 0.7654\n",
      "Iter-430 train loss: 0.9442 valid loss: 0.8662, valid accuracy: 0.7674\n",
      "Iter-440 train loss: 0.9159 valid loss: 0.8546, valid accuracy: 0.7694\n",
      "Iter-450 train loss: 0.9000 valid loss: 0.8437, valid accuracy: 0.7722\n",
      "Iter-460 train loss: 0.9447 valid loss: 0.8330, valid accuracy: 0.7766\n",
      "Iter-470 train loss: 0.7835 valid loss: 0.8233, valid accuracy: 0.7814\n",
      "Iter-480 train loss: 0.8458 valid loss: 0.8128, valid accuracy: 0.7822\n",
      "Iter-490 train loss: 0.6950 valid loss: 0.8033, valid accuracy: 0.7844\n",
      "Iter-500 train loss: 0.7586 valid loss: 0.7925, valid accuracy: 0.7868\n",
      "Iter-510 train loss: 0.7338 valid loss: 0.7833, valid accuracy: 0.7904\n",
      "Iter-520 train loss: 0.7409 valid loss: 0.7746, valid accuracy: 0.7940\n",
      "Iter-530 train loss: 0.7098 valid loss: 0.7660, valid accuracy: 0.7960\n",
      "Iter-540 train loss: 0.8958 valid loss: 0.7570, valid accuracy: 0.7990\n",
      "Iter-550 train loss: 0.8090 valid loss: 0.7486, valid accuracy: 0.8014\n",
      "Iter-560 train loss: 0.7193 valid loss: 0.7407, valid accuracy: 0.8024\n",
      "Iter-570 train loss: 0.6983 valid loss: 0.7330, valid accuracy: 0.8020\n",
      "Iter-580 train loss: 0.8121 valid loss: 0.7259, valid accuracy: 0.8062\n",
      "Iter-590 train loss: 0.6436 valid loss: 0.7191, valid accuracy: 0.8098\n",
      "Iter-600 train loss: 0.6781 valid loss: 0.7096, valid accuracy: 0.8118\n",
      "Iter-610 train loss: 0.8209 valid loss: 0.7029, valid accuracy: 0.8142\n",
      "Iter-620 train loss: 0.7025 valid loss: 0.6969, valid accuracy: 0.8142\n",
      "Iter-630 train loss: 0.6687 valid loss: 0.6919, valid accuracy: 0.8128\n",
      "Iter-640 train loss: 0.6315 valid loss: 0.6843, valid accuracy: 0.8168\n",
      "Iter-650 train loss: 0.7418 valid loss: 0.6775, valid accuracy: 0.8208\n",
      "Iter-660 train loss: 0.6598 valid loss: 0.6725, valid accuracy: 0.8196\n",
      "Iter-670 train loss: 0.5518 valid loss: 0.6666, valid accuracy: 0.8202\n",
      "Iter-680 train loss: 0.5087 valid loss: 0.6605, valid accuracy: 0.8218\n",
      "Iter-690 train loss: 0.6922 valid loss: 0.6549, valid accuracy: 0.8238\n",
      "Iter-700 train loss: 0.5775 valid loss: 0.6489, valid accuracy: 0.8266\n",
      "Iter-710 train loss: 0.5385 valid loss: 0.6439, valid accuracy: 0.8310\n",
      "Iter-720 train loss: 0.6925 valid loss: 0.6386, valid accuracy: 0.8338\n",
      "Iter-730 train loss: 0.5599 valid loss: 0.6338, valid accuracy: 0.8338\n",
      "Iter-740 train loss: 0.6438 valid loss: 0.6284, valid accuracy: 0.8350\n",
      "Iter-750 train loss: 0.7705 valid loss: 0.6237, valid accuracy: 0.8346\n",
      "Iter-760 train loss: 0.4317 valid loss: 0.6188, valid accuracy: 0.8370\n",
      "Iter-770 train loss: 0.7343 valid loss: 0.6141, valid accuracy: 0.8362\n",
      "Iter-780 train loss: 0.7537 valid loss: 0.6095, valid accuracy: 0.8382\n",
      "Iter-790 train loss: 0.6864 valid loss: 0.6048, valid accuracy: 0.8430\n",
      "Iter-800 train loss: 0.6131 valid loss: 0.6007, valid accuracy: 0.8434\n",
      "Iter-810 train loss: 0.6171 valid loss: 0.5955, valid accuracy: 0.8444\n",
      "Iter-820 train loss: 0.5545 valid loss: 0.5918, valid accuracy: 0.8466\n",
      "Iter-830 train loss: 0.5982 valid loss: 0.5887, valid accuracy: 0.8460\n",
      "Iter-840 train loss: 0.5670 valid loss: 0.5856, valid accuracy: 0.8472\n",
      "Iter-850 train loss: 0.5267 valid loss: 0.5813, valid accuracy: 0.8500\n",
      "Iter-860 train loss: 0.5099 valid loss: 0.5766, valid accuracy: 0.8494\n",
      "Iter-870 train loss: 0.4811 valid loss: 0.5732, valid accuracy: 0.8490\n",
      "Iter-880 train loss: 0.4046 valid loss: 0.5690, valid accuracy: 0.8514\n",
      "Iter-890 train loss: 0.6228 valid loss: 0.5656, valid accuracy: 0.8546\n",
      "Iter-900 train loss: 0.5151 valid loss: 0.5618, valid accuracy: 0.8556\n",
      "Iter-910 train loss: 0.5918 valid loss: 0.5585, valid accuracy: 0.8540\n",
      "Iter-920 train loss: 0.4532 valid loss: 0.5564, valid accuracy: 0.8518\n",
      "Iter-930 train loss: 0.5848 valid loss: 0.5520, valid accuracy: 0.8540\n",
      "Iter-940 train loss: 0.6582 valid loss: 0.5483, valid accuracy: 0.8526\n",
      "Iter-950 train loss: 0.6834 valid loss: 0.5451, valid accuracy: 0.8538\n",
      "Iter-960 train loss: 0.4369 valid loss: 0.5420, valid accuracy: 0.8556\n",
      "Iter-970 train loss: 0.5532 valid loss: 0.5390, valid accuracy: 0.8560\n",
      "Iter-980 train loss: 0.6834 valid loss: 0.5358, valid accuracy: 0.8564\n",
      "Iter-990 train loss: 0.5515 valid loss: 0.5335, valid accuracy: 0.8568\n",
      "Iter-1000 train loss: 0.3385 valid loss: 0.5318, valid accuracy: 0.8586\n",
      "Last iteration - Test accuracy mean: 0.8576, std: 0.0000, loss: 0.5363\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "n_iter = 1000 # number of epochs\n",
    "alpha = 1e-4 # learning_rate\n",
    "mb_size = 64 # 2**10==1024 # width, timestep for sequential data or minibatch size\n",
    "print_after = 10 # n_iter//10 # print loss for train, valid, and test\n",
    "num_hidden_units = 16 # number of kernels/ filters in each layer\n",
    "num_input_units = X_train.shape[1] # noise added at the input lavel as input noise we can use dX or for more improvement\n",
    "num_output_units = y_train.max() + 1 # number of classes in this classification problem\n",
    "num_layers = 1 # depth \n",
    "\n",
    "# NOT used now\n",
    "p_dropout = 0.95 #  layer & unit noise: keep_prob = p_dropout, q = 1-p, 0.95 or 0.90 by default, noise at the network level or layers\n",
    "\n",
    "\n",
    "# Build the model/NN and learn it: running session.\n",
    "nn = FFNN(C=num_output_units, D=num_input_units, H=num_hidden_units, p_dropout=p_dropout, L=num_layers)\n",
    "\n",
    "nn.adam(train_set=(X_train, y_train), val_set=(X_val, y_val), mb_size=mb_size, alpha=alpha, \n",
    "           n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVU21zn6qwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1212365c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(nn.losses['train'], label='Train loss')\n",
    "# plt.plot(nn.losses['smooth train'], label='Train smooth loss')\n",
    "plt.plot(nn.losses['valid'], label='Valid loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfRGRPKKkLyKSR5T0RUTyyP8HntwrzwAsu2gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1196867b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn.losses['valid_acc'], label='Valid accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
