{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEACAYAAACnJV25AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2b3aabe8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2b3aa402b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data: time-serie data from smartwatch or smartwatch data\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data reading\n",
    "# The smartwatch historical/time-seris data to visualize\n",
    "# data_path = 'data/smartwatch_data/experimental_data_analysis/Basis_Watch_Data.csv'\n",
    "data_path = 'data/financial_data/USD_INR.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Data: cleaning\n",
    "# Getting rid of NaN\n",
    "data = data.fillna(value=0.0)\n",
    "\n",
    "# # Plotting the smartwatch data before scaling/batch normalization\n",
    "data[:10000].plot() #x='dteday', y='cnt'\n",
    "\n",
    "# data[:100].plot()\n",
    "np.array(data).shape, np.array(data).dtype, np.array(data, dtype=None).dtype, \n",
    "# np.array(data[:, 1:], dtype=None).dtype\n",
    "\n",
    "data = np.array(data)\n",
    "plt.plot(data[:10000, 1], label='Price')\n",
    "# plt.plot(data[:1000, 2], label='Open')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Sequence learning - seq2seq learning - Unsupervised Learning\n",
    "# Training\n",
    "X_train = np.array(data[0:-2, 1], dtype=float).reshape(-1, 1)\n",
    "y_train = np.array(data[1:-1, 1], dtype=float).reshape(-1, 1)\n",
    "X_train.shape, y_train.shape, X_train.dtype, y_train.dtype\n",
    "\n",
    "# # type(X_train[2, 1])\n",
    "# # X_train.shape\n",
    "# np.array(X_train).dtype, np.array(X_train, dtype=None).dtype, np.array(X_train, dtype=float).dtype\n",
    "\n",
    "plt.plot(X_train[:10], label='X_train')\n",
    "plt.plot(y_train[:10], label='y_train')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model or Network\n",
    "import impl.layer as l\n",
    "from impl.loss import *\n",
    "\n",
    "class GRU:\n",
    "    def __init__(self, D, H, L, p_dropout): #, char2idx, idx2char):\n",
    "        self.D = D\n",
    "        self.H = H\n",
    "        self.L = L\n",
    "        self.p_dropout = p_dropout\n",
    "        # For text processing\n",
    "        #         self.idx2char = idx2char\n",
    "        #         self.vocab_size = len(char2idx)\n",
    "        self.losses = {'train':[], 'smooth train':[], 'valid': []}\n",
    "        \n",
    "        # Model params\n",
    "        Z = H + D\n",
    "        m = dict(\n",
    "            Wz=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wr=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wh=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wy=np.random.randn(H, D) / np.sqrt(H / 2.),\n",
    "            bz=np.zeros((1, H)),\n",
    "            br=np.zeros((1, H)),\n",
    "            bh=np.zeros((1, H)),\n",
    "            by=np.zeros((1, D))\n",
    "        )\n",
    "\n",
    "        self.model = []\n",
    "        for _ in range(self.L):\n",
    "            self.model.append(m)\n",
    "\n",
    "    def initial_state(self):\n",
    "        return np.zeros((1, self.H))\n",
    "\n",
    "    def forward(self, X, h, m, train): # This can be used for training & testing\n",
    "        Wz, Wr, Wh, Wy = m['Wz'], m['Wr'], m['Wh'], m['Wy']\n",
    "        bz, br, bh, by = m['bz'], m['br'], m['bh'], m['by']\n",
    "\n",
    "        X_in = X.copy()\n",
    "        h_in = h.copy()\n",
    "\n",
    "        X = np.column_stack((h_in, X_in))\n",
    "\n",
    "        hz, hz_cache = l.fc_forward(X, Wz, bz)\n",
    "        hz, hz_sigm_cache = l.sigmoid_forward(hz)\n",
    "\n",
    "        hr, hr_cache = l.fc_forward(X, Wr, br)\n",
    "        hr, hr_sigm_cache = l.sigmoid_forward(hr)\n",
    "\n",
    "        X = np.column_stack((hr * h_in, X_in))\n",
    "        \n",
    "        hh, hh_cache = l.fc_forward(X, Wh, bh)\n",
    "        hh, hh_tanh_cache = l.tanh_forward(hh)\n",
    "\n",
    "        # h = (1. - hz) * h_old + hz * hh\n",
    "        # or\n",
    "        h = ((1. - hz) * h_in) + (hz * hh)\n",
    "        # or\n",
    "        # h = h_in + hz (hh - h_in)\n",
    "\n",
    "        y, y_cache = l.fc_forward(h, Wy, by)\n",
    "        \n",
    "        # Testing\n",
    "        #         train = None\n",
    "        #         # train = True\n",
    "        #         # train = False\n",
    "        #         if train:\n",
    "        #             print('1')\n",
    "        #         else:\n",
    "        #             print('0')\n",
    "\n",
    "        if train: # is True\n",
    "            y, do_cache = l.dropout_forward(y, self.p_dropout)\n",
    "            cache = (h_in, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache, do_cache)\n",
    "        else:\n",
    "            cache= None # This is not needed for test/ validation\n",
    "\n",
    "        return y, h, cache\n",
    "\n",
    "    def backward(self, dy, dh, cache): # This is only used for training\n",
    "        h_in, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache, do_cache = cache\n",
    "        \n",
    "        dh_out = dh.copy()\n",
    "\n",
    "        dy = l.dropout_backward(dy, do_cache)\n",
    "        dh, dWy, dby = l.fc_backward(dy, y_cache)\n",
    "        dh += dh_out\n",
    "\n",
    "        dh_in1 = (1. - hz) * dh\n",
    "        dhh = hz * dh\n",
    "        dhz = (hh * dh) - (h_in * dh)\n",
    "        # or\n",
    "        # dhz = (hh - h_in) * dh\n",
    "\n",
    "        dhh = l.tanh_backward(dhh, hh_tanh_cache)\n",
    "        dXh, dWh, dbh = l.fc_backward(dhh, hh_cache)\n",
    "\n",
    "        dh = dXh[:, :self.H]\n",
    "        dX_in2 = dXh[:, self.H:]\n",
    "        dh_in2 = hr * dh\n",
    "\n",
    "        dhr = h_in * dh\n",
    "        dhr = l.sigmoid_backward(dhr, hr_sigm_cache)\n",
    "        dXr, dWr, dbr = l.fc_backward(dhr, hr_cache)\n",
    "\n",
    "        dhz = l.sigmoid_backward(dhz, hz_sigm_cache)\n",
    "        dXz, dWz, dbz = l.fc_backward(dhz, hz_cache)\n",
    "\n",
    "        dX = dXr + dXz\n",
    "        dh_in3 = dX[:, :self.H]\n",
    "        dX_in1 = dX[:, self.H:]\n",
    "\n",
    "        dh = dh_in1 + dh_in2 + dh_in3\n",
    "        dX = dX_in1 + dX_in2\n",
    "\n",
    "        grad = dict(Wz=dWz, Wr=dWr, Wh=dWh, Wy=dWy, bz=dbz, br=dbr, bh=dbh, by=dby)\n",
    "        \n",
    "        return dX, dh, grad\n",
    "\n",
    "    def train_forward(self, X_train, h):\n",
    "        ys, caches = [], []\n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "            caches.append([])\n",
    "\n",
    "        for X in X_train:\n",
    "            X = X.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], cache = self.forward(X, h[layer], self.model[layer], train=True)\n",
    "                caches[layer].append(cache)\n",
    "                X = y.copy()\n",
    "            ys.append(y)\n",
    "                    \n",
    "        return ys, caches\n",
    "    \n",
    "    def loss_function(self, y_pred, y_train):\n",
    "        loss, dys = 0.0, []\n",
    "\n",
    "        for y, Y in zip(y_pred, y_train):\n",
    "            loss += l2_regression(y_pred=y, y_train=Y) #/ m: t or number of samples for taking the average\n",
    "            dy = dl2_regression(y_pred=y, y_train=Y)\n",
    "            dys.append(dy)\n",
    "            \n",
    "        return loss, dys\n",
    "    \n",
    "    def train_backward(self, dys, caches):\n",
    "        dh, grad, grads = [], [], []\n",
    "        for layer in range(self.L):\n",
    "            dh.append(np.zeros((1, self.H)))\n",
    "            grad.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            grads.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "\n",
    "        for t in reversed(range(len(dys))):\n",
    "            dy = dys[t]\n",
    "            for layer in reversed(range(self.L)):\n",
    "                dX, dh[layer], grad[layer] = self.backward(dy, dh[layer], caches[layer][t])\n",
    "                for k in grad[layer].keys():\n",
    "                    grads[layer][k] += grad[layer][k]\n",
    "                dy = dX.copy()\n",
    "                \n",
    "        return grads\n",
    "    \n",
    "    def test(self, X_seed, h, size):\n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "\n",
    "        ys = []\n",
    "        X = X_seed.reshape(1, -1)\n",
    "        for _ in range(size):\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], _ = self.forward(X, h[layer], self.model[layer], train=False)\n",
    "                X = y.copy()\n",
    "            ys.append(y)\n",
    "            \n",
    "        return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minibatch(X, y, minibatch_size, shuffle):\n",
    "    minibatches = []\n",
    "\n",
    "    for i in range(0, X.shape[0], minibatch_size):\n",
    "#     for i in range(0, X.shape[0] - minibatch_size + 1, 1):\n",
    "        X_mini = X[i:i + minibatch_size]\n",
    "        y_mini = y[i:i + minibatch_size]\n",
    "        minibatches.append((X_mini, y_mini))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "def adam_rnn(nn, X_train, y_train, alpha, mb_size, n_iter, print_after):\n",
    "    M, R = [], []\n",
    "    for layer in range(nn.L):\n",
    "        M.append({k: np.zeros_like(v) for k, v in nn.model[layer].items()})\n",
    "        R.append({k: np.zeros_like(v) for k, v in nn.model[layer].items()})\n",
    "        \n",
    "    beta1 = .99\n",
    "    beta2 = .999\n",
    "    state = nn.initial_state()\n",
    "    smooth_loss = 1.\n",
    "    minibatches = get_minibatch(X_train, y_train, mb_size, shuffle=False)\n",
    "    \n",
    "    for iter in range(1, n_iter + 1):\n",
    "        for idx in range(len(minibatches)):\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            ys, caches = nn.train_forward(X_mini, state)\n",
    "            # def loss_function(self, y_pred, y_train):\n",
    "            loss, dys = nn.loss_function(y_pred=ys, y_train=y_mini)\n",
    "            grads = nn.train_backward(dys, caches)\n",
    "            \n",
    "            nn.losses['train'].append(loss)\n",
    "            smooth_loss = (0.999 * smooth_loss) + (0.001 * loss)\n",
    "            nn.losses['smooth train'].append(smooth_loss)\n",
    "            \n",
    "            for layer in range(nn.L):\n",
    "                for k in grads[layer].keys(): #key, value: items\n",
    "                    M[layer][k] = l.exp_running_avg(M[layer][k], grads[layer][k], beta1)\n",
    "                    R[layer][k] = l.exp_running_avg(R[layer][k], grads[layer][k]**2, beta2)\n",
    "\n",
    "                    m_k_hat = M[layer][k] / (1. - (beta1**(iter)))\n",
    "                    r_k_hat = R[layer][k] / (1. - (beta2**(iter)))\n",
    "\n",
    "                    nn.model[layer][k] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + l.eps)\n",
    "\n",
    "            # Validation loss to avoid overfitting & underfitting\n",
    "            mb_num = len(minibatches) //2\n",
    "            X_test, y_test = minibatches[mb_num]\n",
    "            ys = nn.test(X_seed=X_test[0], size=mb_size, h=state)\n",
    "            valid_loss, _ = nn.loss_function(y_pred=ys, y_train=y_test)\n",
    "            nn.losses['valid'].append(valid_loss)\n",
    "            \n",
    "        # Print loss and test sample\n",
    "        if iter % print_after == 0:\n",
    "            print('Iter-{}, train loss: {:.4f}, valid loss: {:.4f}'.format(iter, loss, valid_loss))\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1, train loss: 364.1207, valid loss: 53371.5365\n",
      "Iter-2, train loss: 1669.5734, valid loss: 43132.1400\n",
      "Iter-3, train loss: 3042.0524, valid loss: 37105.9662\n",
      "Iter-4, train loss: 4394.9936, valid loss: 33006.8739\n",
      "Iter-5, train loss: 5487.2328, valid loss: 30028.0564\n",
      "Iter-6, train loss: 6511.7035, valid loss: 27735.3047\n",
      "Iter-7, train loss: 7282.0786, valid loss: 25905.5447\n",
      "Iter-8, train loss: 8249.2714, valid loss: 24359.3531\n",
      "Iter-9, train loss: 9050.1426, valid loss: 23025.7048\n",
      "Iter-10, train loss: 9619.8420, valid loss: 21850.5497\n",
      "Iter-11, train loss: 10449.1516, valid loss: 20803.4337\n",
      "Iter-12, train loss: 11350.2268, valid loss: 19865.1234\n",
      "Iter-13, train loss: 12050.6948, valid loss: 19014.5206\n",
      "Iter-14, train loss: 12824.8797, valid loss: 18232.5409\n",
      "Iter-15, train loss: 13210.6835, valid loss: 17501.4824\n",
      "Iter-16, train loss: 13323.2759, valid loss: 16801.3430\n",
      "Iter-17, train loss: 14571.1048, valid loss: 16131.9690\n",
      "Iter-18, train loss: 14643.7734, valid loss: 15505.8767\n",
      "Iter-19, train loss: 15657.5470, valid loss: 14924.1836\n",
      "Iter-20, train loss: 15815.8680, valid loss: 14382.3762\n",
      "Iter-21, train loss: 16091.6621, valid loss: 13876.6789\n",
      "Iter-22, train loss: 16536.1515, valid loss: 13401.4555\n",
      "Iter-23, train loss: 17874.6941, valid loss: 12955.3276\n",
      "Iter-24, train loss: 17299.6273, valid loss: 12533.7700\n",
      "Iter-25, train loss: 18098.8132, valid loss: 12133.9995\n",
      "Iter-26, train loss: 18512.1199, valid loss: 11757.7702\n",
      "Iter-27, train loss: 19340.8247, valid loss: 11403.5433\n",
      "Iter-28, train loss: 19563.5247, valid loss: 11072.7142\n",
      "Iter-29, train loss: 18035.7941, valid loss: 10761.2699\n",
      "Iter-30, train loss: 19119.6139, valid loss: 10460.8545\n",
      "Iter-31, train loss: 20167.7325, valid loss: 10172.3422\n",
      "Iter-32, train loss: 19305.7560, valid loss: 9903.7359\n",
      "Iter-33, train loss: 20374.7954, valid loss: 9649.0839\n",
      "Iter-34, train loss: 19814.7468, valid loss: 9411.4103\n",
      "Iter-35, train loss: 20285.4623, valid loss: 9185.4894\n",
      "Iter-36, train loss: 19649.7686, valid loss: 8969.1527\n",
      "Iter-37, train loss: 19818.2441, valid loss: 8763.4368\n",
      "Iter-38, train loss: 20858.4032, valid loss: 8567.7468\n",
      "Iter-39, train loss: 21794.9795, valid loss: 8377.8076\n",
      "Iter-40, train loss: 19860.2833, valid loss: 8200.4119\n",
      "Iter-41, train loss: 21228.3201, valid loss: 8023.2845\n",
      "Iter-42, train loss: 20978.4938, valid loss: 7844.9134\n",
      "Iter-43, train loss: 20844.8630, valid loss: 7672.8407\n",
      "Iter-44, train loss: 22367.0271, valid loss: 7504.8923\n",
      "Iter-45, train loss: 21993.9082, valid loss: 7344.3296\n",
      "Iter-46, train loss: 23719.0277, valid loss: 7189.5230\n",
      "Iter-47, train loss: 20360.7259, valid loss: 7030.2213\n",
      "Iter-48, train loss: 20813.5487, valid loss: 6868.4887\n",
      "Iter-49, train loss: 20923.9248, valid loss: 6699.8548\n",
      "Iter-50, train loss: 20158.7973, valid loss: 6526.2331\n",
      "Iter-51, train loss: 21106.0045, valid loss: 6338.2191\n",
      "Iter-52, train loss: 19974.4659, valid loss: 6142.0436\n",
      "Iter-53, train loss: 21997.2779, valid loss: 5943.4529\n",
      "Iter-54, train loss: 20005.8045, valid loss: 5745.6604\n",
      "Iter-55, train loss: 19788.0825, valid loss: 5545.1347\n",
      "Iter-56, train loss: 19914.0413, valid loss: 5343.9388\n",
      "Iter-57, train loss: 19355.3857, valid loss: 5140.7624\n",
      "Iter-58, train loss: 17763.1514, valid loss: 4932.2880\n",
      "Iter-59, train loss: 17012.3581, valid loss: 4707.8843\n",
      "Iter-60, train loss: 15411.9175, valid loss: 4477.4630\n",
      "Iter-61, train loss: 16560.7416, valid loss: 4246.7215\n",
      "Iter-62, train loss: 12951.1910, valid loss: 4026.0955\n",
      "Iter-63, train loss: 14493.9979, valid loss: 3808.6558\n",
      "Iter-64, train loss: 15255.7477, valid loss: 3594.8307\n",
      "Iter-65, train loss: 14547.0307, valid loss: 3391.3825\n",
      "Iter-66, train loss: 13890.4678, valid loss: 3208.1414\n",
      "Iter-67, train loss: 12900.4007, valid loss: 3034.2525\n",
      "Iter-68, train loss: 13244.0135, valid loss: 2870.0310\n",
      "Iter-69, train loss: 11522.1761, valid loss: 2717.9963\n",
      "Iter-70, train loss: 10523.3179, valid loss: 2572.7127\n",
      "Iter-71, train loss: 11293.5726, valid loss: 2438.1163\n",
      "Iter-72, train loss: 18107.7324, valid loss: 2307.1096\n",
      "Iter-73, train loss: 11312.2685, valid loss: 2180.9979\n",
      "Iter-74, train loss: 11661.1799, valid loss: 2055.9013\n",
      "Iter-75, train loss: 8698.4469, valid loss: 1939.0682\n",
      "Iter-76, train loss: 11369.4940, valid loss: 1825.3696\n",
      "Iter-77, train loss: 16084.1632, valid loss: 1720.3520\n",
      "Iter-78, train loss: 13891.7509, valid loss: 1624.2452\n",
      "Iter-79, train loss: 9547.5350, valid loss: 1540.9536\n",
      "Iter-80, train loss: 13637.8106, valid loss: 1463.4230\n",
      "Iter-81, train loss: 11448.5633, valid loss: 1392.6146\n",
      "Iter-82, train loss: 15040.7580, valid loss: 1317.5683\n",
      "Iter-83, train loss: 9160.3236, valid loss: 1233.9311\n",
      "Iter-84, train loss: 11764.5803, valid loss: 1155.1767\n",
      "Iter-85, train loss: 10843.3619, valid loss: 1083.0082\n",
      "Iter-86, train loss: 10657.9178, valid loss: 1016.4650\n",
      "Iter-87, train loss: 10482.9822, valid loss: 959.8944\n",
      "Iter-88, train loss: 8739.4830, valid loss: 906.6649\n",
      "Iter-89, train loss: 10039.0225, valid loss: 849.3060\n",
      "Iter-90, train loss: 16453.6328, valid loss: 793.7446\n",
      "Iter-91, train loss: 9080.5047, valid loss: 742.6134\n",
      "Iter-92, train loss: 13389.9379, valid loss: 699.9197\n",
      "Iter-93, train loss: 10560.8112, valid loss: 666.4220\n",
      "Iter-94, train loss: 13459.8511, valid loss: 635.4983\n",
      "Iter-95, train loss: 16802.9053, valid loss: 600.0495\n",
      "Iter-96, train loss: 11620.1637, valid loss: 566.6190\n",
      "Iter-97, train loss: 18410.2171, valid loss: 538.6858\n",
      "Iter-98, train loss: 10234.8653, valid loss: 513.2817\n",
      "Iter-99, train loss: 10446.8328, valid loss: 487.7811\n",
      "Iter-100, train loss: 12264.6877, valid loss: 469.1924\n",
      "Iter-101, train loss: 17907.4985, valid loss: 448.8253\n",
      "Iter-102, train loss: 13276.5063, valid loss: 425.0317\n",
      "Iter-103, train loss: 19138.1428, valid loss: 400.5908\n",
      "Iter-104, train loss: 8879.0268, valid loss: 379.0302\n",
      "Iter-105, train loss: 13231.9947, valid loss: 353.5513\n",
      "Iter-106, train loss: 9511.2452, valid loss: 335.1839\n",
      "Iter-107, train loss: 7986.3972, valid loss: 325.3614\n",
      "Iter-108, train loss: 26210.8328, valid loss: 317.1484\n",
      "Iter-109, train loss: 8867.3814, valid loss: 307.2659\n",
      "Iter-110, train loss: 8804.5009, valid loss: 298.9907\n",
      "Iter-111, train loss: 10240.0059, valid loss: 284.4709\n",
      "Iter-112, train loss: 9145.6695, valid loss: 265.6721\n",
      "Iter-113, train loss: 15456.2895, valid loss: 258.6677\n",
      "Iter-114, train loss: 11439.8236, valid loss: 253.5276\n",
      "Iter-115, train loss: 9732.9863, valid loss: 242.6377\n",
      "Iter-116, train loss: 11680.7296, valid loss: 234.7392\n",
      "Iter-117, train loss: 11351.2893, valid loss: 231.4009\n",
      "Iter-118, train loss: 9578.4357, valid loss: 227.8426\n",
      "Iter-119, train loss: 12057.7344, valid loss: 223.5998\n",
      "Iter-120, train loss: 11267.0019, valid loss: 213.2062\n",
      "Iter-121, train loss: 7792.0037, valid loss: 212.3541\n",
      "Iter-122, train loss: 13917.7681, valid loss: 210.5812\n",
      "Iter-123, train loss: 10047.4763, valid loss: 189.3364\n",
      "Iter-124, train loss: 10900.2040, valid loss: 178.1608\n",
      "Iter-125, train loss: 22349.1219, valid loss: 177.6577\n",
      "Iter-126, train loss: 17535.5221, valid loss: 190.3775\n",
      "Iter-127, train loss: 9619.3742, valid loss: 187.1197\n",
      "Iter-128, train loss: 12050.9674, valid loss: 170.6575\n",
      "Iter-129, train loss: 15099.8579, valid loss: 172.7079\n",
      "Iter-130, train loss: 9224.5906, valid loss: 208.8050\n",
      "Iter-131, train loss: 12883.5250, valid loss: 210.7945\n",
      "Iter-132, train loss: 9374.4391, valid loss: 174.6304\n",
      "Iter-133, train loss: 9595.5880, valid loss: 170.1722\n",
      "Iter-134, train loss: 13387.6699, valid loss: 179.9532\n",
      "Iter-135, train loss: 16729.4601, valid loss: 177.1476\n",
      "Iter-136, train loss: 11237.4217, valid loss: 166.4457\n",
      "Iter-137, train loss: 9256.8806, valid loss: 165.6812\n",
      "Iter-138, train loss: 8545.5050, valid loss: 173.8387\n",
      "Iter-139, train loss: 21684.1895, valid loss: 163.5384\n",
      "Iter-140, train loss: 11648.3206, valid loss: 155.5920\n",
      "Iter-141, train loss: 10576.6878, valid loss: 154.1987\n",
      "Iter-142, train loss: 10975.2987, valid loss: 165.1049\n",
      "Iter-143, train loss: 10684.4024, valid loss: 150.9601\n",
      "Iter-144, train loss: 13336.3885, valid loss: 150.8708\n",
      "Iter-145, train loss: 9867.1544, valid loss: 163.4469\n",
      "Iter-146, train loss: 16437.1450, valid loss: 149.5268\n",
      "Iter-147, train loss: 8541.3753, valid loss: 151.4233\n",
      "Iter-148, train loss: 14679.3284, valid loss: 149.0254\n",
      "Iter-149, train loss: 8909.7001, valid loss: 152.9695\n",
      "Iter-150, train loss: 9311.1062, valid loss: 156.5646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-151, train loss: 8558.5695, valid loss: 151.8533\n",
      "Iter-152, train loss: 7201.9596, valid loss: 152.6381\n",
      "Iter-153, train loss: 12723.3455, valid loss: 154.2575\n",
      "Iter-154, train loss: 12911.4476, valid loss: 156.1104\n",
      "Iter-155, train loss: 12376.8623, valid loss: 159.8995\n",
      "Iter-156, train loss: 12856.6785, valid loss: 158.1811\n",
      "Iter-157, train loss: 11118.5647, valid loss: 158.0051\n",
      "Iter-158, train loss: 7934.7534, valid loss: 158.1356\n",
      "Iter-159, train loss: 8291.9134, valid loss: 159.0236\n",
      "Iter-160, train loss: 22058.5149, valid loss: 160.0962\n",
      "Iter-161, train loss: 14153.6521, valid loss: 161.8620\n",
      "Iter-162, train loss: 12573.4248, valid loss: 163.3511\n",
      "Iter-163, train loss: 7159.5810, valid loss: 164.3170\n",
      "Iter-164, train loss: 13638.1750, valid loss: 166.2014\n",
      "Iter-165, train loss: 9007.4174, valid loss: 165.7063\n",
      "Iter-166, train loss: 18322.0109, valid loss: 164.6639\n",
      "Iter-167, train loss: 20073.7200, valid loss: 164.5078\n",
      "Iter-168, train loss: 15387.2677, valid loss: 165.1968\n",
      "Iter-169, train loss: 12737.4626, valid loss: 167.6139\n",
      "Iter-170, train loss: 7621.1136, valid loss: 169.4498\n",
      "Iter-171, train loss: 12033.5006, valid loss: 170.7861\n",
      "Iter-172, train loss: 14348.8763, valid loss: 169.0338\n",
      "Iter-173, train loss: 10707.6357, valid loss: 169.9804\n",
      "Iter-174, train loss: 7961.4308, valid loss: 176.8716\n",
      "Iter-175, train loss: 12476.6929, valid loss: 170.6209\n",
      "Iter-176, train loss: 13251.1407, valid loss: 172.4412\n",
      "Iter-177, train loss: 8298.1255, valid loss: 179.1005\n",
      "Iter-178, train loss: 13047.5349, valid loss: 174.5933\n",
      "Iter-179, train loss: 8141.6269, valid loss: 183.0347\n",
      "Iter-180, train loss: 16705.9697, valid loss: 181.0757\n",
      "Iter-181, train loss: 23560.1895, valid loss: 178.0417\n",
      "Iter-182, train loss: 9168.6426, valid loss: 181.0638\n",
      "Iter-183, train loss: 11204.3546, valid loss: 185.3299\n",
      "Iter-184, train loss: 15244.2205, valid loss: 201.2291\n",
      "Iter-185, train loss: 10253.5386, valid loss: 197.3453\n",
      "Iter-186, train loss: 9543.7988, valid loss: 186.0237\n",
      "Iter-187, train loss: 9729.6707, valid loss: 188.0067\n",
      "Iter-188, train loss: 9986.7887, valid loss: 201.2019\n",
      "Iter-189, train loss: 14660.1924, valid loss: 196.0845\n",
      "Iter-190, train loss: 8158.8236, valid loss: 196.8369\n",
      "Iter-191, train loss: 10591.6703, valid loss: 189.8207\n",
      "Iter-192, train loss: 7773.9066, valid loss: 195.7129\n",
      "Iter-193, train loss: 11533.8400, valid loss: 202.7244\n",
      "Iter-194, train loss: 19549.3985, valid loss: 194.8346\n",
      "Iter-195, train loss: 7195.3501, valid loss: 212.8415\n",
      "Iter-196, train loss: 20792.5206, valid loss: 234.5975\n",
      "Iter-197, train loss: 7754.2971, valid loss: 195.7218\n",
      "Iter-198, train loss: 9676.2206, valid loss: 198.9488\n",
      "Iter-199, train loss: 11405.9827, valid loss: 203.6084\n",
      "Iter-200, train loss: 7986.4717, valid loss: 194.9779\n",
      "Iter-201, train loss: 8180.1633, valid loss: 191.7573\n",
      "Iter-202, train loss: 6775.8030, valid loss: 194.3601\n",
      "Iter-203, train loss: 15295.8044, valid loss: 193.3926\n",
      "Iter-204, train loss: 13739.2148, valid loss: 194.6066\n",
      "Iter-205, train loss: 11258.6361, valid loss: 212.9450\n",
      "Iter-206, train loss: 15001.4350, valid loss: 219.2954\n",
      "Iter-207, train loss: 13091.1332, valid loss: 197.0992\n",
      "Iter-208, train loss: 6772.1857, valid loss: 211.1616\n",
      "Iter-209, train loss: 8343.2524, valid loss: 227.2234\n",
      "Iter-210, train loss: 6422.2178, valid loss: 209.3149\n",
      "Iter-211, train loss: 9037.7048, valid loss: 219.9426\n",
      "Iter-212, train loss: 23170.9947, valid loss: 227.6167\n",
      "Iter-213, train loss: 9260.0451, valid loss: 224.4901\n",
      "Iter-214, train loss: 11769.3791, valid loss: 217.4371\n",
      "Iter-215, train loss: 19442.5575, valid loss: 211.8531\n",
      "Iter-216, train loss: 10576.9526, valid loss: 215.3509\n",
      "Iter-217, train loss: 11964.0617, valid loss: 225.9404\n",
      "Iter-218, train loss: 6875.2446, valid loss: 223.3550\n",
      "Iter-219, train loss: 12829.2026, valid loss: 229.4412\n",
      "Iter-220, train loss: 8902.0444, valid loss: 208.9928\n",
      "Iter-221, train loss: 9879.8063, valid loss: 277.0812\n",
      "Iter-222, train loss: 12275.7487, valid loss: 263.1151\n",
      "Iter-223, train loss: 10015.0133, valid loss: 213.9343\n",
      "Iter-224, train loss: 6395.4369, valid loss: 294.0012\n",
      "Iter-225, train loss: 8863.0853, valid loss: 317.9017\n",
      "Iter-226, train loss: 6769.8911, valid loss: 222.8381\n",
      "Iter-227, train loss: 6953.7931, valid loss: 219.2955\n",
      "Iter-228, train loss: 13870.1803, valid loss: 231.5266\n",
      "Iter-229, train loss: 6416.9466, valid loss: 243.5833\n",
      "Iter-230, train loss: 8488.5335, valid loss: 234.9075\n",
      "Iter-231, train loss: 9612.7905, valid loss: 231.0587\n",
      "Iter-232, train loss: 7647.9154, valid loss: 242.1414\n",
      "Iter-233, train loss: 5585.3625, valid loss: 264.7554\n",
      "Iter-234, train loss: 14232.9930, valid loss: 265.7281\n",
      "Iter-235, train loss: 11313.6659, valid loss: 263.8883\n",
      "Iter-236, train loss: 10133.7440, valid loss: 270.7776\n",
      "Iter-237, train loss: 12096.2409, valid loss: 265.7134\n",
      "Iter-238, train loss: 16853.1231, valid loss: 249.7287\n",
      "Iter-239, train loss: 10430.9790, valid loss: 255.5195\n",
      "Iter-240, train loss: 12936.0534, valid loss: 357.9011\n",
      "Iter-241, train loss: 7582.0124, valid loss: 283.3535\n",
      "Iter-242, train loss: 9841.9710, valid loss: 279.9191\n",
      "Iter-243, train loss: 6552.5098, valid loss: 316.7606\n",
      "Iter-244, train loss: 12568.0397, valid loss: 331.1281\n",
      "Iter-245, train loss: 10601.3642, valid loss: 276.3342\n",
      "Iter-246, train loss: 7667.9122, valid loss: 463.4202\n",
      "Iter-247, train loss: 5733.7707, valid loss: 326.2912\n",
      "Iter-248, train loss: 6399.2874, valid loss: 270.0006\n",
      "Iter-249, train loss: 15144.8785, valid loss: 292.8532\n",
      "Iter-250, train loss: 13093.7752, valid loss: 319.1541\n",
      "Iter-251, train loss: 13015.6190, valid loss: 395.4093\n",
      "Iter-252, train loss: 30268.4523, valid loss: 336.9125\n",
      "Iter-253, train loss: 9338.5303, valid loss: 349.7895\n",
      "Iter-254, train loss: 13501.1230, valid loss: 355.2377\n",
      "Iter-255, train loss: 15149.9048, valid loss: 391.1887\n",
      "Iter-256, train loss: 5329.5088, valid loss: 332.2746\n",
      "Iter-257, train loss: 11832.3145, valid loss: 330.9659\n",
      "Iter-258, train loss: 8478.3879, valid loss: 438.6924\n",
      "Iter-259, train loss: 5667.2438, valid loss: 323.9734\n",
      "Iter-260, train loss: 11268.4224, valid loss: 326.4834\n",
      "Iter-261, train loss: 7559.1755, valid loss: 491.1027\n",
      "Iter-262, train loss: 5220.3669, valid loss: 422.4337\n",
      "Iter-263, train loss: 7080.5758, valid loss: 425.0723\n",
      "Iter-264, train loss: 9702.3073, valid loss: 417.3431\n",
      "Iter-265, train loss: 6961.9568, valid loss: 372.2020\n",
      "Iter-266, train loss: 5191.9818, valid loss: 459.3003\n",
      "Iter-267, train loss: 4648.1055, valid loss: 382.6048\n",
      "Iter-268, train loss: 10425.5898, valid loss: 499.6108\n",
      "Iter-269, train loss: 6690.8867, valid loss: 428.6829\n",
      "Iter-270, train loss: 8103.9584, valid loss: 504.1925\n",
      "Iter-271, train loss: 5861.0402, valid loss: 442.0547\n",
      "Iter-272, train loss: 18362.9504, valid loss: 482.7343\n",
      "Iter-273, train loss: 5208.0434, valid loss: 518.5933\n",
      "Iter-274, train loss: 14966.5167, valid loss: 429.8203\n",
      "Iter-275, train loss: 7946.2216, valid loss: 588.6928\n",
      "Iter-276, train loss: 7238.6893, valid loss: 400.7446\n",
      "Iter-277, train loss: 13069.7522, valid loss: 539.3318\n",
      "Iter-278, train loss: 22319.4849, valid loss: 509.7551\n",
      "Iter-279, train loss: 7233.8322, valid loss: 528.0802\n",
      "Iter-280, train loss: 4817.8944, valid loss: 518.9381\n",
      "Iter-281, train loss: 11943.5875, valid loss: 466.1794\n",
      "Iter-282, train loss: 4643.7982, valid loss: 488.4645\n",
      "Iter-283, train loss: 12288.9695, valid loss: 524.9764\n",
      "Iter-284, train loss: 5740.0091, valid loss: 559.1738\n",
      "Iter-285, train loss: 7420.9197, valid loss: 444.9652\n",
      "Iter-286, train loss: 5548.2398, valid loss: 492.5823\n",
      "Iter-287, train loss: 4734.7401, valid loss: 537.0226\n",
      "Iter-288, train loss: 7674.6830, valid loss: 531.4992\n",
      "Iter-289, train loss: 11079.4027, valid loss: 583.4353\n",
      "Iter-290, train loss: 26926.7605, valid loss: 547.4613\n",
      "Iter-291, train loss: 14280.1631, valid loss: 688.4919\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "time_step = 100 # width, minibatch size and test sample size as well\n",
    "num_layers = 2 # depth\n",
    "n_iter = 1000 # epochs\n",
    "alpha = 1e-4 # learning_rate\n",
    "print_after = 1 # n_iter//10 # print training loss, valid, and test\n",
    "num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "num_input_units = 1 #len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "p_dropout = 0.95 # dropout = 1- keep_prob, p = 1-q\n",
    "\n",
    "# Build the network and learning it or optimizing it using SGD\n",
    "net = GRU(D=num_input_units, H=num_hidden_units, L=num_layers, p_dropout=p_dropout) #, char2idx=char_to_idx, idx2char=idx_to_char)\n",
    "\n",
    "# Start learning using BP-SGD-ADAM\n",
    "adam_rnn(nn=net, X_train=X_train, y_train=y_train, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)\n",
    "\n",
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(net.losses['train'], label='Train loss')\n",
    "plt.plot(net.losses['smooth train'], label='Train smooth loss')\n",
    "plt.plot(net.losses['valid'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEACAYAAAB/BTv2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w9Plx39G/EpAwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2b3abd4278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(net.losses['train'], label='Train loss')\n",
    "plt.plot(net.losses['smooth train'], label='Train smooth loss')\n",
    "plt.plot(net.losses['valid'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1, train loss: 448.3948, valid loss: 73265.5267\n",
      "Iter-2, train loss: 13.2711, valid loss: 59299.5638\n",
      "Iter-3, train loss: 158.4940, valid loss: 53350.7321\n",
      "Iter-4, train loss: 444.5878, valid loss: 49340.7286\n",
      "Iter-5, train loss: 775.7378, valid loss: 46192.3241\n",
      "Iter-6, train loss: 1100.9398, valid loss: 43624.2927\n",
      "Iter-7, train loss: 1373.7784, valid loss: 41526.1090\n",
      "Iter-8, train loss: 1535.3776, valid loss: 39810.2068\n",
      "Iter-9, train loss: 1511.3778, valid loss: 38381.9482\n",
      "Iter-10, train loss: 1255.8772, valid loss: 37261.2765\n",
      "Iter-11, train loss: 927.6613, valid loss: 36724.5053\n",
      "Iter-12, train loss: 663.6693, valid loss: 37462.2223\n",
      "Iter-13, train loss: 444.8353, valid loss: 38872.6378\n",
      "Iter-14, train loss: 255.4302, valid loss: 39858.8774\n",
      "Iter-15, train loss: 110.4671, valid loss: 40760.4642\n",
      "Iter-16, train loss: 49.0310, valid loss: 41640.2880\n",
      "Iter-17, train loss: 40.2444, valid loss: 37789.7516\n",
      "Iter-18, train loss: 41.6412, valid loss: 32855.7552\n",
      "Iter-19, train loss: 42.7662, valid loss: 30904.7951\n",
      "Iter-20, train loss: 43.5047, valid loss: 29868.2294\n",
      "Iter-21, train loss: 43.6728, valid loss: 28991.8622\n",
      "Iter-22, train loss: 44.2738, valid loss: 28191.5218\n",
      "Iter-23, train loss: 44.7200, valid loss: 27403.4738\n",
      "Iter-24, train loss: 45.2280, valid loss: 26513.4282\n",
      "Iter-25, train loss: 45.7561, valid loss: 25577.4385\n",
      "Iter-26, train loss: 46.1852, valid loss: 24671.3256\n",
      "Iter-27, train loss: 46.6257, valid loss: 23813.3816\n",
      "Iter-28, train loss: 46.9895, valid loss: 23019.1485\n",
      "Iter-29, train loss: 47.2915, valid loss: 22275.4360\n",
      "Iter-30, train loss: 47.5697, valid loss: 21559.7434\n",
      "Iter-31, train loss: 47.8244, valid loss: 20861.3397\n",
      "Iter-32, train loss: 48.0308, valid loss: 20185.4109\n",
      "Iter-33, train loss: 48.1485, valid loss: 19543.9680\n",
      "Iter-34, train loss: 48.1059, valid loss: 18931.9485\n",
      "Iter-35, train loss: 48.0002, valid loss: 18348.2507\n",
      "Iter-36, train loss: 47.6079, valid loss: 17783.7428\n",
      "Iter-37, train loss: 47.4120, valid loss: 17247.3793\n",
      "Iter-38, train loss: 46.5302, valid loss: 16722.0255\n",
      "Iter-39, train loss: 47.4302, valid loss: 16236.1471\n",
      "Iter-40, train loss: 49.7074, valid loss: 15714.6000\n",
      "Iter-41, train loss: 51.9467, valid loss: 15357.8527\n",
      "Iter-42, train loss: 52.2459, valid loss: 14765.7594\n",
      "Iter-43, train loss: 44.9874, valid loss: 14448.3584\n",
      "Iter-44, train loss: 43.8518, valid loss: 13992.6747\n",
      "Iter-45, train loss: 43.5844, valid loss: 13576.0584\n",
      "Iter-46, train loss: 43.4198, valid loss: 13215.6691\n",
      "Iter-47, train loss: 42.3541, valid loss: 12836.0935\n",
      "Iter-48, train loss: 41.7867, valid loss: 12488.7106\n",
      "Iter-49, train loss: 41.0062, valid loss: 12131.6637\n",
      "Iter-50, train loss: 40.2423, valid loss: 11765.3600\n",
      "Iter-51, train loss: 39.4831, valid loss: 11396.0810\n",
      "Iter-52, train loss: 38.6537, valid loss: 11033.9071\n",
      "Iter-53, train loss: 37.9270, valid loss: 10689.7320\n",
      "Iter-54, train loss: 37.2545, valid loss: 10361.4332\n",
      "Iter-55, train loss: 36.8302, valid loss: 10052.4057\n",
      "Iter-56, train loss: 36.5630, valid loss: 9755.1955\n",
      "Iter-57, train loss: 36.6827, valid loss: 9474.3399\n",
      "Iter-58, train loss: 36.8546, valid loss: 9196.7254\n",
      "Iter-59, train loss: 37.8461, valid loss: 8936.6828\n",
      "Iter-60, train loss: 38.9871, valid loss: 8663.8193\n",
      "Iter-61, train loss: 42.4372, valid loss: 8430.7425\n",
      "Iter-62, train loss: 45.8312, valid loss: 8133.1976\n",
      "Iter-63, train loss: 43.0065, valid loss: 7933.8386\n",
      "Iter-64, train loss: 41.3559, valid loss: 7645.0613\n",
      "Iter-65, train loss: 41.5729, valid loss: 7406.3027\n",
      "Iter-66, train loss: 42.7087, valid loss: 7168.3223\n",
      "Iter-67, train loss: 42.9964, valid loss: 6928.2411\n",
      "Iter-68, train loss: 44.0049, valid loss: 6706.7388\n",
      "Iter-69, train loss: 44.3622, valid loss: 6483.7699\n",
      "Iter-70, train loss: 45.0998, valid loss: 6274.6877\n",
      "Iter-71, train loss: 45.5697, valid loss: 6072.4759\n",
      "Iter-72, train loss: 46.1718, valid loss: 5885.2316\n",
      "Iter-73, train loss: 46.5792, valid loss: 5710.8899\n",
      "Iter-74, train loss: 47.1007, valid loss: 5557.3586\n",
      "Iter-75, train loss: 47.4096, valid loss: 5424.5856\n",
      "Iter-76, train loss: 47.9447, valid loss: 5326.4230\n",
      "Iter-77, train loss: 48.2230, valid loss: 5259.4115\n",
      "Iter-78, train loss: 49.2922, valid loss: 5224.1978\n",
      "Iter-79, train loss: 51.6865, valid loss: 5127.3178\n",
      "Iter-80, train loss: 55.1464, valid loss: 4976.8127\n",
      "Iter-81, train loss: 57.1810, valid loss: 4629.0187\n",
      "Iter-82, train loss: 51.1634, valid loss: 4610.8465\n",
      "Iter-83, train loss: 50.5224, valid loss: 4336.1824\n",
      "Iter-84, train loss: 50.7992, valid loss: 4156.4931\n",
      "Iter-85, train loss: 51.0998, valid loss: 3983.2303\n",
      "Iter-86, train loss: 51.0346, valid loss: 3762.8728\n",
      "Iter-87, train loss: 51.1676, valid loss: 3585.0008\n",
      "Iter-88, train loss: 51.1819, valid loss: 3392.5569\n",
      "Iter-89, train loss: 51.2231, valid loss: 3215.9493\n",
      "Iter-90, train loss: 51.2206, valid loss: 3043.9361\n",
      "Iter-91, train loss: 51.2029, valid loss: 2881.5046\n",
      "Iter-92, train loss: 51.1473, valid loss: 2726.2021\n",
      "Iter-93, train loss: 51.0725, valid loss: 2579.0969\n",
      "Iter-94, train loss: 50.9713, valid loss: 2440.4704\n",
      "Iter-95, train loss: 50.8422, valid loss: 2307.5371\n",
      "Iter-96, train loss: 50.7747, valid loss: 2186.5469\n",
      "Iter-97, train loss: 50.6978, valid loss: 2063.3395\n",
      "Iter-98, train loss: 52.0011, valid loss: 1962.9559\n",
      "Iter-99, train loss: 54.1627, valid loss: 1852.6065\n",
      "Iter-100, train loss: 61.3511, valid loss: 1734.9153\n",
      "Iter-101, train loss: 52.4314, valid loss: 1706.7869\n",
      "Iter-102, train loss: 50.7927, valid loss: 1568.5187\n",
      "Iter-103, train loss: 50.1400, valid loss: 1500.6090\n",
      "Iter-104, train loss: 50.1763, valid loss: 1441.3915\n",
      "Iter-105, train loss: 49.9819, valid loss: 1362.3110\n",
      "Iter-106, train loss: 49.7809, valid loss: 1295.4796\n",
      "Iter-107, train loss: 49.5853, valid loss: 1223.2860\n",
      "Iter-108, train loss: 49.4120, valid loss: 1153.5846\n",
      "Iter-109, train loss: 49.2311, valid loss: 1079.5866\n",
      "Iter-110, train loss: 49.0282, valid loss: 1004.3472\n",
      "Iter-111, train loss: 48.8027, valid loss: 929.2487\n",
      "Iter-112, train loss: 48.5569, valid loss: 855.2682\n",
      "Iter-113, train loss: 48.2921, valid loss: 783.4028\n",
      "Iter-114, train loss: 48.0058, valid loss: 715.0194\n",
      "Iter-115, train loss: 47.7061, valid loss: 649.3364\n",
      "Iter-116, train loss: 47.3869, valid loss: 588.7049\n",
      "Iter-117, train loss: 47.0823, valid loss: 528.9592\n",
      "Iter-118, train loss: 46.8559, valid loss: 478.6312\n",
      "Iter-119, train loss: 47.1729, valid loss: 420.9403\n",
      "Iter-120, train loss: 52.1559, valid loss: 382.4708\n",
      "Iter-121, train loss: 55.6928, valid loss: 338.4757\n",
      "Iter-122, train loss: 53.3588, valid loss: 288.8842\n",
      "Iter-123, train loss: 45.9487, valid loss: 269.3303\n",
      "Iter-124, train loss: 45.4460, valid loss: 228.0258\n",
      "Iter-125, train loss: 45.3301, valid loss: 195.8950\n",
      "Iter-126, train loss: 45.0691, valid loss: 171.2177\n",
      "Iter-127, train loss: 44.5568, valid loss: 145.2343\n",
      "Iter-128, train loss: 44.1808, valid loss: 123.3994\n",
      "Iter-129, train loss: 43.7931, valid loss: 103.8406\n",
      "Iter-130, train loss: 43.4036, valid loss: 86.7873\n",
      "Iter-131, train loss: 42.9962, valid loss: 71.8621\n",
      "Iter-132, train loss: 42.5833, valid loss: 59.0489\n",
      "Iter-133, train loss: 42.1554, valid loss: 48.2261\n",
      "Iter-134, train loss: 41.7367, valid loss: 39.2468\n",
      "Iter-135, train loss: 41.3249, valid loss: 31.7787\n",
      "Iter-136, train loss: 40.9269, valid loss: 25.8511\n",
      "Iter-137, train loss: 40.6121, valid loss: 20.5441\n",
      "Iter-138, train loss: 40.3279, valid loss: 16.7814\n",
      "Iter-139, train loss: 40.6921, valid loss: 13.3546\n",
      "Iter-140, train loss: 44.0619, valid loss: 12.2004\n",
      "Iter-141, train loss: 49.3459, valid loss: 12.8613\n",
      "Iter-142, train loss: 47.7513, valid loss: 15.9246\n",
      "Iter-143, train loss: 39.9856, valid loss: 17.9528\n",
      "Iter-144, train loss: 38.7030, valid loss: 25.3836\n",
      "Iter-145, train loss: 38.5208, valid loss: 32.4278\n",
      "Iter-146, train loss: 38.1409, valid loss: 40.4116\n",
      "Iter-147, train loss: 37.7119, valid loss: 51.3144\n",
      "Iter-148, train loss: 37.2270, valid loss: 62.6133\n",
      "Iter-149, train loss: 36.7807, valid loss: 75.3768\n",
      "Iter-150, train loss: 36.3291, valid loss: 88.9173\n",
      "Iter-151, train loss: 35.8744, valid loss: 103.3513\n",
      "Iter-152, train loss: 35.4072, valid loss: 118.1788\n",
      "Iter-153, train loss: 34.9319, valid loss: 133.0168\n",
      "Iter-154, train loss: 34.4582, valid loss: 147.6700\n",
      "Iter-155, train loss: 33.9817, valid loss: 161.1305\n",
      "Iter-156, train loss: 33.5362, valid loss: 174.2348\n",
      "Iter-157, train loss: 33.0832, valid loss: 184.7039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-158, train loss: 32.7299, valid loss: 200.7063\n",
      "Iter-159, train loss: 32.2723, valid loss: 208.8745\n",
      "Iter-160, train loss: 32.1006, valid loss: 249.7564\n",
      "Iter-161, train loss: 32.2716, valid loss: 237.1294\n",
      "Iter-162, train loss: 39.9685, valid loss: 312.0206\n",
      "Iter-163, train loss: 49.6965, valid loss: 319.2507\n",
      "Iter-164, train loss: 35.2581, valid loss: 313.9264\n",
      "Iter-165, train loss: 30.9648, valid loss: 379.0986\n",
      "Iter-166, train loss: 30.7319, valid loss: 368.3631\n",
      "Iter-167, train loss: 30.3808, valid loss: 419.2959\n",
      "Iter-168, train loss: 30.0265, valid loss: 443.4945\n",
      "Iter-169, train loss: 29.5956, valid loss: 471.4377\n",
      "Iter-170, train loss: 29.2497, valid loss: 505.4736\n",
      "Iter-171, train loss: 28.8744, valid loss: 535.8037\n",
      "Iter-172, train loss: 28.4974, valid loss: 567.3021\n",
      "Iter-173, train loss: 28.1222, valid loss: 600.7865\n",
      "Iter-174, train loss: 27.7327, valid loss: 628.1783\n",
      "Iter-175, train loss: 27.3586, valid loss: 665.2121\n",
      "Iter-176, train loss: 26.9601, valid loss: 687.0243\n",
      "Iter-177, train loss: 26.5940, valid loss: 732.4518\n",
      "Iter-178, train loss: 26.1869, valid loss: 739.7595\n",
      "Iter-179, train loss: 25.8408, valid loss: 808.7449\n",
      "Iter-180, train loss: 25.4221, valid loss: 774.3697\n",
      "Iter-181, train loss: 25.1176, valid loss: 904.3239\n",
      "Iter-182, train loss: 24.7582, valid loss: 757.4868\n",
      "Iter-183, train loss: 24.5729, valid loss: 1005.4526\n",
      "Iter-184, train loss: 25.1732, valid loss: 864.0270\n",
      "Iter-185, train loss: 29.4937, valid loss: 855.5463\n",
      "Iter-186, train loss: 34.6978, valid loss: 1250.6536\n",
      "Iter-187, train loss: 30.8896, valid loss: 915.2833\n",
      "Iter-188, train loss: 23.5452, valid loss: 1124.4251\n",
      "Iter-189, train loss: 23.4789, valid loss: 1182.3823\n",
      "Iter-190, train loss: 22.9445, valid loss: 1054.5956\n",
      "Iter-191, train loss: 23.1003, valid loss: 1252.2274\n",
      "Iter-192, train loss: 22.6047, valid loss: 1224.6162\n",
      "Iter-193, train loss: 22.1848, valid loss: 1297.1428\n",
      "Iter-194, train loss: 21.8749, valid loss: 1318.6909\n",
      "Iter-195, train loss: 21.6070, valid loss: 1391.6082\n",
      "Iter-196, train loss: 21.2928, valid loss: 1380.7921\n",
      "Iter-197, train loss: 21.0512, valid loss: 1494.3043\n",
      "Iter-198, train loss: 20.7003, valid loss: 1408.7531\n",
      "Iter-199, train loss: 20.4839, valid loss: 1621.1363\n",
      "Iter-200, train loss: 20.1460, valid loss: 1243.2696\n",
      "Iter-201, train loss: 20.0090, valid loss: 1772.8163\n",
      "Iter-202, train loss: 20.0080, valid loss: 2537.0273\n",
      "Iter-203, train loss: 20.3935, valid loss: 1849.2760\n",
      "Iter-204, train loss: 22.9099, valid loss: 1803.7220\n",
      "Iter-205, train loss: 25.7785, valid loss: 3947.7810\n",
      "Iter-206, train loss: 22.2574, valid loss: 2321.8935\n",
      "Iter-207, train loss: 18.4061, valid loss: 8002.9100\n",
      "Iter-208, train loss: 19.3264, valid loss: 539.1351\n",
      "Iter-209, train loss: 19.2274, valid loss: 2047.5929\n",
      "Iter-210, train loss: 18.0629, valid loss: 1873.6579\n",
      "Iter-211, train loss: 19.4325, valid loss: 2087.4211\n",
      "Iter-212, train loss: 18.9291, valid loss: 2177.7005\n",
      "Iter-213, train loss: 17.1602, valid loss: 2019.6283\n",
      "Iter-214, train loss: 17.0108, valid loss: 2330.2330\n",
      "Iter-215, train loss: 16.6195, valid loss: 2133.0416\n",
      "Iter-216, train loss: 16.4393, valid loss: 2446.4616\n",
      "Iter-217, train loss: 16.1087, valid loss: 1991.8216\n",
      "Iter-218, train loss: 15.9229, valid loss: 2619.9256\n",
      "Iter-219, train loss: 15.6799, valid loss: 1964.5452\n",
      "Iter-220, train loss: 15.5691, valid loss: 2802.9352\n",
      "Iter-221, train loss: 15.9327, valid loss: 1822.6128\n",
      "Iter-222, train loss: 16.2834, valid loss: 2752.7586\n",
      "Iter-223, train loss: 18.2596, valid loss: 3140.3475\n",
      "Iter-224, train loss: 17.2920, valid loss: 6792.1633\n",
      "Iter-225, train loss: 15.3671, valid loss: 3605.1160\n",
      "Iter-226, train loss: 14.0370, valid loss: 5829.5892\n",
      "Iter-227, train loss: 14.3436, valid loss: 295.7583\n",
      "Iter-228, train loss: 13.8686, valid loss: 3008.0265\n",
      "Iter-229, train loss: 15.0698, valid loss: 3186.8823\n",
      "Iter-230, train loss: 15.9003, valid loss: 3306.4747\n",
      "Iter-231, train loss: 14.5742, valid loss: 3615.0712\n",
      "Iter-232, train loss: 12.6319, valid loss: 3340.0971\n",
      "Iter-233, train loss: 12.5145, valid loss: 3783.8101\n",
      "Iter-234, train loss: 12.1492, valid loss: 3560.2676\n",
      "Iter-235, train loss: 12.0106, valid loss: 3943.2322\n",
      "Iter-236, train loss: 11.7473, valid loss: 3583.4396\n",
      "Iter-237, train loss: 11.5706, valid loss: 4156.3354\n",
      "Iter-238, train loss: 11.4606, valid loss: 1653.2833\n",
      "Iter-239, train loss: 11.3714, valid loss: 4353.3062\n",
      "Iter-240, train loss: 11.8859, valid loss: 3918.0654\n",
      "Iter-241, train loss: 11.9049, valid loss: 4225.4802\n",
      "Iter-242, train loss: 12.8188, valid loss: 4871.7145\n",
      "Iter-243, train loss: 10.8562, valid loss: 10210.1717\n",
      "Iter-244, train loss: 10.7194, valid loss: 5242.7593\n",
      "Iter-245, train loss: 11.2110, valid loss: 3709.0261\n",
      "Iter-246, train loss: 10.5292, valid loss: 510.5277\n",
      "Iter-247, train loss: 9.6985, valid loss: 1319.1189\n",
      "Iter-248, train loss: 12.0308, valid loss: 4973.4436\n",
      "Iter-249, train loss: 12.3662, valid loss: 4983.3578\n",
      "Iter-250, train loss: 10.5682, valid loss: 5453.2654\n",
      "Iter-251, train loss: 8.8979, valid loss: 5023.9780\n",
      "Iter-252, train loss: 8.8270, valid loss: 5575.4242\n",
      "Iter-253, train loss: 8.5244, valid loss: 5200.5800\n",
      "Iter-254, train loss: 8.4522, valid loss: 5737.6523\n",
      "Iter-255, train loss: 8.2779, valid loss: 5070.7444\n",
      "Iter-256, train loss: 8.1474, valid loss: 5960.2628\n",
      "Iter-257, train loss: 8.1947, valid loss: 2588.2905\n",
      "Iter-258, train loss: 8.1737, valid loss: 6155.0307\n",
      "Iter-259, train loss: 8.7417, valid loss: 5593.2126\n",
      "Iter-260, train loss: 8.5674, valid loss: 5913.3109\n",
      "Iter-261, train loss: 8.7556, valid loss: 6718.3422\n",
      "Iter-262, train loss: 6.9946, valid loss: 10621.6909\n",
      "Iter-263, train loss: 7.6686, valid loss: 7190.0923\n",
      "Iter-264, train loss: 9.8945, valid loss: 12990.3529\n",
      "Iter-265, train loss: 9.3314, valid loss: 1108.5557\n",
      "Iter-266, train loss: 7.3879, valid loss: 1060.1290\n",
      "Iter-267, train loss: 6.7341, valid loss: 6862.5341\n",
      "Iter-268, train loss: 7.2691, valid loss: 6538.4873\n",
      "Iter-269, train loss: 7.1824, valid loss: 7425.7734\n",
      "Iter-270, train loss: 6.0653, valid loss: 2851.4755\n",
      "Iter-271, train loss: 6.0191, valid loss: 7626.0724\n",
      "Iter-272, train loss: 5.6861, valid loss: 3994.8291\n",
      "Iter-273, train loss: 5.8139, valid loss: 7771.5948\n",
      "Iter-274, train loss: 5.8111, valid loss: 4388.5003\n",
      "Iter-275, train loss: 5.7175, valid loss: 7986.2842\n",
      "Iter-276, train loss: 5.9286, valid loss: 4428.6541\n",
      "Iter-277, train loss: 5.8262, valid loss: 8180.1093\n",
      "Iter-278, train loss: 6.3130, valid loss: 2235.9703\n",
      "Iter-279, train loss: 6.0960, valid loss: 8088.3519\n",
      "Iter-280, train loss: 6.0557, valid loss: 8391.2670\n",
      "Iter-281, train loss: 5.1256, valid loss: 5954.7932\n",
      "Iter-282, train loss: 4.8618, valid loss: 9285.6623\n",
      "Iter-283, train loss: 5.2953, valid loss: 13860.5865\n",
      "Iter-284, train loss: 7.3437, valid loss: 9155.9196\n",
      "Iter-285, train loss: 8.7103, valid loss: 3788.1008\n",
      "Iter-286, train loss: 5.3703, valid loss: 8732.2902\n",
      "Iter-287, train loss: 4.1588, valid loss: 853.0026\n",
      "Iter-288, train loss: 3.9918, valid loss: 9372.8295\n",
      "Iter-289, train loss: 3.7413, valid loss: 3143.1682\n",
      "Iter-290, train loss: 3.8833, valid loss: 9893.7412\n",
      "Iter-291, train loss: 3.7416, valid loss: 6870.4374\n",
      "Iter-292, train loss: 4.1865, valid loss: 10231.6890\n",
      "Iter-293, train loss: 4.8358, valid loss: 8033.6768\n",
      "Iter-294, train loss: 4.9560, valid loss: 10330.3222\n",
      "Iter-295, train loss: 5.1608, valid loss: 2212.6178\n",
      "Iter-296, train loss: 4.8839, valid loss: 3166.6725\n",
      "Iter-297, train loss: 3.6944, valid loss: 10533.3556\n",
      "Iter-298, train loss: 2.9970, valid loss: 4832.1801\n",
      "Iter-299, train loss: 3.2967, valid loss: 11279.6983\n",
      "Iter-300, train loss: 4.1467, valid loss: 10390.8202\n",
      "Iter-301, train loss: 5.2578, valid loss: 11435.9757\n",
      "Iter-302, train loss: 5.9038, valid loss: 6202.1853\n",
      "Iter-303, train loss: 4.9876, valid loss: 10756.1974\n",
      "Iter-304, train loss: 3.1238, valid loss: 11093.6945\n",
      "Iter-305, train loss: 2.5899, valid loss: 1241.4132\n",
      "Iter-306, train loss: 2.5853, valid loss: 11889.7567\n",
      "Iter-307, train loss: 2.7495, valid loss: 3896.7065\n",
      "Iter-308, train loss: 2.8876, valid loss: 12168.6419\n",
      "Iter-309, train loss: 2.9467, valid loss: 1050.4050\n",
      "Iter-310, train loss: 2.5962, valid loss: 1709.0136\n",
      "Iter-311, train loss: 2.3983, valid loss: 12960.4208\n",
      "Iter-312, train loss: 2.3361, valid loss: 12770.8804\n",
      "Iter-313, train loss: 5.3668, valid loss: 13429.5995\n",
      "Iter-314, train loss: 10.1986, valid loss: 18758.1132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-315, train loss: 6.2844, valid loss: 3497.7872\n",
      "Iter-316, train loss: 2.2062, valid loss: 883.0094\n",
      "Iter-317, train loss: 2.1528, valid loss: 13336.3995\n",
      "Iter-318, train loss: 1.7313, valid loss: 4141.3547\n",
      "Iter-319, train loss: 1.9072, valid loss: 13911.1141\n",
      "Iter-320, train loss: 2.4141, valid loss: 7069.4609\n",
      "Iter-321, train loss: 2.7031, valid loss: 14088.3817\n",
      "Iter-322, train loss: 2.8690, valid loss: 7066.1373\n",
      "Iter-323, train loss: 2.5680, valid loss: 14279.1312\n",
      "Iter-324, train loss: 2.5143, valid loss: 5574.5243\n",
      "Iter-325, train loss: 2.2711, valid loss: 14466.5663\n",
      "Iter-326, train loss: 2.1861, valid loss: 3429.1639\n",
      "Iter-327, train loss: 2.0205, valid loss: 14416.2772\n",
      "Iter-328, train loss: 1.7410, valid loss: 1372.1512\n",
      "Iter-329, train loss: 1.4102, valid loss: 1166.0392\n",
      "Iter-330, train loss: 1.3121, valid loss: 15279.4864\n",
      "Iter-331, train loss: 1.5626, valid loss: 9834.8699\n",
      "Iter-332, train loss: 3.2139, valid loss: 15898.8824\n",
      "Iter-333, train loss: 6.1619, valid loss: 13238.4616\n",
      "Iter-334, train loss: 5.7472, valid loss: 5186.3013\n",
      "Iter-335, train loss: 1.6347, valid loss: 5648.3650\n",
      "Iter-336, train loss: 1.7915, valid loss: 620.5528\n",
      "Iter-337, train loss: 0.9745, valid loss: 10382.7059\n",
      "Iter-338, train loss: 1.5439, valid loss: 1376.3690\n",
      "Iter-339, train loss: 0.9374, valid loss: 1806.4504\n",
      "Iter-340, train loss: 0.9106, valid loss: 5709.7001\n",
      "Iter-341, train loss: 0.8832, valid loss: 1419.0936\n",
      "Iter-342, train loss: 0.9965, valid loss: 15264.5605\n",
      "Iter-343, train loss: 1.1552, valid loss: 866.6598\n",
      "Iter-344, train loss: 0.9475, valid loss: 1289.9715\n",
      "Iter-345, train loss: 0.8560, valid loss: 17162.7239\n",
      "Iter-346, train loss: 1.7340, valid loss: 14058.1234\n",
      "Iter-347, train loss: 6.4420, valid loss: 18030.6877\n",
      "Iter-348, train loss: 12.4030, valid loss: 58797.4982\n",
      "Iter-349, train loss: 5.7434, valid loss: 3173.9670\n",
      "Iter-350, train loss: 0.8119, valid loss: 3067.4870\n",
      "Iter-351, train loss: 1.0956, valid loss: 16289.7636\n",
      "Iter-352, train loss: 0.6952, valid loss: 6027.4289\n",
      "Iter-353, train loss: 1.2084, valid loss: 17319.1799\n",
      "Iter-354, train loss: 2.0396, valid loss: 7729.2802\n",
      "Iter-355, train loss: 1.4519, valid loss: 17028.9261\n",
      "Iter-356, train loss: 1.4768, valid loss: 7845.5024\n",
      "Iter-357, train loss: 1.4976, valid loss: 17379.3860\n",
      "Iter-358, train loss: 1.6738, valid loss: 8431.4334\n",
      "Iter-359, train loss: 1.6457, valid loss: 17608.9369\n",
      "Iter-360, train loss: 1.8133, valid loss: 8325.5707\n",
      "Iter-361, train loss: 1.7307, valid loss: 17284.4366\n",
      "Iter-362, train loss: 1.6795, valid loss: 6909.4302\n",
      "Iter-363, train loss: 1.5995, valid loss: 16005.8633\n",
      "Iter-364, train loss: 1.4054, valid loss: 4214.6943\n",
      "Iter-365, train loss: 1.2934, valid loss: 7119.8875\n",
      "Iter-366, train loss: 0.9905, valid loss: 434.5898\n",
      "Iter-367, train loss: 0.7779, valid loss: 550.2803\n",
      "Iter-368, train loss: 0.6434, valid loss: 8852.7326\n",
      "Iter-369, train loss: 0.8045, valid loss: 6433.5312\n",
      "Iter-370, train loss: 1.6963, valid loss: 19758.1613\n",
      "Iter-371, train loss: 3.0031, valid loss: 6662.5998\n",
      "Iter-372, train loss: 3.1229, valid loss: 2816.8764\n",
      "Iter-373, train loss: 1.0663, valid loss: 17356.4120\n",
      "Iter-374, train loss: 0.8472, valid loss: 8178.4324\n",
      "Iter-375, train loss: 1.7365, valid loss: 20666.4153\n",
      "Iter-376, train loss: 8.2206, valid loss: 13497.5206\n",
      "Iter-377, train loss: 3.2324, valid loss: 16807.5629\n",
      "Iter-378, train loss: 1.3684, valid loss: 7340.5301\n",
      "Iter-379, train loss: 1.8273, valid loss: 13024.0230\n",
      "Iter-380, train loss: 1.2221, valid loss: 6656.4993\n",
      "Iter-381, train loss: 1.2507, valid loss: 19381.9638\n",
      "Iter-382, train loss: 1.9282, valid loss: 7588.8043\n",
      "Iter-383, train loss: 1.9732, valid loss: 17977.6005\n",
      "Iter-384, train loss: 1.7465, valid loss: 4370.2440\n",
      "Iter-385, train loss: 1.4999, valid loss: 6574.0731\n",
      "Iter-386, train loss: 1.0523, valid loss: 879.1408\n",
      "Iter-387, train loss: 0.8231, valid loss: 851.7617\n",
      "Iter-388, train loss: 0.8972, valid loss: 16516.4150\n",
      "Iter-389, train loss: 1.2272, valid loss: 4642.8729\n",
      "Iter-390, train loss: 1.6690, valid loss: 19711.1112\n",
      "Iter-391, train loss: 1.4370, valid loss: 1537.4796\n",
      "Iter-392, train loss: 0.9937, valid loss: 6420.9427\n",
      "Iter-393, train loss: 1.8283, valid loss: 23079.0409\n",
      "Iter-394, train loss: 6.3273, valid loss: 34630.5447\n",
      "Iter-395, train loss: 9.6520, valid loss: 21397.5806\n",
      "Iter-396, train loss: 4.1764, valid loss: 15300.8714\n",
      "Iter-397, train loss: 1.6996, valid loss: 14068.0339\n",
      "Iter-398, train loss: 1.1705, valid loss: 7400.8987\n",
      "Iter-399, train loss: 1.3959, valid loss: 21195.1201\n",
      "Iter-400, train loss: 1.9614, valid loss: 8899.0906\n",
      "Iter-401, train loss: 1.9933, valid loss: 20527.7545\n",
      "Iter-402, train loss: 1.9826, valid loss: 8197.9368\n",
      "Iter-403, train loss: 2.0415, valid loss: 20342.3107\n",
      "Iter-404, train loss: 1.8417, valid loss: 7526.8105\n",
      "Iter-405, train loss: 1.9757, valid loss: 20474.5488\n",
      "Iter-406, train loss: 1.9518, valid loss: 6591.3114\n",
      "Iter-407, train loss: 2.1258, valid loss: 19493.9755\n",
      "Iter-408, train loss: 1.8104, valid loss: 3640.8194\n",
      "Iter-409, train loss: 1.8684, valid loss: 8378.3117\n",
      "Iter-410, train loss: 1.4115, valid loss: 672.2788\n",
      "Iter-411, train loss: 1.2836, valid loss: 1188.0010\n",
      "Iter-412, train loss: 1.3310, valid loss: 20581.6627\n",
      "Iter-413, train loss: 1.8962, valid loss: 6142.7972\n",
      "Iter-414, train loss: 2.7555, valid loss: 22848.3403\n",
      "Iter-415, train loss: 2.5568, valid loss: 158.7685\n",
      "Iter-416, train loss: 1.9236, valid loss: 4070.9137\n",
      "Iter-417, train loss: 1.8667, valid loss: 24694.9377\n",
      "Iter-418, train loss: 4.5324, valid loss: 21290.6113\n",
      "Iter-419, train loss: 7.8601, valid loss: 23478.1768\n",
      "Iter-420, train loss: 8.5630, valid loss: 13306.1520\n",
      "Iter-421, train loss: 1.6198, valid loss: 15997.4789\n",
      "Iter-422, train loss: 1.9272, valid loss: 4672.9834\n",
      "Iter-423, train loss: 2.1751, valid loss: 17727.2329\n",
      "Iter-424, train loss: 1.5347, valid loss: 5025.1127\n",
      "Iter-425, train loss: 1.8659, valid loss: 20937.3793\n",
      "Iter-426, train loss: 2.0455, valid loss: 5016.1831\n",
      "Iter-427, train loss: 2.1699, valid loss: 18983.4581\n",
      "Iter-428, train loss: 1.7831, valid loss: 854.5149\n",
      "Iter-429, train loss: 1.8137, valid loss: 493.8787\n",
      "Iter-430, train loss: 1.5341, valid loss: 17163.9198\n",
      "Iter-431, train loss: 1.7501, valid loss: 5130.8437\n",
      "Iter-432, train loss: 2.3533, valid loss: 24113.8972\n",
      "Iter-433, train loss: 2.5733, valid loss: 2633.9080\n",
      "Iter-434, train loss: 2.4722, valid loss: 1297.2041\n",
      "Iter-435, train loss: 1.7852, valid loss: 24770.4419\n",
      "Iter-436, train loss: 3.2359, valid loss: 15971.2542\n",
      "Iter-437, train loss: 6.4333, valid loss: 25901.6471\n",
      "Iter-438, train loss: 9.0347, valid loss: 17686.3844\n",
      "Iter-439, train loss: 3.1254, valid loss: 9937.7099\n",
      "Iter-440, train loss: 2.0852, valid loss: 4202.3469\n",
      "Iter-441, train loss: 2.6386, valid loss: 15085.2484\n",
      "Iter-442, train loss: 1.8643, valid loss: 4780.4250\n",
      "Iter-443, train loss: 2.0170, valid loss: 21852.3878\n",
      "Iter-444, train loss: 2.6077, valid loss: 5417.4475\n",
      "Iter-445, train loss: 2.5094, valid loss: 19526.7430\n",
      "Iter-446, train loss: 2.1878, valid loss: 1608.0430\n",
      "Iter-447, train loss: 2.0098, valid loss: 921.0752\n",
      "Iter-448, train loss: 1.7652, valid loss: 9993.1437\n",
      "Iter-449, train loss: 1.9078, valid loss: 3790.4201\n",
      "Iter-450, train loss: 2.3114, valid loss: 23816.6083\n",
      "Iter-451, train loss: 2.4483, valid loss: 854.6491\n",
      "Iter-452, train loss: 2.1377, valid loss: 3531.1576\n",
      "Iter-453, train loss: 2.0801, valid loss: 26400.0007\n",
      "Iter-454, train loss: 4.8615, valid loss: 21254.1721\n",
      "Iter-455, train loss: 8.8717, valid loss: 26712.2797\n",
      "Iter-456, train loss: 7.8246, valid loss: 25495.2591\n",
      "Iter-457, train loss: 3.2594, valid loss: 5441.6683\n",
      "Iter-458, train loss: 2.0802, valid loss: 5493.4797\n",
      "Iter-459, train loss: 2.4656, valid loss: 21361.8072\n",
      "Iter-460, train loss: 2.3307, valid loss: 6951.9370\n",
      "Iter-461, train loss: 2.8201, valid loss: 22879.5908\n",
      "Iter-462, train loss: 2.9797, valid loss: 7233.4040\n",
      "Iter-463, train loss: 2.9703, valid loss: 20605.7757\n",
      "Iter-464, train loss: 2.4605, valid loss: 4145.6032\n",
      "Iter-465, train loss: 2.4586, valid loss: 9963.1012\n",
      "Iter-466, train loss: 2.0919, valid loss: 148.3118\n",
      "Iter-467, train loss: 2.0015, valid loss: 174.9404\n",
      "Iter-468, train loss: 1.9466, valid loss: 16466.5615\n",
      "Iter-469, train loss: 2.1792, valid loss: 3419.9848\n",
      "Iter-470, train loss: 2.5012, valid loss: 21895.3815\n",
      "Iter-471, train loss: 2.1260, valid loss: 2048.9511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-472, train loss: 2.1104, valid loss: 9178.1129\n",
      "Iter-473, train loss: 3.6012, valid loss: 28559.5006\n",
      "Iter-474, train loss: 8.1511, valid loss: 50382.4490\n",
      "Iter-475, train loss: 10.1023, valid loss: 20623.4799\n",
      "Iter-476, train loss: 3.2545, valid loss: 9582.2024\n",
      "Iter-477, train loss: 2.8190, valid loss: 5873.1338\n",
      "Iter-478, train loss: 3.0980, valid loss: 3763.4950\n",
      "Iter-479, train loss: 2.1869, valid loss: 18304.5248\n",
      "Iter-480, train loss: 2.2806, valid loss: 3803.4740\n",
      "Iter-481, train loss: 2.7178, valid loss: 12124.8811\n",
      "Iter-482, train loss: 2.4053, valid loss: 1312.0004\n",
      "Iter-483, train loss: 2.2882, valid loss: 1437.3430\n",
      "Iter-484, train loss: 2.0174, valid loss: 1504.9932\n",
      "Iter-485, train loss: 2.0599, valid loss: 1320.6347\n",
      "Iter-486, train loss: 2.1722, valid loss: 16910.4099\n",
      "Iter-487, train loss: 2.2195, valid loss: 223.0042\n",
      "Iter-488, train loss: 2.1752, valid loss: 2488.4409\n",
      "Iter-489, train loss: 2.1505, valid loss: 25438.8851\n",
      "Iter-490, train loss: 3.9957, valid loss: 10645.5029\n",
      "Iter-491, train loss: 6.1616, valid loss: 27790.7185\n",
      "Iter-492, train loss: 3.8355, valid loss: 4970.3547\n",
      "Iter-493, train loss: 2.5492, valid loss: 5196.9880\n",
      "Iter-494, train loss: 2.5858, valid loss: 26937.3790\n",
      "Iter-495, train loss: 4.7468, valid loss: 17679.7196\n",
      "Iter-496, train loss: 6.6518, valid loss: 22294.5589\n",
      "Iter-497, train loss: 3.8405, valid loss: 10089.5963\n",
      "Iter-498, train loss: 2.5747, valid loss: 21995.5965\n",
      "Iter-499, train loss: 2.5258, valid loss: 8557.9056\n",
      "Iter-500, train loss: 3.3277, valid loss: 22779.2389\n",
      "Iter-501, train loss: 2.7498, valid loss: 6963.2258\n",
      "Iter-502, train loss: 3.0788, valid loss: 18471.4227\n",
      "Iter-503, train loss: 2.4013, valid loss: 2541.5686\n",
      "Iter-504, train loss: 2.3899, valid loss: 1714.5320\n",
      "Iter-505, train loss: 2.0433, valid loss: 1503.4996\n",
      "Iter-506, train loss: 2.0584, valid loss: 1784.8526\n",
      "Iter-507, train loss: 2.2051, valid loss: 19448.1814\n",
      "Iter-508, train loss: 2.3148, valid loss: 874.3038\n",
      "Iter-509, train loss: 2.2621, valid loss: 1819.9997\n",
      "Iter-510, train loss: 2.0746, valid loss: 25376.2518\n",
      "Iter-511, train loss: 3.9067, valid loss: 13670.6118\n",
      "Iter-512, train loss: 6.8613, valid loss: 28885.7147\n",
      "Iter-513, train loss: 5.2618, valid loss: 7977.4616\n",
      "Iter-514, train loss: 3.6419, valid loss: 467.9136\n",
      "Iter-515, train loss: 2.1384, valid loss: 20804.3247\n",
      "Iter-516, train loss: 2.7737, valid loss: 4054.7363\n",
      "Iter-517, train loss: 3.0852, valid loss: 3326.7644\n",
      "Iter-518, train loss: 2.3412, valid loss: 132.2304\n",
      "Iter-519, train loss: 2.0707, valid loss: 576.7958\n",
      "Iter-520, train loss: 2.0415, valid loss: 1539.0403\n",
      "Iter-521, train loss: 2.0465, valid loss: 185.2234\n",
      "Iter-522, train loss: 2.0699, valid loss: 1527.7800\n",
      "Iter-523, train loss: 2.0249, valid loss: 1230.1253\n",
      "Iter-524, train loss: 2.0679, valid loss: 2323.8442\n",
      "Iter-525, train loss: 2.2301, valid loss: 22283.4924\n",
      "Iter-526, train loss: 2.2976, valid loss: 93.6960\n",
      "Iter-527, train loss: 2.1385, valid loss: 10301.8001\n",
      "Iter-528, train loss: 3.4850, valid loss: 29966.9469\n",
      "Iter-529, train loss: 10.6067, valid loss: 146957.8301\n",
      "Iter-530, train loss: 14.5325, valid loss: 24458.2177\n",
      "Iter-531, train loss: 4.0456, valid loss: 76757.3355\n",
      "Iter-532, train loss: 2.7584, valid loss: 20296.2895\n",
      "Iter-533, train loss: 3.3751, valid loss: 10477.6524\n",
      "Iter-534, train loss: 2.7427, valid loss: 22921.2960\n",
      "Iter-535, train loss: 2.5834, valid loss: 11377.9387\n",
      "Iter-536, train loss: 3.4872, valid loss: 21300.4412\n",
      "Iter-537, train loss: 2.6973, valid loss: 10295.0914\n",
      "Iter-538, train loss: 2.9283, valid loss: 22614.5090\n",
      "Iter-539, train loss: 2.7097, valid loss: 10703.0959\n",
      "Iter-540, train loss: 3.2119, valid loss: 22825.3201\n",
      "Iter-541, train loss: 2.9201, valid loss: 10280.4255\n",
      "Iter-542, train loss: 3.2025, valid loss: 22165.6114\n",
      "Iter-543, train loss: 2.7722, valid loss: 8398.8599\n",
      "Iter-544, train loss: 3.0665, valid loss: 20224.7621\n",
      "Iter-545, train loss: 2.5964, valid loss: 5183.3926\n",
      "Iter-546, train loss: 2.6777, valid loss: 11841.0217\n",
      "Iter-547, train loss: 2.2004, valid loss: 405.8316\n",
      "Iter-548, train loss: 2.1310, valid loss: 239.5846\n",
      "Iter-549, train loss: 1.9334, valid loss: 9127.6698\n",
      "Iter-550, train loss: 2.1179, valid loss: 3609.5366\n",
      "Iter-551, train loss: 2.4698, valid loss: 22251.8315\n",
      "Iter-552, train loss: 2.3262, valid loss: 221.7071\n",
      "Iter-553, train loss: 2.0782, valid loss: 6887.2183\n",
      "Iter-554, train loss: 2.6158, valid loss: 29333.7202\n",
      "Iter-555, train loss: 6.2552, valid loss: 57259.0876\n",
      "Iter-556, train loss: 10.1599, valid loss: 26764.1979\n",
      "Iter-557, train loss: 5.3225, valid loss: 13969.7033\n",
      "Iter-558, train loss: 2.5024, valid loss: 3099.4200\n",
      "Iter-559, train loss: 2.0030, valid loss: 3723.7024\n",
      "Iter-560, train loss: 2.2550, valid loss: 18377.7138\n",
      "Iter-561, train loss: 2.1678, valid loss: 5164.9041\n",
      "Iter-562, train loss: 2.7544, valid loss: 17190.9469\n",
      "Iter-563, train loss: 2.3063, valid loss: 2861.1049\n",
      "Iter-564, train loss: 2.3178, valid loss: 1925.1175\n",
      "Iter-565, train loss: 1.9222, valid loss: 1167.7112\n",
      "Iter-566, train loss: 1.9449, valid loss: 1768.5799\n",
      "Iter-567, train loss: 2.0688, valid loss: 18135.3330\n",
      "Iter-568, train loss: 2.1896, valid loss: 942.1034\n",
      "Iter-569, train loss: 2.1311, valid loss: 1951.4023\n",
      "Iter-570, train loss: 1.9632, valid loss: 25351.6268\n",
      "Iter-571, train loss: 3.8566, valid loss: 13999.2787\n",
      "Iter-572, train loss: 6.6930, valid loss: 29421.8935\n",
      "Iter-573, train loss: 4.4006, valid loss: 4888.8034\n",
      "Iter-574, train loss: 2.9603, valid loss: 1940.3883\n",
      "Iter-575, train loss: 2.0412, valid loss: 23627.0567\n",
      "Iter-576, train loss: 2.9703, valid loss: 6608.5214\n",
      "Iter-577, train loss: 3.4832, valid loss: 10427.3092\n",
      "Iter-578, train loss: 2.4482, valid loss: 1261.6741\n",
      "Iter-579, train loss: 2.0114, valid loss: 954.8025\n",
      "Iter-580, train loss: 1.8632, valid loss: 1348.8238\n",
      "Iter-581, train loss: 1.8912, valid loss: 659.6091\n",
      "Iter-582, train loss: 1.9182, valid loss: 3985.2684\n",
      "Iter-583, train loss: 1.8991, valid loss: 310.1147\n",
      "Iter-584, train loss: 1.8823, valid loss: 2514.8748\n",
      "Iter-585, train loss: 2.0266, valid loss: 24042.6843\n",
      "Iter-586, train loss: 2.5620, valid loss: 3084.9092\n",
      "Iter-587, train loss: 2.6158, valid loss: 2993.7928\n",
      "Iter-588, train loss: 1.8937, valid loss: 28129.8602\n",
      "Iter-589, train loss: 6.1958, valid loss: 152320.9644\n",
      "Iter-590, train loss: 12.1163, valid loss: 29477.4835\n",
      "Iter-591, train loss: 11.2454, valid loss: 82669.5683\n",
      "Iter-592, train loss: 5.9527, valid loss: 18012.9622\n",
      "Iter-593, train loss: 3.7284, valid loss: 7298.0089\n",
      "Iter-594, train loss: 2.2872, valid loss: 12278.4627\n",
      "Iter-595, train loss: 1.7693, valid loss: 5658.6898\n",
      "Iter-596, train loss: 2.1256, valid loss: 18337.5135\n",
      "Iter-597, train loss: 2.4995, valid loss: 6061.1421\n",
      "Iter-598, train loss: 2.1821, valid loss: 17435.2894\n",
      "Iter-599, train loss: 2.1447, valid loss: 5942.1439\n",
      "Iter-600, train loss: 2.4116, valid loss: 17414.1068\n",
      "Iter-601, train loss: 2.2233, valid loss: 4789.8495\n",
      "Iter-602, train loss: 2.4192, valid loss: 12732.3010\n",
      "Iter-603, train loss: 2.0140, valid loss: 1500.3415\n",
      "Iter-604, train loss: 2.0869, valid loss: 931.7901\n",
      "Iter-605, train loss: 1.7235, valid loss: 2289.6574\n",
      "Iter-606, train loss: 1.7862, valid loss: 3192.1095\n",
      "Iter-607, train loss: 1.9987, valid loss: 22298.2170\n",
      "Iter-608, train loss: 2.1874, valid loss: 1908.7439\n",
      "Iter-609, train loss: 2.2081, valid loss: 1432.0397\n",
      "Iter-610, train loss: 1.7134, valid loss: 25907.2120\n",
      "Iter-611, train loss: 3.1257, valid loss: 18915.3319\n",
      "Iter-612, train loss: 6.9301, valid loss: 30213.0987\n",
      "Iter-613, train loss: 5.9615, valid loss: 102745.6187\n",
      "Iter-614, train loss: 6.7430, valid loss: 6475.1561\n",
      "Iter-615, train loss: 2.6535, valid loss: 6774.9038\n",
      "Iter-616, train loss: 1.7496, valid loss: 21292.7370\n",
      "Iter-617, train loss: 2.4761, valid loss: 8404.8484\n",
      "Iter-618, train loss: 2.8889, valid loss: 22115.6367\n",
      "Iter-619, train loss: 2.3992, valid loss: 7640.6344\n",
      "Iter-620, train loss: 2.8565, valid loss: 15413.2916\n",
      "Iter-621, train loss: 2.0066, valid loss: 3520.3245\n",
      "Iter-622, train loss: 2.0794, valid loss: 2940.3364\n",
      "Iter-623, train loss: 1.7816, valid loss: 191.0771\n",
      "Iter-624, train loss: 1.7520, valid loss: 279.8033\n",
      "Iter-625, train loss: 1.7211, valid loss: 10388.7976\n",
      "Iter-626, train loss: 1.9022, valid loss: 2180.8469\n",
      "Iter-627, train loss: 1.9659, valid loss: 2184.6375\n",
      "Iter-628, train loss: 1.6770, valid loss: 12576.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-629, train loss: 2.3413, valid loss: 11769.2749\n",
      "Iter-630, train loss: 4.3419, valid loss: 30831.5377\n",
      "Iter-631, train loss: 5.0037, valid loss: 11409.1793\n",
      "Iter-632, train loss: 4.6804, valid loss: 273.3879\n",
      "Iter-633, train loss: 1.9008, valid loss: 25784.3250\n",
      "Iter-634, train loss: 3.2002, valid loss: 8894.8403\n",
      "Iter-635, train loss: 3.3504, valid loss: 18680.6255\n",
      "Iter-636, train loss: 2.0232, valid loss: 4368.4271\n",
      "Iter-637, train loss: 2.6583, valid loss: 3159.0251\n",
      "Iter-638, train loss: 1.7109, valid loss: 232.7791\n",
      "Iter-639, train loss: 1.7383, valid loss: 642.4408\n",
      "Iter-640, train loss: 1.6187, valid loss: 1282.6516\n",
      "Iter-641, train loss: 1.6675, valid loss: 766.3609\n",
      "Iter-642, train loss: 1.6772, valid loss: 4226.3756\n",
      "Iter-643, train loss: 1.6944, valid loss: 491.1071\n",
      "Iter-644, train loss: 1.6590, valid loss: 4013.6542\n",
      "Iter-645, train loss: 1.8369, valid loss: 26437.7645\n",
      "Iter-646, train loss: 2.6824, valid loss: 2955.7633\n",
      "Iter-647, train loss: 2.6070, valid loss: 4331.2692\n",
      "Iter-648, train loss: 1.5623, valid loss: 29672.7712\n",
      "Iter-649, train loss: 6.9705, valid loss: 170247.5597\n",
      "Iter-650, train loss: 11.4731, valid loss: 28401.0341\n",
      "Iter-651, train loss: 4.1536, valid loss: 76109.7180\n",
      "Iter-652, train loss: 6.5807, valid loss: 20747.4505\n",
      "Iter-653, train loss: 4.7762, valid loss: 6862.0955\n",
      "Iter-654, train loss: 1.7882, valid loss: 6839.2790\n",
      "Iter-655, train loss: 1.6244, valid loss: 4974.7835\n",
      "Iter-656, train loss: 2.1026, valid loss: 15388.5086\n",
      "Iter-657, train loss: 1.8745, valid loss: 5540.9288\n",
      "Iter-658, train loss: 1.9536, valid loss: 15154.0782\n",
      "Iter-659, train loss: 1.8331, valid loss: 5299.2834\n",
      "Iter-660, train loss: 2.1221, valid loss: 13912.2468\n",
      "Iter-661, train loss: 1.8387, valid loss: 3503.8408\n",
      "Iter-662, train loss: 2.0570, valid loss: 3978.0742\n",
      "Iter-663, train loss: 1.6349, valid loss: 48.8403\n",
      "Iter-664, train loss: 1.6853, valid loss: 82.5238\n",
      "Iter-665, train loss: 1.4966, valid loss: 9516.4746\n",
      "Iter-666, train loss: 1.6610, valid loss: 3954.7872\n",
      "Iter-667, train loss: 1.8823, valid loss: 20483.7270\n",
      "Iter-668, train loss: 1.7916, valid loss: 514.3626\n",
      "Iter-669, train loss: 1.6658, valid loss: 7114.6386\n",
      "Iter-670, train loss: 1.9102, valid loss: 30308.6821\n",
      "Iter-671, train loss: 4.8466, valid loss: 90150.2065\n",
      "Iter-672, train loss: 9.4644, valid loss: 26315.3508\n",
      "Iter-673, train loss: 5.1162, valid loss: 28105.3389\n",
      "Iter-674, train loss: 2.1230, valid loss: 6872.0574\n",
      "Iter-675, train loss: 1.6459, valid loss: 5646.5332\n",
      "Iter-676, train loss: 1.8912, valid loss: 21717.3920\n",
      "Iter-677, train loss: 2.3253, valid loss: 7660.6983\n",
      "Iter-678, train loss: 2.6716, valid loss: 18928.8713\n",
      "Iter-679, train loss: 1.9653, valid loss: 5457.1795\n",
      "Iter-680, train loss: 2.0714, valid loss: 7976.1871\n",
      "Iter-681, train loss: 1.6920, valid loss: 1279.3677\n",
      "Iter-682, train loss: 1.6124, valid loss: 729.1119\n",
      "Iter-683, train loss: 1.4577, valid loss: 1722.0797\n",
      "Iter-684, train loss: 1.5479, valid loss: 2030.6038\n",
      "Iter-685, train loss: 1.6440, valid loss: 12259.3852\n",
      "Iter-686, train loss: 1.6188, valid loss: 338.7910\n",
      "Iter-687, train loss: 1.5125, valid loss: 5519.0332\n",
      "Iter-688, train loss: 2.0122, valid loss: 28527.2867\n",
      "Iter-689, train loss: 3.8482, valid loss: 7874.0973\n",
      "Iter-690, train loss: 4.4215, valid loss: 4925.1765\n",
      "Iter-691, train loss: 1.7475, valid loss: 26193.0351\n",
      "Iter-692, train loss: 2.6155, valid loss: 12540.7239\n",
      "Iter-693, train loss: 4.5650, valid loss: 28266.8620\n",
      "Iter-694, train loss: 4.8114, valid loss: 47495.7226\n",
      "Iter-695, train loss: 4.2986, valid loss: 19956.7255\n",
      "Iter-696, train loss: 2.0436, valid loss: 11042.7426\n",
      "Iter-697, train loss: 2.5121, valid loss: 23620.3063\n",
      "Iter-698, train loss: 2.4903, valid loss: 11402.8553\n",
      "Iter-699, train loss: 2.9137, valid loss: 23168.7183\n",
      "Iter-700, train loss: 2.4802, valid loss: 10038.4697\n",
      "Iter-701, train loss: 2.6174, valid loss: 19205.5366\n",
      "Iter-702, train loss: 2.0960, valid loss: 6401.7578\n",
      "Iter-703, train loss: 2.0862, valid loss: 13300.8607\n",
      "Iter-704, train loss: 1.7429, valid loss: 2673.3133\n",
      "Iter-705, train loss: 1.6604, valid loss: 1418.7347\n",
      "Iter-706, train loss: 1.3951, valid loss: 1015.4129\n",
      "Iter-707, train loss: 1.4189, valid loss: 1942.8547\n",
      "Iter-708, train loss: 1.5115, valid loss: 15260.0442\n",
      "Iter-709, train loss: 1.6511, valid loss: 569.1730\n",
      "Iter-710, train loss: 1.5094, valid loss: 2774.6087\n",
      "Iter-711, train loss: 1.4499, valid loss: 26057.2407\n",
      "Iter-712, train loss: 3.2810, valid loss: 11905.5122\n",
      "Iter-713, train loss: 5.4557, valid loss: 28697.3412\n",
      "Iter-714, train loss: 3.1276, valid loss: 3970.1038\n",
      "Iter-715, train loss: 1.5953, valid loss: 4571.8957\n",
      "Iter-716, train loss: 1.8306, valid loss: 26581.9119\n",
      "Iter-717, train loss: 3.1618, valid loss: 9028.8770\n",
      "Iter-718, train loss: 3.9114, valid loss: 14665.4546\n",
      "Iter-719, train loss: 1.7328, valid loss: 3757.9515\n",
      "Iter-720, train loss: 1.5363, valid loss: 3246.5750\n",
      "Iter-721, train loss: 1.4134, valid loss: 738.1150\n",
      "Iter-722, train loss: 1.4099, valid loss: 802.7232\n",
      "Iter-723, train loss: 1.2989, valid loss: 1259.4720\n",
      "Iter-724, train loss: 1.3648, valid loss: 1589.4622\n",
      "Iter-725, train loss: 1.4222, valid loss: 9312.5888\n",
      "Iter-726, train loss: 1.4323, valid loss: 368.3369\n",
      "Iter-727, train loss: 1.3350, valid loss: 5152.9882\n",
      "Iter-728, train loss: 1.7997, valid loss: 28499.0690\n",
      "Iter-729, train loss: 3.2049, valid loss: 5211.7500\n",
      "Iter-730, train loss: 3.6338, valid loss: 1103.1094\n",
      "Iter-731, train loss: 1.3433, valid loss: 28805.8707\n",
      "Iter-732, train loss: 3.8761, valid loss: 22516.7039\n",
      "Iter-733, train loss: 7.4264, valid loss: 28464.1225\n",
      "Iter-734, train loss: 4.6975, valid loss: 61398.0284\n",
      "Iter-735, train loss: 4.2272, valid loss: 22122.5264\n",
      "Iter-736, train loss: 1.9745, valid loss: 13249.1886\n",
      "Iter-737, train loss: 2.7684, valid loss: 24305.1067\n",
      "Iter-738, train loss: 2.1723, valid loss: 13227.8184\n",
      "Iter-739, train loss: 2.6084, valid loss: 23003.9040\n",
      "Iter-740, train loss: 2.3937, valid loss: 12641.5160\n",
      "Iter-741, train loss: 2.5157, valid loss: 21998.1786\n",
      "Iter-742, train loss: 2.1267, valid loss: 10963.1713\n",
      "Iter-743, train loss: 2.4227, valid loss: 21865.0729\n",
      "Iter-744, train loss: 2.2040, valid loss: 9781.7786\n",
      "Iter-745, train loss: 2.3946, valid loss: 20349.8527\n",
      "Iter-746, train loss: 2.0620, valid loss: 7689.4185\n",
      "Iter-747, train loss: 2.1517, valid loss: 16422.9759\n",
      "Iter-748, train loss: 1.7911, valid loss: 4684.1130\n",
      "Iter-749, train loss: 1.7404, valid loss: 4928.4387\n",
      "Iter-750, train loss: 1.4049, valid loss: 292.9402\n",
      "Iter-751, train loss: 1.3001, valid loss: 132.0820\n",
      "Iter-752, train loss: 1.1641, valid loss: 3586.3095\n",
      "Iter-753, train loss: 1.3275, valid loss: 2694.0286\n",
      "Iter-754, train loss: 1.4742, valid loss: 9272.8986\n",
      "Iter-755, train loss: 1.3192, valid loss: 1283.9495\n",
      "Iter-756, train loss: 1.2682, valid loss: 7418.3312\n",
      "Iter-757, train loss: 2.1264, valid loss: 30167.2403\n",
      "Iter-758, train loss: 4.1596, valid loss: 9521.6096\n",
      "Iter-759, train loss: 4.9037, valid loss: 1429.8509\n",
      "Iter-760, train loss: 1.7017, valid loss: 24277.5350\n",
      "Iter-761, train loss: 2.0630, valid loss: 8068.2925\n",
      "Iter-762, train loss: 2.8536, valid loss: 24412.1428\n",
      "Iter-763, train loss: 2.3594, valid loss: 6720.0614\n",
      "Iter-764, train loss: 2.4332, valid loss: 7190.8697\n",
      "Iter-765, train loss: 1.2869, valid loss: 2330.5102\n",
      "Iter-766, train loss: 1.2935, valid loss: 1984.6009\n",
      "Iter-767, train loss: 1.1945, valid loss: 31.3385\n",
      "Iter-768, train loss: 1.1683, valid loss: 128.1738\n",
      "Iter-769, train loss: 1.1139, valid loss: 2516.9924\n",
      "Iter-770, train loss: 1.2162, valid loss: 1557.2752\n",
      "Iter-771, train loss: 1.2546, valid loss: 1746.9849\n",
      "Iter-772, train loss: 1.1371, valid loss: 5500.0302\n",
      "Iter-773, train loss: 1.3825, valid loss: 7211.0948\n",
      "Iter-774, train loss: 2.4279, valid loss: 29745.4039\n",
      "Iter-775, train loss: 2.2389, valid loss: 365.2925\n",
      "Iter-776, train loss: 1.5079, valid loss: 7053.7706\n",
      "Iter-777, train loss: 1.4346, valid loss: 31613.8557\n",
      "Iter-778, train loss: 7.4700, valid loss: 143152.1486\n",
      "Iter-779, train loss: 10.0134, valid loss: 24934.7498\n",
      "Iter-780, train loss: 1.5088, valid loss: 19901.6541\n",
      "Iter-781, train loss: 3.3719, valid loss: 24069.4296\n",
      "Iter-782, train loss: 3.9320, valid loss: 16567.3367\n",
      "Iter-783, train loss: 2.0679, valid loss: 22478.7420\n",
      "Iter-784, train loss: 1.9042, valid loss: 13607.8401\n",
      "Iter-785, train loss: 1.9307, valid loss: 20068.5600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-786, train loss: 1.8417, valid loss: 11306.4028\n",
      "Iter-787, train loss: 1.8553, valid loss: 20536.5084\n",
      "Iter-788, train loss: 1.8771, valid loss: 10441.0832\n",
      "Iter-789, train loss: 1.9604, valid loss: 20173.2060\n",
      "Iter-790, train loss: 1.9212, valid loss: 9366.5330\n",
      "Iter-791, train loss: 1.9903, valid loss: 18685.3774\n",
      "Iter-792, train loss: 1.7882, valid loss: 7259.8424\n",
      "Iter-793, train loss: 1.8070, valid loss: 14077.7158\n",
      "Iter-794, train loss: 1.5267, valid loss: 4105.7848\n",
      "Iter-795, train loss: 1.4532, valid loss: 2477.8696\n",
      "Iter-796, train loss: 1.1504, valid loss: 70.7386\n",
      "Iter-797, train loss: 1.0715, valid loss: 195.6506\n",
      "Iter-798, train loss: 1.0081, valid loss: 5742.4400\n",
      "Iter-799, train loss: 1.1915, valid loss: 2567.1588\n",
      "Iter-800, train loss: 1.2778, valid loss: 1942.8643\n",
      "Iter-801, train loss: 1.0327, valid loss: 5956.8992\n",
      "Iter-802, train loss: 1.2805, valid loss: 9328.8096\n",
      "Iter-803, train loss: 2.6450, valid loss: 30634.5019\n",
      "Iter-804, train loss: 3.6954, valid loss: 6486.4147\n",
      "Iter-805, train loss: 3.3087, valid loss: 823.8990\n",
      "Iter-806, train loss: 1.0666, valid loss: 26885.1644\n",
      "Iter-807, train loss: 2.5541, valid loss: 11749.0372\n",
      "Iter-808, train loss: 3.8634, valid loss: 23675.5900\n",
      "Iter-809, train loss: 2.5931, valid loss: 6208.4803\n",
      "Iter-810, train loss: 1.6037, valid loss: 6311.8695\n",
      "Iter-811, train loss: 1.1269, valid loss: 1966.5427\n",
      "Iter-812, train loss: 1.2062, valid loss: 1233.5503\n",
      "Iter-813, train loss: 0.9494, valid loss: 219.0523\n",
      "Iter-814, train loss: 0.9653, valid loss: 37.0430\n",
      "Iter-815, train loss: 0.9421, valid loss: 1895.3900\n",
      "Iter-816, train loss: 1.0038, valid loss: 496.0884\n",
      "Iter-817, train loss: 0.9911, valid loss: 228.3307\n",
      "Iter-818, train loss: 0.9499, valid loss: 8040.3923\n",
      "Iter-819, train loss: 1.1785, valid loss: 4619.2464\n",
      "Iter-820, train loss: 1.5256, valid loss: 21538.0821\n",
      "Iter-821, train loss: 1.0066, valid loss: 13220.3396\n",
      "Iter-822, train loss: 1.9124, valid loss: 22039.3043\n",
      "Iter-823, train loss: 6.5727, valid loss: 32613.2153\n",
      "Iter-824, train loss: 10.1865, valid loss: 129783.3513\n",
      "Iter-825, train loss: 6.2923, valid loss: 16406.6542\n",
      "Iter-826, train loss: 1.3391, valid loss: 15423.5163\n",
      "Iter-827, train loss: 2.5812, valid loss: 22350.0389\n",
      "Iter-828, train loss: 2.0159, valid loss: 11302.6631\n",
      "Iter-829, train loss: 1.6119, valid loss: 20210.0581\n",
      "Iter-830, train loss: 2.2791, valid loss: 10199.9956\n",
      "Iter-831, train loss: 1.5435, valid loss: 18951.3834\n",
      "Iter-832, train loss: 1.6109, valid loss: 10491.5409\n",
      "Iter-833, train loss: 1.6915, valid loss: 20328.3129\n",
      "Iter-834, train loss: 1.8469, valid loss: 10327.4655\n",
      "Iter-835, train loss: 1.7556, valid loss: 20092.7613\n",
      "Iter-836, train loss: 1.8247, valid loss: 9078.2740\n",
      "Iter-837, train loss: 1.7597, valid loss: 18288.3092\n",
      "Iter-838, train loss: 1.6132, valid loss: 6727.4662\n",
      "Iter-839, train loss: 1.5540, valid loss: 12014.6256\n",
      "Iter-840, train loss: 1.2840, valid loss: 3307.5498\n",
      "Iter-841, train loss: 1.1678, valid loss: 1396.1466\n",
      "Iter-842, train loss: 0.9102, valid loss: 536.5628\n",
      "Iter-843, train loss: 0.8859, valid loss: 1498.2483\n",
      "Iter-844, train loss: 0.9220, valid loss: 8882.4548\n",
      "Iter-845, train loss: 1.0546, valid loss: 1248.6607\n",
      "Iter-846, train loss: 1.0035, valid loss: 1003.6228\n",
      "Iter-847, train loss: 0.8456, valid loss: 21805.4412\n",
      "Iter-848, train loss: 1.7380, valid loss: 9720.0179\n",
      "Iter-849, train loss: 3.4554, valid loss: 28632.4939\n",
      "Iter-850, train loss: 2.2246, valid loss: 3214.7150\n",
      "Iter-851, train loss: 1.0342, valid loss: 6351.0608\n",
      "Iter-852, train loss: 1.7859, valid loss: 29645.6166\n",
      "Iter-853, train loss: 4.2374, valid loss: 45392.7407\n",
      "Iter-854, train loss: 5.4198, valid loss: 21722.7332\n",
      "Iter-855, train loss: 1.7538, valid loss: 9912.4984\n",
      "Iter-856, train loss: 1.4115, valid loss: 20539.1231\n",
      "Iter-857, train loss: 1.5062, valid loss: 8349.4415\n",
      "Iter-858, train loss: 2.0183, valid loss: 21897.2019\n",
      "Iter-859, train loss: 1.6115, valid loss: 7350.7153\n",
      "Iter-860, train loss: 1.6839, valid loss: 14009.4182\n",
      "Iter-861, train loss: 1.2129, valid loss: 3665.2977\n",
      "Iter-862, train loss: 1.1019, valid loss: 1695.5055\n",
      "Iter-863, train loss: 0.8577, valid loss: 306.6807\n",
      "Iter-864, train loss: 0.8164, valid loss: 728.1852\n",
      "Iter-865, train loss: 0.8237, valid loss: 4792.5683\n",
      "Iter-866, train loss: 0.9309, valid loss: 846.0154\n",
      "Iter-867, train loss: 0.8828, valid loss: 571.4432\n",
      "Iter-868, train loss: 0.7945, valid loss: 18607.5884\n",
      "Iter-869, train loss: 1.3799, valid loss: 6445.5530\n",
      "Iter-870, train loss: 2.2010, valid loss: 22872.8586\n",
      "Iter-871, train loss: 1.0665, valid loss: 18301.4575\n",
      "Iter-872, train loss: 1.4379, valid loss: 18469.2842\n",
      "Iter-873, train loss: 4.9879, valid loss: 31538.5243\n",
      "Iter-874, train loss: 7.2052, valid loss: 117122.7632\n",
      "Iter-875, train loss: 6.0296, valid loss: 20914.1188\n",
      "Iter-876, train loss: 1.4083, valid loss: 18893.8106\n",
      "Iter-877, train loss: 2.0788, valid loss: 24277.9274\n",
      "Iter-878, train loss: 2.0394, valid loss: 16572.3976\n",
      "Iter-879, train loss: 2.0964, valid loss: 23474.8881\n",
      "Iter-880, train loss: 2.0618, valid loss: 16379.8627\n",
      "Iter-881, train loss: 1.7410, valid loss: 22342.8652\n",
      "Iter-882, train loss: 1.6563, valid loss: 15215.9366\n",
      "Iter-883, train loss: 1.9060, valid loss: 22488.9795\n",
      "Iter-884, train loss: 1.7595, valid loss: 14214.0282\n",
      "Iter-885, train loss: 1.8976, valid loss: 21934.5587\n",
      "Iter-886, train loss: 1.7275, valid loss: 12626.4705\n",
      "Iter-887, train loss: 1.8944, valid loss: 21037.0193\n",
      "Iter-888, train loss: 1.6508, valid loss: 10289.8713\n",
      "Iter-889, train loss: 1.7691, valid loss: 18894.1168\n",
      "Iter-890, train loss: 1.4683, valid loss: 7434.1183\n",
      "Iter-891, train loss: 1.4937, valid loss: 12233.9862\n",
      "Iter-892, train loss: 1.1497, valid loss: 3851.2133\n",
      "Iter-893, train loss: 1.0508, valid loss: 1518.6452\n",
      "Iter-894, train loss: 0.7794, valid loss: 346.4434\n",
      "Iter-895, train loss: 0.7292, valid loss: 1193.2542\n",
      "Iter-896, train loss: 0.7420, valid loss: 6528.7618\n",
      "Iter-897, train loss: 0.8912, valid loss: 1721.5665\n",
      "Iter-898, train loss: 0.8776, valid loss: 83.9012\n",
      "Iter-899, train loss: 0.6803, valid loss: 18208.0812\n",
      "Iter-900, train loss: 1.3285, valid loss: 9767.3811\n",
      "Iter-901, train loss: 2.9984, valid loss: 28983.7602\n",
      "Iter-902, train loss: 2.2409, valid loss: 1132.5974\n",
      "Iter-903, train loss: 0.9071, valid loss: 6226.6879\n",
      "Iter-904, train loss: 1.4255, valid loss: 29869.2691\n",
      "Iter-905, train loss: 4.0757, valid loss: 24330.0261\n",
      "Iter-906, train loss: 5.6550, valid loss: 23090.6765\n",
      "Iter-907, train loss: 1.9883, valid loss: 12313.6675\n",
      "Iter-908, train loss: 1.3038, valid loss: 21125.7548\n",
      "Iter-909, train loss: 1.3234, valid loss: 9399.5032\n",
      "Iter-910, train loss: 1.9327, valid loss: 22475.7686\n",
      "Iter-911, train loss: 1.4605, valid loss: 9085.5329\n",
      "Iter-912, train loss: 1.6874, valid loss: 18741.2171\n",
      "Iter-913, train loss: 1.2515, valid loss: 6134.3273\n",
      "Iter-914, train loss: 1.1999, valid loss: 8076.4942\n",
      "Iter-915, train loss: 0.9226, valid loss: 2131.4791\n",
      "Iter-916, train loss: 0.7797, valid loss: 617.3167\n",
      "Iter-917, train loss: 0.6328, valid loss: 1226.6896\n",
      "Iter-918, train loss: 0.6859, valid loss: 2113.3422\n",
      "Iter-919, train loss: 0.7635, valid loss: 4467.7497\n",
      "Iter-920, train loss: 0.7401, valid loss: 557.4055\n",
      "Iter-921, train loss: 0.6493, valid loss: 5186.0315\n",
      "Iter-922, train loss: 1.0379, valid loss: 26997.3790\n",
      "Iter-923, train loss: 1.7085, valid loss: 2488.8669\n",
      "Iter-924, train loss: 1.4597, valid loss: 4817.3345\n",
      "Iter-925, train loss: 0.6226, valid loss: 30008.0278\n",
      "Iter-926, train loss: 4.4004, valid loss: 21713.6171\n",
      "Iter-927, train loss: 9.1290, valid loss: 28029.8388\n",
      "Iter-928, train loss: 3.5041, valid loss: 58470.3959\n",
      "Iter-929, train loss: 2.8923, valid loss: 23997.8070\n",
      "Iter-930, train loss: 1.6323, valid loss: 17061.8160\n",
      "Iter-931, train loss: 2.7062, valid loss: 24290.2357\n",
      "Iter-932, train loss: 1.4167, valid loss: 16702.6949\n",
      "Iter-933, train loss: 1.8261, valid loss: 23049.8924\n",
      "Iter-934, train loss: 1.5979, valid loss: 15995.8165\n",
      "Iter-935, train loss: 1.7592, valid loss: 22498.4875\n",
      "Iter-936, train loss: 1.4675, valid loss: 15253.6222\n",
      "Iter-937, train loss: 1.7532, valid loss: 22264.6183\n",
      "Iter-938, train loss: 1.5623, valid loss: 14350.3884\n",
      "Iter-939, train loss: 1.7345, valid loss: 21711.3015\n",
      "Iter-940, train loss: 1.5607, valid loss: 13045.7649\n",
      "Iter-941, train loss: 1.6881, valid loss: 20732.6135\n",
      "Iter-942, train loss: 1.4890, valid loss: 10608.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-943, train loss: 1.5424, valid loss: 18399.6811\n",
      "Iter-944, train loss: 1.3067, valid loss: 7523.5569\n",
      "Iter-945, train loss: 1.2623, valid loss: 11136.8801\n",
      "Iter-946, train loss: 0.9906, valid loss: 3715.1811\n",
      "Iter-947, train loss: 0.8446, valid loss: 1331.2909\n",
      "Iter-948, train loss: 0.6272, valid loss: 419.1029\n",
      "Iter-949, train loss: 0.5778, valid loss: 1406.4921\n",
      "Iter-950, train loss: 0.6107, valid loss: 5948.1412\n",
      "Iter-951, train loss: 0.7356, valid loss: 1141.7418\n",
      "Iter-952, train loss: 0.6790, valid loss: 1233.4455\n",
      "Iter-953, train loss: 0.5587, valid loss: 20771.8468\n",
      "Iter-954, train loss: 1.2950, valid loss: 8908.4732\n",
      "Iter-955, train loss: 2.7553, valid loss: 26632.1988\n",
      "Iter-956, train loss: 1.5332, valid loss: 9409.2223\n",
      "Iter-957, train loss: 0.6841, valid loss: 9691.3962\n",
      "Iter-958, train loss: 2.5835, valid loss: 30475.7215\n",
      "Iter-959, train loss: 4.5013, valid loss: 85267.3699\n",
      "Iter-960, train loss: 5.2435, valid loss: 22322.0331\n",
      "Iter-961, train loss: 1.8011, valid loss: 15482.2185\n",
      "Iter-962, train loss: 1.4969, valid loss: 23129.5708\n",
      "Iter-963, train loss: 1.5244, valid loss: 13209.4209\n",
      "Iter-964, train loss: 1.8092, valid loss: 23601.9349\n",
      "Iter-965, train loss: 1.5927, valid loss: 14527.5512\n",
      "Iter-966, train loss: 1.7959, valid loss: 22975.6194\n",
      "Iter-967, train loss: 1.4986, valid loss: 12767.0335\n",
      "Iter-968, train loss: 1.6752, valid loss: 21890.6362\n",
      "Iter-969, train loss: 1.4459, valid loss: 10253.9121\n",
      "Iter-970, train loss: 1.4593, valid loss: 19127.8455\n",
      "Iter-971, train loss: 1.1815, valid loss: 7087.3447\n",
      "Iter-972, train loss: 1.1072, valid loss: 10144.6455\n",
      "Iter-973, train loss: 0.8373, valid loss: 3048.0322\n",
      "Iter-974, train loss: 0.6808, valid loss: 890.2428\n",
      "Iter-975, train loss: 0.5108, valid loss: 837.0448\n",
      "Iter-976, train loss: 0.5225, valid loss: 2064.4878\n",
      "Iter-977, train loss: 0.6021, valid loss: 5115.5430\n",
      "Iter-978, train loss: 0.6299, valid loss: 110.5909\n",
      "Iter-979, train loss: 0.5122, valid loss: 4305.2772\n",
      "Iter-980, train loss: 0.7107, valid loss: 25460.7803\n",
      "Iter-981, train loss: 1.5082, valid loss: 4607.6743\n",
      "Iter-982, train loss: 1.7440, valid loss: 2091.5148\n",
      "Iter-983, train loss: 0.4693, valid loss: 27916.1173\n",
      "Iter-984, train loss: 2.9671, valid loss: 21040.7596\n",
      "Iter-985, train loss: 7.6127, valid loss: 29313.4665\n",
      "Iter-986, train loss: 3.1293, valid loss: 77823.9282\n",
      "Iter-987, train loss: 3.4254, valid loss: 23143.6775\n",
      "Iter-988, train loss: 1.7778, valid loss: 17106.6802\n",
      "Iter-989, train loss: 1.8701, valid loss: 24383.0365\n",
      "Iter-990, train loss: 1.5195, valid loss: 18127.9854\n",
      "Iter-991, train loss: 1.8225, valid loss: 23770.4664\n",
      "Iter-992, train loss: 1.5620, valid loss: 18552.0619\n",
      "Iter-993, train loss: 1.7157, valid loss: 23255.7774\n",
      "Iter-994, train loss: 1.4744, valid loss: 17769.6910\n",
      "Iter-995, train loss: 1.7082, valid loss: 23048.8475\n",
      "Iter-996, train loss: 1.5301, valid loss: 16902.9233\n",
      "Iter-997, train loss: 1.6620, valid loss: 22567.6876\n",
      "Iter-998, train loss: 1.4871, valid loss: 15604.2505\n",
      "Iter-999, train loss: 1.6134, valid loss: 21754.6335\n",
      "Iter-1000, train loss: 1.4170, valid loss: 13219.5798\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEACAYAAACK+7BGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsAXLcfwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2b3ab907b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Hyper-parameters\n",
    "# time_step = 100 # width, minibatch size and test sample size as well\n",
    "# num_layers = 1 # depth\n",
    "# n_iter = 200 # epochs\n",
    "# alpha = 1e-4 # learning_rate\n",
    "# print_after = 1 # n_iter//10 # print training loss, valid, and test\n",
    "# num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "# num_input_units = 1 #len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "# p_dropout = 0.95 # dropout = 1- keep_prob, p = 1-q\n",
    "\n",
    "# # Build the network and learning it or optimizing it using SGD\n",
    "# net = GRU(D=num_input_units, H=num_hidden_units, L=num_layers) #, char2idx=char_to_idx, idx2char=idx_to_char)\n",
    "\n",
    "# # Start learning using BP-SGD-ADAM\n",
    "# adam_rnn(nn=net, X_train=X_train, y_train=y_train, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)\n",
    "\n",
    "# # # Display the learning curve and losses for training, validation, and testing\n",
    "# # %matplotlib inline\n",
    "# # %config InlineBackend.figure_format = 'retina'\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(net.losses['train'], label='Train loss')\n",
    "# plt.plot(net.losses['smooth train'], label='Train smooth loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
