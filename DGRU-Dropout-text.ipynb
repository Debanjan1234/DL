{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "\n",
    "with open('data/text_data/japan.txt', 'r') as f:\n",
    "    txt = f.read()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    char_to_idx = {char: i for i, char in enumerate(set(txt))}\n",
    "    idx_to_char = {i: char for i, char in enumerate(set(txt))}\n",
    "\n",
    "    X = np.array([char_to_idx[x] for x in txt])\n",
    "    y = [char_to_idx[x] for x in txt[1:]]\n",
    "    y.append(char_to_idx['.'])\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model or Network\n",
    "import impl.layer as l\n",
    "\n",
    "class GRU:\n",
    "\n",
    "    def __init__(self, D, H, L, char2idx, idx2char, p_dropout):\n",
    "        self.D = D\n",
    "        self.H = H\n",
    "        self.L = L\n",
    "        self.char2idx = char2idx\n",
    "        self.idx2char = idx2char\n",
    "        self.vocab_size = len(char2idx)\n",
    "        self.losses = {'train':[], 'smooth train':[]}\n",
    "        self.p_dropout = p_dropout\n",
    "        \n",
    "        # Model parameters weights and biases\n",
    "        Z = H + D\n",
    "        m = dict(\n",
    "            Wz=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wr=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wh=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wy=np.random.randn(H, D) / np.sqrt(H / 2.),\n",
    "            bz=np.zeros((1, H)),\n",
    "            br=np.zeros((1, H)),\n",
    "            bh=np.zeros((1, H)),\n",
    "            by=np.zeros((1, D))\n",
    "        )\n",
    "\n",
    "        self.model = []\n",
    "        for _ in range(self.L):\n",
    "            self.model.append(m)\n",
    "\n",
    "    def initial_state(self):\n",
    "        return np.zeros((1, self.H))\n",
    "\n",
    "    def forward(self, X, h, m, train):\n",
    "        Wz, Wr, Wh, Wy = m['Wz'], m['Wr'], m['Wh'], m['Wy']\n",
    "        bz, br, bh, by = m['bz'], m['br'], m['bh'], m['by']\n",
    "\n",
    "        X_one_hot = X.copy()\n",
    "        h_old = h.copy()\n",
    "\n",
    "        X = np.column_stack((h_old, X_one_hot))\n",
    "\n",
    "        hz, hz_cache = l.fc_forward(X, Wz, bz)\n",
    "        hz, hz_sigm_cache = l.sigmoid_forward(hz)\n",
    "\n",
    "        hr, hr_cache = l.fc_forward(X, Wr, br)\n",
    "        hr, hr_sigm_cache = l.sigmoid_forward(hr)\n",
    "\n",
    "        X_prime = np.column_stack((hr * h_old, X_one_hot))\n",
    "        hh, hh_cache = l.fc_forward(X_prime, Wh, bh)\n",
    "        hh, hh_tanh_cache = l.tanh_forward(hh)\n",
    "\n",
    "        h = (1. - hz) * h_old + hz * hh\n",
    "        y, y_cache = l.fc_forward(h, Wy, by)\n",
    "        if train: \n",
    "            y, do_cache = self.dropout_forward(X=y, p_dropout=self.p_dropout)\n",
    "            cache = (X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, \n",
    "                     hh_tanh_cache, y_cache, do_cache)\n",
    "        else: # not train but test\n",
    "            cache = (X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, \n",
    "                     hh_tanh_cache, y_cache)\n",
    "\n",
    "        return y, h, cache\n",
    "\n",
    "    def backward(self, dy, dh, cache, train):\n",
    "        if train: # include dropout_cache/do_cache\n",
    "            X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache, do_cache = cache\n",
    "            dy = self.dropout_backward(dout=dy, cache=do_cache)\n",
    "        else: # not train but test\n",
    "            X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache = cache\n",
    "        \n",
    "        dh_next = dh.copy()\n",
    "        \n",
    "        dh, dWy, dby = l.fc_backward(dy, y_cache)\n",
    "        dh += dh_next\n",
    "\n",
    "        dhh = hz * dh\n",
    "        dh_old1 = (1. - hz) * dh\n",
    "        dhz = hh * dh - h_old * dh\n",
    "\n",
    "        dhh = l.tanh_backward(dhh, hh_tanh_cache)\n",
    "        dX_prime, dWh, dbh = l.fc_backward(dhh, hh_cache)\n",
    "\n",
    "        dh_prime = dX_prime[:, :self.H]\n",
    "        dh_old2 = hr * dh_prime\n",
    "\n",
    "        dhr = h_old * dh_prime\n",
    "        dhr = l.sigmoid_backward(dhr, hr_sigm_cache)\n",
    "        dXr, dWr, dbr = l.fc_backward(dhr, hr_cache)\n",
    "\n",
    "        dhz = l.sigmoid_backward(dhz, hz_sigm_cache)\n",
    "        dXz, dWz, dbz = l.fc_backward(dhz, hz_cache)\n",
    "\n",
    "        dX = dXr + dXz\n",
    "        dh_old3 = dX[:, :self.H]\n",
    "\n",
    "        dh = dh_old1 + dh_old2 + dh_old3\n",
    "        dX = dX[:, self.H:] + dX_prime[:, self.H:]\n",
    "\n",
    "        grad = dict(Wz=dWz, Wr=dWr, Wh=dWh, Wy=dWy, bz=dbz, br=dbr, bh=dbh, by=dby)\n",
    "        \n",
    "        return dX, dh, grad\n",
    "\n",
    "    def dropout_forward(self, X, p_dropout):\n",
    "        u = np.random.binomial(1, p_dropout, size=X.shape) / p_dropout\n",
    "        #         q = 1-p_dropout\n",
    "        #         u = np.random.binomial(1, q, size=X.shape)\n",
    "        out = X * u\n",
    "        cache = u\n",
    "        return out, cache\n",
    "\n",
    "    def dropout_backward(self, dout, cache):\n",
    "        dX = dout * cache\n",
    "        return dX\n",
    "\n",
    "    def train_forward(self, X_train, h):\n",
    "        ys, caches = [], []\n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "            caches.append([])\n",
    "\n",
    "        for X in X_train:\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], cache = self.forward(y, h[layer], self.model[layer], train=True)\n",
    "                caches[layer].append(cache)\n",
    "                \n",
    "            ys.append(y)\n",
    "            \n",
    "        return ys, caches\n",
    "\n",
    "    def cross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(prob[range(m), y_train])\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        grad_y = l.softmax(y_pred)\n",
    "        grad_y[range(m), y_train] -= 1.0\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "    \n",
    "    def loss_function(self, y_train, ys):\n",
    "        loss, dys = 0.0, []\n",
    "\n",
    "        for y_pred, y in zip(ys, y_train):\n",
    "            loss += self.cross_entropy(y_pred, y)\n",
    "            dy = self.dcross_entropy(y_pred, y)\n",
    "            dys.append(dy)\n",
    "            \n",
    "        return loss, dys\n",
    "    \n",
    "    def train_backward(self, dys, caches):\n",
    "        dh, grad, grads = [], [], []\n",
    "        for layer in range(self.L):\n",
    "            dh.append(np.zeros((1, self.H)))\n",
    "            grad.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            grads.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "        \n",
    "        for t in reversed(range(len(dys))):\n",
    "            dX = dys[t]\n",
    "            for layer in reversed(range(self.L)):\n",
    "                dX, dh[layer], grad[layer] = self.backward(dX, dh[layer], caches[layer][t], train=True)\n",
    "                for key in grad[layer].keys():\n",
    "                    grads[layer][key] += grad[layer][key]\n",
    "                \n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X_seed, h, size):\n",
    "        chars = [self.idx2char[X_seed]]\n",
    "        idx_list = list(range(self.vocab_size))\n",
    "        X = X_seed\n",
    "        \n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "\n",
    "        for _ in range(size):\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], _ = self.forward(y, h[layer], self.model[layer], train=False)\n",
    "                \n",
    "            prob = l.softmax(y)\n",
    "            idx = np.random.choice(idx_list, p=prob.ravel())\n",
    "            chars.append(self.idx2char[idx])\n",
    "            X = idx\n",
    "\n",
    "        return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backprop\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "def get_minibatch(X, y, minibatch_size, shuffle):\n",
    "    minibatches = []\n",
    "\n",
    "    if shuffle:\n",
    "        X, y = skshuffle(X, y)\n",
    "\n",
    "    #     for i in range(0, X.shape[0], minibatch_size):\n",
    "    for i in range(0, X.shape[0] - minibatch_size +1, 1):\n",
    "        X_mini = X[i:i + minibatch_size]\n",
    "        y_mini = y[i:i + minibatch_size]\n",
    "        minibatches.append((X_mini, y_mini))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "def adam_rnn(nn, X_train, y_train, alpha, mb_size, n_iter, print_after):\n",
    "    M, R = [], []\n",
    "    for layer in range(nn.L):\n",
    "        M.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        R.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        \n",
    "    beta1 = .99\n",
    "    beta2 = .999\n",
    "    eps = 1e-8\n",
    "    state = nn.initial_state()\n",
    "    smooth_loss = 1.0\n",
    "    minibatches = get_minibatch(X_train, y_train, mb_size, shuffle=False)\n",
    "\n",
    "    # Epochs\n",
    "    for iter in range(1, n_iter + 1):\n",
    "\n",
    "        # No batches/ full batches/ batch files\n",
    "        # Minibacthes\n",
    "        for idx in range(len(minibatches)):\n",
    "            \n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            ys, caches = nn.train_forward(X_mini, state)\n",
    "            loss, dys = nn.loss_function(y_mini, ys)\n",
    "            _, grads = nn.train_backward(dys, caches)\n",
    "            nn.losses['train'].append(loss)\n",
    "            smooth_loss = (0.999 * smooth_loss) + (0.001 * loss)\n",
    "            nn.losses['smooth train'].append(smooth_loss)\n",
    "        \n",
    "            for layer in range(nn.L):\n",
    "                for key in grads[layer].keys(): #key, value: items\n",
    "                    M[layer][key] = l.exp_running_avg(M[layer][key], grads[layer][key], beta1)\n",
    "                    R[layer][key] = l.exp_running_avg(R[layer][key], grads[layer][key]**2, beta2)\n",
    "\n",
    "                    m_k_hat = M[layer][key] / (1. - (beta1**(iter)))\n",
    "                    r_k_hat = R[layer][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                    nn.model[layer][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + eps)\n",
    "                \n",
    "        # Print loss and test sample\n",
    "        if iter % print_after == 0:\n",
    "            print('Iter-{} loss: {:.4f}'.format(iter, loss))\n",
    "            sample = nn.test(X_mini[0], state, size=100)\n",
    "            print(sample)\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1 loss: 308.7220\n",
      " AAy Ay Ay-ist rn in cou country y Astivtount6 A nbgi-cobis cob-sber th yes-riunt yy and rt on courit\n",
      "Iter-2 loss: 301.0368\n",
      " al PP0Polektiis Po60oun the Pccinto theestoulant to the iun PobatirtP th sery A06 G20t20al P60P0h ra\n",
      "Iter-3 loss: 266.8158\n",
      " th cobca coor is Po akean to t5r kananiga coudan coshilourala housbthe the aceopalaskdP the the the \n",
      "Iter-4 loss: 285.9768\n",
      " obaropan is G5–20pease Picaphaa avita. Inlob ronest Poblbtesa colarot s the G5P5–se the G5–20aga Int\n",
      "Iter-5 loss: 267.6097\n",
      " the th-robtataniv1l enk in 201015–an–h pinek1-Japan ran the Rhod Ihod in cobecobect ralg Iantipakeal\n",
      "Iter-6 loss: 264.6845\n",
      " the 1947––2 Pr Pa. Aren. Asin 19h halciacoy en bel Ina–20cing cinonh ovel in sobagea. Rth Pail2 is r\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "time_step = 100 # width, minibatch size and test sample size as well\n",
    "num_layers = 2 # depth\n",
    "n_iter = 130 # epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "p_dropout = 0.95 # q=1-p, q=keep_prob and p=dropout.\n",
    "print_after = 1 #n_iter//100 # print training loss, valid, and test\n",
    "num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "num_input_units = len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "\n",
    "# Build the network and learning it or optimizing it using SGD\n",
    "net = GRU(D=num_input_units, H=num_hidden_units, L=num_layers, char2idx=char_to_idx, idx2char=idx_to_char, \n",
    "          p_dropout=p_dropout)\n",
    "\n",
    "# Start learning using BP-SGD-ADAM\n",
    "adam_rnn(nn=net, X_train=X, y_train=y, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28705f8c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(net.losses['train'], label='Train loss')\n",
    "plt.plot(net.losses['smooth train'], label='Smooth train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
