{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "\n",
    "with open('data/text_data/japan.txt', 'r') as f:\n",
    "    txt = f.read()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    char_to_idx = {char: i for i, char in enumerate(set(txt))}\n",
    "    idx_to_char = {i: char for i, char in enumerate(set(txt))}\n",
    "\n",
    "    X = np.array([char_to_idx[x] for x in txt])\n",
    "    y = [char_to_idx[x] for x in txt[1:]]\n",
    "    y.append(char_to_idx['.'])\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model or Network\n",
    "import impl.layer as l\n",
    "\n",
    "class GRU:\n",
    "\n",
    "    def __init__(self, D, H, L, char2idx, idx2char, p_dropout):\n",
    "        self.D = D\n",
    "        self.H = H\n",
    "        self.L = L\n",
    "        self.char2idx = char2idx\n",
    "        self.idx2char = idx2char\n",
    "        self.vocab_size = len(char2idx)\n",
    "        self.losses = {'train':[], 'smooth train':[]}\n",
    "        self.p_dropout = p_dropout\n",
    "        \n",
    "        # Model parameters weights and biases\n",
    "        Z = H + D\n",
    "        m = dict(\n",
    "            Wz=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wr=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wh=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wy=np.random.randn(H, D) / np.sqrt(H / 2.),\n",
    "            bz=np.zeros((1, H)),\n",
    "            br=np.zeros((1, H)),\n",
    "            bh=np.zeros((1, H)),\n",
    "            by=np.zeros((1, D))\n",
    "        )\n",
    "\n",
    "        self.model = []\n",
    "        for _ in range(self.L):\n",
    "            self.model.append(m)\n",
    "\n",
    "    def initial_state(self):\n",
    "        return np.zeros((1, self.H))\n",
    "\n",
    "    def forward(self, X, h, m, train):\n",
    "        Wz, Wr, Wh, Wy = m['Wz'], m['Wr'], m['Wh'], m['Wy']\n",
    "        bz, br, bh, by = m['bz'], m['br'], m['bh'], m['by']\n",
    "\n",
    "        X_one_hot = X.copy()\n",
    "        h_old = h.copy()\n",
    "\n",
    "        X = np.column_stack((h_old, X_one_hot))\n",
    "\n",
    "        hz, hz_cache = l.fc_forward(X, Wz, bz)\n",
    "        hz, hz_sigm_cache = l.sigmoid_forward(hz)\n",
    "\n",
    "        hr, hr_cache = l.fc_forward(X, Wr, br)\n",
    "        hr, hr_sigm_cache = l.sigmoid_forward(hr)\n",
    "\n",
    "        X_prime = np.column_stack((hr * h_old, X_one_hot))\n",
    "        hh, hh_cache = l.fc_forward(X_prime, Wh, bh)\n",
    "        hh, hh_tanh_cache = l.tanh_forward(hh)\n",
    "\n",
    "        h = (1. - hz) * h_old + hz * hh\n",
    "        y, y_cache = l.fc_forward(h, Wy, by)\n",
    "        \n",
    "        if train: \n",
    "            y, do_cache = self.dropout_forward(X=y, p_dropout=self.p_dropout)\n",
    "            cache = (X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, \n",
    "                     hh_tanh_cache, y_cache, do_cache)\n",
    "        else: # not train but test\n",
    "            cache = (X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, \n",
    "                     hh_tanh_cache, y_cache)\n",
    "\n",
    "        return y, h, cache\n",
    "\n",
    "    def backward(self, dy, dh, cache, train):\n",
    "        if train: # include dropout_cache/do_cache\n",
    "            X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache, do_cache = cache\n",
    "            dy = self.dropout_backward(dout=dy, cache=do_cache)\n",
    "        else: # not train but test\n",
    "            X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache = cache\n",
    "        \n",
    "        dh_next = dh.copy()\n",
    "        \n",
    "        dh, dWy, dby = l.fc_backward(dy, y_cache)\n",
    "        dh += dh_next\n",
    "\n",
    "        dhh = hz * dh\n",
    "        dh_old1 = (1. - hz) * dh\n",
    "        dhz = hh * dh - h_old * dh\n",
    "\n",
    "        dhh = l.tanh_backward(dhh, hh_tanh_cache)\n",
    "        dX_prime, dWh, dbh = l.fc_backward(dhh, hh_cache)\n",
    "\n",
    "        dh_prime = dX_prime[:, :self.H]\n",
    "        dh_old2 = hr * dh_prime\n",
    "\n",
    "        dhr = h_old * dh_prime\n",
    "        dhr = l.sigmoid_backward(dhr, hr_sigm_cache)\n",
    "        dXr, dWr, dbr = l.fc_backward(dhr, hr_cache)\n",
    "\n",
    "        dhz = l.sigmoid_backward(dhz, hz_sigm_cache)\n",
    "        dXz, dWz, dbz = l.fc_backward(dhz, hz_cache)\n",
    "\n",
    "        dX = dXr + dXz\n",
    "        dh_old3 = dX[:, :self.H]\n",
    "\n",
    "        dh = dh_old1 + dh_old2 + dh_old3\n",
    "        dX = dX[:, self.H:] + dX_prime[:, self.H:]\n",
    "\n",
    "        grad = dict(Wz=dWz, Wr=dWr, Wh=dWh, Wy=dWy, bz=dbz, br=dbr, bh=dbh, by=dby)\n",
    "        \n",
    "        return dX, dh, grad\n",
    "\n",
    "    def dropout_forward(self, X, p_dropout):\n",
    "        u = np.random.binomial(1, p_dropout, size=X.shape) / p_dropout\n",
    "        #         q = 1-p_dropout\n",
    "        #         u = np.random.binomial(1, q, size=X.shape)\n",
    "        out = X * u\n",
    "        cache = u\n",
    "        return out, cache\n",
    "\n",
    "    def dropout_backward(self, dout, cache):\n",
    "        dX = dout * cache\n",
    "        return dX\n",
    "\n",
    "    def train_forward(self, X_train, h):\n",
    "        ys, caches = [], []\n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "            caches.append([])\n",
    "\n",
    "        for X in X_train:\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], cache = self.forward(y, h[layer], self.model[layer], train=True)\n",
    "                caches[layer].append(cache)\n",
    "                \n",
    "            ys.append(y)\n",
    "            \n",
    "        return ys, caches\n",
    "\n",
    "    def cross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(prob[range(m), y_train])\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        grad_y = l.softmax(y_pred)\n",
    "        grad_y[range(m), y_train] -= 1.0\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "    \n",
    "    def loss_function(self, y_train, ys):\n",
    "        loss, dys = 0.0, []\n",
    "\n",
    "        for y_pred, y in zip(ys, y_train):\n",
    "            loss += self.cross_entropy(y_pred, y)\n",
    "            dy = self.dcross_entropy(y_pred, y)\n",
    "            dys.append(dy)\n",
    "            \n",
    "        return loss, dys\n",
    "    \n",
    "    def train_backward(self, dys, caches):\n",
    "        dh, grad, grads = [], [], []\n",
    "        for layer in range(self.L):\n",
    "            dh.append(np.zeros((1, self.H)))\n",
    "            grad.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            grads.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "        \n",
    "        for t in reversed(range(len(dys))):\n",
    "            dX = dys[t]\n",
    "            for layer in reversed(range(self.L)):\n",
    "                dX, dh[layer], grad[layer] = self.backward(dX, dh[layer], caches[layer][t], train=True)\n",
    "                for key in grad[layer].keys():\n",
    "                    grads[layer][key] += grad[layer][key]\n",
    "                \n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X_seed, h, size):\n",
    "        chars = [self.idx2char[X_seed]]\n",
    "        idx_list = list(range(self.vocab_size))\n",
    "        X = X_seed\n",
    "        \n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "\n",
    "        for _ in range(size):\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], _ = self.forward(y, h[layer], self.model[layer], train=False)\n",
    "                \n",
    "            prob = l.softmax(y)\n",
    "            idx = np.random.choice(idx_list, p=prob.ravel())\n",
    "            chars.append(self.idx2char[idx])\n",
    "            X = idx\n",
    "\n",
    "        return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backprop\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "def get_minibatch(X, y, minibatch_size, shuffle):\n",
    "    minibatches = []\n",
    "\n",
    "    if shuffle:\n",
    "        X, y = skshuffle(X, y)\n",
    "\n",
    "    #     for i in range(0, X.shape[0], minibatch_size):\n",
    "    for i in range(0, X.shape[0] - minibatch_size +1, 1):\n",
    "        X_mini = X[i:i + minibatch_size]\n",
    "        y_mini = y[i:i + minibatch_size]\n",
    "        minibatches.append((X_mini, y_mini))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "def adam_rnn(nn, X_train, y_train, alpha, mb_size, n_iter, print_after):\n",
    "    M, R = [], []\n",
    "    for layer in range(nn.L):\n",
    "        M.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        R.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        \n",
    "    beta1 = .99\n",
    "    beta2 = .999\n",
    "    eps = 1e-8\n",
    "    state = nn.initial_state()\n",
    "    smooth_loss = 1.0\n",
    "    minibatches = get_minibatch(X_train, y_train, mb_size, shuffle=False)\n",
    "\n",
    "    # Epochs\n",
    "    for iter in range(1, n_iter + 1):\n",
    "\n",
    "        # No batches/ full batches/ batch files\n",
    "        # Minibacthes\n",
    "        for idx in range(len(minibatches)):\n",
    "            \n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            ys, caches = nn.train_forward(X_mini, state)\n",
    "            loss, dys = nn.loss_function(y_mini, ys)\n",
    "            _, grads = nn.train_backward(dys, caches)\n",
    "            nn.losses['train'].append(loss)\n",
    "            smooth_loss = (0.999 * smooth_loss) + (0.001 * loss)\n",
    "            nn.losses['smooth train'].append(smooth_loss)\n",
    "        \n",
    "            for layer in range(nn.L):\n",
    "                for key in grads[layer].keys(): #key, value: items\n",
    "                    M[layer][key] = l.exp_running_avg(M[layer][key], grads[layer][key], beta1)\n",
    "                    R[layer][key] = l.exp_running_avg(R[layer][key], grads[layer][key]**2, beta2)\n",
    "\n",
    "                    m_k_hat = M[layer][key] / (1. - (beta1**(iter)))\n",
    "                    r_k_hat = R[layer][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                    nn.model[layer][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + eps)\n",
    "                \n",
    "        # Print loss and test sample\n",
    "        if iter % print_after == 0:\n",
    "            print('Iter-{} loss: {:.4f}'.format(iter, loss))\n",
    "            sample = nn.test(X_mini[0], state, size=100)\n",
    "            print(sample)\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "time_step = 10 # width, minibatch size and test sample size as well\n",
    "num_layers = 1 # depth\n",
    "n_iter = 130 # epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "p_dropout = 0.95 # q=1-p, q=keep_prob and p=dropout.\n",
    "print_after = n_iter//10 # print training loss, valid, and test\n",
    "num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "num_input_units = len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "\n",
    "# Build the network and learning it or optimizing it using SGD\n",
    "net = GRU(D=num_input_units, H=num_hidden_units, L=num_layers, char2idx=char_to_idx, idx2char=idx_to_char, \n",
    "          p_dropout=p_dropout)\n",
    "\n",
    "# Start learning using BP-SGD-ADAM\n",
    "adam_rnn(nn=net, X_train=X, y_train=y, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74634cbba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(net.losses['train'], label='Train loss')\n",
    "plt.plot(net.losses['smooth train'], label='Train smooth loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
