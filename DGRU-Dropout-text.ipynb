{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "\n",
    "with open('data/text_data/japan.txt', 'r') as f:\n",
    "    txt = f.read()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    char_to_idx = {char: i for i, char in enumerate(set(txt))}\n",
    "    idx_to_char = {i: char for i, char in enumerate(set(txt))}\n",
    "\n",
    "    X = np.array([char_to_idx[x] for x in txt])\n",
    "    y = [char_to_idx[x] for x in txt[1:]]\n",
    "    y.append(char_to_idx['.'])\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model or Network\n",
    "import impl.layer as l\n",
    "\n",
    "class GRU:\n",
    "\n",
    "    def __init__(self, D, H, L, char2idx, idx2char, p_dropout):\n",
    "        self.D = D\n",
    "        self.H = H\n",
    "        self.L = L\n",
    "        self.char2idx = char2idx\n",
    "        self.idx2char = idx2char\n",
    "        self.vocab_size = len(char2idx)\n",
    "        self.losses = {'train':[], 'smooth train':[]}\n",
    "        self.p_dropout = p_dropout\n",
    "        \n",
    "        # Model parameters weights and biases\n",
    "        Z = H + D\n",
    "        m = dict(\n",
    "            Wz=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wr=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wh=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wy=np.random.randn(H, D) / np.sqrt(H / 2.),\n",
    "            bz=np.zeros((1, H)),\n",
    "            br=np.zeros((1, H)),\n",
    "            bh=np.zeros((1, H)),\n",
    "            by=np.zeros((1, D))\n",
    "        )\n",
    "\n",
    "        self.model = []\n",
    "        for _ in range(self.L):\n",
    "            self.model.append(m)\n",
    "\n",
    "    def initial_state(self):\n",
    "        return np.zeros((1, self.H))\n",
    "\n",
    "    def forward(self, X, h, m, train):\n",
    "        Wz, Wr, Wh, Wy = m['Wz'], m['Wr'], m['Wh'], m['Wy']\n",
    "        bz, br, bh, by = m['bz'], m['br'], m['bh'], m['by']\n",
    "\n",
    "        X_one_hot = X.copy()\n",
    "        h_old = h.copy()\n",
    "\n",
    "        X = np.column_stack((h_old, X_one_hot))\n",
    "\n",
    "        hz, hz_cache = l.fc_forward(X, Wz, bz)\n",
    "        hz, hz_sigm_cache = l.sigmoid_forward(hz)\n",
    "\n",
    "        hr, hr_cache = l.fc_forward(X, Wr, br)\n",
    "        hr, hr_sigm_cache = l.sigmoid_forward(hr)\n",
    "\n",
    "        X_prime = np.column_stack((hr * h_old, X_one_hot))\n",
    "        hh, hh_cache = l.fc_forward(X_prime, Wh, bh)\n",
    "        hh, hh_tanh_cache = l.tanh_forward(hh)\n",
    "\n",
    "        h = (1. - hz) * h_old + hz * hh\n",
    "        y, y_cache = l.fc_forward(h, Wy, by)\n",
    "        if train: \n",
    "            y, do_cache = self.dropout_forward(X=y, p_dropout=self.p_dropout)\n",
    "            cache = (X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, \n",
    "                     hh_tanh_cache, y_cache, do_cache)\n",
    "        else: # not train but test\n",
    "            cache = (X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, \n",
    "                     hh_tanh_cache, y_cache)\n",
    "\n",
    "        return y, h, cache\n",
    "\n",
    "    def backward(self, dy, dh, cache, train):\n",
    "        if train: # include dropout_cache/do_cache\n",
    "            X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache, do_cache = cache\n",
    "            dy = self.dropout_backward(dout=dy, cache=do_cache)\n",
    "        else: # not train but test\n",
    "            X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache = cache\n",
    "        \n",
    "        dh_next = dh.copy()\n",
    "        \n",
    "        dh, dWy, dby = l.fc_backward(dy, y_cache)\n",
    "        dh += dh_next\n",
    "\n",
    "        dhh = hz * dh\n",
    "        dh_old1 = (1. - hz) * dh\n",
    "        dhz = hh * dh - h_old * dh\n",
    "\n",
    "        dhh = l.tanh_backward(dhh, hh_tanh_cache)\n",
    "        dX_prime, dWh, dbh = l.fc_backward(dhh, hh_cache)\n",
    "\n",
    "        dh_prime = dX_prime[:, :self.H]\n",
    "        dh_old2 = hr * dh_prime\n",
    "\n",
    "        dhr = h_old * dh_prime\n",
    "        dhr = l.sigmoid_backward(dhr, hr_sigm_cache)\n",
    "        dXr, dWr, dbr = l.fc_backward(dhr, hr_cache)\n",
    "\n",
    "        dhz = l.sigmoid_backward(dhz, hz_sigm_cache)\n",
    "        dXz, dWz, dbz = l.fc_backward(dhz, hz_cache)\n",
    "\n",
    "        dX = dXr + dXz\n",
    "        dh_old3 = dX[:, :self.H]\n",
    "\n",
    "        dh = dh_old1 + dh_old2 + dh_old3\n",
    "        dX = dX[:, self.H:]\n",
    "\n",
    "        grad = dict(Wz=dWz, Wr=dWr, Wh=dWh, Wy=dWy, bz=dbz, br=dbr, bh=dbh, by=dby)\n",
    "        \n",
    "        return dX, dh, grad\n",
    "\n",
    "    def dropout_forward(self, X, p_dropout):\n",
    "        u = np.random.binomial(1, p_dropout, size=X.shape) / p_dropout\n",
    "        #         q = 1-p_dropout\n",
    "        #         u = np.random.binomial(1, q, size=X.shape)\n",
    "        out = X * u\n",
    "        cache = u\n",
    "        return out, cache\n",
    "\n",
    "    def dropout_backward(self, dout, cache):\n",
    "        dX = dout * cache\n",
    "        return dX\n",
    "\n",
    "    def train_forward(self, X_train, h):\n",
    "        ys, caches = [], []\n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "            caches.append([])\n",
    "\n",
    "        for X in X_train:\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], cache = self.forward(y, h[layer], self.model[layer], train=True)\n",
    "                caches[layer].append(cache)\n",
    "                \n",
    "            ys.append(y)\n",
    "            \n",
    "        return ys, caches\n",
    "\n",
    "    def cross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(prob[range(m), y_train])\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        grad_y = l.softmax(y_pred)\n",
    "        grad_y[range(m), y_train] -= 1.0\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "    \n",
    "    def loss_function(self, y_train, ys):\n",
    "        loss, dys = 0.0, []\n",
    "\n",
    "        for y_pred, y in zip(ys, y_train):\n",
    "            loss += self.cross_entropy(y_pred, y)\n",
    "            dy = self.dcross_entropy(y_pred, y)\n",
    "            dys.append(dy)\n",
    "            \n",
    "        return loss, dys\n",
    "    \n",
    "    def train_backward(self, dys, caches):\n",
    "        dh, grad, grads = [], [], []\n",
    "        for layer in range(self.L):\n",
    "            dh.append(np.zeros((1, self.H)))\n",
    "            grad.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            grads.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "        \n",
    "        for t in reversed(range(len(dys))):\n",
    "            dX = dys[t]\n",
    "            for layer in reversed(range(self.L)):\n",
    "                dX, dh[layer], grad[layer] = self.backward(dX, dh[layer], caches[layer][t], train=True)\n",
    "                for key in grad[0].keys():\n",
    "                    grads[layer][key] += grad[layer][key]\n",
    "                \n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X_seed, h, size):\n",
    "        chars = [self.idx2char[X_seed]]\n",
    "        idx_list = list(range(self.vocab_size))\n",
    "        X = X_seed\n",
    "        \n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "\n",
    "        for _ in range(size):\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], _ = self.forward(y, h[layer], self.model[layer], train=False)\n",
    "                \n",
    "            prob = l.softmax(y)\n",
    "            idx = np.random.choice(idx_list, p=prob.ravel())\n",
    "            chars.append(self.idx2char[idx])\n",
    "            X = idx\n",
    "\n",
    "        return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backprop\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "def get_minibatch(X, y, minibatch_size, shuffle):\n",
    "    minibatches = []\n",
    "\n",
    "    if shuffle:\n",
    "        X, y = skshuffle(X, y)\n",
    "\n",
    "    #     for i in range(0, X.shape[0], minibatch_size):\n",
    "    for i in range(0, X.shape[0] - minibatch_size +1, 1):\n",
    "        X_mini = X[i:i + minibatch_size]\n",
    "        y_mini = y[i:i + minibatch_size]\n",
    "        minibatches.append((X_mini, y_mini))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "def adam_rnn(nn, X_train, y_train, alpha, mb_size, n_iter, print_after):\n",
    "    M, R = [], []\n",
    "    for layer in range(nn.L):\n",
    "        M.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        R.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        \n",
    "    beta1 = .99\n",
    "    beta2 = .999\n",
    "    # import impl.constant as c\n",
    "    eps = 1e-8\n",
    "    state = nn.initial_state()\n",
    "    smooth_loss = 1.0\n",
    "\n",
    "    # Epochs\n",
    "    for iter in range(1, n_iter + 1):\n",
    "\n",
    "        # No batches/ full batches/ batch files\n",
    "        # Minibacthes\n",
    "        minibatches = get_minibatch(X_train, y_train, mb_size, shuffle=False)\n",
    "        for idx in range(len(minibatches)):\n",
    "            \n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            ys, caches = nn.train_forward(X_mini, state)\n",
    "            loss, dys = nn.loss_function(y_mini, ys)\n",
    "            dX, grads = nn.train_backward(dys, caches)\n",
    "            nn.losses['train'].append(loss)\n",
    "            smooth_loss = (0.999 * smooth_loss) + (0.001 * loss)\n",
    "            nn.losses['smooth train'].append(smooth_loss)\n",
    "        \n",
    "            for layer in range(nn.L):\n",
    "                for key in grads[0].keys(): #key, value: items\n",
    "                    M[layer][key] = l.exp_running_avg(M[layer][key], grads[layer][key], beta1)\n",
    "                    R[layer][key] = l.exp_running_avg(R[layer][key], grads[layer][key]**2, beta2)\n",
    "\n",
    "                    m_k_hat = M[layer][key] / (1. - (beta1**(iter)))\n",
    "                    r_k_hat = R[layer][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                    nn.model[layer][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + eps)\n",
    "                \n",
    "        # Print loss and test sample\n",
    "        if iter % print_after == 0:\n",
    "            print('Iter-{} loss: {:.4f}'.format(iter, loss))\n",
    "            sample = nn.test(X_mini[0], state, size=100)\n",
    "            print(sample)\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-10 loss: 35.3477\n",
      "ing the wor\n",
      "Iter-20 loss: 29.2639\n",
      "in taecaren\n",
      "Iter-30 loss: 24.0952\n",
      "ich and vin\n",
      "Iter-40 loss: 20.5889\n",
      "iclaiced Em\n",
      "Iter-50 loss: 18.4828\n",
      "instimy whi\n",
      "Iter-60 loss: 16.8765\n",
      "itonplee Ab\n",
      "Iter-70 loss: 17.4987\n",
      "ins. Japan \n",
      "Iter-80 loss: 14.6960\n",
      "ity from of\n",
      "Iter-90 loss: 14.2719\n",
      "ith revised\n",
      "Iter-100 loss: 13.8543\n",
      "iDgestounes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.GRU at 0x106948208>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "time_step = 100 # width, minibatch size and test sample size as well\n",
    "num_layers = 1 # depth\n",
    "n_iter = 100 # epochs\n",
    "alpha = 1e-4 # learning_rate\n",
    "p_dropout = 0.95 # q=1-p, q=keep_prob and p=dropout.\n",
    "print_after = n_iter//10 # print training loss, valid, and test\n",
    "num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "num_input_units = len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "\n",
    "# Build the network and learning it or optimizing it using SGD\n",
    "net = GRU(D=num_input_units, H=num_hidden_units, L=num_layers, char2idx=char_to_idx, idx2char=idx_to_char, \n",
    "          p_dropout=p_dropout)\n",
    "\n",
    "# Start learning using BP-SGD-ADAM\n",
    "adam_rnn(nn=net, X_train=X, y_train=y, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlIphGgSUUiqGaRBQSqkYpkFAKaVi2P8DS/Xxm22Mvo4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c0dc438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(net.losses['train'], label='Train loss')\n",
    "plt.plot(net.losses['smooth train'], label='Smooth train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
