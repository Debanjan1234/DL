{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from impl.solver import *\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iter = 1000 # number of epochs\n",
    "alpha = 1e-3\n",
    "mb_size = 64 # minibatch size usually compatible to the Cache/RAM size\n",
    "n_experiment = 1\n",
    "reg = 1e-5\n",
    "print_after = 100\n",
    "p_dropout = 0.8\n",
    "loss = 'cross_ent'\n",
    "nonlin = 'relu'\n",
    "solver = 'sgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10000,), (5000,), (55000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import hipsternet.input_data as input_data  # NOT used for MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('data/MNIST_data/', one_hot=False)\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "y_test.shape, y_val.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M, D, C = X_train.shape[0], X_train.shape[1], y_train.max() + 1\n",
    "M, D, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 784), (5000, 784), (10000, 784))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import impl.utils as utils\n",
    "X_train, X_val, X_test = utils.prepro(X_train, X_val, X_test)\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 1, 28, 28), (5000, 1, 28, 28), (10000, 1, 28, 28))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if net_type == 'cnn':\n",
    "img_shape = (1, 28, 28)\n",
    "X_train = X_train.reshape(-1, *img_shape)\n",
    "X_val = X_val.reshape(-1, *img_shape)\n",
    "X_test = X_test.reshape(-1, *img_shape)\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adagrad': <function impl.solver.adagrad>,\n",
       " 'adam': <function impl.solver.adam>,\n",
       " 'momentum': <function impl.solver.momentum>,\n",
       " 'nesterov': <function impl.solver.nesterov>,\n",
       " 'rmsprop': <function impl.solver.rmsprop>,\n",
       " 'sgd': <function impl.solver.sgd>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solvers = dict(\n",
    "    sgd=sgd,\n",
    "    momentum=momentum,\n",
    "    nesterov=nesterov,\n",
    "    adagrad=adagrad,\n",
    "    rmsprop=rmsprop,\n",
    "    adam=adam\n",
    ")\n",
    "solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimenting on sgd\n"
     ]
    }
   ],
   "source": [
    "solver_fun = solvers[solver] # solver functions\n",
    "accs = np.zeros(n_experiment)\n",
    "solver_fun, accs\n",
    "# print()\n",
    "print('Experimenting on {}'.format(solver))\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### import numpy as np\n",
    "import impl.loss as loss_fun\n",
    "import impl.layer as l\n",
    "import impl.NN as nn\n",
    "import impl.pyramidnet as pyramidnet\n",
    "\n",
    "class SPNN(nn.NN):\n",
    "\n",
    "    def __init__(self, D, C, H, lam=1e-3, p_dropout=.8, loss='cross_ent', nonlin='relu'):\n",
    "        super().__init__(D, C, H, lam, p_dropout, loss, nonlin)\n",
    "        \n",
    "    def forward(self, X, train=False):\n",
    "\n",
    "        # 1st layer -  convolution to change the size from x_txcxhxw to h_txhxwxd, c==channels of image, d=depth/num_units\n",
    "        h1_txhxwxd_logit, h1_txhxwxd_logit_cache = l.conv_forward(b=self.model['b1'], #b_1xh\n",
    "                                                    padding=1, #padding=true means image size stays the same: 'SAME'\n",
    "                                                    stride=1, # stride one means include all and no jump\n",
    "                                                    W=self.model['W1'], # kernel size cx3x3xd for all layers\n",
    "                                                    X=X) # input image in SPNN for spatial PNN        # 2nd layer - adding to the linear layer output\n",
    "        #         dX, dw1, db1 = l.conv_backward(dout=dh1_txhxwxd_logit, cache=h1_txhxwxd_logit_cache)\n",
    "\n",
    "        # 1st layer - nonlinearity-relu\n",
    "        h1_txhxwxd_act, h1_txhxwxd_act_cache = l.relu_forward(h1_txhxwxd_logit)\n",
    "        #         dh1_txhxwxd_logit = l.relu_backward(cache=h1_txhxwxd_act_cache, dout=dh1_txhxwxd_act)\n",
    "\n",
    "        # midst layer: Pyrmidnet as core layer\n",
    "        h1_txhxwxd_act, h1_txhxwxd_act_pyrmidnet_cache = pyramidnet.fwd(\n",
    "                    b1=self.model['b11'], b21=self.model['b21'], b22=self.model['b22'], \n",
    "                      w1=self.model['W11'], w21=self.model['W21'], w22=self.model['W22'], \n",
    "                      X=h1_txhxwxd_act)\n",
    "        #         dh1_txhxwxd_act, dw11, db11, dw21, db21, dw22, db22 = pyrmidnet_bwd(cache=h1_txhxwxd_act_pyrmidnet_cache, \n",
    "        #                                                                           dy_txhxwxd_act=dh1_txhxwxd_act)\n",
    "\n",
    "        # midst layer: Pyrmidnet as core layer 2\n",
    "        h1_txhxwxd_act, h1_txhxwxd_act_pyrmidnet_cache_2 = pyramidnet.fwd(\n",
    "                    b1=self.model['b11_2'], b21=self.model['b21_2'], b22=self.model['b22_2'], \n",
    "                      w1=self.model['W11_2'], w21=self.model['W21_2'], w22=self.model['W22_2'], \n",
    "                      X=h1_txhxwxd_act)\n",
    "        #         dh1_txhxwxd_act, dw11_2, db11_2, dw21_2, db21_2, dw22_2, db22_2 = pyrmidnet_bwd(cache=h1_txhxwxd_act_pyrmidnet_cache_2, \n",
    "        #                                                                           dy_txhxwxd_act=dh1_txhxwxd_act)\n",
    "\n",
    "        # midst layer: Pyrmidnet as core layer 3\n",
    "        h1_txhxwxd_act, h1_txhxwxd_act_pyrmidnet_cache_3 = pyramidnet.fwd(\n",
    "                    b1=self.model['b11_3'], b21=self.model['b21_3'], b22=self.model['b22_3'], \n",
    "                      w1=self.model['W11_3'], w21=self.model['W21_3'], w22=self.model['W22_3'], \n",
    "                      X=h1_txhxwxd_act)\n",
    "        #         dh1_txhxwxd_act, dw11_3, db11_3, dw21_3, db21_3, dw22_3, db22_3 = pyrmidnet_bwd(cache=h1_txhxwxd_act_pyrmidnet_cache_3, \n",
    "        #                                                                           dy_txhxwxd_act=dh1_txhxwxd_act)\n",
    "\n",
    "        # last layer : FC layer -  fully connected to the output layer (visible layer)\n",
    "        # n=hxwxd flattened\n",
    "        h1_txn_act = h1_txhxwxd_act.reshape([h1_txhxwxd_act_cache.shape[0], -1])\n",
    "        #         dh1_txhxwxd_act = dh1_txn_act.reshape(h1_txhxwxd_act_cache.shape)\n",
    "\n",
    "        y_tx10_logit, y_tx10_logit_cache = l.fc_forward(X=h1_txn_act, W=self.model['W2'], b=self.model['b2'])\n",
    "        #         dh1_txn_act, dw2, db2 = l.fc_backward(dout=dy_tx10_logit, cache=y_tx10_logit_cache)\n",
    "\n",
    "        # Output\n",
    "        cache = h1_txhxwxd_logit_cache, h1_txhxwxd_act_cache, h1_txhxwxd_act_pyrmidnet_cache, h1_txhxwxd_act_pyrmidnet_cache_2, h1_txhxwxd_act_pyrmidnet_cache_3, y_tx10_logit_cache\n",
    "        #         h1_txhxwxd_logit_cache, h1_txhxwxd_act_cache, h1_txhxwxd_act_pyrmidnet_cache, h1_txhxwxd_act_pyrmidnet_cache_2, h1_txhxwxd_act_pyrmidnet_cache_3, y_tx10_logit_cache = cache\n",
    "\n",
    "        return y_tx10_logit, cache\n",
    "\n",
    "    def backward(self, y, y_train, cache):\n",
    "\n",
    "        #         # Output\n",
    "        #         cache = h1_txhxwxd_logit_cache, h1_txhxwxd_act_cache, h1_txhxwxd_act_pyrmidnet_cache, h1_txhxwxd_act_pyrmidnet_cache_2, y_tx10_logit_cache\n",
    "        h1_txhxwxd_logit_cache, h1_txhxwxd_act_cache, h1_txhxwxd_act_pyrmidnet_cache, h1_txhxwxd_act_pyrmidnet_cache_2, h1_txhxwxd_act_pyrmidnet_cache_3, y_tx10_logit_cache = cache\n",
    "\n",
    "        # Output layer backward\n",
    "        dy_tx10_logit = self.dloss_funs[self.loss](y, y_train) # y==y_logits\n",
    "\n",
    "        #         y_tx10_logit, y_tx10_logit_cache = l.fc_forward(X=h1_txn_act, W=self.model['W2'], b=self.model['b2'])\n",
    "        dh1_txn_act, dw2, db2 = l.fc_backward(dout=dy_tx10_logit, cache=y_tx10_logit_cache)\n",
    "\n",
    "        #         # last layer : FC layer -  fully connected to the output layer (visible layer)\n",
    "        #         # n=hxwxd flattened\n",
    "        #         h1_txn_act = h1_txhxwxd_act.reshape([h1_txhxwxd_act_cache.shape[0], -1])\n",
    "        dh1_txhxwxd_act = dh1_txn_act.reshape(h1_txhxwxd_act_cache.shape)\n",
    "\n",
    "        #         # midst layer: Pyrmidnet as core layer\n",
    "        #         h1_txhxwxd_act, h1_txhxwxd_act_pyrmidnet_cache = pyrmidnet_fwd(\n",
    "        #                     b1=self.model['b11'], b21=self.model['b21'], b22=self.model['b22'], \n",
    "        #                       w1=self.model['w11'], w21=self.model['w21'], w22=self.model['w22'], \n",
    "        #                       X=h1_txhxwxd_act)\n",
    "        dh1_txhxwxd_act, dw11, db11, dw21, db21, dw22, db22 = pyramidnet.bwd(cache=h1_txhxwxd_act_pyrmidnet_cache, \n",
    "                                                                          dy_txhxwxd_act=dh1_txhxwxd_act)\n",
    "        #         # midst layer: Pyrmidnet as core layer 2\n",
    "        #         h1_txhxwxd_act, h1_txhxwxd_act_pyrmidnet_cache_2 = pyramidnet.fwd(\n",
    "        #                     b1=self.model['b11_2'], b21=self.model['b21_2'], b22=self.model['b22_2'], \n",
    "        #                       w1=self.model['W11_2'], w21=self.model['W21_2'], w22=self.model['W22_2'], \n",
    "        #                       X=h1_txhxwxd_act)\n",
    "        dh1_txhxwxd_act, dw11_2, db11_2, dw21_2, db21_2, dw22_2, db22_2 = pyramidnet.bwd(cache=h1_txhxwxd_act_pyrmidnet_cache_2, \n",
    "                                                                          dy_txhxwxd_act=dh1_txhxwxd_act)\n",
    "\n",
    "        #         # midst layer: Pyrmidnet as core layer 3\n",
    "        #         h1_txhxwxd_act, h1_txhxwxd_act_pyrmidnet_cache_2 = pyramidnet.fwd(\n",
    "        #                     b1=self.model['b11_2'], b21=self.model['b21_2'], b22=self.model['b22_2'], \n",
    "        #                       w1=self.model['W11_2'], w21=self.model['W21_2'], w22=self.model['W22_2'], \n",
    "        #                       X=h1_txhxwxd_act)\n",
    "        dh1_txhxwxd_act, dw11_3, db11_3, dw21_3, db21_3, dw22_3, db22_3 = pyramidnet.bwd(cache=h1_txhxwxd_act_pyrmidnet_cache_3, \n",
    "                                                                          dy_txhxwxd_act=dh1_txhxwxd_act)\n",
    "\n",
    "        #         # 1st layer - nonlinearity-relu\n",
    "        #         h1_txhxwxd_act, h1_txhxwxd_act_cache = l.relu_forward(h1_txhxwxd_logit)\n",
    "        dh1_txhxwxd_logit = l.relu_backward(cache=h1_txhxwxd_act_cache, dout=dh1_txhxwxd_act)\n",
    "\n",
    "        #         # 1st layer -  convolution to change the size from x_txcxhxw to h_txhxwxd, c==channels of image, d=depth/num_units\n",
    "        #         h1_txhxwxd_logit, h1_txhxwxd_logit_cache = l.conv_forward(b=self.model['b1'], #b_1xh\n",
    "        #                                                     padding=1, #padding=true means image size stays the same: 'SAME'\n",
    "        #                                                     stride=1, # stride one means include all and no jump\n",
    "        #                                                     W=self.model['W1'], # kernel size cx3x3xd for all layers\n",
    "        #                                                     X=X) # input image in SPNN for spatial PNN        # 2nd layer - adding to the linear layer output\n",
    "        dX, dw1, db1 = l.conv_backward(dout=dh1_txhxwxd_logit, cache=h1_txhxwxd_logit_cache)\n",
    "\n",
    "        # grad for GD\n",
    "        grad = dict(\n",
    "            # Input layer to Conv: 1st layer in SPNN: Conv layer from the input\n",
    "            W1=dw1, \n",
    "            b1=db1,\n",
    "            #             W1=np.random.randn(H, 1, 3, 3) / np.sqrt(H / 2.),\n",
    "            #             b1=np.zeros((H, 1)),\n",
    "\n",
    "            # Pyrmidnet layer: midst layer\n",
    "            W11=dw11, \n",
    "            b11=db11,\n",
    "            #             W11=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            #             b11=np.zeros((H, 1)),\n",
    "            W21=dw21, \n",
    "            b21=db21,\n",
    "            #             W21=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            #             b21=np.zeros((H, 1)), # 1st layer Conv the input\n",
    "            W22=dw22, \n",
    "            b22=db22, # 1st layer in SPNN: Conv layer from the input\n",
    "            #             W22=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            #             b22=np.zeros((H, 1)), # 1st layer Conv the input\n",
    "\n",
    "            # Pyrmidnet layer: midst layer 2\n",
    "            W11_2=dw11_2, \n",
    "            b11_2=db11_2,\n",
    "            #             W11_2=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            #             b11_2=np.zeros((H, 1)),\n",
    "            W21_2=dw21_2, \n",
    "            b21_2=db21_2,\n",
    "            #             W21_2=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            #             b21_2=np.zeros((H, 1)), # 1st layer Conv the input\n",
    "            W22_2=dw22_2, \n",
    "            b22_2=db22_2, # 1st layer in SPNN: Conv layer from the input\n",
    "            #             W22_2=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            #             b22_2=np.zeros((H, 1)), # 1st layer Conv the input\n",
    "\n",
    "            # Pyrmidnet layer: midst layer 3\n",
    "            W11_3=dw11_3, \n",
    "            b11_3=db11_3,\n",
    "            #             W11_2=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            #             b11_2=np.zeros((H, 1)),\n",
    "            W21_3=dw21_3, \n",
    "            b21_3=db21_3,\n",
    "            #             W21_2=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            #             b21_2=np.zeros((H, 1)), # 1st layer Conv the input\n",
    "            W22_3=dw22_3, \n",
    "            b22_3=db22_3, # 1st layer in SPNN: Conv layer from the input\n",
    "            #             W22_2=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            #             b22_2=np.zeros((H, 1)), # 1st layer Conv the input\n",
    "\n",
    "            #             # FC to output layer: last layer in SPNN: FC layer to the output \n",
    "            W2=dw2, \n",
    "            b2=db2\n",
    "            #             W2=np.random.randn(H * D, C) / np.sqrt(H * D / 2.), \n",
    "            #             b2=np.zeros((1, C))\n",
    "            )\n",
    "        \n",
    "        return grad\n",
    "\n",
    "    def _init_model(self, D, C, H):\n",
    "        self.model = dict(\n",
    "            #             # Input layer to Conv: 1st layer in SPNN: Conv layer from the input\n",
    "            #             W1=dw1, \n",
    "            #             b1=db1,\n",
    "            W1=np.random.randn(H, 1, 3, 3) / np.sqrt(H / 2.),\n",
    "            b1=np.zeros((H, 1)),\n",
    "\n",
    "            #             # Pyrmidnet layer: midst layer\n",
    "            #             W11=dw11, \n",
    "            #             b11=db11,\n",
    "            W11=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            b11=np.zeros((H, 1)),\n",
    "            #             W21=dw21, \n",
    "            #             b21=db21,\n",
    "            W21=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            b21=np.zeros((H, 1)), # 1st layer Conv the input\n",
    "            #             W22=dw22, \n",
    "            #             b22=db22, # 1st layer in SPNN: Conv layer from the input\n",
    "            W22=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            b22=np.zeros((H, 1)), # 1st layer Conv the input\n",
    "\n",
    "            #             # Pyrmidnet layer: midst layer 2\n",
    "            #             W11_2=dw11_2, \n",
    "            #             b11_2=db11_2,\n",
    "            W11_2=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            b11_2=np.zeros((H, 1)),\n",
    "            #             W21_2=dw21_2, \n",
    "            #             b21_2=db21_2,\n",
    "            W21_2=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            b21_2=np.zeros((H, 1)), # 1st layer Conv the input\n",
    "            #             W22_2=dw22_2, \n",
    "            #             b22_2=db22_2, # 1st layer in SPNN: Conv layer from the input\n",
    "            W22_2=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            b22_2=np.zeros((H, 1)), # 1st layer Conv the input\n",
    "\n",
    "            #             # Pyrmidnet layer: midst layer 3\n",
    "            #             W11_2=dw11_2, \n",
    "            #             b11_2=db11_2,\n",
    "            W11_3=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            b11_3=np.zeros((H, 1)),\n",
    "            #             W21_2=dw21_2, \n",
    "            #             b21_2=db21_2,\n",
    "            W21_3=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            b21_3=np.zeros((H, 1)), # 1st layer Conv the input\n",
    "            #             W22_2=dw22_2, \n",
    "            #             b22_2=db22_2, # 1st layer in SPNN: Conv layer from the input\n",
    "            W22_3=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "            b22_3=np.zeros((H, 1)), # 1st layer Conv the input\n",
    "\n",
    "            #             #             # FC to output layer: last layer in SPNN: FC layer to the output \n",
    "            #             W2=dw2, \n",
    "            #             b2=db2\n",
    "            W2=np.random.randn(H * D, C) / np.sqrt(H * D / 2.), \n",
    "            b2=np.zeros((1, C))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arasdar/arasdar-DL-git/impl/loss.py:28: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = -np.log(prob[range(m), y_train])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-100 loss: inf validation: 0.100200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arasdar/arasdar-DL-git/impl/layer.py:197: RuntimeWarning: invalid value encountered in less_equal\n",
      "  dX[cache <= 0] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-200 loss: nan validation: 0.095800\n",
      "Iter-300 loss: nan validation: 0.095800\n",
      "Iter-400 loss: nan validation: 0.095800\n",
      "Iter-500 loss: nan validation: 0.095800\n",
      "Iter-600 loss: nan validation: 0.095800\n",
      "Iter-700 loss: nan validation: 0.095800\n",
      "Iter-800 loss: nan validation: 0.095800\n",
      "Iter-900 loss: nan validation: 0.095800\n",
      "Iter-1000 loss: nan validation: 0.095800\n",
      "\n",
      "Test Mean accuracy: 0.0980, std: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for k in range(n_experiment):\n",
    "    print('Experiment-{}'.format(k + 1))\n",
    "\n",
    "#     net = PNN(C=C, D=10, H=128) # Mine\n",
    "    net = SPNN(C=C, D=D, H=2) #, lam=, loss=, nonlin=, p_dropout=, self=\n",
    "\n",
    "    net = solver_fun(nn=net, X_train=X_train, y_train=y_train, val_set=(X_val, y_val), \n",
    "                     mb_size=mb_size, alpha=alpha, n_iter=n_iter, print_after=print_after)\n",
    "\n",
    "    y_pred = net.predict(X_test)\n",
    "    accs[k] = np.mean(y_pred == y_test)\n",
    "\n",
    "print()\n",
    "print('Test Mean accuracy: {:.4f}, std: {:.4f}'.format(accs.mean(), accs.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
