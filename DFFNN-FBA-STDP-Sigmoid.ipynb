{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import impl.layer as l\n",
    "\n",
    "# Dataset preparation and pre-processing\n",
    "mnist = input_data.read_data_sets('data/MNIST_data/', one_hot=False)\n",
    "\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "# y_test.shape, y_val.shape, y_train.shape\n",
    "# X_train.shape, X_train.dtype, X_val.shape, X_val.dtype, X_test.shape, X_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-processing: normalizing\n",
    "def normalize(X):\n",
    "    # max scale for images 255= 2**8= 8 bit grayscale for each channel\n",
    "    return (X - X.mean(axis=0)) #/ X.std(axis=0)\n",
    "\n",
    "X_train, X_val, X_test = normalize(X=X_train), normalize(X=X_val), normalize(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l # or from impl.layer import *\n",
    "from impl.loss import * # import all functions from impl.loss file # import impl.loss as loss_func\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "class FFNN:\n",
    "\n",
    "    def __init__(self, D, C, H, L):\n",
    "        self.L = L # number of layers or depth\n",
    "        self.losses = {'train':[], 'valid':[], 'valid_acc':[]}\n",
    "        \n",
    "        # The adaptive/learnable/updatable random feedforward\n",
    "        self.model = []\n",
    "        self.W_fixed = []\n",
    "        self.grads = []\n",
    "        self.ys_prev = []\n",
    "        low, high = -1, 1\n",
    "        \n",
    "        # Input layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.), b=np.zeros((1, H)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Input layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[0].items()})\n",
    "        # Previous output layer\n",
    "        self.ys_prev.append(0.0)\n",
    "\n",
    "        # Hidden layers: weights/ biases\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = dict(W=np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, H)))\n",
    "            m_L.append(m)\n",
    "        self.model.append(m_L)\n",
    "        # Fixed feedback weight\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.)\n",
    "            m_L.append(m)\n",
    "        self.W_fixed.append(m_L)\n",
    "        # Hidden layer: gradients\n",
    "        grad_L = []\n",
    "        for _ in range(L):\n",
    "            grad_L.append({key: np.zeros_like(val) for key, val in self.model[1][0].items()})\n",
    "        self.grads.append(grad_L)\n",
    "        # Previous output layer\n",
    "        ys_prev_L = []\n",
    "        for _ in range(L):\n",
    "            ys_prev_L.append(0.0)\n",
    "        self.ys_prev.append(ys_prev_L)\n",
    "        \n",
    "        # Output layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, C)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Outout layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[2].items()})\n",
    "        # Previous output layer\n",
    "        self.ys_prev.append(0.0)\n",
    "        \n",
    "    def fc_forward(self, X, W, b):\n",
    "        out = (X @ W) + b\n",
    "        cache = (W, X)\n",
    "        return out, cache\n",
    "\n",
    "    def fc_backward(self, dout, cache, W_fixed):\n",
    "        W, X = cache\n",
    "\n",
    "        dW = X.T @ dout\n",
    "        db = np.sum(dout, axis=0).reshape(1, -1) # db_1xn\n",
    "        \n",
    "        # dX = dout @ W.T # Backprop\n",
    "        dX = dout @ W_fixed.T # fb alignment\n",
    "\n",
    "        return dX, dW, db\n",
    "\n",
    "    def train_forward(self, X, train):\n",
    "        caches, ys = [], []\n",
    "        \n",
    "        # Input layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[0]['W'], b=self.model[0]['b']) # X_1xD, y_1xc\n",
    "#         y, _ = l.selu_forward(X=y)\n",
    "#         y = l.elu_fwd(X=y)\n",
    "        y = l.sigmoid(X=y)\n",
    "        if train:\n",
    "            caches.append(fc_cache)\n",
    "        ys.append(y) # ys[0]\n",
    "        X = y.copy() # pass to the next layer\n",
    "        \n",
    "        # Hidden layers\n",
    "        fc_caches, ys_L, do_caches = [], [], []\n",
    "        for layer in range(self.L):\n",
    "            y, fc_cache = self.fc_forward(X=X, W=self.model[1][layer]['W'], b=self.model[1][layer]['b'])\n",
    "#             y, _ = l.selu_forward(X=y)\n",
    "#             y = l.elu_fwd(X=y)\n",
    "            y = l.sigmoid(X=y)\n",
    "            fc_caches.append(fc_cache)\n",
    "            ys_L.append(y) # ys[1][layer]\n",
    "            X = y.copy() # pass to next layer\n",
    "        if train:\n",
    "            caches.append(fc_caches) # caches[1]\n",
    "        ys.append(ys_L) # ys[1]            \n",
    "        \n",
    "        # Output layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[2]['W'], b=self.model[2]['b'])\n",
    "        if train:\n",
    "            caches.append(fc_cache)\n",
    "        ys.append(y) # ys[2]\n",
    "\n",
    "        return ys, caches # for backpropating the error\n",
    "\n",
    "    def loss_function(self, y, y_train):\n",
    "        \n",
    "        loss = cross_entropy(y, y_train) # softmax is included\n",
    "        dy = dcross_entropy(y, y_train) # dsoftmax is included\n",
    "        \n",
    "        return loss, dy\n",
    "        \n",
    "    def train_backward(self, dy, caches):\n",
    "        grads = self.grads # initialized by Zero in every iteration/epoch\n",
    "        ys, ys_prev = self.ys, self.ys_prev # temporal diff instead of differentiable function\n",
    "        \n",
    "        # Output layer\n",
    "        fc_cache = caches[2]\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[2])\n",
    "        dy = dX.copy()\n",
    "        grads[2]['W'] = dW\n",
    "        grads[2]['b'] = db\n",
    "\n",
    "        # Hidden layer\n",
    "        fc_caches = caches[1]\n",
    "        for layer in reversed(range(self.L)):\n",
    "            dy *= ys[1][layer] - ys_prev[1][layer] # temporal diff instead of differentiable function\n",
    "            dX, dW, db = self.fc_backward(dout=dy, cache=fc_caches[layer], W_fixed=self.W_fixed[1][layer])\n",
    "            dy = dX.copy()\n",
    "            grads[1][layer]['W'] = dW\n",
    "            grads[1][layer]['b'] = db\n",
    "        \n",
    "        # Input layer\n",
    "        fc_cache = caches[0]\n",
    "        dy *= ys[0] - ys_prev[0] # temporal diff instead of differentiable function\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[0])\n",
    "        grads[0]['W'] = dW\n",
    "        grads[0]['b'] = db\n",
    "\n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X):\n",
    "        ys_logit, _ = self.train_forward(X, train=False)\n",
    "        y_logit = ys_logit[2] # last layer\n",
    "        \n",
    "        # if self.mode == 'classification':\n",
    "        y_prob = l.softmax(y_logit) # for accuracy == acc\n",
    "        y_pred = np.argmax(y_prob, axis=1) # for loss ==err\n",
    "        \n",
    "        return y_pred, y_logit\n",
    "        \n",
    "    def get_minibatch(self, X, y, minibatch_size, shuffle):\n",
    "        minibatches = []\n",
    "\n",
    "        if shuffle:\n",
    "            X, y = skshuffle(X, y)\n",
    "\n",
    "        for i in range(0, X.shape[0], minibatch_size):\n",
    "            X_mini = X[i:i + minibatch_size]\n",
    "            y_mini = y[i:i + minibatch_size]\n",
    "            minibatches.append((X_mini, y_mini))\n",
    "\n",
    "        return minibatches\n",
    "\n",
    "    def sgd(self, train_set, val_set, alpha, mb_size, n_iter, print_after):\n",
    "        X_train, y_train = train_set\n",
    "        X_val, y_val = val_set\n",
    "\n",
    "        # Epochs\n",
    "        for iter in range(1, n_iter + 1):\n",
    "\n",
    "            # Minibatches\n",
    "            minibatches = self.get_minibatch(X_train, y_train, mb_size, shuffle=True)\n",
    "            idx = np.random.randint(0, len(minibatches))\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            \n",
    "            # Train the model\n",
    "            self.ys, caches = self.train_forward(X_mini, train=True)\n",
    "            loss, dy = self.loss_function(self.ys[2], y_mini)\n",
    "            _, grads = self.train_backward(dy, caches) # self.ys_prev is used here for dfunc/ diff\n",
    "            self.ys_prev = self.ys # for next iteration or epoch\n",
    "            self.losses['train'].append(loss)\n",
    "            \n",
    "            # Update the model for input layer\n",
    "            for key in grads[0].keys():\n",
    "                self.model[0][key] -= alpha * grads[0][key]\n",
    "\n",
    "            # Update the model for the hidden layers\n",
    "            for layer in range(self.L):\n",
    "                for key in grads[1][layer].keys():\n",
    "                    self.model[1][layer][key] -= alpha * grads[1][layer][key]\n",
    "\n",
    "            # Update the model for output layer\n",
    "            for key in grads[2].keys():\n",
    "                self.model[2][key] -= alpha * grads[2][key]\n",
    "                \n",
    "            # Validate the updated model\n",
    "            y_pred, y_logit = self.test(X_val)\n",
    "            valid_loss, _ = self.loss_function(y_logit, y_val) # softmax is included in entropy loss function\n",
    "            self.losses['valid'].append(valid_loss)\n",
    "            valid_acc = np.mean(y_pred == y_val) # confusion matrix\n",
    "            self.losses['valid_acc'].append(valid_acc)\n",
    "            \n",
    "            # Print the model info: loss & accuracy or err & acc\n",
    "            if iter % print_after == 0:\n",
    "                print('Iter-{} train loss: {:.4f} valid loss: {:.4f}, valid accuracy: {:.4f}'.format(\n",
    "                    iter, loss, valid_loss, valid_acc))\n",
    "\n",
    "        # Test the final model\n",
    "        y_pred, y_logit = nn.test(X_test)\n",
    "        loss, _ = self.loss_function(y_logit, y_test) # softmax is included in entropy loss function\n",
    "        acc = np.mean(y_pred == y_test)\n",
    "        print('Last iteration - Test accuracy mean: {:.4f}, std: {:.4f}, loss: {:.4f}'.format(\n",
    "            acc.mean(), acc.std(), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-100 train loss: 2.3046 valid loss: 2.3789, valid accuracy: 0.0924\n",
      "Iter-200 train loss: 2.3562 valid loss: 2.3674, valid accuracy: 0.0924\n",
      "Iter-300 train loss: 2.2661 valid loss: 2.3570, valid accuracy: 0.0924\n",
      "Iter-400 train loss: 2.3218 valid loss: 2.3486, valid accuracy: 0.0924\n",
      "Iter-500 train loss: 2.3462 valid loss: 2.3411, valid accuracy: 0.0924\n",
      "Iter-600 train loss: 2.3094 valid loss: 2.3347, valid accuracy: 0.0924\n",
      "Iter-700 train loss: 2.3516 valid loss: 2.3292, valid accuracy: 0.0924\n",
      "Iter-800 train loss: 2.2686 valid loss: 2.3249, valid accuracy: 0.0924\n",
      "Iter-900 train loss: 2.3181 valid loss: 2.3210, valid accuracy: 0.0924\n",
      "Iter-1000 train loss: 2.3839 valid loss: 2.3179, valid accuracy: 0.0934\n",
      "Iter-1100 train loss: 2.3392 valid loss: 2.3155, valid accuracy: 0.0938\n",
      "Iter-1200 train loss: 2.3025 valid loss: 2.3129, valid accuracy: 0.0986\n",
      "Iter-1300 train loss: 2.2937 valid loss: 2.3111, valid accuracy: 0.0986\n",
      "Iter-1400 train loss: 2.3059 valid loss: 2.3097, valid accuracy: 0.0986\n",
      "Iter-1500 train loss: 2.2994 valid loss: 2.3082, valid accuracy: 0.0986\n",
      "Iter-1600 train loss: 2.3197 valid loss: 2.3068, valid accuracy: 0.0986\n",
      "Iter-1700 train loss: 2.2978 valid loss: 2.3060, valid accuracy: 0.0986\n",
      "Iter-1800 train loss: 2.2980 valid loss: 2.3052, valid accuracy: 0.1126\n",
      "Iter-1900 train loss: 2.3176 valid loss: 2.3045, valid accuracy: 0.1126\n",
      "Iter-2000 train loss: 2.2978 valid loss: 2.3041, valid accuracy: 0.1126\n",
      "Iter-2100 train loss: 2.2950 valid loss: 2.3035, valid accuracy: 0.1126\n",
      "Iter-2200 train loss: 2.2850 valid loss: 2.3030, valid accuracy: 0.1126\n",
      "Iter-2300 train loss: 2.3022 valid loss: 2.3027, valid accuracy: 0.1126\n",
      "Iter-2400 train loss: 2.2955 valid loss: 2.3024, valid accuracy: 0.1126\n",
      "Iter-2500 train loss: 2.3010 valid loss: 2.3024, valid accuracy: 0.1126\n",
      "Iter-2600 train loss: 2.3020 valid loss: 2.3021, valid accuracy: 0.1126\n",
      "Iter-2700 train loss: 2.2973 valid loss: 2.3019, valid accuracy: 0.1126\n",
      "Iter-2800 train loss: 2.2983 valid loss: 2.3017, valid accuracy: 0.1126\n",
      "Iter-2900 train loss: 2.3228 valid loss: 2.3016, valid accuracy: 0.1126\n",
      "Iter-3000 train loss: 2.3020 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-3100 train loss: 2.2921 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-3200 train loss: 2.3035 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-3300 train loss: 2.2837 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-3400 train loss: 2.2974 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-3500 train loss: 2.3124 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3600 train loss: 2.2970 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3700 train loss: 2.3047 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3800 train loss: 2.2906 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-3900 train loss: 2.3011 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-4000 train loss: 2.3059 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-4100 train loss: 2.2918 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-4200 train loss: 2.2957 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-4300 train loss: 2.2991 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-4400 train loss: 2.2946 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-4500 train loss: 2.2907 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-4600 train loss: 2.2875 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-4700 train loss: 2.3033 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-4800 train loss: 2.3060 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-4900 train loss: 2.3010 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5000 train loss: 2.3084 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5100 train loss: 2.2904 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5200 train loss: 2.3117 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5300 train loss: 2.3068 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5400 train loss: 2.3080 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5500 train loss: 2.3077 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5600 train loss: 2.2923 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5700 train loss: 2.2930 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5800 train loss: 2.2952 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5900 train loss: 2.3050 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-6000 train loss: 2.3001 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-6100 train loss: 2.2909 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-6200 train loss: 2.2995 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6300 train loss: 2.3039 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6400 train loss: 2.3031 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6500 train loss: 2.3029 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-6600 train loss: 2.3139 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6700 train loss: 2.3072 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6800 train loss: 2.3013 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6900 train loss: 2.2994 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7000 train loss: 2.3145 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7100 train loss: 2.3065 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7200 train loss: 2.2966 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7300 train loss: 2.3127 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7400 train loss: 2.3048 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7500 train loss: 2.3069 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7600 train loss: 2.2980 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7700 train loss: 2.3001 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7800 train loss: 2.3018 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-7900 train loss: 2.2971 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8000 train loss: 2.2841 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8100 train loss: 2.2936 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8200 train loss: 2.2951 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8300 train loss: 2.3000 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8400 train loss: 2.3007 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8500 train loss: 2.2931 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8600 train loss: 2.3104 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8700 train loss: 2.2994 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8800 train loss: 2.3005 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8900 train loss: 2.2992 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9000 train loss: 2.3082 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9100 train loss: 2.2893 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-9200 train loss: 2.2890 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9300 train loss: 2.2917 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9400 train loss: 2.3099 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-9500 train loss: 2.3035 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-9600 train loss: 2.3035 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-9700 train loss: 2.3031 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-9800 train loss: 2.3033 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-9900 train loss: 2.2944 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-10000 train loss: 2.3165 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Last iteration - Test accuracy mean: 0.1135, std: 0.0000, loss: 2.3008\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "n_iter = 10000 # number of epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "mb_size = 50 # 2**10==1024 # width, timestep for sequential data or minibatch size\n",
    "print_after = 100 # n_iter//10 # print loss for train, valid, and test\n",
    "num_hidden_units = 32 # number of kernels/ filters in each layer\n",
    "num_input_units = X_train.shape[1] # noise added at the input lavel as input noise we can use dX or for more improvement\n",
    "num_output_units = y_train.max() + 1 # number of classes in this classification problem\n",
    "num_layers = 2 # depth \n",
    "\n",
    "# Build the model/NN and learn it: running session.\n",
    "nn = FFNN(C=num_output_units, D=num_input_units, H=num_hidden_units, L=num_layers)\n",
    "\n",
    "nn.sgd(train_set=(X_train, y_train), val_set=(X_val, y_val), mb_size=mb_size, alpha=alpha, \n",
    "           n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XeYFFW6+PHvO4kgMCKwRAUFzAkFFgQF1wAGMCOimF1z\n/Cmy7LrClb3CveqqK67iCipgwoirXDOuqIgJRRgFUYIEJQiSZIaZ9/fH6ZqqTtM9M93TPTPv53nq\n6apTp6pOVXfXW+dUElXFGGOMCcrJdAGMMcZkHwsOxhhjolhwMMYYE8WCgzHGmCgWHIwxxkSx4GCM\nMSZKwuAgIh1E5B0RWSAi80Xkuhh5+onIRhH5PNT9JTBuoIh8IyKLROTWVK+AMcaY1JNE9zmISBug\njarOE5EmwGfAKar6TSBPP+D/qergiGlzgEXAMcAq4BNgaHBaY4wx2SdhzUFV16jqvFD/FqAIaB8j\nq8RI6wksVtVlqloCPA2cUo3yGmOMqQGVOucgIp2AQ4GPY4zuLSLzRORVEdk/lNYeWBHI8yOxA4sx\nxpgskpdsxlCT0nPA9aEaRNBnwB6quk1ETgBeAvZOXTGNMcbUpKSCg4jk4QLDFFV9OXJ8MFio6kwR\neVBEdgNWAnsEsnYIpcVahj3kyRhjKklVYzXpV1uyzUqTgIWqel+skSLSOtDfE3eiewPuBHQXEeko\nIgXAUGBG/MUoqtbdfvvtGS9DNnS2HWxb2LaouEunhDUHEekDnAvMF5EvAAVGAR0BVdWJwJkiciVQ\nAmwHzsaNLBWRa4A3cIHoUVUtSsuaGGOMSZmEwUFVPwByE+SZAEyIM+7/gH2qVDpjjDEZYXdIZ6H+\n/ftnughZwbaDz7aFz7ZFzUh4E1xNcSeklXjFefBB6N8f9t8/9nhjjKlvRARN0wnpWhMcROD88+Hx\nx2u2XMbUN506dWLZsmWZLoYJ6NixI0uXLo1KT2dwSPo+h5q2dSv07AkLFmS6JMbUL8uWLUv7lTCm\nckTSsv+vUNaec1izBhYuzHQpjDGmfsq64DBnDnGblowxxtSMrAsOvXtDkd0JYYwxGZV1wQGgtDTT\nJTDG1HVlZWU0bdqUH3/8sdLTLlmyhJycrNx9pkytWjtrbjKm/mratCnNmjWjWbNm5Obm0rhx4/K0\np556qtLzy8nJYfPmzXTo0KFK5cnESeKalLVXKxljTNDmzZvL+/faay8effRRjj766Lj5S0tLyc2t\n8OEOpgJZWXOo4wHZGFNNsR48d9tttzF06FCGDRtGYWEh06ZNY86cOfTu3ZvmzZvTvn17rr/+ekpD\n7dalpaXk5OSwfPlyAIYPH87111/PiSeeSLNmzejTp0/S93usXLmSQYMG0aJFC/bZZx8mT55cPu7j\njz/m8MMPp7CwkLZt23Lrre5tydu3b+fcc8+lZcuWNG/enF69erFhw4ZUbJ6UyMrgABYgjDGV99JL\nL3HeeeexadMmzj77bPLz87n//vvZsGEDH3zwAa+//joPP/xwef7IpqGnnnqKv/3tb/zyyy/svvvu\n3HbbbUkt9+yzz6Zz586sWbOGp59+mhEjRvD+++8DcO211zJixAg2bdrEd999x5lnngnA5MmT2b59\nO6tWrWLDhg08+OCDNGzYMEVbovqyMjhUdJe0MSazRFLTpUPfvn058cQTAWjQoAGHH344PXr0QETo\n1KkTl112Ge+99155/sjax5lnnkm3bt3Izc3l3HPPZd68eQmX+cMPP/DJJ58wbtw48vPz6datGxdd\ndBFTpkwBoKCggMWLF7NhwwZ22WUXevToAUB+fj7r1q1j0aJFiAiHHXYYjRs3TtWmqLasDA5gJ5+N\nyVaqqenSYffddw8b/vbbbzn55JNp27YthYWF3H777axbty7u9G3atCnvb9y4MVu2RL70Mtrq1atp\n2bJl2FF/x44dWbnSvdds8uTJLFiwgH322YdevXoxc+ZMAC688EKOPfZYhgwZwu67786oUaMoKyur\n1PqmU1YGB6shGGOqIrKZ6PLLL+eggw7i+++/Z9OmTYwZMybljwZp164d69atY/v27eVpy5cvp337\n9gB07dqVp556irVr13LTTTdxxhlnUFxcTH5+Pn/9619ZuHAhs2fP5oUXXmDatGkpLVt1ZGVw2LYt\ndrrVJowxlbF582YKCwtp1KgRRUVFYecbqssLMp06daJ79+6MGjWK4uJi5s2bx+TJkxk+fDgAU6dO\nZf369QA0a9aMnJwccnJyePfdd1mwYAGqSpMmTcjPz8+qeyeypyQBEydCly6ZLoUxJlsle4/B3Xff\nzWOPPUazZs248sorGTp0aNz5VPa+hWD+Z555hkWLFtGmTRuGDBnCuHHjOPLIIwF47bXX2G+//Sgs\nLGTEiBE8++yz5OXlsWrVKk4//XQKCws56KCDOP744xk2bFilypBOWffIboCLL4ZJk1y6VzwRGD4c\nnngiQwU0pp4IPQY608UwAfG+k3Q+sjsraw7GGGMyKyuDgx20GGNMZmVlcDDGGJNZWRkc7FJWY4zJ\nrKwMDiUlmS6BMcbUb1kZHEJ3nRtjjMmQrAwOQY0bw88/Z7oUxhhTv2R9cNi+HZJ8aq4xxpgUyfrg\nYIwxqbBs2TJycnLKH2534oknlj85NVHeSHvuuSfvvPNO2sqaDSw4GGNqhRNOOIHRo0dHpb/88su0\nbds2qSeaBh958dprr5U//yhR3vooYXAQkQ4i8o6ILBCR+SJyXQV5e4hIiYicHkhbKiJfisgXIjK3\nOoW1m+OMqb8uuOACpk6dGpU+depUhg8fnlUPrasLktmaO4GbVPUAoDdwtYjsG5lJRHKAccDrEaPK\ngP6q2k1Ve1a3wMaY+unUU09l/fr1zJ49uzxt48aN/Pvf/+b8888HXG3gsMMOo7CwkI4dOzJmzJi4\n8zv66KOZFHqIW1lZGTfffDOtWrWiS5cuvPrqq0mXq7i4mBtuuIH27dvToUMHbrzxRkpC1+OvX7+e\nQYMG0bx5c1q0aEG/fv3Kpxs/fjwdOnSgWbNm7Lfffrz77ruV2h7plpcog6quAdaE+reISBHQHvgm\nIuu1wHNAj4h0IUXNV/W8lmdMvdawYUPOOussnnjiCfr27Qu4p6Hut99+HHjggQA0adKEKVOmcMAB\nB/D1119z3HHH0a1bNwYPHlzhvCdOnMhrr73Gl19+SePGjTn99NMrzB80duxY5s6dy1dffQXA4MGD\nGTt2LGPGjOHuu+9m9913Z/369agqc+bMAWDRokVMmDCBzz77jNatW7N8+fLyd1tni4TBIUhEOgGH\nAh9HpLcDTlXVo0UksnagwJsiUgpMVNVHql5cY0ymyZjUHKXp7ZVvJ77gggs4+eSTeeCBBygoKGDK\nlClccMEF5eOPOuqo8v4DDzyQoUOH8t577yUMDtOnT+eGG26gXbt2APzpT38Ke51oRZ588kkmTJhA\nixYtALj99tu54oorGDNmDPn5+axevZoffviBzp0706dPHwByc3MpLi7m66+/pkWLFuyxxx6V2g41\nIengICJNcDWD61U18t159wK3BrMH+vuo6moRaYULEkWqOptKsBqDMdmjKjv1VOnTpw+tWrXipZde\nonv37nzyySe8+OKL5ePnzp3LyJEj+frrrykuLqa4uJizzjor4XxXrVoV9orRjh07Jl2mVatWhe3c\nO3bsyKpVqwC45ZZbGD16NMcffzwiwmWXXcatt95K586duffeexk9ejQLFy5kwIAB3H333bRt2zbp\n5aZbUs09IpKHCwxTVPXlGFm6A0+LyA/AmcAEERkMoKqrQ59rgReBCs47jA50s8pTI09E//WvsHFj\nMiU3xtQ1w4cP5/HHH2fq1KkMGDCAVq1alY8bNmwYp556KitXrmTjxo1cfvnlSb2bom3btqxYsaJ8\neFklbq5q165dWP5ly5aV10CaNGnCXXfdxZIlS5gxYwb33HNP+bmFoUOH8v7775dPO3LkyITLmjVr\nFqNHjy7v0inZmsMkYKGq3hdrpKru5fWLyGTgFVWdISKNgZzQuYpdgOOB+GeIGF1hIbzv+I47oFs3\nOO20JEtvjKkzzj//fMaOHcv8+fP5+9//HjZuy5YtNG/enPz8fObOncuTTz7JgAEDysfHCxRDhgzh\n/vvv56STTqJx48aMHz8+6fKcc845jB07lu7duwNwxx13lF8i++qrr7LvvvvSuXNnmjZtSl5eHjk5\nOSxatIiVK1fSp08fCgoKaNSoUVKX4vbv35/+/fuXD1d0wr26krmUtQ9wLvCH0OWon4vIQBG5XET+\nGGOS4NZvDcwWkS+AObig8UZKSm6MqZc6duzIEUccwbZt26LOJTz44IPcdtttFBYWMnbsWM4+++yw\n8fFeC3rZZZcxYMAADjnkELp3784ZZ5xRYRmC0/7lL3+he/fuHHzwweXT//nPfwZg8eLFHHvssTRt\n2pQ+ffpw9dVX069fP3bs2MHIkSNp1aoV7dq1Y+3atdx5551V3ibpkJWvCY00dy707AnnneceyicC\nL7xgNQdj0sFeE5p97DWhxhhjsoIFB2OMMVFqRXDwmvfsklZjjKkZtSI4xGKBwhhj0qdWBAfvPIyd\nIzPGmJpRK4JDPMXF0KsXrFmT6ZIYY0zdUqlnK2XKxx9Hp334oX8p65dfQps2NVsmY+qqjh071vt3\nGWSbyjzOI1VqRXC49trotJUra74cxtQHS5cuzXQRTBaotc1KdmBjjDHpU2uDgzHGmPSpE8HBahHG\nGJNadSI4GGOMSa06ERzs/gdjjEmtOhEcjDHGpJYFB2OMMVFqXXC45x73GTwJbSekjTEmtWpdcHj/\n/UyXwBhj6r5aFRyCJ57tJLQxxqRPrQoO4AeFV18NT3/oIfj885ovjzHG1EW1Ljh4Nm4MH77ySrj9\n9syUxRhj6ppaFRzsxLMxxtSMWvFUVs/UqZkugTHG1A+1quZgjDGmZtSJ4GDNTcYYk1p1Ijh4LEgY\nY0xq1Ing4F3e+umnmS2HMcbUFXUiOHhWr850CYwxpm6oE8GhorulmzaFjz+uubIYY0xdUCeCw8CB\nfv+2beHjtmxxzU3dusGDD9ZsuYwxprZKGBxEpIOIvCMiC0RkvohcV0HeHiJSIiKnB9IGisg3IrJI\nRG5NVcHj2bAhdvq8eTBzZrqXbowxdUMyNYedwE2qegDQG7haRPaNzCQiOcA44PWItAeAAcABwDmx\npk0leyCfMcZUX8LgoKprVHVeqH8LUAS0j5H1WuA54OdAWk9gsaouU9US4GnglGqXugJlZemcuzHG\n1A+VOucgIp2AQ4GPI9LbAaeq6j+B4N0G7YEVgeEfiR1YUsZqDsYYU31JP1tJRJrgagbXh2oQQfcC\nKTifMDrQ3z/UVc4//gF/+xs0bAjvvVf9EhljTLaYNWsWs2bNqpFliSZxqC0iecC/gZmqel+M8d97\nvUBLYCvwR1wT02hVHRjKNxJQVR0fYx4KqTnsnzUL+vXz75ieMAGuvhpOPhleeSUlizDGmIwTEVQ1\nLc+GSLbmMAlYGCswAKjqXl6/iEwGXlHVGSKSC3QRkY7AamAocE41y2yMMSbNEgYHEekDnAvMF5Ev\ncIf3o4COuFrAxIhJyg//VbVURK4B3sCd33hUVYtSVXhjjDHpkTA4qOoHQG6yM1TViyOG/w/Yp/JF\nSx2v5UwEliyBvfayh/QZY0xF6sQd0pXRpQu8+WamS2GMMdmt3gUHgK1bM10CY4zJbvUiOHhNSF7z\nkt0LYYwxFcuu4NDwl0yXwBhjDNkWHPZ6KyWzufpqKC6OTt++vfLz2rnTTl4bY+qf7AoOBz6dktks\nWAANGkSnv/125edVUlL98hhjTG2TXcFhr7egwaa0LybWOYcvvrCXAhljjCe7gsPS/rDvyxlZdN++\n0KtXRhZtjDFZJ7uCw9dD4cCn0jb7yKuWguwKJmOM8WVXcPh2MOz+ITRel9bFeOcRNmywcwrGGBNL\ndgWHkl1gWT/o/HrivNVw443us0ULGDHC9VvNwRhjfNkVHAC+Ohe6TUrLrL1mpZ9+8tOWL0/Loowx\nplbLvuDwzWnwu6+hxaJMl8QYY+qt7AsOpQUw70I4PPJJ4FVX0YloY4wx0bIvOAB8fhkc8gTk/Za2\nRcye7T5V4Z134Lc4i7K7o40x9VF2BocNXWDNIbDfCymdbbDm8NFHfv/LFdxaYbUNY0x9lJ3BAeDT\nK+DwhzNdCmOMqZeyNzgsGgSt50PTlWlflNUOjDEmXPYGh9ICWHgmdJtc7VnFermPd39DonMKds7B\nGFMfZW9wAJh7tWtaytlZrdksXRp/nNUajDEmWnYHh58OgU0dYZ8Z1ZrNhAkVj4/17gePBQ9jTH2U\n3cEBXO2hR4K9ezUtinO/3aefwjXXuP73309rEYwxJqtkf3AoOgNaLYSWRTW+6MmTYVLoSR5HHVXj\nizfGmIzJ/uBQWgCfXwo901d7sKYjY4wJl/3BAeCzy+GgJ6HhxpTP+sUXYdaslM/WGGNqtdoRHH7t\nAN8NgIOnpH1RRx4JO6t3cZQxxtR6tSM4AMy9Bo64O63PWwL3zKXt29O6CGOMyXq1Jzis6OOet5Tm\nK5cAfv01uXznnQePP57eshhjTCYkDA4i0kFE3hGRBSIyX0Sui5FnsIh8KSJfiMhcEekTGLc0OK5a\npX1rHPQdB402VGs2iXTokFy+adP8q5mMMaYuSabmsBO4SVUPAHoDV4vIvhF53lLVQ1S1G3AJ8K/A\nuDKgv6p2U9We1Srtuv2g6HToe2e1ZpMs77Heno0xzofb4zWMMXVRwuCgqmtUdV6ofwtQBLSPyLMt\nMNgEFxA8ksxykjZrjHuN6K5LUzbLeL76Kny4efPoPBYcjDF1UaV22iLSCTgU+DjGuFNFpAh4Bbg4\nMEqBN0XkExG5rOpFDdnSBuZeC3/4S7VnlQoWHIwxdVFeshlFpAnwHHB9qAYRRlVfAl4Skb7AWOC4\n0Kg+qrpaRFrhgkSRqs6OnN4ZHejvH+pi+PBmuLare9f0zwcmuwqVEm+nLxJ+05wFB2NMTZk1axaz\naujGLNEkbg8WkTzg38BMVb0vifxLgB6quiEi/XZgs6reE2MadZWMJB01Flp8Cy+m/96HSKruMeBN\nmsAxx8Bbb9V4EYwxBhFBVdNyiJpss9IkYGG8wCAinQP9hwEFqrpBRBqHahyIyC7A8cDX1Syz8/G1\n0HWme+5SDXvnHXjpJddvNQdjTF2UsFkpdFnqucB8EfkCd3g/CugIqKpOBM4QkfOBYmA7MCQ0eWvg\nRVcrIA+YpqpvpKTkOwrh3TEw6I8w+T+gNXfLxjHHQO/eNbY4Y4ypcUk1K9WESjcrAUgZXNwXvjzf\nvXO6BvXuDR99BMcdB2/ECHerV0O7dvZQP2NM+mRDs1J20hx4ZSIcfRs0XVWji/aak+I1K/38c82V\nxRhjUq12BwdwVyt9egWccG1GFh8ZHE45xT3p1RhjarPaHxwA3v+zu6x135dqbJHxagwzZsDpp9uJ\namNM7VY3gsPOhq556YRroUGST82rJm/n/+absGRJjSzSGGNqTN0IDgDL+sF3A2HgDVT6xHYVeM9d\nKiuDLl2ixwdrDj/9FP0oDmOMyWZ1JzgAvHEXtPsEejxY44seMAAuv9wfDl6lNGwYHHJIjRfJGGOq\nLOnHZ9QKOwrh6Zfg0l6wqgesrN5DYCvjjTegVSt/ONjUtGNHjRXDGGNSom7VHAB+6QwzHoWzT4Om\nK2t00fGeufTBB7Hzf/013HZbestkjDFVUfeCA8C3g91rRc8ZDPlba2yxiR7Id+yx4cMPPwxjx6a3\nTMYYUxV1MzgAzB7p7oE4fThIaY0vPlZwePvtxHmMMSYb1N3ggLjLWxuvhX7/VSNLDL57uqIdfzLv\nqBaBdeuqXyZjjKmKOhwcgNIGMH06HDwNjvxb2hdXUuL3X3pp/HyFhfDuu7HH/fabuzwW/BPcGzbA\nP/+ZmjKa7LFjh/tujclGdTs4gHtz3KTZcNBTcOxIauIeCPCfrVRcHJ4+fnz4+KCdO6FRIxg9Ojz9\nqafgqqtSXkSTYddfDy1aZLoUJpVGjYIff4xOf/NNGDGi5stTHXU/OIALEJPfgz3fgZOvpKYCBITf\n+wAwcqT7LCvzm55Whi6q8pqbiopiz2vRotSXL571610tpiL/+Q8880zNlKcuWrYs0yUwqXbnnfDc\nc9Hp994L//u/0ekisYNJNqgfwQFgewt4/G3Y/UN3F3VuceJpUuD772OnBx+7ccop7tO72inWjwtg\nn30qXtawYdCvX+XLGEvLlnDeeRXn6dcPhg5NzfJM9nj5Zf+AJVJhYfh9O6l+dMwPP6T/Qg1VuO66\n1M1v7Vr3ZkiP1ywcucx4Vq+ueP6bNiXOkxaqmhUdoG4TprlruEE5Z5BySS+lcFnNLDOJ7owzVN9/\nP/a4ww7z+3fZRfXtt1VLSzXKrru6PFUBqgsXhg+D6ty5FU9T1eXVJ889p3ruudHpAwdm5/YD1Ysv\njj9u7VrXv2NH1cr/00+qs2bFHvfuu26e69apjh5d+Xkn47ffosu9Zo1qWZnrX7ZMdcmS5OcHqied\n5PfH2iZHHx07HVQ//rji+ffrF387u114evbJ9afm4PmtubuL+pvT4LKe0OX/Ml0iAJ5/Hm6+Ofa4\nzz/3+7dudW+ie+CB6Hxaidaybdtcdfa55/yXFcVqtnowzpNI4tWIUmn6dHj//cT5SkszdGSVpEcf\nhWnT/OGdO6FZs8qVubgYZs6MPocF7ntbsSL+tFW5Q7+io3fvd+Z9enlVYc2a8Lxdu0Zfwn3DDdC/\nv2tW27499jJeey363Fsiqm4b3XknjBsHd92VOL+nTRt4/XXXf/jh0LmzP+7XXxOf84tX0/LEuwAl\nlsiayKpVsZexfHny86ySdEWdynbUVM0h2HV8T7mpvXLCNUqTVRmvPVSmu/FGd+Tw9NOqc+b4RyGg\nesUV7uhuwgT/COPZZ1VPOEF1xQo3fNFFfv5Wrfx+/4jE7y67zKVt3qzaqFH0+Ipcd53qPfeoTpxY\ncT7Pb7+Fl6FLl/h5Fy5U3bpV9e9/d3lLS10NLNuccEL4dnrzzfDt9/jjibfjk0+6PHvs4acVF/vz\n6Ngx/rSRtcJEvO980CDVoqLocY884o6yvSNwr+xvvx29HqD65z/7w2Vlqt26+dMNHhxeO/VqDlOm\nJN4mkZ5/Pny75uXFzrd9u/97UfXXY9o0v8zBZb/zjhv+4YfoMpWWurRDD409raeidO//G0w77TR/\nuEuX6Omfe85LQzXG/jQVXVpmWqWCZCI4oErjtcqJVyv/r43S5bWM7/ST7bp2jf7Rxcrn2WsvP23V\nqvCmqtato6eJNZ+lS2OP37ZNtaTEpR96qGsSCP7Q4/0xIr3wgp/vyivD1zMWb74jRrjPJUvcp9c8\nEGnHDtU771S94ILEZUklLziA6tlnq772WsXfVdCqVapHHunvLIP5tmwJ/w7jAdX//Cc8bf362HmP\nOsrl/+Mf3ed990XPC1Q/+SQ6ODz7rOv/6qvw/KNGuf4GDcLXI9a6ezviZH8zQccfHz6tFxx++y38\noGHrVjfe+816+eMFhyFD3LBXtqCWLWOvz8knRx+0xVofCA8Offq4tB49/LTgfxdU//QnF7jdMKpq\nwSG93Z5vKdd3Us46U2m2PLNlSbIL/vCGD0+cJ17Xtm3iaVRVX3wx/vhrr1WdN8/1f/ihy/P999Hz\niCd4vkVV9aCD/OG99449Tbx1X7bMjS8rU736alezWLVKNT+/4rJceaVrG06VrVvdp3duweu8NuRY\n21hVdepUV97t21WvusqNixUcvJ0cqLZo4S8vErjt+8orqscc408zeXLso1ZwtU9Qvfdel/7666o7\nd4aX1zsCB3f0/8gj/vAtt6h++63rv+QSF4zA39FGdrfe6g4yIoPDyy+7nXbwwCGeeNvU+x16Nm92\nwzt2qN5xh5/3yivdb8Yb/v57VwP3hhs1Cp/PN98k/m8F5xdZ/iOPdGnB7yBW3j33rGgZqKoFh/R3\neduU/rcrI3ZTTrpSaVmU+TJV0AWbFeJ1o0dXfr6x/mjBtFjjjzvO7z/zzPjzjbRwoTsZ6O0EvXwH\nHljxtJE7qshu+fLE66jqmuVWr3b97dpFr9/atarnnef/gefOVX344djrMmOG2xls3OjXDlSjg0O8\nrqjIb1YZMUJ10qTY+WbMcPMNBoeKtjHEv9ihd+/ovOBqOF7/F1+4z5Ejw6ddubLi9RkwwO8vLEy8\n/p9+Gr7cRL+hTZtilz3Y3XST3xy0ZYs/HYTXfLxu8eLk/h+q4c1j8Tqv2cnrJkxQPeKI+PMMps2b\nl3h7WHCo6a5wmQsSt7RUBtzgrnDKdJlqsIv1R/OaecBvPqjKfJctU/3sM/cn9HaEkV1ZmapIdPo/\n/+l21rH+1JHdRx9VPN5rbwbVm292yywocMPBo/Q33nCfw4aFb5dI++8fe9uUlSUfHILdqaeGH4lH\ndpHt6163bZtq48aqH3ygOn26n96/f+z8hx+eeAcbr+vRI7W/uw8/TO43NH++ax70hgcNUv3yy9j5\nu3Z1QRdU9903fB1jbd/PP09chhtvdOfQOnRInHfq1PDh5s1j5/vDH6K3f2QzWewOCw4Z6Xb5STn5\nj8pN7ZQ+45SGv2S+TDXQVXYnkWw3Z05q5pOTkziPd1lvvG78eD/I3HKLf8I3snvoIb/fu3TT64In\na720Sy7J7Hc3d677zMtLfprJk/2j6cp0wROlqegim5RidZFH0nffXbllRDbzRHZe02kmusiyxQvo\n4R0WHDLatflcOX2YMrKZcuYQZe8ZSu5vmS+XddXqjj3WfY4Y4YJFovxXXx2dtmqVaxrL9Lp4XdOm\nlZ8mVjNHMl3kuarqdsGr5tLV3XNP5r+jeN0vv1RlOtIWHCS0Y844EVFq8LEWVdLwFzjoSTjwaWg9\nHxadDF8PhSXHQ2lBpktnMuD1190rYo2prunT4ayzKjuVoKppuafcgkNV7fITHDDdBYrC5TD/HPhu\nIKw4wj0N1tQLM2fCCSdkuhSm/rLgkN3afg77vgSd34Dm38OCIbCiN/zYGzZ2Aq1/N6IbY2qCBYfa\nY7fFLlDiCxQnAAAYyUlEQVTs/hG0n+uaojZ0hR97uYCx+nBYtw+U5We6pMaYWi+DwUFEOgBPAK2B\nMuARVb0/Is9g4I7Q+BLgRlX9IDRuIHAv7gmwj6rq+DjLqRvBIVLBZmj5Dewx2wWLdp9BsxWwtTVs\n2gM2dIFf9nL9W1rDrx1cbaNkl0yX3BiT9TIbHNoAbVR1nog0AT4DTlHVbwJ5GqvqtlD/QcCzqrqf\niOQAi4BjgFXAJ8DQ4LSBedTN4BBL3m/QdCUUroAWi2DXpS5gNF3t0nddCjuauaCxsROs39sFkd92\nheImfleyi99vJ8SNqYfSFxzyEmVQ1TXAmlD/FhEpAtoD3wTybAtM0gRXgwDoCSxW1WUAIvI0cEpw\n2nppZ0P4pbPrlvaPHi9l0GQN7PoDNP8BWnwLXWdCg1+hYIvr8rf6/QVbAHEBorQAfiuEHYUuwPwW\n+txR6Pp3NnLL/21XKGkMOTthZ4NQnmZQ3BRKGrn5aC7klECDza4GVFrgTraXFgAKOaUgpW4emuOP\nL2kMxbu4z9ICVzZjTK2SMDgEiUgn4FDg4xjjTgXuBFoBJ4WS2wPBhwn/iAsYpiKaA5vbuW5Fn+Sm\nyS12NZLcYhdEGmxynw03uf6GoeG87dB4szs3UrAVSvMD04S6/O0uTcqgLA92NHW1k9wSyN0RelGS\nQFmuG6+5Lm9usRufv83NO38riLpAUVrgglJZvptOcyK6WGk54XkRF6zK8tx8SvND04lbTs7O0PYT\nlz+nNFSm0LqUb1+hPGCVH3QJoC6f5obmFVGT9eZVlh/7IoOYB3Ax0pLNl2xeKQ1fv1TJ2enW1wvy\nOxu55eSUBLapuDLmlrj8OSWh/tAL1b3vtSzX9XufFaV5v6ng/KTML09ucag8DdxvqrSBv51E3W+w\nYKvbLpoT+F3EuTDE+/2V5YW6QL+3DhD43QR+a6UN3MFUWR7k7fD/A96BWs5OV37U/W68Mu9s5Kbz\nyiSB35qUuf9yzs7w7e3970rzQ/NoCK+m5JuOKengEGpSeg64XlW3RI5X1ZeAl0SkLzAWOK7yxRkd\n6O8f6kxSvB8jwLaWmS1LUE6JCxZ5O0I/+NAfPdjllEanSZm/0wt2ZfkRO41S98dS8f/Mon5gKy3w\ngwjgAoD6/V5+j+a4eZblRe9MyvLcziCnJHya4LyCovJUJl8l8no71VTTXLczK9gaOvjYDohLKw+Q\noe1Zmh8K/Hl+P/jfY3ktszRxWs7O0HcQmJ/m+AcFOxuEyhP6TeUGXlgh6naaxbv4By2l+aHtFmc7\nB8uRs9Nffm6Jvw5hvxtCvw9xy8/f7tfAvZp1eRALrYN3YJO3w21Hb7qwMgUOWHY29INk+e+4ALZ+\nDdu/gpxtfoBKk6SCg4jk4QLDFFV9uaK8qjpbRPYSkd2AlcAegdEdQmlxjE6mOKY2KcsPNXFluiDG\n1AVnRgynr8k22QvwJwELVfW+WCNFpHOg/zCgQFU34E5AdxGRjiJSAAwFZlSzzMYYY9IsYc1BRPoA\n5wLzReQLXD1oFNAR91yPicAZInI+UAxsB4bgRpaKyDXAG/iXshalZU2MMcakjN0EZ4wxtVb6LmW1\n5zoYY4yJYsHBmAy57LJMl8CY+Cw4mIz44x8zXYLMGzky0yUwJj4LDrXM7rtnugTxXXhh+PBhh8XP\n2yANTzX/5JPUzzOdOnVKLl/XrjB4cHrKcPjhqZvX3XdXfpr99kvd8qtq6FA45ZTY4667rmrz/O47\nv3/69MT5//Y3v79Vq6otM9UsONQyU6f6/TurcA/MJZdEp7VpE502YgR06FC5eZ98cvhwVa91aN++\n4vETJsRO79Il8bzXr4dZs+COO/y0yy9PumgpU1AAInD11X7aAw+E59lnH/f55ZfwcsTdRWefnZpy\n3Hab+9y8Obn8770Xf9xNNyU3jwUL/PLnVeoZDenRrRsceWTscZX9Dxx5pPvdd+7sp50ZeWsC0DLi\nPtVDD/X7f/4Z5syp3HLTwYJDLZMT+MZyc2HIkPh577zT73/rLfd57rnR+R57LDpt/Hh/55SsM86A\nrVtd//nn+8GhT4wngEjg+opmzcLHPfig3799u/vs1i3x8kX8I9HmzeH556Pz7LYb9OsHf/mLGz7r\nLDjppOh8FUnmbV2bNoUP9+gRfo5hzZrwbQD+Ufz9oWcev/uu+/TyBb+nHj38/qoefXfo4I6YVaFJ\nE+jVy19mz4iH3HTsCJ9/Hr0Tjcz3xBMwapQ/nJsL//Vfrr9rV/e5//7w9NOJy3fAAX7/iSfCf/4T\nP29ODsyenXiesai632vQkCFuJ10ZBxwAxx4bnjZoUHS+nBwoLQ1PizxA+/3v3efee1euDCmV6XdH\n14p3SFeie++96k1/1lnu85RTYo/fuNHv98SbV/Ddxm++6T7fftuVsajIH/f66+7znHNUp0zx5330\n0ZUre7A855+vevDBfvpVV7n+P//ZfV53nT/drruGz2fLlvB5Xnyx6kMPueGjj1Z94IH422b//V3/\npElu2rIy1V9/dWlHHaVhCgpUx41T/fLLxOu2eLH7vPBC1Z9+Sm5bxNs24N4XrBr+XuqPPvLz/vqr\nn/+336Kn37RJ9aKLopcV7M/Lc58HHBC7jB06aEyg2ru3n+9f/1ItKYn9ezvmmOh1VFUtLVV9/33V\n7dtV77/fje/XL3pbHH54dLlmz1bdvNnlWbNG9ZFHVFeujF52sPvxR3/8G28k/u8Eu3Hjouf99dcu\nbeLEir/nyy9XPfvs6PX35jdvXvS8f/c71eOOi/597LZb9PaJzHfSSZFlQFXTs0+2mkMCBx9cufxH\nHVW5/PvuGz4cq5o9dKg72r3lluTmWRZ6BtvvfueOCAH69nWfqq6M++4b3Sx11FFw3nlQUuLnrchp\np8HAgfDss+Hp//3fcMMN8NRT8OabLs2r4Ywd646QBw708wePoFVhl4hXWTz6qGv6OeggdyI7XlVf\n1dUYgkSgaVO45x4YMyZ83I4dcOut/vIrWl+vyWqPPdx2Lf9rxuAdLW7YEH9+iTRt6vcHt88997jP\nZs1czTDYVu7VKr1ytW3r+r1aY/fuyS8/N9d1Xn+85p/I7ypYlr59oWFDuOIKd9QfbEID+Mc/4PTT\n/eFRo+Dii11N0/vdtm4Nl14K7dq54YULYy/La4pUheOO8/8DBx7o5yssjF3WYBOQxzu3d/HFsHRp\ndJOfp2lT9/9Mxocf+v2vxnhg3sKF0c1Jwe/+hx9cs/Iee1Az0hV1KttBdtYczjgjcZ5PPw0/AqjM\n/Bcs8Ptffll17VrXf+qpfu0haPNml/bWW9FHKqqqd93ljpY9y5erfv+9X6433wzPD35t56GHwscN\nGRK7zG3auM/SUpfv2Wejyxnp3Xej84Bqw4bhtRiPV2uJJVgbAFUR97lhg+q6da5/+vSKyxO0fbvq\njTf6ZWrd2q9pgWrfvv64v/41eh0iu5NPDh9fVBSdf9MmN3zNNdG/haB//zt82KtBRQLV3Fx/uGVL\n1QEDwscPGxZezs6dY2+PFi1UR4xQfeEFl++jj8LHN2rkz+OKK6K/u3ieey4634QJyU/vmThRtUkT\nf7qrroqdD1R79lQtLIz+b06e7D6Li8Pzg6t9Rtq5U/WCC/w8L77oPj/80NV04n0nX3zh93/4oas9\nXXhh+PLirTu4mklknj33DE6LqqZpn5yuGVe6IPjB4Q9/iP2ny0SXTHBYvTr8C8zJqTh/y5Z+fzA4\nrF7t/yhOO83tAL3qcpC3s68scFXuyLS5c93nww+Hj9uyRfWDD9y4MWNUjzhCy3fCXrOIanLB4Z13\novOA6u9/7/cHx0c2QcRbn0svdQEQVNevd+lLloQHyMoAV+0PlqlfP384Mji0bRv9/Z50kj/+jjvC\ny3L//aqXXOIPL1qkes89/vDPP1dcvrVrVf/nf6LTL7ssfCe5ZYsLekHbtvnb6tRTXX88FW0/r1lv\nyhS3jMWLVe+7r+Jyq1YcHKqiVy/XdBXPP/7hfneTJvnb2PuOJk2K/XsE1/QaS3Gxn+f558On37gx\nOn+s4BB04IGqe+8df/1Bddq06LJacAj82cI3RuW6Sy+t+rTB4OB9WeCOrIJ51qwJ37kVFYW393vd\nwIHu86mnVPv316jg8NNP/nJOOy32D6Y6wNVyItNWrdKYwUHV7STmzHH9jz3mftCRkgkOH34Y+8/Y\ns6ffL+KPO+qoxPN8//3wtvl16yrOn4zXX/ePlL3vZepUfzgyOKi6cxfB7/nEE6tfjnRq3Dh+zTMZ\nsXasyXjmmejpZs6s2ryq6r773PK8mkNQ5AFKLF4e7/+dKK8XHC6/3D+PEvToo/Hns22b+/9FltXb\nH7ploJqmfXIWXEgWzcWK1Bg8GP71r9TM67PPXHt58+bukkhPZLurdx5hn33g22/99CeecO3VIq6d\nfv161ybrCbYvRl7JkgobN0a3u3rbOicn9hVBIv6VExdc4Lqq6NUL5s8PT/vHP8KvSAlux/Hj3SWc\nFfHOo3hS8bs5/vjw4Ycein2FV9BFF8G2bTBlSurKkU7eFWVVdcIJ7pxSZXXvHn01z8CB/jmumnDd\ndXD99fHHJ3M/yYknJn8VkfdbeOih2OOHDfPPp0Rq1Mh9Ru4LBg2CefOSW351ZGVwiJTsjrJNG3eJ\nYFCsS8mqKtZNXe3b+yfPIkWW2xsWcTe6eDe7rFjhToB548eMif4TpUK8E3IQfWldqomEnxwEuOaa\n+Pl79XJdZWRqp+z98b3gkA03dqVTmzbw979Xfrq99vIvUAjKxL0O3gnroEz8fho2DL84I5YBA+Da\na/3h+2K+OCH1sjI4RH5JyQaH1q2jg0NlnXsuTJuWfP4//cl9Tp8OLVqEj4tcj+AVKEGRV9/89a/J\nL7+ueOwxaNy46tMPGgS77pqy4lRZp07wP/+T6VKYRPbfv+rTirgruGbNSllxKtSmjX/vS03KyuAQ\nKR1NLPE8/nh4cEh0NOFdnhfrLsigQYP8R0bk58fOk1OPLyyuanOVZ0aWvEKqYUP/ElCTnY45xt1E\nWNWaglcD79cvdWXKRlkZHM46q3pRuW/fqt0tOXdu9B+7sncJBwWD2hlnuM8PP4y+qzRW/toksrmo\nLknmkRyev/yler8XUzO8+z6qYvFid94wWdl+/qkiWXmsetVV4TemJHsjmvdFeIHlkUfcZ+SNUfEE\nH0kA7satYcOSmzZZvXvXvSPL/far3X+CeFTdUaanXbvok+BBd9zhbiI0dVeXLtGPe6lIbf5fZGVw\niDRkSOU2srfz9Z56+c03VVvuM89U72jeu9ogWfW5Wak2WLnS3X1rTH1QK3ZHld3Jerwde2Wqgan0\n6qtQVOQuEe3dO3H+2tqsZIype7I+ODRoEP0o6Kr6/e/h5psrN81ee0U/5vqII5Kbtm1bd8/D558n\nd110Ot5xYIzJnFiPw68tsjY4eM1I++8f3twSvGmsIq+8En01wT77RLcZJwoWjRpF30S3334uaKSS\nqgUHY+oS1cTvJslmWXm1UkXat4clSxLni6xtbNrkAkt+vrtTeOFC95TD/v3hrruSX/6mTe5OXu9k\ntzHG1EVZHxwqaof/5ZfwK5EqOmkdvMKgsNCdA0jmPEBF8zHGmLoqa5uV4vGCRW5udtwRa4wxdVHW\nBgevFhB5ItcLDpdemt7lH3RQeudvjDHZLGuDg+fxx5PPm8obThI99M0uOzXG1GVZGxy8nW9BQcXj\n06GgwH9MtTHG1EdZf0I6E3bsyHQJjDEmsxIGBxHpADwBtAbKgEdU9f6IPMOAW0ODm4GrVPWr0Lil\nwKbQtCWqGuexc5Vz6KHRaePHw6JFqZh7YtasZIypy0QTNNSLSBugjarOE5EmwGfAKar6TSBPL6BI\nVTeJyEBgtKr2Co37HjhcVX9JsBwFVxZVd5PZDz+En0cYMgS6doX//m8/3dtJn39+5c5PhC+b8uUm\nq2tX+O672v1gLWNM7SYiqGpaDlUT1hxUdQ2wJtS/RUSKgPbAN4E8cwKTzAmN9whJntv43e8qfv3d\ns8/CzJmxx40fn8wSUuemm9xzk4wxpi6q1DkHEekEHAp8XEG2S4HgLlyBN0WkFJioqnHvLf7pp8qU\nxldSUr1XDZ53Xvi7npNx5ZVVX54xxmS7pHepoSal54DrVXVLnDxHAxcBwScY9VHV1SLSChckilS1\nCq/iSR/v3b/GGGOcpIKDiOThAsMUVX05Tp6DgYnAwOD5BVVdHfpcKyIvAj2BmMFh9OjR5f3bt/cH\n+kflqWsvyjHGmGTNmjWLWTX08uqEJ6QBROQJYJ2q3hRn/B7A28Dw4PkHEWkM5ITOVewCvAGMUdU3\nYsxDg2XZc09YujT6hG9pKbz3HvzhD950sHOnBQ1jTP2TzhPSyVyt1Af4DzAfd/5AgVFAR0BVdaKI\nPAKcDizDnYAuUdWeIrIn8GJomjxgmqqOi7OcpIJD9HQWHIwx9VNGg0NNseBgjDGVk87gkLWPz0jW\nYYfZu5eNMSbVsvbxGfGeqRTps8/SWw5jjKmPsjY4vPUWbN6c6VIYY0z9lLXnHIwxxlTMzjkYY4yp\nURYcjDHGRLHgYIwxJooFB2OMMVEsOBhjjIliwcEYY0wUCw7GGGOiWHAwxhgTxYKDMcaYKBYcjDHG\nRLHgYIwxJooFB2OMMVEsOBhjjIliwcEYY0wUCw7GGGOiWHAwxhgTxYKDMcaYKBYcjDHGRLHgYIwx\nJooFB2OMMVEsOBhjjIliwcEYY0wUCw7GGGOiWHAwxhgTJWFwEJEOIvKOiCwQkfkicl2MPMNE5MtQ\nN1tEDg6MGygi34jIIhG5NdUrYIwxJvWSqTnsBG5S1QOA3sDVIrJvRJ7vgaNU9RBgLDARQERygAeA\nAcABwDkxpjURZs2alekiZAXbDj7bFj7bFjUjYXBQ1TWqOi/UvwUoAtpH5JmjqptCg3MC43sCi1V1\nmaqWAE8Dp6Sq8HWV/fgd2w4+2xY+2xY1o1LnHESkE3Ao8HEF2S4FZob62wMrAuN+JCKwGGOMyT55\nyWYUkSbAc8D1oRpErDxHAxcBfVNTPGOMMZkgqpo4k0ge8G9gpqreFyfPwcDzwEBVXRJK6wWMVtWB\noeGRgKrq+BjTJy6IMcaYMKoq6ZhvssHhCWCdqt4UZ/wewNvAcFWdE0jPBb4FjgFWA3OBc1S1KAVl\nN8YYkyYJg4OI9AH+A8wHNNSNAjriagETReQR4HRgGSBAiar2DE0/ELgPd37jUVUdl6Z1McYYkyJJ\n1RyMMcbULxm/Q7o+3CQX70ZCEWkuIm+IyLci8rqIFAam+ZOILBaRIhE5PpB+mIh8Fdpe92ZifapL\nRHJE5HMRmREarq/boVBEpofWbYGI/L4eb4sbReTr0HpME5GC+rQtRORREflJRL4KpKVs/UPb8+nQ\nNB+FTgVUTFUz1uGC03e4Jqp8YB6wbybLlKb1bAMcGupvgjsPsy8wHhgRSr8VGBfq3x/4Anc1WafQ\nNvJqeR8DPUL9rwEDMr1+VdgeNwJTgRmh4fq6HR4DLgr15wGF9XFbAO1wN9IWhIafAS6oT9sCd4Xn\nocBXgbSUrT9wJfBgqP9s4OlEZcp0zaFe3CSnsW8k7IBb18dD2R4HTg31D8Z9eTtVdSmwGOgpIm2A\npqr6SSjfE4FpagUR6QCcCPwrkFwft0Mz4EhVnQwQWsdN1MNtEZIL7BK6MrIRsJJ6tC1UdTbwS0Ry\nKtc/OK/ncBcJVSjTwaHe3SQXuJFwDtBaVX8CF0CA34WyRW6XlaG09rht5KmN2+vvwC24Cxs89XE7\n7AmsE5HJoSa2iSLSmHq4LVR1FXA3sBy3XptU9S3q4baI8LsUrn/5NKpaCmwUkd0qWnimg0O9EuNG\nwsirAer01QEichLwU6gWVdG12XV6O4TkAYcBE1T1MGArMJJ69psAEJFdcUe2HXFNTLuIyLnUw22R\nQCrXP+G9EZkODiuB4ImRDqG0OidUXX4OmKKqL4eSfxKR1qHxbYCfQ+krgd0Dk3vbJV56bdEHGCwi\n3wNPAX8QkSnAmnq2HcAd1a1Q1U9Dw8/jgkV9+00AHAt8r6obQke1LwJHUD+3RVAq1798nLj7z5qp\n6oaKFp7p4PAJ0EVEOopIATAUmJHhMqXLJGChht9hPgO4MNR/AfByIH1o6AqDPYEuwNxQ1XKTiPQU\nEQHOD0yT9VR1lKruoap74b7rd1R1OPAK9Wg7AISaC1aIyN6hpGOABdSz30TIcqCXiDQMrcMxwELq\n37YQwo/oU7n+M0LzADgLeCdhabLgLP1A3NU7i4GRmS5PmtaxD1CKuxrrC+Dz0HrvBrwVWv83gF0D\n0/wJdxVCEXB8IP1w3A2Ji4H7Mr1u1dgm/fCvVqqX2wE4BHeANA94AXe1Un3dFreH1usr3InT/Pq0\nLYAngVXADlywvAhonqr1BxoAz4bS5wCdEpXJboIzxhgTJdPNSsYYY7KQBQdjjDFRLDgYY4yJYsHB\nGGNMFAsOxhhjolhwMMYYE8WCgzHGmCgWHIwxxkT5/xgU3RFmA+DzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1197bae48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(nn.losses['train'], label='Train loss')\n",
    "plt.plot(nn.losses['valid'], label='Valid loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEACAYAAABPiSrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1197ba400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn.losses['valid_acc'], label='Valid accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
