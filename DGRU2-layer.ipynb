{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3629,),\n",
       " (3629,),\n",
       " array([67, 21, 36, 21, 16, 31,  7, 67, 21, 36]),\n",
       " array([21, 36, 21, 16, 31,  7, 67, 21, 36, 21]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "\n",
    "with open('data/text_data/japan.txt', 'r') as f:\n",
    "# with open('data/text_data/anna.txt', 'r') as f:\n",
    "\n",
    "    txt = f.read()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    char_to_idx = {char: i for i, char in enumerate(set(txt))}\n",
    "    idx_to_char = {i: char for i, char in enumerate(set(txt))}\n",
    "\n",
    "    X = np.array([char_to_idx[x] for x in txt])\n",
    "    y = [char_to_idx[x] for x in txt[1:]]\n",
    "    y.append(char_to_idx['.'])\n",
    "    y = np.array(y)\n",
    "\n",
    "# Looking at the X, y\n",
    "X.shape, y.shape, X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model or Network\n",
    "import impl.layer as l\n",
    "from impl.loss import *\n",
    "\n",
    "class GRU:\n",
    "    def __init__(self, D, H, L, char2idx, idx2char):\n",
    "        self.D = D\n",
    "        self.H = H\n",
    "        self.L = L\n",
    "        self.char2idx = char2idx\n",
    "        self.idx2char = idx2char\n",
    "        self.vocab_size = len(char2idx)\n",
    "        self.losses = {'train':[], 'smooth train':[]}\n",
    "        \n",
    "        # Model params\n",
    "        Z = H + D\n",
    "        m = dict(\n",
    "            Wz=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wh=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wy=np.random.randn(H, D) / np.sqrt(H / 2.), \n",
    "            bz=np.zeros((1, H)),\n",
    "            bh=np.zeros((1, H)),\n",
    "            by=np.zeros((1, D))\n",
    "        )\n",
    "\n",
    "        self.model = []\n",
    "        for layer in range(self.L):\n",
    "            self.model.append(m)\n",
    "\n",
    "    def initial_state(self):\n",
    "        return np.zeros((1, self.H))\n",
    "\n",
    "    def forward(self, X, h, m):\n",
    "        Wz, Wh, Wy = m['Wz'], m['Wh'], m['Wy']\n",
    "        bz, bh, by = m['bz'], m['bh'], m['by']\n",
    "\n",
    "        X_in = X.copy()\n",
    "        h_in = h.copy()\n",
    "\n",
    "        X = np.column_stack((h_in, X_in))\n",
    "\n",
    "        hz, hz_cache = l.fc_forward(X, Wz, bz)\n",
    "        hz, hz_sigm_cache = l.sigmoid_forward(hz)\n",
    "        \n",
    "        hh, hh_cache = l.fc_forward(X, Wh, bh)\n",
    "        hh, hh_tanh_cache = l.tanh_forward(hh)\n",
    "\n",
    "        # h = (1. - hz) * h_old + hz * hh\n",
    "        # or\n",
    "        # h = ((1. - hz) * h_in) + (hz * hh)\n",
    "        # or\n",
    "        h = h_in + (hz * (hh - h_in))\n",
    "\n",
    "        y, y_cache = l.fc_forward(h, Wy, by)\n",
    "\n",
    "        cache = (h_in, hz, hz_cache, hz_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache)\n",
    "\n",
    "        return y, h, cache\n",
    "\n",
    "    def backward(self, dy, dh, cache):\n",
    "        h_in, hz, hz_cache, hz_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache = cache\n",
    "        \n",
    "        dh_out = dh.copy()\n",
    "\n",
    "        dh, dWy, dby = l.fc_backward(dy, y_cache)\n",
    "        dh += dh_out\n",
    "\n",
    "        dh_in1 = (1. - hz) * dh\n",
    "        \n",
    "        dhh = hz * dh\n",
    "        dhh = l.tanh_backward(dhh, hh_tanh_cache)\n",
    "        dXh, dWh, dbh = l.fc_backward(dhh, hh_cache)\n",
    "\n",
    "        # dhz = (hh * dh) - (h_in * dh)\n",
    "        # or\n",
    "        dhz = (hh - h_in) * dh\n",
    "        dhz = l.sigmoid_backward(dhz, hz_sigm_cache)\n",
    "        dXz, dWz, dbz = l.fc_backward(dhz, hz_cache)\n",
    "\n",
    "        dX = dXh + dXz\n",
    "        dh_in2 = dX[:, :self.H]\n",
    "        dX_in = dX[:, self.H:]\n",
    "\n",
    "        dh = dh_in1 + dh_in2\n",
    "        dX = dX_in\n",
    "\n",
    "        grad = dict(Wz=dWz, Wh=dWh, Wy=dWy, bz=dbz, bh=dbh, by=dby)\n",
    "        \n",
    "        return dX, dh, grad\n",
    "\n",
    "    def train_forward(self, X_train, h):\n",
    "        ys, caches = [], []\n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "            caches.append([])\n",
    "        \n",
    "        # for layer in range(self.L):\n",
    "        # layer = 0 # 1st layer or input layer\n",
    "        for layer in range(0, 1):\n",
    "            for X in X_train:\n",
    "                X_one_hot = np.zeros(self.D)\n",
    "                X_one_hot[X] = 1.\n",
    "                X = X_one_hot.reshape(1, -1)\n",
    "                y, h[layer], cache = self.forward(X, h[layer], self.model[layer])\n",
    "                caches[layer].append(cache)\n",
    "                ys.append(y)\n",
    "            \n",
    "        # for layer in range(self.L): # from 0 to L-1\n",
    "        for layer in range(1, self.L):\n",
    "            Xs = ys.copy()\n",
    "            ys = []\n",
    "            for X in Xs:\n",
    "                X = X.reshape(1, -1)\n",
    "                y, h[layer], cache = self.forward(X, h[layer], self.model[layer])\n",
    "                caches[layer].append(cache)\n",
    "                ys.append(y)\n",
    "\n",
    "        return ys, caches\n",
    "    \n",
    "    def loss_function(self, y_train, ys):\n",
    "        loss, dys = 0.0, []\n",
    "\n",
    "        for y_pred, y in zip(ys, y_train):\n",
    "            loss += cross_entropy(y_pred, y)\n",
    "            dy = dcross_entropy(y_pred, y)\n",
    "            dys.append(dy)\n",
    "            \n",
    "        return loss, dys\n",
    "    \n",
    "    def train_backward(self, dys, caches):\n",
    "        dh, grad, grads = [], [], []\n",
    "        for layer in range(self.L):\n",
    "            dh.append(np.zeros((1, self.H)))\n",
    "            grad.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            grads.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "        \n",
    "        dXs = dys.copy()\n",
    "        for layer in reversed(range(self.L)):\n",
    "            dys = dXs.copy()\n",
    "            for t in reversed(range(len(dys))):\n",
    "                dy = dys[t]\n",
    "                dX, dh[layer], grad[layer] = self.backward(dy, dh[layer], caches[layer][t])\n",
    "                for k in grad[layer].keys():\n",
    "                    grads[layer][k] += grad[layer][k]\n",
    "                dXs[t] = dX\n",
    "                \n",
    "        return dXs, grads\n",
    "\n",
    "    def test(self, X_seed, h, size):\n",
    "        chars = [self.idx2char[X_seed]]\n",
    "        idx_list = list(range(self.vocab_size))\n",
    "        X = X_seed\n",
    "        \n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "\n",
    "        for _ in range(size):\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            X = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], _ = self.forward(X, h[layer], self.model[layer])\n",
    "                X = y.copy()\n",
    "            prob = l.softmax(y)\n",
    "            idx = np.random.choice(idx_list, p=prob.ravel())\n",
    "            chars.append(self.idx2char[idx])\n",
    "            X = idx\n",
    "\n",
    "        return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minibatch(X, y, minibatch_size, shuffle):\n",
    "    minibatches = []\n",
    "\n",
    "    #for i in range(0, X.shape[0], minibatch_size):\n",
    "    for i in range(0, X.shape[0] - minibatch_size + 1, 1):\n",
    "        X_mini = X[i:i + minibatch_size]\n",
    "        y_mini = y[i:i + minibatch_size]\n",
    "        minibatches.append((X_mini, y_mini))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "def adam_rnn(nn, X_train, y_train, alpha, mb_size, n_iter, print_after):\n",
    "\n",
    "    M, R = [], []\n",
    "    for layer in range(nn.L):\n",
    "        M.append({k: np.zeros_like(v) for k, v in nn.model[layer].items()})\n",
    "        R.append({k: np.zeros_like(v) for k, v in nn.model[layer].items()})\n",
    "        \n",
    "    beta1 = .99\n",
    "    beta2 = .999\n",
    "    state = nn.initial_state()\n",
    "    smooth_loss = 1.\n",
    "    minibatches = get_minibatch(X_train, y_train, mb_size, shuffle=False)\n",
    "    \n",
    "    for iter in range(1, n_iter + 1):\n",
    "        for idx in range(len(minibatches)):\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            ys, caches = nn.train_forward(X_mini, state)\n",
    "            loss, dys = nn.loss_function(y_mini, ys)\n",
    "            _, grads = nn.train_backward(dys, caches)\n",
    "            nn.losses['train'].append(loss)\n",
    "            smooth_loss = (0.999 * smooth_loss) + (0.001 * loss)\n",
    "            nn.losses['smooth train'].append(smooth_loss)\n",
    "\n",
    "            for layer in range(nn.L):\n",
    "                for k in grads[layer].keys(): #key, value: items\n",
    "                    M[layer][k] = l.exp_running_avg(M[layer][k], grads[layer][k], beta1)\n",
    "                    R[layer][k] = l.exp_running_avg(R[layer][k], grads[layer][k]**2, beta2)\n",
    "\n",
    "                    m_k_hat = M[layer][k] / (1. - (beta1**(iter)))\n",
    "                    r_k_hat = R[layer][k] / (1. - (beta2**(iter)))\n",
    "\n",
    "                    nn.model[layer][k] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + l.eps)\n",
    "\n",
    "        # Print loss and test sample\n",
    "        if iter % print_after == 0:\n",
    "            print('Iter-{} loss: {:.4f}'.format(iter, loss))\n",
    "            sample = nn.test(X_mini[0], state, 100)\n",
    "            print(sample)\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "time_step = 100 # width, minibatch size and test sample size as well\n",
    "num_layers = 2 # depth\n",
    "n_iter = 50 # epochs\n",
    "alpha = 1e-4 # learning_rate\n",
    "print_after = 1 # n_iter//10 # print training loss, valid, and test\n",
    "num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "num_input_units = len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "\n",
    "# Build the network and learning it or optimizing it using SGD\n",
    "net = GRU(D=num_input_units, H=num_hidden_units, L=num_layers, char2idx=char_to_idx, idx2char=idx_to_char)\n",
    "\n",
    "# Start learning using BP-SGD-ADAM\n",
    "adam_rnn(nn=net, X_train=X, y_train=y, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)\n",
    "\n",
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(net.losses['train'], label='Train loss')\n",
    "plt.plot(net.losses['smooth train'], label='Train smooth loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1 loss: 217.5480\n",
      " Ue6 the Npamagt Wranhd IndFf6 ArranS ustirsin indes ree,Gtef in the Gors hethe estax,essy fech d Pra\n",
      "Iter-2 loss: 197.5714\n",
      " the doonndekth Rsithe rofy eun C1k. Anichess lapan fivext on6t rLan Whor oullat 3uxJan Indd farkked \n",
      "Iter-3 loss: 191.1596\n",
      " pancp liut exJar ith onde Jaunwh, hingy ex4 t7 anditre n mi8 C8 Gnunrthe 7af%ges mtint nNortles, fom\n",
      "Iter-4 loss: 205.4693\n",
      " is rhes Eusser ran useapend expinnD poppunord and fir5ld, is the G4 tere aI bontar Ned Japand nanwJa\n",
      "Iter-5 loss: 214.9694\n",
      " wan wus, in the hidsteuntt in the Gter e8iJar Gvele1nomteanloming and napan isorees of the 8uper ala\n",
      "Iter-6 loss: 194.1631\n",
      " man morrekyy eand Japan its of of, Ind the cinst in the G2glytAJapan intan's the the sevrinment. Jap\n",
      "Iter-7 loss: 195.4187\n",
      " panse suuntry omG Nnal of wake. Japan hafin sivint exploreate Japan is laniny unnenst in6pest powesn\n",
      "Iter-8 loss: 200.8147\n",
      " ron segens poknemt into opNyG at a pevild inlalitiand in the Glebounowhen and and Rantassedeppeuntry\n",
      "Iter-9 loss: 198.7497\n",
      " and unlopape folearys, Iixrowerth liver. Japan ban-toyusaprfe pors sicrd and iunade Ubsiresidcol of \n",
      "Iter-10 loss: 181.7189\n",
      " a Urome biturinary)P miped an. Sea, the Sea and Nameborolaroming Hictine sirecs iss ringce, ferth li\n",
      "Iter-11 loss: 176.0341\n",
      " powe. Asintanky buclile sust nest inmfy untce foustuladimed an egonst of the cinet gentopme a Nomrel\n",
      "Iter-12 loss: 179.6159\n",
      " poundtivelese inteln Japan was coper. Japan lamultoowestire Japan wored forld and purtiourth Degoleo\n",
      "Iter-13 loss: 170.2611\n",
      " the Rleate excheled in the number of an eights damo\n",
      "e of Japanese War and of feltury in for and is t\n",
      "Iter-14 loss: 154.1775\n",
      " the Global Peace Index. Japan was the rane miled Huro-ndevexelcllopectans s gsth portakkkk omN int t\n",
      "Iter-15 loss: 149.5623\n",
      " 1nd eighosiond cored into llaldise malimatiof mapan of Japanese War Ind War loatere fountDy Asionst \n",
      "Iter-16 loss: 136.7709\n",
      " IndexJonas the G8, the Grom opgrsiferecolst in emperobe net, himtere nas isoe gigith lacedegeliberbe\n",
      "Iter-17 loss: 123.7842\n",
      " renterndicy thics dighth largest expore of Japan was axd tan the natinu the cored,d ary the with the\n",
      "Iter-18 loss: 120.5374\n",
      " part caread fouxhanked country in the world. The Greatan 3mefetere and fourth-largest importer. Alth\n",
      "Iter-19 loss: 118.6712\n",
      " pantest legotan ycistury flcontarintad in the narcy ward of test intreatern of Japan was proclaiwics\n",
      "Iter-20 loss: 113.8900\n",
      " and of the eustry warl toe cemberid dich on in raslargest are Hond piten hiutropoped inss period int\n",
      "Iter-21 loss: 103.7971\n",
      " Residen to pan edecore the hirllity i ha woriral1 1mtrourd Japan to pexterun\"k an the Gwal courch In\n",
      "Iter-22 loss: 94.8978\n",
      " 1942 in the nity in the world, and ranked first in the number of Nobel lawe, which was ends Hirst lo\n",
      "Iter-23 loss: 88.4543\n",
      " world's tenth largest military buxbud a Ure turth in the Gloobombeowerd Sifudct inlapin the wost uof\n",
      "Iter-24 loss: 81.1914\n",
      " Unper the Glom Japan was proclaimed, with the world. Flroc LiccaiPar enth the world's elciton sea ad\n",
      "Iter-25 loss: 72.8582\n",
      " host internd fourlu,hhiu, a maber Indexy floper was kors 5uadiJand Japan is and eunthichaman Emperor\n",
      "Iter-26 loss: 68.3401\n",
      " Unped giss ingh the G8Wird to parte-nekin. Japan is ranked firse Shunde war, it in roin the fortt 0o\n",
      "Iter-27 loss: 64.4210\n",
      " 1947 an eneas country in the Global Peace Index. Japan was the first country in Asia to hest iftopul\n",
      "Iter-28 loss: 61.4159\n",
      " world's eighth-largest miling follos of the \"Land of the Rusior and is empire dicreatized Rising an \n",
      "Iter-29 loss: 57.4617\n",
      " ramky. GP ares rentry oron\"a Japan was rucce,,h iplas aodsth-largest economy. choxth furtal bif the \n",
      "Iter-30 loss: 50.5653\n",
      " is the world, as legiod in the erecons. Jhina and 6onation enjoys the highest life expentere and pea\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxQ8VDoqiKIof/w84g4j47ZUh3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c1a1668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Hyper-parameters\n",
    "# time_step = 100 # width, minibatch size and test sample size as well\n",
    "# num_layers = 2 # depth\n",
    "# n_iter = 30 # epochs\n",
    "# alpha = 1e-4 # learning_rate\n",
    "# print_after = 1 # n_iter//10 # print training loss, valid, and test\n",
    "# num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "# num_input_units = len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "\n",
    "# # Build the network and learning it or optimizing it using SGD\n",
    "# net = GRU(D=num_input_units, H=num_hidden_units, L=num_layers, char2idx=char_to_idx, idx2char=idx_to_char)\n",
    "\n",
    "# # Start learning using BP-SGD-ADAM\n",
    "# adam_rnn(nn=net, X_train=X, y_train=y, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)\n",
    "\n",
    "# # # Display the learning curve and losses for training, validation, and testing\n",
    "# # %matplotlib inline\n",
    "# # %config InlineBackend.figure_format = 'retina'\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(net.losses['train'], label='Train loss')\n",
    "# plt.plot(net.losses['smooth train'], label='Train smooth loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
