{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((55000, 1, 28, 28), (5000, 1, 28, 28), (10000, 1, 28, 28))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import impl.layer as l\n",
    "\n",
    "# Dataset preparation and pre-processing\n",
    "mnist = input_data.read_data_sets('data/MNIST_data/', one_hot=False)\n",
    "\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "# y_test.shape, y_val.shape, y_train.shape\n",
    "\n",
    "M, D, C = X_train.shape[0], X_train.shape[1], y_train.max() + 1\n",
    "# M, D, C\n",
    "\n",
    "X_train, X_val, X_test = l.prepro(X_train, X_val, X_test)\n",
    "# X_train.shape, X_val.shape, X_test.shape\n",
    "# if net_type == 'cnn':\n",
    "img_shape = (1, 28, 28)\n",
    "\n",
    "X_train = X_train.reshape(-1, *img_shape)\n",
    "X_val = X_val.reshape(-1, *img_shape)\n",
    "X_test = X_test.reshape(-1, *img_shape)\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l\n",
    "\n",
    "class CNN:\n",
    "\n",
    "    def __init__(self, D, C, H, L, p_dropout):\n",
    "        self.p_dropout = p_dropout\n",
    "        self.mode = 'classification'\n",
    "        self.L = L # number of layers or depth\n",
    "        self.p_dropout = p_dropout\n",
    "        self.losses = {'train':[]}\n",
    "        \n",
    "        # Model parameters: weights and biases\n",
    "        # Input layer of Conv\n",
    "        self.model = []\n",
    "        self.model.append(dict(\n",
    "            W1=np.random.randn(H, 1, 3, 3) / np.sqrt(H / 2.),\n",
    "            b1=np.zeros((H, 1)),\n",
    "            W1_res=np.random.randn(H, 1, 3, 3) / np.sqrt(H / 2.),\n",
    "            b1_res=np.zeros((H, 1))\n",
    "        ))\n",
    "        \n",
    "        # Hidden layers of Conv-bn-relu-dropout\n",
    "        m = []\n",
    "        self.bn_caches = []\n",
    "        for _ in range(self.L):\n",
    "            m.append(dict(\n",
    "                    W2=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "                    b2=np.zeros((H, 1)),\n",
    "                    W2_res=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "                    b2_res=np.zeros((H, 1))\n",
    "            ))\n",
    "        self.model.append(m) # self.model[0][]\n",
    "        \n",
    "        # Output layer of FC to output\n",
    "        self.model.append(dict(\n",
    "            W3=np.random.randn(H*D, C) / np.sqrt(H*D / 2.),\n",
    "            b3=np.zeros((1, C))\n",
    "        ))\n",
    "\n",
    "    def selu_forward(self, X):\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        out = scale * np.where(X>=0.0, X, alpha * (np.exp(X)-1))\n",
    "        cache = X\n",
    "        return out, cache\n",
    "\n",
    "    def selu_backward(self, dout, cache):\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        X = cache\n",
    "        dX_pos = dout.copy()\n",
    "        dX_pos[X<0] = 0\n",
    "        dX_neg = dout.copy()\n",
    "        dX_neg[X>0] = 0\n",
    "        dX = scale * np.where(X>=0.0, dX_pos, dX_neg * alpha * np.exp(X))\n",
    "        return dX\n",
    "\n",
    "    def alpha_dropout_fwd(self, h, q):\n",
    "        '''h is activation, q is keep probability: q=1-p, p=p_dropout, and q=keep_prob'''\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        alpha_p = -scale * alpha\n",
    "        mask = np.random.binomial(1, q, size=h.shape)\n",
    "        dropped = mask * h + (1 - mask) * alpha_p\n",
    "        a = 1. / np.sqrt(q + alpha_p ** 2 * q  * (1 - q))\n",
    "        b = -a * (1 - q) * alpha_p\n",
    "        out = a * dropped + b\n",
    "        cache = (a, mask)\n",
    "        return out, cache\n",
    "\n",
    "    def alpha_dropout_bwd(self, dout, cache):\n",
    "        a, mask = cache\n",
    "        d_dropped = dout * a\n",
    "        dh = d_dropped * mask\n",
    "        return dh\n",
    "\n",
    "    def forward(self, X, train):\n",
    "\n",
    "        # 1st layer: Input to Conv\n",
    "        h1_res, conv1_res_cache = l.conv_forward(X=X, W=self.model[0]['W1_res'], b=self.model[0]['b1_res']) \n",
    "        h1, conv1_cache = l.conv_forward(X=X, W=self.model[0]['W1'], b=self.model[0]['b1']) \n",
    "        #         h2, nl1_cache = l.relu_forward(h1)\n",
    "        h2, nl1_cache = self.selu_forward(h1)\n",
    "        if train: \n",
    "            do1_cache = None\n",
    "            #         if train: h2, do1_cache = self.dropout_selu_forward(X=h2, p_dropout=self.p_dropout)\n",
    "            h2, do1_cache = self.alpha_dropout_fwd(h=h2, q=self.p_dropout)\n",
    "            # x = x + f(x)\n",
    "            h1_res += h2\n",
    "            h1_cache = (conv1_res_cache, conv1_cache, nl1_cache, do1_cache)\n",
    "        else: \n",
    "            # x = x + f(x)\n",
    "            h1_res += h2\n",
    "            h1_cache = (conv1_res_cache, conv1_cache, nl1_cache)\n",
    "\n",
    "        ###########################################################################################\n",
    "        # midst layer: Convnet 1\n",
    "        h2_cache = []\n",
    "        for layer in range(self.L):\n",
    "            if not layer == 0: h2 = h2.reshape(nl1_cache.shape)\n",
    "\n",
    "            h2_res, conv2_res_cache = l.conv_forward(X=h2, W=self.model[1][layer]['W2_res'], \n",
    "                                                     b=self.model[1][layer]['b2_res'])\n",
    "            h2_res = h2_res.reshape([nl1_cache.shape[0], -1])\n",
    "\n",
    "            h2, conv2_cache = l.conv_forward(X=h2, W=self.model[1][layer]['W2'], b=self.model[1][layer]['b2'])\n",
    "            h2 = h2.reshape([nl1_cache.shape[0], -1])\n",
    "            \n",
    "            #             h2, nl2_cache = l.relu_forward(h2)\n",
    "            h2, nl2_cache = self.selu_forward(X=h2)\n",
    "            if train: \n",
    "                do2_cache = None # ERROR: referenced before assigned!\n",
    "                #             if train: h2, do2_cache = l.dropout_forward(X=h2, p_dropout=self.p_dropout)\n",
    "                #             if train: h2, do2_cache = self.dropout_selu_forward(X=h2, p_dropout=self.p_dropout)\n",
    "                h2, do2_cache = self.alpha_dropout_fwd(h=h2, q=self.p_dropout)\n",
    "                h2_res += h2    \n",
    "                cache = (conv2_res_cache, conv2_cache, nl2_cache, do2_cache)\n",
    "            else:\n",
    "                h2_res += h2    \n",
    "                cache = (conv2_res_cache, conv2_cache, nl2_cache)\n",
    "\n",
    "            h2_cache.append(cache)\n",
    "        ############################################################################################\n",
    "            \n",
    "        # last layer : FC to Output\n",
    "        h3, h3_cache = l.fc_forward(X=h2, W=self.model[2]['W3'], b=self.model[2]['b3'])\n",
    "\n",
    "        cache = (h1_cache, h2_cache, h3_cache)\n",
    "        return h3, cache\n",
    "\n",
    "    def cross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(prob[range(m), y_train])\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        grad_y = l.softmax(y_pred)\n",
    "        grad_y[range(m), y_train] -= 1.0\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "\n",
    "    def loss_function(self, y, y_train):\n",
    "        loss = self.cross_entropy(y, y_train) #/ y_train.shape[0] # (t, n)=txn, t: minibatch_size/ num_samples\n",
    "        dy = self.dcross_entropy(y, y_train) #/ y_train.shape[0]\n",
    "        return loss, dy\n",
    "    \n",
    "    def backward(self, dy, cache, train):\n",
    "        h1_cache, h2_cache, h3_cache = cache\n",
    "        if train: conv1_res_cache, conv1_cache, nl1_cache, do1_cache = h1_cache\n",
    "        else: conv1_res_cache, conv1_cache, nl1_cache = h1_cache\n",
    "\n",
    "        # last layer\n",
    "        dh2, dw3, db3 = l.fc_backward(dout=dy, cache=h3_cache)\n",
    "        \n",
    "        # midst layer 2\n",
    "        g = []\n",
    "        for layer in reversed(range(self.L)):\n",
    "            \n",
    "            conv2_res_cache, conv2_cache, nl2_cache, do2_cache = h2_cache[layer]\n",
    "            dh2_res = dh2.reshape(nl1_cache.shape)\n",
    "            dh2_res, dw2_res, db2_res = l.conv_backward(dout=dh2_res, cache=conv2_res_cache)\n",
    "            \n",
    "            if train:\n",
    "                #             dh2 = l.dropout_backward(dout=dh2, cache=do2_cache)\n",
    "                #             dh2 = self.dropout_selu_backward(dout=dh2, cache=do2_cache)\n",
    "                dh2 = self.alpha_dropout_bwd(dout=dh2, cache=do2_cache)\n",
    "                \n",
    "            #             dh2 = l.relu_backward(dout=dh2, cache=nl2_cache)\n",
    "            dh2 = self.selu_backward(dout=dh2, cache=nl2_cache)\n",
    "            dh2 = dh2.reshape(nl1_cache.shape)\n",
    "            dh2, dw2, db2 = l.conv_backward(dout=dh2, cache=conv2_cache)\n",
    "            dh2 += dh2_res\n",
    "            if not layer==0: dh2 = dh2.reshape([nl1_cache.shape[0], -1])\n",
    "            g.append(dict(\n",
    "                    W2=dw2,\n",
    "                    b2=db2,\n",
    "                    W2_res=dw2_res,\n",
    "                    b2_res=db2_res\n",
    "                    ))\n",
    "            \n",
    "        # 1st layer\n",
    "        #         conv1_res_cache, conv1_cache, nl1_cache, do1_cache = h1_cache\n",
    "        dX_res, dw1_res, db1_res = l.conv_backward(dout=dh2, cache=conv1_res_cache)\n",
    "        #         dh2 = self.dropout_selu_backward(dout=dh2, cache=do1_cache)\n",
    "        if train: dh2 = self.alpha_dropout_bwd(dout=dh2, cache=do1_cache)\n",
    "        #         dh1 = l.relu_backward(dout=dh2, cache=nl1_cache)\n",
    "        dh1 = self.selu_backward(dout=dh2, cache=nl1_cache)\n",
    "        dX, dw1, db1 = l.conv_backward(dout=dh1, cache=conv1_cache)\n",
    "        dX += dX_res\n",
    "\n",
    "        # grad for GD\n",
    "        grad = []\n",
    "        \n",
    "        # Input layer to conv layer\n",
    "        grad.append(dict(\n",
    "            W1=dw1, \n",
    "            b1=db1,\n",
    "            W1_res=dw1_res, \n",
    "            b1_res=db1_res\n",
    "        ))\n",
    "        \n",
    "        # Hidden layers of conv-bn-nl/relu-dropout/do\n",
    "        grad.append(g)\n",
    "        \n",
    "        # Output later to FC layer\n",
    "        grad.append(dict(\n",
    "            W3=dw3, \n",
    "            b3=db3\n",
    "        ))\n",
    "        \n",
    "        return dX, grad\n",
    "    \n",
    "    def test(self, X):\n",
    "        y_logit, cache = self.forward(X, train=False)\n",
    "        y_prob = l.softmax(y_logit)\n",
    "        if self.mode == 'classification':\n",
    "            return np.argmax(y_prob, axis=1)\n",
    "        else: # self.mode == 'regression'\n",
    "            return np.round(y_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SGD\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "def get_minibatch(X, y, minibatch_size, shuffle):\n",
    "    minibatches = []\n",
    "\n",
    "    if shuffle:\n",
    "        X, y = skshuffle(X, y)\n",
    "\n",
    "    for i in range(0, X.shape[0], minibatch_size):\n",
    "        X_mini = X[i:i + minibatch_size]\n",
    "        y_mini = y[i:i + minibatch_size]\n",
    "        minibatches.append((X_mini, y_mini))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "def adam(nn, X_train, y_train, val_set, alpha, mb_size, n_iter, print_after):\n",
    "    if val_set:\n",
    "        X_val, y_val = val_set\n",
    "        \n",
    "    M, R = [], []\n",
    "    M.append({key: np.zeros_like(val) for key, val in nn.model[0].items()})\n",
    "    R.append({key: np.zeros_like(val) for key, val in nn.model[0].items()})\n",
    "    \n",
    "    M_, R_ = [], []\n",
    "    for layer in range(nn.L):\n",
    "        M_.append({key: np.zeros_like(val) for key, val in nn.model[1][layer].items()})\n",
    "        R_.append({key: np.zeros_like(val) for key, val in nn.model[1][layer].items()})\n",
    "    M.append(M_)\n",
    "    R.append(R_)\n",
    "\n",
    "    M.append({key: np.zeros_like(val) for key, val in nn.model[2].items()})\n",
    "    R.append({key: np.zeros_like(val) for key, val in nn.model[2].items()})\n",
    "    \n",
    "    beta1 = .99\n",
    "    beta2 = .999\n",
    "    #     import impl.constant as c, c.eps\n",
    "    eps = 1e-8 # constant\n",
    "\n",
    "    # Epochs\n",
    "    for iter in range(1, n_iter + 1):\n",
    "        \n",
    "        # Minibatches\n",
    "        #         \"\"\"\n",
    "        #         Single training step over minibatch: forward, loss, backprop\n",
    "        #         \"\"\"\n",
    "        # Shuffle for each epochs/ stochasticity/ randomly choosing\n",
    "        minibatches = get_minibatch(X_train, y_train, mb_size, shuffle=True)\n",
    "        for _ in range(10):\n",
    "            idx = np.random.randint(0, len(minibatches))\n",
    "            #         for idx in range(len(minibatches)):\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            y, cache = nn.forward(X_mini, train=True)\n",
    "            loss, dy = nn.loss_function(y, y_mini)\n",
    "            dX, grad = nn.backward(dy, cache, train=True)\n",
    "            nn.losses['train'].append(loss)\n",
    "\n",
    "            for key in grad[0]:\n",
    "                M[0][key] = l.exp_running_avg(M[0][key], grad[0][key], beta1)\n",
    "                R[0][key] = l.exp_running_avg(R[0][key], grad[0][key]**2, beta2)\n",
    "\n",
    "                m_k_hat = M[0][key] / (1. - (beta1**(iter)))\n",
    "                r_k_hat = R[0][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                nn.model[0][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + eps)\n",
    "\n",
    "            for layer in range(nn.L):\n",
    "                for key in grad[1][layer]:\n",
    "                    M[1][layer][key] = l.exp_running_avg(M[1][layer][key], grad[1][layer][key], beta1)\n",
    "                    R[1][layer][key] = l.exp_running_avg(R[1][layer][key], grad[1][layer][key]**2, beta2)\n",
    "\n",
    "                    m_k_hat = M[1][layer][key] / (1. - (beta1**(iter)))\n",
    "                    r_k_hat = R[1][layer][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                    nn.model[1][layer][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + eps)\n",
    "\n",
    "            for key in grad[2]:\n",
    "                M[2][key] = l.exp_running_avg(M[2][key], grad[2][key], beta1)\n",
    "                R[2][key] = l.exp_running_avg(R[2][key], grad[2][key]**2, beta2)\n",
    "\n",
    "                m_k_hat = M[2][key] / (1. - (beta1**(iter)))\n",
    "                r_k_hat = R[2][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                nn.model[2][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + eps)\n",
    "\n",
    "        # Epochs\n",
    "        if iter % print_after == 0:\n",
    "            if val_set:\n",
    "                val_acc = l.accuracy(y_val, nn.test(X_val))\n",
    "                print('Iter-{} training loss: {:.4f} validation accuracy: {:4f}'.format(iter, loss, val_acc))\n",
    "                \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-10 training loss: 5.1880 validation accuracy: 0.850200\n",
      "Iter-20 training loss: 1.7259 validation accuracy: 0.900600\n",
      "Iter-30 training loss: 5.7726 validation accuracy: 0.908400\n",
      "Iter-40 training loss: 4.9907 validation accuracy: 0.902600\n",
      "Iter-50 training loss: 3.0941 validation accuracy: 0.926200\n",
      "Iter-60 training loss: 2.0855 validation accuracy: 0.929600\n",
      "Iter-70 training loss: 3.2685 validation accuracy: 0.924600\n",
      "Iter-80 training loss: 3.3855 validation accuracy: 0.929000\n",
      "Iter-90 training loss: 3.2735 validation accuracy: 0.929200\n",
      "Iter-100 training loss: 2.7068 validation accuracy: 0.936800\n",
      "Test Mean accuracy: 0.9292, std: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "n_iter = 100 # number of epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "mb_size = 64 # width, timestep for sequential data or minibatch size\n",
    "num_layers = 2 # depth \n",
    "print_after = n_iter//10 # print loss for train, valid, and test\n",
    "num_hidden_units = 8\n",
    "p_dropout = 0.95 #  keep_prob = 1.0 - p_dropout, q = 1-p, q=0.95, o=0.05\n",
    "\n",
    "# build the model/NN and learn it: running session.\n",
    "net = CNN(C=C, D=D, H=num_hidden_units, p_dropout=p_dropout, L=num_layers)\n",
    "\n",
    "net = adam(nn=net, X_train=X_train, y_train=y_train, val_set=(X_val, y_val), mb_size=mb_size, alpha=alpha, \n",
    "           n_iter=n_iter, print_after=print_after)\n",
    "\n",
    "y_pred = net.test(X_test)\n",
    "accs = np.mean(y_pred == y_test)\n",
    "print('Test Mean accuracy: {:.4f}, std: {:.4f}'.format(accs.mean(), accs.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzvn/vgcPrXAI71wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e9cac59e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(net.losses['train'], label='Train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
