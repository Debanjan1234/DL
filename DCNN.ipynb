{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((55000, 1, 28, 28), (5000, 1, 28, 28), (10000, 1, 28, 28))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import impl.layer as l\n",
    "\n",
    "# Dataset preparation and pre-processing\n",
    "mnist = input_data.read_data_sets('data/MNIST_data/', one_hot=False)\n",
    "\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "# y_test.shape, y_val.shape, y_train.shape\n",
    "\n",
    "M, D, C = X_train.shape[0], X_train.shape[1], y_train.max() + 1\n",
    "# M, D, C\n",
    "\n",
    "X_train, X_val, X_test = l.prepro(X_train, X_val, X_test)\n",
    "# X_train.shape, X_val.shape, X_test.shape\n",
    "# if net_type == 'cnn':\n",
    "img_shape = (1, 28, 28)\n",
    "img_shape[:]\n",
    "# *img_shape\n",
    "# X_train = X_train.reshape(-1, img_shape[:])\n",
    "X_train = X_train.reshape(-1, *img_shape)\n",
    "# X_train = X_train.reshape(-1, img_shape[0], img_shape[1], img_shape[2])\n",
    "X_val = X_val.reshape(-1, *img_shape)\n",
    "X_test = X_test.reshape(-1, *img_shape)\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l # or from impl.layer import *\n",
    "from impl.loss import * # import all functions from impl.loss file # import impl.loss as loss_func\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "class CNN:\n",
    "\n",
    "    def __init__(self, D, C, H, L, p_dropout):\n",
    "        self.mode = 'classification'\n",
    "        self.L = L # number of layers or depth\n",
    "        self.p_dropout = p_dropout\n",
    "        self.losses = {'train':[], 'smooth train':[]}\n",
    "        \n",
    "        # Model parameters: weights and biases\n",
    "        # Input layer of Conv\n",
    "        self.model = []\n",
    "        self.model.append(dict(\n",
    "            W1=np.random.randn(H, 1, 3, 3) / np.sqrt(H / 2.),\n",
    "            b1=np.zeros((H, 1)),\n",
    "        ))\n",
    "        \n",
    "        # Hidden layers of Conv-bn-relu-dropout\n",
    "        m = []\n",
    "        for _ in range(self.L):\n",
    "            m.append(dict(\n",
    "                W2=np.random.randn(H, H, 3, 3) / np.sqrt(H / 2.),\n",
    "                b2=np.zeros((H, 1)),\n",
    "            ))\n",
    "        self.model.append(m) # self.model[0][]\n",
    "        \n",
    "        # Output layer of FC to output\n",
    "        self.model.append(dict(\n",
    "            W3=np.random.randn(H*D, C) / np.sqrt(H*D / 2.),\n",
    "            b3=np.zeros((1, C))\n",
    "        ))\n",
    "\n",
    "    def forward(self, X, train):\n",
    "        # 1st layer - Input layer: X\n",
    "        X, X_conv_cache = l.conv_forward(X=X, W=self.model[0]['W1'], b=self.model[0]['b1'])\n",
    "        X_cache = X_conv_cache\n",
    "\n",
    "        # 2nd layers - Hidden layers: h\n",
    "        h_cache = []\n",
    "        for layer in range(self.L):\n",
    "            h, h_conv_cache = l.conv_forward(X=X, W=self.model[1][layer]['W2'], b=self.model[1][layer]['b2'])\n",
    "            h, h_nl_cache = l.selu_forward(X=h)\n",
    "            h += X # residual connection\n",
    "            if train: \n",
    "                # h_do_cache = None # ERROR: referenced before assigned?\n",
    "                h, h_do_cache = l.alpha_dropout_fwd(h=h, q=self.p_dropout)\n",
    "                cache = (h_conv_cache, h_nl_cache, h_do_cache)\n",
    "            else:\n",
    "                cache = (h_conv_cache, h_nl_cache)\n",
    "            h_cache.append(cache)\n",
    "            \n",
    "        # 3rd layer - Output layer: y\n",
    "        y = h.reshape([X.shape[0], -1]) # flattening\n",
    "        y, y_fc_cache = l.fc_forward(X=y, W=self.model[2]['W3'], b=self.model[2]['b3'])\n",
    "        y_cache = X, y_fc_cache\n",
    "\n",
    "        cache = (X_cache, h_cache, y_cache)\n",
    "        \n",
    "        return y, cache\n",
    "\n",
    "    def loss_function(self, y, y_train):\n",
    "        loss = cross_entropy(y, y_train)\n",
    "        dy = dcross_entropy(y, y_train)\n",
    "        return loss, dy\n",
    "    \n",
    "    def backward(self, dy, cache):\n",
    "        X_cache, h_cache, y_cache = cache\n",
    "\n",
    "        # 3rd layer: Ouput layer y\n",
    "        X, y_fc_cache = y_cache\n",
    "        dy, dw3, db3 = l.fc_backward(dout=dy, cache=y_fc_cache)\n",
    "        dy = dy.reshape([-1, *X.shape[1:4]])\n",
    "        \n",
    "        # 2nd layers: Hidden layers h\n",
    "        g = []\n",
    "        for layer in reversed(range(self.L)):\n",
    "            # if train: There is no backward in testing/prediction\n",
    "            h_conv_cache, h_nl_cache, h_do_cache = h_cache[layer]\n",
    "            dy = l.alpha_dropout_bwd(dout=dy, cache=h_do_cache)\n",
    "            dh = l.selu_backward(dout=dy, cache=h_nl_cache)\n",
    "            dh, dw2, db2 = l.conv_backward(dout=dh, cache=h_conv_cache)\n",
    "            dh += dy\n",
    "            g.append(dict(\n",
    "                    W2=dw2,\n",
    "                    b2=db2\n",
    "                    ))\n",
    "            \n",
    "        # 1st layer: Input layer X\n",
    "        X_conv_cache = X_cache\n",
    "        dX, dw1, db1 = l.conv_backward(dout=dh, cache=X_conv_cache)\n",
    "\n",
    "        # grad for GD\n",
    "        grad = []\n",
    "        \n",
    "        # Input layer to conv layer\n",
    "        grad.append(dict(\n",
    "            W1=dw1, \n",
    "            b1=db1\n",
    "        ))\n",
    "        \n",
    "        # Hidden layers of conv-bn-nl/relu-dropout/do\n",
    "        grad.append(g)\n",
    "        \n",
    "        # Output later to FC layer\n",
    "        grad.append(dict(\n",
    "            W3=dw3, \n",
    "            b3=db3\n",
    "        ))\n",
    "        \n",
    "        return dX, grad\n",
    "    \n",
    "    def test(self, X):\n",
    "        y_logit, cache = self.forward(X, train=False)\n",
    "        y_prob = l.softmax(y_logit)\n",
    "        if self.mode == 'classification':\n",
    "            return np.argmax(y_prob, axis=1)\n",
    "        else: # self.mode == 'regression'\n",
    "            return np.round(y_logit)\n",
    "        \n",
    "    def get_minibatch(self, X, y, minibatch_size, shuffle):\n",
    "        minibatches = []\n",
    "\n",
    "        if shuffle:\n",
    "            X, y = skshuffle(X, y)\n",
    "\n",
    "        for i in range(0, X.shape[0], minibatch_size):\n",
    "            X_mini = X[i:i + minibatch_size]\n",
    "            y_mini = y[i:i + minibatch_size]\n",
    "            minibatches.append((X_mini, y_mini))\n",
    "\n",
    "        return minibatches\n",
    "\n",
    "    def adam(self, X_train, y_train, val_set, alpha, mb_size, n_iter, print_after):\n",
    "        if val_set:\n",
    "            X_val, y_val = val_set\n",
    "\n",
    "        M, R = [], []\n",
    "        M.append({key: np.zeros_like(val) for key, val in self.model[0].items()})\n",
    "        R.append({key: np.zeros_like(val) for key, val in self.model[0].items()})\n",
    "\n",
    "        M_, R_ = [], []\n",
    "        for layer in range(self.L):\n",
    "            M_.append({key: np.zeros_like(val) for key, val in self.model[1][layer].items()})\n",
    "            R_.append({key: np.zeros_like(val) for key, val in self.model[1][layer].items()})\n",
    "        M.append(M_)\n",
    "        R.append(R_)\n",
    "\n",
    "        M.append({key: np.zeros_like(val) for key, val in self.model[2].items()})\n",
    "        R.append({key: np.zeros_like(val) for key, val in self.model[2].items()})\n",
    "\n",
    "        beta1 = .99\n",
    "        beta2 = .999\n",
    "        smooth_train = 1.\n",
    "\n",
    "        # Epochs\n",
    "        for iter in range(1, n_iter + 1):\n",
    "\n",
    "            # Minibatches\n",
    "            #         \"\"\"\n",
    "            #         Single training step over minibatch: forward, loss, backprop\n",
    "            #         \"\"\"\n",
    "            # Shuffle for each epochs/ stochasticity/ randomly choosing\n",
    "            #             for idx in range(len(minibatches)):\n",
    "            #             for _ in range(10):\n",
    "            minibatches = self.get_minibatch(X_train, y_train, mb_size, shuffle=True)\n",
    "            idx = np.random.randint(0, len(minibatches))\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            y, cache = self.forward(X_mini, train=True)\n",
    "            loss, dy = self.loss_function(y, y_mini)\n",
    "            _, grad = self.backward(dy, cache)\n",
    "            self.losses['train'].append(loss)\n",
    "            smooth_train = (0.999 * smooth_train) + (0.001 * loss)\n",
    "            self.losses['smooth train'].append(smooth_train)\n",
    "\n",
    "            for key in grad[0]:\n",
    "                M[0][key] = l.exp_running_avg(M[0][key], grad[0][key], beta1)\n",
    "                R[0][key] = l.exp_running_avg(R[0][key], grad[0][key]**2, beta2)\n",
    "\n",
    "                m_k_hat = M[0][key] / (1. - (beta1**(iter)))\n",
    "                r_k_hat = R[0][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                self.model[0][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + l.eps)\n",
    "\n",
    "            for layer in range(self.L):\n",
    "                for key in grad[1][layer]:\n",
    "                    M[1][layer][key] = l.exp_running_avg(M[1][layer][key], grad[1][layer][key], beta1)\n",
    "                    R[1][layer][key] = l.exp_running_avg(R[1][layer][key], grad[1][layer][key]**2, beta2)\n",
    "\n",
    "                    m_k_hat = M[1][layer][key] / (1. - (beta1**(iter)))\n",
    "                    r_k_hat = R[1][layer][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                    self.model[1][layer][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + l.eps)\n",
    "\n",
    "            for key in grad[2]:\n",
    "                M[2][key] = l.exp_running_avg(M[2][key], grad[2][key], beta1)\n",
    "                R[2][key] = l.exp_running_avg(R[2][key], grad[2][key]**2, beta2)\n",
    "\n",
    "                m_k_hat = M[2][key] / (1. - (beta1**(iter)))\n",
    "                r_k_hat = R[2][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                self.model[2][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + l.eps)\n",
    "\n",
    "            # Epochs\n",
    "            if iter % print_after == 0:\n",
    "                if val_set:\n",
    "                    val_acc = l.accuracy(y_val, self.test(X_val))\n",
    "                    print('Iter-{} training loss: {:.4f} validation accuracy: {:4f}'.format(iter, loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1 training loss: 4.9490 validation accuracy: 0.099400\n",
      "Iter-2 training loss: 4.7768 validation accuracy: 0.102800\n",
      "Iter-3 training loss: 4.1257 validation accuracy: 0.107000\n",
      "Iter-4 training loss: 4.3070 validation accuracy: 0.108600\n",
      "Iter-5 training loss: 4.4215 validation accuracy: 0.111800\n",
      "Iter-6 training loss: 4.4410 validation accuracy: 0.114000\n",
      "Iter-7 training loss: 4.0530 validation accuracy: 0.118800\n",
      "Iter-8 training loss: 3.6373 validation accuracy: 0.122400\n",
      "Iter-9 training loss: 3.6851 validation accuracy: 0.126400\n",
      "Iter-10 training loss: 3.7518 validation accuracy: 0.133000\n",
      "Iter-11 training loss: 3.8301 validation accuracy: 0.137800\n",
      "Iter-12 training loss: 3.9978 validation accuracy: 0.143000\n",
      "Iter-13 training loss: 3.7776 validation accuracy: 0.150800\n",
      "Iter-14 training loss: 3.6619 validation accuracy: 0.156800\n",
      "Iter-15 training loss: 3.6769 validation accuracy: 0.166200\n",
      "Iter-16 training loss: 3.6105 validation accuracy: 0.174200\n",
      "Iter-17 training loss: 3.3981 validation accuracy: 0.180400\n",
      "Iter-18 training loss: 3.4920 validation accuracy: 0.189000\n",
      "Iter-19 training loss: 2.9650 validation accuracy: 0.196000\n",
      "Iter-20 training loss: 2.9768 validation accuracy: 0.203400\n",
      "Iter-21 training loss: 3.0982 validation accuracy: 0.211800\n",
      "Iter-22 training loss: 2.9553 validation accuracy: 0.221600\n",
      "Iter-23 training loss: 2.9453 validation accuracy: 0.231000\n",
      "Iter-24 training loss: 2.9266 validation accuracy: 0.241000\n",
      "Iter-25 training loss: 3.0295 validation accuracy: 0.251200\n",
      "Iter-26 training loss: 2.8978 validation accuracy: 0.260600\n",
      "Iter-27 training loss: 2.2986 validation accuracy: 0.269000\n",
      "Iter-28 training loss: 2.5187 validation accuracy: 0.282200\n",
      "Iter-29 training loss: 2.6502 validation accuracy: 0.296600\n",
      "Iter-30 training loss: 2.5917 validation accuracy: 0.306400\n",
      "Iter-31 training loss: 2.7847 validation accuracy: 0.316000\n",
      "Iter-32 training loss: 2.6876 validation accuracy: 0.329400\n",
      "Iter-33 training loss: 2.6510 validation accuracy: 0.342400\n",
      "Iter-34 training loss: 2.7112 validation accuracy: 0.353200\n",
      "Iter-35 training loss: 2.1023 validation accuracy: 0.364000\n",
      "Iter-36 training loss: 2.7482 validation accuracy: 0.374200\n",
      "Iter-37 training loss: 2.2498 validation accuracy: 0.386600\n",
      "Iter-38 training loss: 2.1272 validation accuracy: 0.395800\n",
      "Iter-39 training loss: 2.1233 validation accuracy: 0.403400\n",
      "Iter-40 training loss: 2.2354 validation accuracy: 0.412400\n",
      "Iter-41 training loss: 2.0130 validation accuracy: 0.422000\n",
      "Iter-42 training loss: 2.2086 validation accuracy: 0.431400\n",
      "Iter-43 training loss: 2.1269 validation accuracy: 0.441800\n",
      "Iter-44 training loss: 1.9333 validation accuracy: 0.453600\n",
      "Iter-45 training loss: 1.6808 validation accuracy: 0.465800\n",
      "Iter-46 training loss: 1.8307 validation accuracy: 0.471000\n",
      "Iter-47 training loss: 1.8560 validation accuracy: 0.480000\n",
      "Iter-48 training loss: 1.5954 validation accuracy: 0.489200\n",
      "Iter-49 training loss: 2.1611 validation accuracy: 0.495600\n",
      "Iter-50 training loss: 1.6828 validation accuracy: 0.504200\n",
      "Iter-51 training loss: 1.7022 validation accuracy: 0.512600\n",
      "Iter-52 training loss: 1.5182 validation accuracy: 0.518800\n",
      "Iter-53 training loss: 1.8127 validation accuracy: 0.527600\n",
      "Iter-54 training loss: 1.6184 validation accuracy: 0.535800\n",
      "Iter-55 training loss: 1.7378 validation accuracy: 0.543200\n",
      "Iter-56 training loss: 1.5956 validation accuracy: 0.550200\n",
      "Iter-57 training loss: 1.3652 validation accuracy: 0.555600\n",
      "Iter-58 training loss: 1.6268 validation accuracy: 0.561000\n",
      "Iter-59 training loss: 1.7641 validation accuracy: 0.568600\n",
      "Iter-60 training loss: 1.6017 validation accuracy: 0.573400\n",
      "Iter-61 training loss: 1.0333 validation accuracy: 0.579000\n",
      "Iter-62 training loss: 1.1811 validation accuracy: 0.586000\n",
      "Iter-63 training loss: 1.5597 validation accuracy: 0.591600\n",
      "Iter-64 training loss: 1.8076 validation accuracy: 0.596600\n",
      "Iter-65 training loss: 1.5530 validation accuracy: 0.600200\n",
      "Iter-66 training loss: 1.3986 validation accuracy: 0.605600\n",
      "Iter-67 training loss: 1.6321 validation accuracy: 0.609600\n",
      "Iter-68 training loss: 1.5863 validation accuracy: 0.615800\n",
      "Iter-69 training loss: 0.9795 validation accuracy: 0.620800\n",
      "Iter-70 training loss: 1.2790 validation accuracy: 0.624800\n",
      "Iter-71 training loss: 1.6081 validation accuracy: 0.630000\n",
      "Iter-72 training loss: 1.3156 validation accuracy: 0.633800\n",
      "Iter-73 training loss: 1.4175 validation accuracy: 0.637800\n",
      "Iter-74 training loss: 1.0534 validation accuracy: 0.641800\n",
      "Iter-75 training loss: 1.0761 validation accuracy: 0.647000\n",
      "Iter-76 training loss: 0.8437 validation accuracy: 0.650400\n",
      "Iter-77 training loss: 1.1997 validation accuracy: 0.653000\n",
      "Iter-78 training loss: 1.2237 validation accuracy: 0.656200\n",
      "Iter-79 training loss: 1.4841 validation accuracy: 0.660400\n",
      "Iter-80 training loss: 1.7146 validation accuracy: 0.664800\n",
      "Iter-81 training loss: 1.3135 validation accuracy: 0.669200\n",
      "Iter-82 training loss: 1.0213 validation accuracy: 0.672400\n",
      "Iter-83 training loss: 1.3429 validation accuracy: 0.676800\n",
      "Iter-84 training loss: 1.5417 validation accuracy: 0.681000\n",
      "Iter-85 training loss: 0.9502 validation accuracy: 0.685000\n",
      "Iter-86 training loss: 1.1560 validation accuracy: 0.688200\n",
      "Iter-87 training loss: 1.3360 validation accuracy: 0.691600\n",
      "Iter-88 training loss: 1.2041 validation accuracy: 0.693600\n",
      "Iter-89 training loss: 1.1685 validation accuracy: 0.695000\n",
      "Iter-90 training loss: 1.0101 validation accuracy: 0.698400\n",
      "Iter-91 training loss: 1.1362 validation accuracy: 0.701600\n",
      "Iter-92 training loss: 1.1241 validation accuracy: 0.704200\n",
      "Iter-93 training loss: 1.2285 validation accuracy: 0.705600\n",
      "Iter-94 training loss: 1.0223 validation accuracy: 0.708400\n",
      "Iter-95 training loss: 1.0662 validation accuracy: 0.712200\n",
      "Iter-96 training loss: 0.9649 validation accuracy: 0.715000\n",
      "Iter-97 training loss: 1.2311 validation accuracy: 0.717800\n",
      "Iter-98 training loss: 0.7501 validation accuracy: 0.720800\n",
      "Iter-99 training loss: 0.8960 validation accuracy: 0.723000\n",
      "Iter-100 training loss: 0.7877 validation accuracy: 0.724800\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122af26a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "n_iter = 100 # number of epochs\n",
    "alpha = 1e-4 # learning_rate\n",
    "mb_size = 64 # 2**10==1024 # width, timestep for sequential data or minibatch size\n",
    "num_layers = 20 # depth \n",
    "print_after = 1 # n_iter//10 # print loss for train, valid, and test\n",
    "num_hidden_units = 4\n",
    "p_dropout = 0.95 #  keep_prob = 1.0 - p_dropout, q = 1-p, q=0.95, o=0.05\n",
    "\n",
    "# build the model/NN and learn it: running session.\n",
    "nn = CNN(C=C, D=D, H=num_hidden_units, p_dropout=p_dropout, L=num_layers)\n",
    "\n",
    "nn.adam(X_train=X_train, y_train=y_train, val_set=(X_val, y_val), mb_size=mb_size, alpha=alpha, \n",
    "           n_iter=n_iter, print_after=print_after)\n",
    "\n",
    "# # Kernel dead problem\n",
    "# y_pred = nn.test(X_test)\n",
    "# accs = np.mean(y_pred == y_test)\n",
    "# print('Test Mean accuracy: {:.4f}, std: {:.4f}'.format(accs.mean(), accs.std()))\n",
    "\n",
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(nn.losses['train'], label='Train loss')\n",
    "# plt.plot(nn.losses['smooth train'], label='Train smooth loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1 training loss: 4.3135 validation accuracy: 0.037000\n",
      "Iter-2 training loss: 4.8087 validation accuracy: 0.046000\n",
      "Iter-3 training loss: 3.8557 validation accuracy: 0.054800\n",
      "Iter-4 training loss: 3.6322 validation accuracy: 0.060000\n",
      "Iter-5 training loss: 3.9788 validation accuracy: 0.069600\n",
      "Iter-6 training loss: 3.6795 validation accuracy: 0.077600\n",
      "Iter-7 training loss: 3.8124 validation accuracy: 0.088800\n",
      "Iter-8 training loss: 3.6667 validation accuracy: 0.099800\n",
      "Iter-9 training loss: 4.0479 validation accuracy: 0.111800\n",
      "Iter-10 training loss: 3.7656 validation accuracy: 0.125600\n",
      "Iter-11 training loss: 3.0473 validation accuracy: 0.140800\n",
      "Iter-12 training loss: 3.5275 validation accuracy: 0.152600\n",
      "Iter-13 training loss: 3.1857 validation accuracy: 0.165200\n",
      "Iter-14 training loss: 3.6096 validation accuracy: 0.176600\n",
      "Iter-15 training loss: 3.2929 validation accuracy: 0.185800\n",
      "Iter-16 training loss: 2.7087 validation accuracy: 0.198400\n",
      "Iter-17 training loss: 3.0986 validation accuracy: 0.211000\n",
      "Iter-18 training loss: 3.2938 validation accuracy: 0.219600\n",
      "Iter-19 training loss: 3.3397 validation accuracy: 0.230400\n",
      "Iter-20 training loss: 2.7864 validation accuracy: 0.240200\n",
      "Iter-21 training loss: 2.8017 validation accuracy: 0.251000\n",
      "Iter-22 training loss: 2.8098 validation accuracy: 0.261600\n",
      "Iter-23 training loss: 2.5773 validation accuracy: 0.272800\n",
      "Iter-24 training loss: 2.6681 validation accuracy: 0.283200\n",
      "Iter-25 training loss: 2.5402 validation accuracy: 0.292400\n",
      "Iter-26 training loss: 2.1314 validation accuracy: 0.304800\n",
      "Iter-27 training loss: 2.5868 validation accuracy: 0.313200\n",
      "Iter-28 training loss: 2.2078 validation accuracy: 0.323200\n",
      "Iter-29 training loss: 2.0475 validation accuracy: 0.332800\n",
      "Iter-30 training loss: 2.2934 validation accuracy: 0.343800\n",
      "Iter-31 training loss: 1.7846 validation accuracy: 0.354600\n",
      "Iter-32 training loss: 1.9248 validation accuracy: 0.363600\n",
      "Iter-33 training loss: 2.1145 validation accuracy: 0.376400\n",
      "Iter-34 training loss: 2.3949 validation accuracy: 0.390000\n",
      "Iter-35 training loss: 2.4030 validation accuracy: 0.399200\n",
      "Iter-36 training loss: 1.9803 validation accuracy: 0.409200\n",
      "Iter-37 training loss: 2.1368 validation accuracy: 0.419200\n",
      "Iter-38 training loss: 2.0523 validation accuracy: 0.431800\n",
      "Iter-39 training loss: 2.0509 validation accuracy: 0.444200\n",
      "Iter-40 training loss: 1.9813 validation accuracy: 0.455200\n",
      "Iter-41 training loss: 1.8673 validation accuracy: 0.464800\n",
      "Iter-42 training loss: 1.9181 validation accuracy: 0.476200\n",
      "Iter-43 training loss: 1.6712 validation accuracy: 0.486400\n",
      "Iter-44 training loss: 1.5562 validation accuracy: 0.494800\n",
      "Iter-45 training loss: 1.7888 validation accuracy: 0.506000\n",
      "Iter-46 training loss: 1.9891 validation accuracy: 0.514600\n",
      "Iter-47 training loss: 1.3992 validation accuracy: 0.526200\n",
      "Iter-48 training loss: 1.4534 validation accuracy: 0.536200\n",
      "Iter-49 training loss: 1.6360 validation accuracy: 0.546000\n",
      "Iter-50 training loss: 1.5421 validation accuracy: 0.558400\n",
      "Iter-51 training loss: 1.5472 validation accuracy: 0.565000\n",
      "Iter-52 training loss: 1.2105 validation accuracy: 0.572400\n",
      "Iter-53 training loss: 1.4537 validation accuracy: 0.582200\n",
      "Iter-54 training loss: 1.3346 validation accuracy: 0.590400\n",
      "Iter-55 training loss: 1.4366 validation accuracy: 0.598000\n",
      "Iter-56 training loss: 1.1549 validation accuracy: 0.605000\n",
      "Iter-57 training loss: 1.3576 validation accuracy: 0.611400\n",
      "Iter-58 training loss: 1.5255 validation accuracy: 0.618400\n",
      "Iter-59 training loss: 1.4953 validation accuracy: 0.624400\n",
      "Iter-60 training loss: 1.3631 validation accuracy: 0.630200\n",
      "Iter-61 training loss: 1.1863 validation accuracy: 0.635800\n",
      "Iter-62 training loss: 1.2392 validation accuracy: 0.641600\n",
      "Iter-63 training loss: 1.4943 validation accuracy: 0.647200\n",
      "Iter-64 training loss: 1.1808 validation accuracy: 0.652800\n",
      "Iter-65 training loss: 1.1536 validation accuracy: 0.657400\n",
      "Iter-66 training loss: 1.0415 validation accuracy: 0.663800\n",
      "Iter-67 training loss: 1.3798 validation accuracy: 0.668200\n",
      "Iter-68 training loss: 1.1338 validation accuracy: 0.674200\n",
      "Iter-69 training loss: 0.9934 validation accuracy: 0.677600\n",
      "Iter-70 training loss: 1.2433 validation accuracy: 0.681400\n",
      "Iter-71 training loss: 1.0300 validation accuracy: 0.684800\n",
      "Iter-72 training loss: 0.9892 validation accuracy: 0.689600\n",
      "Iter-73 training loss: 0.8411 validation accuracy: 0.692200\n",
      "Iter-74 training loss: 1.0121 validation accuracy: 0.696600\n",
      "Iter-75 training loss: 0.9389 validation accuracy: 0.700600\n",
      "Iter-76 training loss: 0.9615 validation accuracy: 0.703200\n",
      "Iter-77 training loss: 1.1719 validation accuracy: 0.706400\n",
      "Iter-78 training loss: 0.9238 validation accuracy: 0.710800\n",
      "Iter-79 training loss: 1.0559 validation accuracy: 0.714400\n",
      "Iter-80 training loss: 1.1507 validation accuracy: 0.716600\n",
      "Iter-81 training loss: 0.9010 validation accuracy: 0.718600\n",
      "Iter-82 training loss: 1.0166 validation accuracy: 0.722800\n",
      "Iter-83 training loss: 1.1221 validation accuracy: 0.726800\n",
      "Iter-84 training loss: 0.5403 validation accuracy: 0.730600\n",
      "Iter-85 training loss: 0.8767 validation accuracy: 0.731400\n",
      "Iter-86 training loss: 1.1358 validation accuracy: 0.733800\n",
      "Iter-87 training loss: 1.0194 validation accuracy: 0.736400\n",
      "Iter-88 training loss: 1.1877 validation accuracy: 0.737400\n",
      "Iter-89 training loss: 0.9547 validation accuracy: 0.740000\n",
      "Iter-90 training loss: 1.0514 validation accuracy: 0.742600\n",
      "Iter-91 training loss: 0.7251 validation accuracy: 0.743600\n",
      "Iter-92 training loss: 0.9189 validation accuracy: 0.745400\n",
      "Iter-93 training loss: 0.8965 validation accuracy: 0.747600\n",
      "Iter-94 training loss: 0.9622 validation accuracy: 0.749400\n",
      "Iter-95 training loss: 0.7462 validation accuracy: 0.749200\n",
      "Iter-96 training loss: 0.7568 validation accuracy: 0.751200\n",
      "Iter-97 training loss: 0.7673 validation accuracy: 0.753200\n",
      "Iter-98 training loss: 0.8534 validation accuracy: 0.755200\n",
      "Iter-99 training loss: 0.7222 validation accuracy: 0.758000\n",
      "Iter-100 training loss: 0.7362 validation accuracy: 0.760600\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122afe4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Hyper-parameters\n",
    "# n_iter = 100 # number of epochs\n",
    "# alpha = 1e-4 # learning_rate\n",
    "# mb_size = 64 # 2**10==1024 # width, timestep for sequential data or minibatch size\n",
    "# num_layers = 10 # depth \n",
    "# print_after = 1 # n_iter//10 # print loss for train, valid, and test\n",
    "# num_hidden_units = 4\n",
    "# p_dropout = 0.95 #  keep_prob = 1.0 - p_dropout, q = 1-p, q=0.95, o=0.05\n",
    "\n",
    "# # build the model/NN and learn it: running session.\n",
    "# nn = CNN(C=C, D=D, H=num_hidden_units, p_dropout=p_dropout, L=num_layers)\n",
    "\n",
    "# nn.adam(X_train=X_train, y_train=y_train, val_set=(X_val, y_val), mb_size=mb_size, alpha=alpha, \n",
    "#            n_iter=n_iter, print_after=print_after)\n",
    "\n",
    "# # # Kernel dead problem\n",
    "# # y_pred = nn.test(X_test)\n",
    "# # accs = np.mean(y_pred == y_test)\n",
    "# # print('Test Mean accuracy: {:.4f}, std: {:.4f}'.format(accs.mean(), accs.std()))\n",
    "\n",
    "# # # Display the learning curve and losses for training, validation, and testing\n",
    "# # %matplotlib inline\n",
    "# # %config InlineBackend.figure_format = 'retina'\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(nn.losses['train'], label='Train loss')\n",
    "# # plt.plot(nn.losses['smooth train'], label='Train smooth loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
