{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import impl.layer as l\n",
    "\n",
    "# Dataset preparation and pre-processing\n",
    "mnist = input_data.read_data_sets('data/MNIST_data/', one_hot=False)\n",
    "\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "# y_test.shape, y_val.shape, y_train.shape\n",
    "# X_train.shape, X_train.dtype, X_val.shape, X_val.dtype, X_test.shape, X_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-processing: normalizing\n",
    "def normalize(X):\n",
    "    # max scale for images 255= 2**8= 8 bit grayscale for each channel\n",
    "    return (X - X.mean(axis=0)) #/ X.std(axis=0)\n",
    "\n",
    "X_train, X_val, X_test = normalize(X=X_train), normalize(X=X_val), normalize(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l # or from impl.layer import *\n",
    "from impl.loss import * # import all functions from impl.loss file # import impl.loss as loss_func\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "class FFNN:\n",
    "\n",
    "    def __init__(self, D, C, H, L):\n",
    "        self.L = L # number of layers or depth\n",
    "        self.losses = {'train':[], 'valid':[], 'valid_acc':[]}\n",
    "        \n",
    "        # The adaptive/learnable/updatable random feedforward\n",
    "        self.model = []\n",
    "        self.W_fixed = []\n",
    "        self.grads = []\n",
    "        self.ys_prev = []\n",
    "        low, high = -1, 1\n",
    "        \n",
    "        # Input layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.), b=np.zeros((1, H)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Input layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[0].items()})\n",
    "        # Previous output layer\n",
    "        self.ys_prev.append(0.0)\n",
    "\n",
    "        # Hidden layers: weights/ biases\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = dict(W=np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, H)))\n",
    "            m_L.append(m)\n",
    "        self.model.append(m_L)\n",
    "        # Fixed feedback weight\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.)\n",
    "            m_L.append(m)\n",
    "        self.W_fixed.append(m_L)\n",
    "        # Hidden layer: gradients\n",
    "        grad_L = []\n",
    "        for _ in range(L):\n",
    "            grad_L.append({key: np.zeros_like(val) for key, val in self.model[1][0].items()})\n",
    "        self.grads.append(grad_L)\n",
    "        # Previous output layer\n",
    "        ys_prev_L = []\n",
    "        for _ in range(L):\n",
    "            ys_prev_L.append(0.0)\n",
    "        self.ys_prev.append(ys_prev_L)\n",
    "        \n",
    "        # Output layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, C)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Outout layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[2].items()})\n",
    "        # Previous output layer\n",
    "        self.ys_prev.append(0.0)\n",
    "        \n",
    "    def fc_forward(self, X, W, b):\n",
    "        out = (X @ W) + b\n",
    "        cache = (W, X)\n",
    "        return out, cache\n",
    "\n",
    "    def fc_backward(self, dout, cache, W_fixed):\n",
    "        W, X = cache\n",
    "\n",
    "        dW = X.T @ dout\n",
    "        db = np.sum(dout, axis=0).reshape(1, -1) # db_1xn\n",
    "        \n",
    "        # dX = dout @ W.T # Backprop\n",
    "        dX = dout @ W_fixed.T # fb alignment\n",
    "\n",
    "        return dX, dW, db\n",
    "\n",
    "    def train_forward(self, X):\n",
    "        caches, ys = [], []\n",
    "        \n",
    "        # Input layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[0]['W'], b=self.model[0]['b']) # X_1xD, y_1xc\n",
    "#         y = np.tanh(y)\n",
    "#         y, _ = l.relu_forward(X=y)\n",
    "#         y, _ = l.lrelu_forward(X=y)\n",
    "#         y = l.elu_fwd(X=y)\n",
    "        y, _ = l.softplus_forward(X=y)\n",
    "#         y, _ = l.selu_forward(X=y)\n",
    "#         y = np.exp(y) #/ np.exp(y).sum(axis=1).reshape(-1, 1) # txn\n",
    "#         y = l.sigmoid(X=y) # non-linearity\n",
    "        X = y.copy() # pass to the next layer\n",
    "        caches.append(fc_cache) # caches[0]\n",
    "        ys.append(y) # ys[0]\n",
    "        \n",
    "        # Hidden layers\n",
    "        fc_caches, ys_L = [], []\n",
    "        for layer in range(self.L):\n",
    "            y, fc_cache = self.fc_forward(X=X, W=self.model[1][layer]['W'], b=self.model[1][layer]['b'])\n",
    "#             y = np.tanh(y)\n",
    "#             y, _ = l.relu_forward(X=y)\n",
    "#             y, _ = l.lrelu_forward(X=y)\n",
    "#             y = l.elu_fwd(X=y)\n",
    "            y, _ = l.softplus_forward(X=y)\n",
    "#             y, _ = l.selu_forward(X=y)\n",
    "#             y = np.exp(y) #/ np.exp(y).sum(axis=1).reshape(-1, 1) # txn\n",
    "#             y = l.sigmoid(X=y) # non-linearity\n",
    "            X = y.copy() # pass to next layer\n",
    "            fc_caches.append(fc_cache)\n",
    "            ys_L.append(y) # ys[1][layer]\n",
    "        caches.append(fc_caches) # caches[1]\n",
    "        ys.append(ys_L) # ys[1]\n",
    "        \n",
    "        # Output layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[2]['W'], b=self.model[2]['b'])\n",
    "        caches.append(fc_cache) # caches[2]\n",
    "        ys.append(y) # ys[2]\n",
    "\n",
    "        return ys, caches\n",
    "\n",
    "    def loss_function(self, y, y_train):\n",
    "        \n",
    "        loss = cross_entropy(y, y_train) # softmax is included\n",
    "        dy = dcross_entropy(y, y_train) # dsoftmax is included\n",
    "        \n",
    "        return loss, dy\n",
    "        \n",
    "    def train_backward(self, dy, caches):\n",
    "        grads = self.grads # initialized by Zero in every iteration/epoch\n",
    "        \n",
    "        # Output layer\n",
    "        fc_cache = caches[2]\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[2])\n",
    "        dy = dX.copy()\n",
    "        grads[2]['W'] = dW\n",
    "        grads[2]['b'] = db\n",
    "\n",
    "        # Hidden layer\n",
    "        fc_caches = caches[1]\n",
    "        for layer in reversed(range(self.L)):\n",
    "#             dy = l.selu_backward(cache=nl_caches[layer], dout=dy)\n",
    "#             dy = np.exp(dy) #/ np.exp(dy).sum(axis=1).reshape(-1, 1) # txn\n",
    "            dy *= self.ys[1][layer] - self.ys_prev[1][layer] # function derivative or dfunc\n",
    "            dX, dW, db = self.fc_backward(dout=dy, cache=fc_caches[layer], W_fixed=self.W_fixed[1][layer])\n",
    "            dy = dX.copy()\n",
    "            grads[1][layer]['W'] = dW\n",
    "            grads[1][layer]['b'] = db\n",
    "        \n",
    "        # Input layer\n",
    "        fc_cache = caches[0]\n",
    "#         dy = l.selu_backward(cache=nl_cache, dout=dy)\n",
    "#         dy = np.exp(dy) #/ np.exp(dy).sum(axis=1).reshape(-1, 1) # txn\n",
    "        dy *= self.ys[0] - self.ys_prev[0]\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[0])\n",
    "        # dy = dX.copy()\n",
    "        grads[0]['W'] = dW\n",
    "        grads[0]['b'] = db\n",
    "\n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X):\n",
    "        ys_logit, _ = self.train_forward(X)\n",
    "        y_logit = ys_logit[2] # last layer\n",
    "        \n",
    "        # if self.mode == 'classification':\n",
    "        y_prob = l.softmax(y_logit) # for accuracy == acc\n",
    "        y_pred = np.argmax(y_prob, axis=1) # for loss ==err\n",
    "        \n",
    "        return y_pred, y_logit\n",
    "        \n",
    "    def get_minibatch(self, X, y, minibatch_size, shuffle):\n",
    "        minibatches = []\n",
    "\n",
    "        if shuffle:\n",
    "            X, y = skshuffle(X, y)\n",
    "\n",
    "        for i in range(0, X.shape[0], minibatch_size):\n",
    "            X_mini = X[i:i + minibatch_size]\n",
    "            y_mini = y[i:i + minibatch_size]\n",
    "            minibatches.append((X_mini, y_mini))\n",
    "\n",
    "        return minibatches\n",
    "\n",
    "    def sgd(self, train_set, val_set, alpha, mb_size, n_iter, print_after):\n",
    "        X_train, y_train = train_set\n",
    "        X_val, y_val = val_set\n",
    "\n",
    "        # Epochs\n",
    "        for iter in range(1, n_iter + 1):\n",
    "\n",
    "            # Minibatches\n",
    "            minibatches = self.get_minibatch(X_train, y_train, mb_size, shuffle=True)\n",
    "            idx = np.random.randint(0, len(minibatches))\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            \n",
    "            # Train the model\n",
    "            self.ys, caches = self.train_forward(X_mini)\n",
    "#             print(self.ys[2].shape)\n",
    "            loss, dy = self.loss_function(self.ys[2], y_mini)\n",
    "            _, grads = self.train_backward(dy, caches) # self.ys_prev is used here for dfunc/ diff\n",
    "            self.ys_prev = self.ys # for next iteration or epoch\n",
    "            self.losses['train'].append(loss)\n",
    "            \n",
    "            # Update the model for input layer\n",
    "            for key in grads[0].keys():\n",
    "                self.model[0][key] -= alpha * grads[0][key]\n",
    "\n",
    "            # Update the model for the hidden layers\n",
    "            for layer in range(self.L):\n",
    "                for key in grads[1][layer].keys():\n",
    "                    self.model[1][layer][key] -= alpha * grads[1][layer][key]\n",
    "\n",
    "            # Update the model for output layer\n",
    "            for key in grads[2].keys():\n",
    "                self.model[2][key] -= alpha * grads[2][key]\n",
    "                \n",
    "            # Validate the updated model\n",
    "            y_pred, y_logit = self.test(X_val)\n",
    "            valid_loss, _ = self.loss_function(y_logit, y_val) # softmax is included in entropy loss function\n",
    "            self.losses['valid'].append(valid_loss)\n",
    "            valid_acc = np.mean(y_pred == y_val) # confusion matrix\n",
    "            self.losses['valid_acc'].append(valid_acc)\n",
    "            \n",
    "            # Print the model info: loss & accuracy or err & acc\n",
    "            if iter % print_after == 0:\n",
    "                print('Iter-{} train loss: {:.4f} valid loss: {:.4f}, valid accuracy: {:.4f}'.format(\n",
    "                    iter, loss, valid_loss, valid_acc))\n",
    "\n",
    "        # Test the final model\n",
    "        y_pred, y_logit = nn.test(X_test)\n",
    "        loss, _ = self.loss_function(y_logit, y_test) # softmax is included in entropy loss function\n",
    "        acc = np.mean(y_pred == y_test)\n",
    "        print('Last iteration - Test accuracy mean: {:.4f}, std: {:.4f}, loss: {:.4f}'.format(\n",
    "            acc.mean(), acc.std(), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-10 train loss: 2.5654 valid loss: 2.4952, valid accuracy: 0.1070\n",
      "Iter-20 train loss: 2.5186 valid loss: 2.4828, valid accuracy: 0.1070\n",
      "Iter-30 train loss: 2.4126 valid loss: 2.4727, valid accuracy: 0.1070\n",
      "Iter-40 train loss: 2.3790 valid loss: 2.4628, valid accuracy: 0.1070\n",
      "Iter-50 train loss: 2.2923 valid loss: 2.4548, valid accuracy: 0.1070\n",
      "Iter-60 train loss: 2.3851 valid loss: 2.4473, valid accuracy: 0.1070\n",
      "Iter-70 train loss: 2.3240 valid loss: 2.4402, valid accuracy: 0.1070\n",
      "Iter-80 train loss: 2.4803 valid loss: 2.4326, valid accuracy: 0.1070\n",
      "Iter-90 train loss: 2.5293 valid loss: 2.4255, valid accuracy: 0.1070\n",
      "Iter-100 train loss: 2.3658 valid loss: 2.4199, valid accuracy: 0.1070\n",
      "Iter-110 train loss: 2.4016 valid loss: 2.4140, valid accuracy: 0.1070\n",
      "Iter-120 train loss: 2.3816 valid loss: 2.4085, valid accuracy: 0.1070\n",
      "Iter-130 train loss: 2.3766 valid loss: 2.4031, valid accuracy: 0.1070\n",
      "Iter-140 train loss: 2.3610 valid loss: 2.3979, valid accuracy: 0.1070\n",
      "Iter-150 train loss: 2.4833 valid loss: 2.3928, valid accuracy: 0.1070\n",
      "Iter-160 train loss: 2.3183 valid loss: 2.3883, valid accuracy: 0.1070\n",
      "Iter-170 train loss: 2.4328 valid loss: 2.3845, valid accuracy: 0.1070\n",
      "Iter-180 train loss: 2.3479 valid loss: 2.3810, valid accuracy: 0.1070\n",
      "Iter-190 train loss: 2.4700 valid loss: 2.3774, valid accuracy: 0.1070\n",
      "Iter-200 train loss: 2.4143 valid loss: 2.3740, valid accuracy: 0.1070\n",
      "Iter-210 train loss: 2.4368 valid loss: 2.3699, valid accuracy: 0.1070\n",
      "Iter-220 train loss: 2.3182 valid loss: 2.3669, valid accuracy: 0.1070\n",
      "Iter-230 train loss: 2.3860 valid loss: 2.3643, valid accuracy: 0.1070\n",
      "Iter-240 train loss: 2.4156 valid loss: 2.3615, valid accuracy: 0.1070\n",
      "Iter-250 train loss: 2.4088 valid loss: 2.3589, valid accuracy: 0.1070\n",
      "Iter-260 train loss: 2.2719 valid loss: 2.3567, valid accuracy: 0.1070\n",
      "Iter-270 train loss: 2.2826 valid loss: 2.3546, valid accuracy: 0.1070\n",
      "Iter-280 train loss: 2.4051 valid loss: 2.3523, valid accuracy: 0.1070\n",
      "Iter-290 train loss: 2.3124 valid loss: 2.3504, valid accuracy: 0.1070\n",
      "Iter-300 train loss: 2.3848 valid loss: 2.3479, valid accuracy: 0.1070\n",
      "Iter-310 train loss: 2.2538 valid loss: 2.3460, valid accuracy: 0.1070\n",
      "Iter-320 train loss: 2.3741 valid loss: 2.3441, valid accuracy: 0.1070\n",
      "Iter-330 train loss: 2.3317 valid loss: 2.3419, valid accuracy: 0.1070\n",
      "Iter-340 train loss: 2.3082 valid loss: 2.3402, valid accuracy: 0.1070\n",
      "Iter-350 train loss: 2.2926 valid loss: 2.3387, valid accuracy: 0.1070\n",
      "Iter-360 train loss: 2.2903 valid loss: 2.3372, valid accuracy: 0.1070\n",
      "Iter-370 train loss: 2.3374 valid loss: 2.3360, valid accuracy: 0.1070\n",
      "Iter-380 train loss: 2.3422 valid loss: 2.3345, valid accuracy: 0.1070\n",
      "Iter-390 train loss: 2.3507 valid loss: 2.3327, valid accuracy: 0.1070\n",
      "Iter-400 train loss: 2.3749 valid loss: 2.3312, valid accuracy: 0.1070\n",
      "Iter-410 train loss: 2.3215 valid loss: 2.3299, valid accuracy: 0.1070\n",
      "Iter-420 train loss: 2.3420 valid loss: 2.3286, valid accuracy: 0.1070\n",
      "Iter-430 train loss: 2.3234 valid loss: 2.3273, valid accuracy: 0.1070\n",
      "Iter-440 train loss: 2.3005 valid loss: 2.3264, valid accuracy: 0.1070\n",
      "Iter-450 train loss: 2.3105 valid loss: 2.3252, valid accuracy: 0.1070\n",
      "Iter-460 train loss: 2.3181 valid loss: 2.3245, valid accuracy: 0.1070\n",
      "Iter-470 train loss: 2.3266 valid loss: 2.3236, valid accuracy: 0.1070\n",
      "Iter-480 train loss: 2.2770 valid loss: 2.3228, valid accuracy: 0.1070\n",
      "Iter-490 train loss: 2.3009 valid loss: 2.3219, valid accuracy: 0.1070\n",
      "Iter-500 train loss: 2.3267 valid loss: 2.3207, valid accuracy: 0.1070\n",
      "Iter-510 train loss: 2.3049 valid loss: 2.3199, valid accuracy: 0.1070\n",
      "Iter-520 train loss: 2.3285 valid loss: 2.3193, valid accuracy: 0.1070\n",
      "Iter-530 train loss: 2.3632 valid loss: 2.3185, valid accuracy: 0.1070\n",
      "Iter-540 train loss: 2.2949 valid loss: 2.3179, valid accuracy: 0.1070\n",
      "Iter-550 train loss: 2.3167 valid loss: 2.3174, valid accuracy: 0.1070\n",
      "Iter-560 train loss: 2.3065 valid loss: 2.3168, valid accuracy: 0.1070\n",
      "Iter-570 train loss: 2.3240 valid loss: 2.3160, valid accuracy: 0.1070\n",
      "Iter-580 train loss: 2.3186 valid loss: 2.3154, valid accuracy: 0.1070\n",
      "Iter-590 train loss: 2.3289 valid loss: 2.3146, valid accuracy: 0.1070\n",
      "Iter-600 train loss: 2.3262 valid loss: 2.3141, valid accuracy: 0.1070\n",
      "Iter-610 train loss: 2.3199 valid loss: 2.3137, valid accuracy: 0.1070\n",
      "Iter-620 train loss: 2.2945 valid loss: 2.3132, valid accuracy: 0.1070\n",
      "Iter-630 train loss: 2.3363 valid loss: 2.3126, valid accuracy: 0.1070\n",
      "Iter-640 train loss: 2.2875 valid loss: 2.3119, valid accuracy: 0.1070\n",
      "Iter-650 train loss: 2.3064 valid loss: 2.3116, valid accuracy: 0.1070\n",
      "Iter-660 train loss: 2.3160 valid loss: 2.3114, valid accuracy: 0.1070\n",
      "Iter-670 train loss: 2.3479 valid loss: 2.3108, valid accuracy: 0.1070\n",
      "Iter-680 train loss: 2.3128 valid loss: 2.3102, valid accuracy: 0.1070\n",
      "Iter-690 train loss: 2.3029 valid loss: 2.3096, valid accuracy: 0.1070\n",
      "Iter-700 train loss: 2.3154 valid loss: 2.3094, valid accuracy: 0.1070\n",
      "Iter-710 train loss: 2.3183 valid loss: 2.3089, valid accuracy: 0.1070\n",
      "Iter-720 train loss: 2.3036 valid loss: 2.3086, valid accuracy: 0.1070\n",
      "Iter-730 train loss: 2.3282 valid loss: 2.3081, valid accuracy: 0.1070\n",
      "Iter-740 train loss: 2.3047 valid loss: 2.3079, valid accuracy: 0.1070\n",
      "Iter-750 train loss: 2.3199 valid loss: 2.3077, valid accuracy: 0.1070\n",
      "Iter-760 train loss: 2.3044 valid loss: 2.3073, valid accuracy: 0.1070\n",
      "Iter-770 train loss: 2.2973 valid loss: 2.3069, valid accuracy: 0.1070\n",
      "Iter-780 train loss: 2.2842 valid loss: 2.3067, valid accuracy: 0.1070\n",
      "Iter-790 train loss: 2.3023 valid loss: 2.3064, valid accuracy: 0.1070\n",
      "Iter-800 train loss: 2.3338 valid loss: 2.3062, valid accuracy: 0.1070\n",
      "Iter-810 train loss: 2.3137 valid loss: 2.3061, valid accuracy: 0.1070\n",
      "Iter-820 train loss: 2.2867 valid loss: 2.3060, valid accuracy: 0.1070\n",
      "Iter-830 train loss: 2.2960 valid loss: 2.3058, valid accuracy: 0.1070\n",
      "Iter-840 train loss: 2.3228 valid loss: 2.3056, valid accuracy: 0.1070\n",
      "Iter-850 train loss: 2.3073 valid loss: 2.3054, valid accuracy: 0.1070\n",
      "Iter-860 train loss: 2.3299 valid loss: 2.3049, valid accuracy: 0.1070\n",
      "Iter-870 train loss: 2.3156 valid loss: 2.3046, valid accuracy: 0.1070\n",
      "Iter-880 train loss: 2.2876 valid loss: 2.3044, valid accuracy: 0.1070\n",
      "Iter-890 train loss: 2.3007 valid loss: 2.3043, valid accuracy: 0.1070\n",
      "Iter-900 train loss: 2.3052 valid loss: 2.3042, valid accuracy: 0.1070\n",
      "Iter-910 train loss: 2.3045 valid loss: 2.3041, valid accuracy: 0.1070\n",
      "Iter-920 train loss: 2.3032 valid loss: 2.3039, valid accuracy: 0.1070\n",
      "Iter-930 train loss: 2.2964 valid loss: 2.3037, valid accuracy: 0.1070\n",
      "Iter-940 train loss: 2.2865 valid loss: 2.3036, valid accuracy: 0.1126\n",
      "Iter-950 train loss: 2.3145 valid loss: 2.3033, valid accuracy: 0.1126\n",
      "Iter-960 train loss: 2.3051 valid loss: 2.3032, valid accuracy: 0.1126\n",
      "Iter-970 train loss: 2.3116 valid loss: 2.3030, valid accuracy: 0.1126\n",
      "Iter-980 train loss: 2.3120 valid loss: 2.3027, valid accuracy: 0.1126\n",
      "Iter-990 train loss: 2.3016 valid loss: 2.3027, valid accuracy: 0.1126\n",
      "Iter-1000 train loss: 2.3211 valid loss: 2.3027, valid accuracy: 0.1126\n",
      "Iter-1010 train loss: 2.3142 valid loss: 2.3027, valid accuracy: 0.1126\n",
      "Iter-1020 train loss: 2.3109 valid loss: 2.3026, valid accuracy: 0.1126\n",
      "Iter-1030 train loss: 2.3097 valid loss: 2.3024, valid accuracy: 0.1126\n",
      "Iter-1040 train loss: 2.2824 valid loss: 2.3024, valid accuracy: 0.1126\n",
      "Iter-1050 train loss: 2.3042 valid loss: 2.3024, valid accuracy: 0.1126\n",
      "Iter-1060 train loss: 2.3093 valid loss: 2.3022, valid accuracy: 0.1126\n",
      "Iter-1070 train loss: 2.3124 valid loss: 2.3021, valid accuracy: 0.1126\n",
      "Iter-1080 train loss: 2.2962 valid loss: 2.3020, valid accuracy: 0.1126\n",
      "Iter-1090 train loss: 2.3037 valid loss: 2.3020, valid accuracy: 0.1126\n",
      "Iter-1100 train loss: 2.3031 valid loss: 2.3020, valid accuracy: 0.1126\n",
      "Iter-1110 train loss: 2.2906 valid loss: 2.3019, valid accuracy: 0.1126\n",
      "Iter-1120 train loss: 2.2937 valid loss: 2.3018, valid accuracy: 0.1126\n",
      "Iter-1130 train loss: 2.2941 valid loss: 2.3017, valid accuracy: 0.1126\n",
      "Iter-1140 train loss: 2.3004 valid loss: 2.3017, valid accuracy: 0.1126\n",
      "Iter-1150 train loss: 2.3007 valid loss: 2.3016, valid accuracy: 0.1126\n",
      "Iter-1160 train loss: 2.3016 valid loss: 2.3015, valid accuracy: 0.1126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1170 train loss: 2.3081 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-1180 train loss: 2.2965 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-1190 train loss: 2.2962 valid loss: 2.3016, valid accuracy: 0.1126\n",
      "Iter-1200 train loss: 2.2950 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-1210 train loss: 2.2999 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-1220 train loss: 2.3044 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-1230 train loss: 2.3004 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-1240 train loss: 2.3060 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-1250 train loss: 2.2997 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-1260 train loss: 2.3019 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-1270 train loss: 2.2929 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-1280 train loss: 2.3143 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-1290 train loss: 2.3023 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-1300 train loss: 2.2953 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-1310 train loss: 2.3044 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-1320 train loss: 2.3071 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1330 train loss: 2.2905 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1340 train loss: 2.3001 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-1350 train loss: 2.3040 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-1360 train loss: 2.3031 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1370 train loss: 2.2926 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1380 train loss: 2.2772 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1390 train loss: 2.3099 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1400 train loss: 2.2994 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1410 train loss: 2.3103 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1420 train loss: 2.3056 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1430 train loss: 2.2937 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1440 train loss: 2.2934 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1450 train loss: 2.3021 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1460 train loss: 2.2923 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1470 train loss: 2.3071 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-1480 train loss: 2.3117 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1490 train loss: 2.3101 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-1500 train loss: 2.3083 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1510 train loss: 2.2959 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1520 train loss: 2.2899 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1530 train loss: 2.2899 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1540 train loss: 2.3021 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-1550 train loss: 2.3169 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-1560 train loss: 2.2879 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-1570 train loss: 2.2890 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-1580 train loss: 2.3089 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-1590 train loss: 2.2964 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1600 train loss: 2.3037 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1610 train loss: 2.3044 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1620 train loss: 2.3059 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1630 train loss: 2.3113 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1640 train loss: 2.3142 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1650 train loss: 2.2947 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1660 train loss: 2.3006 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1670 train loss: 2.3057 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1680 train loss: 2.2997 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1690 train loss: 2.2975 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1700 train loss: 2.2872 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1710 train loss: 2.3083 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1720 train loss: 2.3135 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1730 train loss: 2.2877 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1740 train loss: 2.3042 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1750 train loss: 2.2973 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1760 train loss: 2.3020 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1770 train loss: 2.2844 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1780 train loss: 2.2955 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1790 train loss: 2.2990 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-1800 train loss: 2.2957 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1810 train loss: 2.2979 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1820 train loss: 2.2858 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1830 train loss: 2.3106 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1840 train loss: 2.2940 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1850 train loss: 2.2973 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1860 train loss: 2.3057 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1870 train loss: 2.3027 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1880 train loss: 2.3021 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1890 train loss: 2.2973 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1900 train loss: 2.2963 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1910 train loss: 2.2987 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1920 train loss: 2.3126 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1930 train loss: 2.3178 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1940 train loss: 2.3056 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1950 train loss: 2.3055 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1960 train loss: 2.3167 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-1970 train loss: 2.2940 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1980 train loss: 2.3041 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-1990 train loss: 2.2939 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2000 train loss: 2.3005 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2010 train loss: 2.3013 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2020 train loss: 2.2919 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2030 train loss: 2.3028 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2040 train loss: 2.3129 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2050 train loss: 2.2950 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2060 train loss: 2.2993 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2070 train loss: 2.3052 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2080 train loss: 2.3041 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2090 train loss: 2.3064 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2100 train loss: 2.3012 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-2110 train loss: 2.2866 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2120 train loss: 2.3107 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2130 train loss: 2.2973 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2140 train loss: 2.3091 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2150 train loss: 2.3235 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2160 train loss: 2.2881 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2170 train loss: 2.3041 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2180 train loss: 2.3037 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2190 train loss: 2.3074 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2200 train loss: 2.2990 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2210 train loss: 2.3064 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2220 train loss: 2.3042 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2230 train loss: 2.2908 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2240 train loss: 2.3154 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2250 train loss: 2.3076 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2260 train loss: 2.2984 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2270 train loss: 2.3043 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2280 train loss: 2.3093 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2290 train loss: 2.3036 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2300 train loss: 2.3014 valid loss: 2.3008, valid accuracy: 0.1126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-2310 train loss: 2.3085 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2320 train loss: 2.3083 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2330 train loss: 2.2915 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2340 train loss: 2.2852 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2350 train loss: 2.2928 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2360 train loss: 2.3067 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2370 train loss: 2.3034 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2380 train loss: 2.2913 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2390 train loss: 2.3054 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2400 train loss: 2.2983 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2410 train loss: 2.2923 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2420 train loss: 2.3152 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2430 train loss: 2.3104 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2440 train loss: 2.3003 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2450 train loss: 2.3118 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2460 train loss: 2.2908 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2470 train loss: 2.3025 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2480 train loss: 2.2998 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2490 train loss: 2.3083 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2500 train loss: 2.3123 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2510 train loss: 2.3115 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2520 train loss: 2.3011 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2530 train loss: 2.3185 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2540 train loss: 2.3071 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2550 train loss: 2.2981 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2560 train loss: 2.3110 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2570 train loss: 2.3027 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2580 train loss: 2.2973 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2590 train loss: 2.3090 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2600 train loss: 2.3090 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2610 train loss: 2.3088 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2620 train loss: 2.3041 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2630 train loss: 2.3017 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2640 train loss: 2.2962 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2650 train loss: 2.3043 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2660 train loss: 2.2888 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2670 train loss: 2.3000 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2680 train loss: 2.2959 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-2690 train loss: 2.3023 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2700 train loss: 2.3031 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-2710 train loss: 2.3077 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2720 train loss: 2.3021 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-2730 train loss: 2.3258 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2740 train loss: 2.2889 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2750 train loss: 2.3086 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2760 train loss: 2.3086 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2770 train loss: 2.3015 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2780 train loss: 2.3085 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2790 train loss: 2.3073 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2800 train loss: 2.2969 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2810 train loss: 2.3031 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2820 train loss: 2.3023 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-2830 train loss: 2.3047 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2840 train loss: 2.3167 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2850 train loss: 2.2925 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2860 train loss: 2.2951 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2870 train loss: 2.3035 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2880 train loss: 2.3056 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-2890 train loss: 2.2968 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-2900 train loss: 2.3138 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-2910 train loss: 2.3030 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-2920 train loss: 2.2969 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-2930 train loss: 2.3001 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-2940 train loss: 2.3188 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-2950 train loss: 2.3022 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-2960 train loss: 2.3101 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-2970 train loss: 2.3127 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-2980 train loss: 2.3006 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-2990 train loss: 2.2956 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3000 train loss: 2.3026 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3010 train loss: 2.2907 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3020 train loss: 2.2969 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3030 train loss: 2.3039 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3040 train loss: 2.3054 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3050 train loss: 2.2815 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3060 train loss: 2.2888 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3070 train loss: 2.3087 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3080 train loss: 2.2980 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-3090 train loss: 2.3083 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3100 train loss: 2.3186 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-3110 train loss: 2.3000 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-3120 train loss: 2.2998 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-3130 train loss: 2.2972 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-3140 train loss: 2.3076 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-3150 train loss: 2.2914 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-3160 train loss: 2.3114 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-3170 train loss: 2.3038 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-3180 train loss: 2.3083 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-3190 train loss: 2.2986 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-3200 train loss: 2.2924 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-3210 train loss: 2.3079 valid loss: 2.3016, valid accuracy: 0.1126\n",
      "Iter-3220 train loss: 2.3022 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-3230 train loss: 2.3061 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-3240 train loss: 2.3086 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-3250 train loss: 2.3121 valid loss: 2.3015, valid accuracy: 0.1126\n",
      "Iter-3260 train loss: 2.2867 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-3270 train loss: 2.3015 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3280 train loss: 2.3034 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3290 train loss: 2.2964 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3300 train loss: 2.3090 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3310 train loss: 2.3072 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3320 train loss: 2.3122 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3330 train loss: 2.3015 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3340 train loss: 2.3037 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3350 train loss: 2.2945 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3360 train loss: 2.2956 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3370 train loss: 2.3065 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3380 train loss: 2.3156 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3390 train loss: 2.3005 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-3400 train loss: 2.3084 valid loss: 2.3014, valid accuracy: 0.1126\n",
      "Iter-3410 train loss: 2.2873 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3420 train loss: 2.2967 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3430 train loss: 2.3135 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3440 train loss: 2.3108 valid loss: 2.3012, valid accuracy: 0.1126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-3450 train loss: 2.2962 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3460 train loss: 2.3040 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3470 train loss: 2.3003 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3480 train loss: 2.3038 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3490 train loss: 2.3007 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3500 train loss: 2.3046 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3510 train loss: 2.3005 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3520 train loss: 2.3009 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3530 train loss: 2.3020 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3540 train loss: 2.3202 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3550 train loss: 2.2915 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3560 train loss: 2.3019 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3570 train loss: 2.3115 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3580 train loss: 2.3017 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3590 train loss: 2.2810 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-3600 train loss: 2.3177 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3610 train loss: 2.3110 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-3620 train loss: 2.3096 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3630 train loss: 2.2951 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3640 train loss: 2.3007 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3650 train loss: 2.3061 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3660 train loss: 2.3006 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3670 train loss: 2.3175 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3680 train loss: 2.3082 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-3690 train loss: 2.3132 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-3700 train loss: 2.3025 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-3710 train loss: 2.3040 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3720 train loss: 2.3069 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3730 train loss: 2.3083 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-3740 train loss: 2.2943 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3750 train loss: 2.3010 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3760 train loss: 2.3053 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3770 train loss: 2.3153 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3780 train loss: 2.3051 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3790 train loss: 2.3045 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3800 train loss: 2.3037 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3810 train loss: 2.3107 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3820 train loss: 2.3082 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3830 train loss: 2.2996 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3840 train loss: 2.2967 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-3850 train loss: 2.3124 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-3860 train loss: 2.2985 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-3870 train loss: 2.3045 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-3880 train loss: 2.2988 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-3890 train loss: 2.2987 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-3900 train loss: 2.2982 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-3910 train loss: 2.2989 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3920 train loss: 2.2894 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-3930 train loss: 2.3003 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-3940 train loss: 2.2982 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3950 train loss: 2.2970 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3960 train loss: 2.3020 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3970 train loss: 2.2987 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3980 train loss: 2.3029 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-3990 train loss: 2.2994 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4000 train loss: 2.3003 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4010 train loss: 2.3133 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4020 train loss: 2.3077 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4030 train loss: 2.3107 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4040 train loss: 2.2951 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4050 train loss: 2.3070 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4060 train loss: 2.2977 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4070 train loss: 2.2902 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-4080 train loss: 2.3068 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-4090 train loss: 2.2869 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4100 train loss: 2.3071 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4110 train loss: 2.2884 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4120 train loss: 2.2943 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4130 train loss: 2.3040 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4140 train loss: 2.2965 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4150 train loss: 2.2889 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4160 train loss: 2.3034 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4170 train loss: 2.3039 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4180 train loss: 2.2974 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4190 train loss: 2.2963 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4200 train loss: 2.3156 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4210 train loss: 2.3024 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4220 train loss: 2.2950 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4230 train loss: 2.3004 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4240 train loss: 2.2988 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-4250 train loss: 2.3228 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-4260 train loss: 2.3062 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4270 train loss: 2.2932 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4280 train loss: 2.2993 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4290 train loss: 2.3119 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4300 train loss: 2.3063 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4310 train loss: 2.2970 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4320 train loss: 2.3118 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4330 train loss: 2.2960 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4340 train loss: 2.2994 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4350 train loss: 2.2786 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4360 train loss: 2.3076 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4370 train loss: 2.3061 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-4380 train loss: 2.2988 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-4390 train loss: 2.2926 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-4400 train loss: 2.3088 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-4410 train loss: 2.2996 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-4420 train loss: 2.3031 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-4430 train loss: 2.2873 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4440 train loss: 2.3146 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-4450 train loss: 2.3016 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4460 train loss: 2.3058 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4470 train loss: 2.2854 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4480 train loss: 2.3065 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4490 train loss: 2.3047 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-4500 train loss: 2.2995 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-4510 train loss: 2.2998 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-4520 train loss: 2.3002 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-4530 train loss: 2.3090 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4540 train loss: 2.3055 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4550 train loss: 2.2947 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4560 train loss: 2.2986 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4570 train loss: 2.2976 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4580 train loss: 2.3040 valid loss: 2.3012, valid accuracy: 0.1126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-4590 train loss: 2.2988 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4600 train loss: 2.2907 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4610 train loss: 2.3090 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4620 train loss: 2.3048 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4630 train loss: 2.3011 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4640 train loss: 2.3032 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4650 train loss: 2.3116 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4660 train loss: 2.2954 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4670 train loss: 2.3030 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4680 train loss: 2.3017 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-4690 train loss: 2.3040 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-4700 train loss: 2.2916 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-4710 train loss: 2.3048 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-4720 train loss: 2.3024 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-4730 train loss: 2.2943 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-4740 train loss: 2.2981 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-4750 train loss: 2.2924 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-4760 train loss: 2.3003 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-4770 train loss: 2.3047 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-4780 train loss: 2.2859 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4790 train loss: 2.2937 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4800 train loss: 2.3028 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4810 train loss: 2.3068 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4820 train loss: 2.2970 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-4830 train loss: 2.2939 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-4840 train loss: 2.3051 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4850 train loss: 2.3128 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4860 train loss: 2.3047 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4870 train loss: 2.3079 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4880 train loss: 2.2908 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4890 train loss: 2.2945 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4900 train loss: 2.3107 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4910 train loss: 2.3025 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4920 train loss: 2.3008 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4930 train loss: 2.2983 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4940 train loss: 2.3044 valid loss: 2.3013, valid accuracy: 0.1126\n",
      "Iter-4950 train loss: 2.2857 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-4960 train loss: 2.3035 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4970 train loss: 2.3066 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-4980 train loss: 2.3140 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-4990 train loss: 2.2988 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5000 train loss: 2.2958 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5010 train loss: 2.3054 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5020 train loss: 2.2940 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5030 train loss: 2.2941 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5040 train loss: 2.3087 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5050 train loss: 2.3009 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5060 train loss: 2.2912 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5070 train loss: 2.3020 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5080 train loss: 2.3036 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5090 train loss: 2.2935 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5100 train loss: 2.2998 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5110 train loss: 2.2979 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5120 train loss: 2.3039 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5130 train loss: 2.3016 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5140 train loss: 2.2985 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5150 train loss: 2.2957 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5160 train loss: 2.3034 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5170 train loss: 2.2948 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5180 train loss: 2.3031 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5190 train loss: 2.3031 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5200 train loss: 2.3009 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-5210 train loss: 2.2981 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5220 train loss: 2.3000 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5230 train loss: 2.3028 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5240 train loss: 2.3088 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5250 train loss: 2.2876 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5260 train loss: 2.3074 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5270 train loss: 2.3054 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5280 train loss: 2.2938 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5290 train loss: 2.2830 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5300 train loss: 2.2904 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5310 train loss: 2.2940 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5320 train loss: 2.2984 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5330 train loss: 2.3049 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5340 train loss: 2.3035 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5350 train loss: 2.2984 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5360 train loss: 2.2832 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5370 train loss: 2.2998 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-5380 train loss: 2.3037 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5390 train loss: 2.3109 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5400 train loss: 2.3026 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5410 train loss: 2.3144 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-5420 train loss: 2.3101 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-5430 train loss: 2.3000 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-5440 train loss: 2.3180 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-5450 train loss: 2.2961 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-5460 train loss: 2.3037 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-5470 train loss: 2.2969 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-5480 train loss: 2.3029 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-5490 train loss: 2.3044 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-5500 train loss: 2.3083 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-5510 train loss: 2.3080 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-5520 train loss: 2.3017 valid loss: 2.3005, valid accuracy: 0.1126\n",
      "Iter-5530 train loss: 2.3042 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-5540 train loss: 2.2937 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-5550 train loss: 2.3103 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-5560 train loss: 2.3220 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5570 train loss: 2.3031 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5580 train loss: 2.3107 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5590 train loss: 2.3105 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5600 train loss: 2.3034 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5610 train loss: 2.3022 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5620 train loss: 2.2983 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-5630 train loss: 2.2978 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5640 train loss: 2.2978 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5650 train loss: 2.3011 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5660 train loss: 2.3075 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5670 train loss: 2.3030 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-5680 train loss: 2.2861 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-5690 train loss: 2.3042 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-5700 train loss: 2.2957 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-5710 train loss: 2.2891 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-5720 train loss: 2.2937 valid loss: 2.3005, valid accuracy: 0.1126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-5730 train loss: 2.2918 valid loss: 2.3005, valid accuracy: 0.1126\n",
      "Iter-5740 train loss: 2.3091 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-5750 train loss: 2.3083 valid loss: 2.3005, valid accuracy: 0.1126\n",
      "Iter-5760 train loss: 2.2898 valid loss: 2.3005, valid accuracy: 0.1126\n",
      "Iter-5770 train loss: 2.3009 valid loss: 2.3005, valid accuracy: 0.1126\n",
      "Iter-5780 train loss: 2.2911 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-5790 train loss: 2.2975 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-5800 train loss: 2.3056 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-5810 train loss: 2.2993 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-5820 train loss: 2.2967 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-5830 train loss: 2.3025 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-5840 train loss: 2.3127 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5850 train loss: 2.3063 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5860 train loss: 2.3008 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5870 train loss: 2.3052 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5880 train loss: 2.3161 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5890 train loss: 2.3049 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5900 train loss: 2.3000 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-5910 train loss: 2.2933 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5920 train loss: 2.2965 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5930 train loss: 2.3001 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5940 train loss: 2.3076 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5950 train loss: 2.2946 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5960 train loss: 2.3042 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-5970 train loss: 2.2954 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5980 train loss: 2.2988 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-5990 train loss: 2.2895 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-6000 train loss: 2.3053 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6010 train loss: 2.2953 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-6020 train loss: 2.2998 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-6030 train loss: 2.3113 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6040 train loss: 2.3181 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6050 train loss: 2.3032 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6060 train loss: 2.3059 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6070 train loss: 2.3092 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6080 train loss: 2.3023 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6090 train loss: 2.2788 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6100 train loss: 2.2947 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6110 train loss: 2.3075 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6120 train loss: 2.3010 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6130 train loss: 2.2948 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6140 train loss: 2.3026 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6150 train loss: 2.2963 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6160 train loss: 2.3151 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6170 train loss: 2.3004 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6180 train loss: 2.2985 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6190 train loss: 2.2884 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6200 train loss: 2.3008 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6210 train loss: 2.3033 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6220 train loss: 2.2998 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6230 train loss: 2.3071 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6240 train loss: 2.2958 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6250 train loss: 2.3092 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6260 train loss: 2.2916 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6270 train loss: 2.3132 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6280 train loss: 2.2981 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6290 train loss: 2.3089 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-6300 train loss: 2.3092 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6310 train loss: 2.3033 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6320 train loss: 2.3017 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6330 train loss: 2.3003 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6340 train loss: 2.3147 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6350 train loss: 2.2911 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6360 train loss: 2.3087 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6370 train loss: 2.2911 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6380 train loss: 2.3070 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6390 train loss: 2.2995 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-6400 train loss: 2.3004 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6410 train loss: 2.3223 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6420 train loss: 2.3007 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-6430 train loss: 2.2905 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-6440 train loss: 2.2825 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6450 train loss: 2.2971 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6460 train loss: 2.2937 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6470 train loss: 2.2882 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6480 train loss: 2.2947 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-6490 train loss: 2.3061 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6500 train loss: 2.3040 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6510 train loss: 2.3105 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6520 train loss: 2.3078 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6530 train loss: 2.2968 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6540 train loss: 2.2924 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6550 train loss: 2.2967 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6560 train loss: 2.2988 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6570 train loss: 2.2989 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6580 train loss: 2.3012 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6590 train loss: 2.2918 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6600 train loss: 2.3114 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6610 train loss: 2.3026 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6620 train loss: 2.2928 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6630 train loss: 2.3104 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6640 train loss: 2.2982 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6650 train loss: 2.3019 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6660 train loss: 2.3020 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6670 train loss: 2.3076 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6680 train loss: 2.2925 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6690 train loss: 2.3105 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6700 train loss: 2.3025 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6710 train loss: 2.3002 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6720 train loss: 2.3094 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6730 train loss: 2.2945 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6740 train loss: 2.3041 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6750 train loss: 2.2910 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6760 train loss: 2.3088 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6770 train loss: 2.3007 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6780 train loss: 2.2967 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6790 train loss: 2.2972 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6800 train loss: 2.3000 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6810 train loss: 2.2979 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6820 train loss: 2.3107 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6830 train loss: 2.3016 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6840 train loss: 2.2992 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6850 train loss: 2.3209 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6860 train loss: 2.2983 valid loss: 2.3011, valid accuracy: 0.1126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-6870 train loss: 2.2997 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-6880 train loss: 2.2923 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6890 train loss: 2.3094 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6900 train loss: 2.3147 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6910 train loss: 2.3027 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6920 train loss: 2.3077 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-6930 train loss: 2.3052 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-6940 train loss: 2.3008 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-6950 train loss: 2.2915 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6960 train loss: 2.3040 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-6970 train loss: 2.2858 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-6980 train loss: 2.3009 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-6990 train loss: 2.3134 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7000 train loss: 2.3063 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7010 train loss: 2.3076 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7020 train loss: 2.3088 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7030 train loss: 2.2954 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7040 train loss: 2.2986 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7050 train loss: 2.3102 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7060 train loss: 2.2942 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7070 train loss: 2.2963 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7080 train loss: 2.2911 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7090 train loss: 2.2856 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7100 train loss: 2.2978 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7110 train loss: 2.3027 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7120 train loss: 2.2911 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7130 train loss: 2.3088 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7140 train loss: 2.3004 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7150 train loss: 2.3002 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7160 train loss: 2.2979 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7170 train loss: 2.3024 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7180 train loss: 2.3128 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7190 train loss: 2.2998 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7200 train loss: 2.3087 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7210 train loss: 2.2996 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7220 train loss: 2.2912 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7230 train loss: 2.3090 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7240 train loss: 2.2982 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7250 train loss: 2.2957 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7260 train loss: 2.3021 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7270 train loss: 2.3104 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7280 train loss: 2.2986 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7290 train loss: 2.3107 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7300 train loss: 2.3010 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7310 train loss: 2.3112 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7320 train loss: 2.3068 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7330 train loss: 2.3054 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7340 train loss: 2.3039 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7350 train loss: 2.2859 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-7360 train loss: 2.3096 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-7370 train loss: 2.3030 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-7380 train loss: 2.3025 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-7390 train loss: 2.2898 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-7400 train loss: 2.3041 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-7410 train loss: 2.3019 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-7420 train loss: 2.3126 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-7430 train loss: 2.2907 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-7440 train loss: 2.2883 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-7450 train loss: 2.3083 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-7460 train loss: 2.3052 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-7470 train loss: 2.2967 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-7480 train loss: 2.2956 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-7490 train loss: 2.3076 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-7500 train loss: 2.2999 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-7510 train loss: 2.2945 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-7520 train loss: 2.3144 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-7530 train loss: 2.3071 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-7540 train loss: 2.2940 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-7550 train loss: 2.3064 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-7560 train loss: 2.3008 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-7570 train loss: 2.2970 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-7580 train loss: 2.2852 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-7590 train loss: 2.3162 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-7600 train loss: 2.3131 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7610 train loss: 2.2969 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7620 train loss: 2.2966 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7630 train loss: 2.3045 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7640 train loss: 2.2961 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7650 train loss: 2.3045 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7660 train loss: 2.3020 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7670 train loss: 2.2996 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7680 train loss: 2.2850 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7690 train loss: 2.2990 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-7700 train loss: 2.3009 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7710 train loss: 2.3058 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7720 train loss: 2.3036 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7730 train loss: 2.2992 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7740 train loss: 2.2943 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7750 train loss: 2.3077 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7760 train loss: 2.3145 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7770 train loss: 2.3086 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7780 train loss: 2.3007 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7790 train loss: 2.3103 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7800 train loss: 2.2904 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7810 train loss: 2.3017 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-7820 train loss: 2.3099 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7830 train loss: 2.3120 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7840 train loss: 2.3131 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-7850 train loss: 2.3081 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7860 train loss: 2.3039 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7870 train loss: 2.2998 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7880 train loss: 2.3040 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-7890 train loss: 2.2987 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-7900 train loss: 2.3041 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-7910 train loss: 2.3135 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7920 train loss: 2.3082 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7930 train loss: 2.3140 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7940 train loss: 2.3048 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-7950 train loss: 2.2995 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-7960 train loss: 2.3024 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7970 train loss: 2.2961 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7980 train loss: 2.2973 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-7990 train loss: 2.3071 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-8000 train loss: 2.2955 valid loss: 2.3011, valid accuracy: 0.1126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-8010 train loss: 2.2943 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-8020 train loss: 2.2885 valid loss: 2.3012, valid accuracy: 0.1126\n",
      "Iter-8030 train loss: 2.2939 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-8040 train loss: 2.2999 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-8050 train loss: 2.2988 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-8060 train loss: 2.3086 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8070 train loss: 2.2953 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8080 train loss: 2.2978 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-8090 train loss: 2.2878 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-8100 train loss: 2.3046 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-8110 train loss: 2.3077 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-8120 train loss: 2.3160 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-8130 train loss: 2.2949 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-8140 train loss: 2.3003 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8150 train loss: 2.2869 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8160 train loss: 2.3007 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8170 train loss: 2.3072 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8180 train loss: 2.3049 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8190 train loss: 2.2969 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8200 train loss: 2.3035 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8210 train loss: 2.2944 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8220 train loss: 2.3076 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8230 train loss: 2.2973 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8240 train loss: 2.2990 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8250 train loss: 2.2946 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8260 train loss: 2.2951 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8270 train loss: 2.3105 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8280 train loss: 2.3031 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8290 train loss: 2.3054 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8300 train loss: 2.3066 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8310 train loss: 2.3113 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8320 train loss: 2.3077 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8330 train loss: 2.3010 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8340 train loss: 2.2940 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8350 train loss: 2.3094 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8360 train loss: 2.2911 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8370 train loss: 2.3177 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8380 train loss: 2.3050 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8390 train loss: 2.3120 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8400 train loss: 2.3030 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8410 train loss: 2.2980 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8420 train loss: 2.3091 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8430 train loss: 2.3007 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8440 train loss: 2.2995 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8450 train loss: 2.3136 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-8460 train loss: 2.3042 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8470 train loss: 2.3033 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8480 train loss: 2.3034 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8490 train loss: 2.2933 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-8500 train loss: 2.3145 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8510 train loss: 2.2944 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8520 train loss: 2.3020 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8530 train loss: 2.2862 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-8540 train loss: 2.2993 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8550 train loss: 2.3054 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8560 train loss: 2.3069 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8570 train loss: 2.3073 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8580 train loss: 2.3103 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-8590 train loss: 2.3043 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8600 train loss: 2.2981 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8610 train loss: 2.3062 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8620 train loss: 2.2816 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8630 train loss: 2.2792 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8640 train loss: 2.3044 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8650 train loss: 2.3114 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8660 train loss: 2.3145 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8670 train loss: 2.3223 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8680 train loss: 2.3035 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8690 train loss: 2.3030 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8700 train loss: 2.3066 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8710 train loss: 2.3029 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-8720 train loss: 2.2993 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-8730 train loss: 2.3108 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8740 train loss: 2.2993 valid loss: 2.3011, valid accuracy: 0.1126\n",
      "Iter-8750 train loss: 2.2882 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-8760 train loss: 2.3027 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8770 train loss: 2.2974 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8780 train loss: 2.3083 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8790 train loss: 2.3002 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8800 train loss: 2.2960 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8810 train loss: 2.2992 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8820 train loss: 2.3032 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8830 train loss: 2.3014 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8840 train loss: 2.2880 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-8850 train loss: 2.3072 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8860 train loss: 2.2896 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8870 train loss: 2.3039 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8880 train loss: 2.2898 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-8890 train loss: 2.2928 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-8900 train loss: 2.2992 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-8910 train loss: 2.3095 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-8920 train loss: 2.2987 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-8930 train loss: 2.2971 valid loss: 2.3006, valid accuracy: 0.1126\n",
      "Iter-8940 train loss: 2.3125 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-8950 train loss: 2.3145 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-8960 train loss: 2.2939 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-8970 train loss: 2.3103 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-8980 train loss: 2.3105 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-8990 train loss: 2.2876 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-9000 train loss: 2.3016 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-9010 train loss: 2.2990 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-9020 train loss: 2.2865 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-9030 train loss: 2.3003 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-9040 train loss: 2.2906 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9050 train loss: 2.3082 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9060 train loss: 2.2831 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9070 train loss: 2.3127 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9080 train loss: 2.3156 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9090 train loss: 2.2934 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9100 train loss: 2.3015 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-9110 train loss: 2.3115 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9120 train loss: 2.2929 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9130 train loss: 2.3133 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9140 train loss: 2.3030 valid loss: 2.3009, valid accuracy: 0.1126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-9150 train loss: 2.3068 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9160 train loss: 2.2943 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9170 train loss: 2.3027 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9180 train loss: 2.2852 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-9190 train loss: 2.3067 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9200 train loss: 2.3087 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9210 train loss: 2.2955 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9220 train loss: 2.2748 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9230 train loss: 2.3055 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9240 train loss: 2.3128 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9250 train loss: 2.3068 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9260 train loss: 2.3203 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9270 train loss: 2.3030 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9280 train loss: 2.2952 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9290 train loss: 2.3075 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9300 train loss: 2.2994 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9310 train loss: 2.2959 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9320 train loss: 2.3096 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9330 train loss: 2.2884 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9340 train loss: 2.3022 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9350 train loss: 2.2992 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9360 train loss: 2.3089 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9370 train loss: 2.3032 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9380 train loss: 2.3084 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9390 train loss: 2.3075 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9400 train loss: 2.3037 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-9410 train loss: 2.3093 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-9420 train loss: 2.2945 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9430 train loss: 2.3010 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9440 train loss: 2.3046 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9450 train loss: 2.2975 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9460 train loss: 2.2970 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9470 train loss: 2.3010 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9480 train loss: 2.2978 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9490 train loss: 2.3015 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9500 train loss: 2.3105 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9510 train loss: 2.2941 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9520 train loss: 2.3055 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-9530 train loss: 2.2944 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-9540 train loss: 2.3105 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-9550 train loss: 2.3014 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9560 train loss: 2.3016 valid loss: 2.3010, valid accuracy: 0.1126\n",
      "Iter-9570 train loss: 2.2965 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9580 train loss: 2.3029 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9590 train loss: 2.3076 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9600 train loss: 2.3066 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9610 train loss: 2.3195 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9620 train loss: 2.3021 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9630 train loss: 2.3049 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9640 train loss: 2.3158 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9650 train loss: 2.3047 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9660 train loss: 2.2931 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9670 train loss: 2.2922 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9680 train loss: 2.2940 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9690 train loss: 2.2971 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9700 train loss: 2.2965 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9710 train loss: 2.2807 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9720 train loss: 2.3031 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9730 train loss: 2.2993 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9740 train loss: 2.3010 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9750 train loss: 2.2973 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9760 train loss: 2.2997 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9770 train loss: 2.2986 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9780 train loss: 2.3019 valid loss: 2.3007, valid accuracy: 0.1126\n",
      "Iter-9790 train loss: 2.2998 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9800 train loss: 2.2863 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9810 train loss: 2.3002 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9820 train loss: 2.3039 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9830 train loss: 2.2873 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9840 train loss: 2.3058 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9850 train loss: 2.3062 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9860 train loss: 2.3019 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9870 train loss: 2.3133 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9880 train loss: 2.2967 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9890 train loss: 2.3182 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9900 train loss: 2.3069 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9910 train loss: 2.2946 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9920 train loss: 2.2969 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9930 train loss: 2.2910 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9940 train loss: 2.2942 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9950 train loss: 2.3005 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9960 train loss: 2.2730 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Iter-9970 train loss: 2.3119 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9980 train loss: 2.2798 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-9990 train loss: 2.2981 valid loss: 2.3008, valid accuracy: 0.1126\n",
      "Iter-10000 train loss: 2.2968 valid loss: 2.3009, valid accuracy: 0.1126\n",
      "Last iteration - Test accuracy mean: 0.1135, std: 0.0000, loss: 2.3012\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "n_iter = 10000 # number of epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "mb_size = 50 # 2**10==1024 # width, timestep for sequential data or minibatch size\n",
    "print_after = 10 # n_iter//10 # print loss for train, valid, and test\n",
    "num_hidden_units = 32 # number of kernels/ filters in each layer\n",
    "num_input_units = X_train.shape[1] # noise added at the input lavel as input noise we can use dX or for more improvement\n",
    "num_output_units = y_train.max() + 1 # number of classes in this classification problem\n",
    "num_layers = 10 # depth \n",
    "\n",
    "# Build the model/NN and learn it: running session.\n",
    "nn = FFNN(C=num_output_units, D=num_input_units, H=num_hidden_units, L=num_layers)\n",
    "\n",
    "nn.sgd(train_set=(X_train, y_train), val_set=(X_val, y_val), mb_size=mb_size, alpha=alpha, \n",
    "           n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npiAgIpLH/j/qkcmgEeldbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1212450b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(nn.losses['train'], label='Train loss')\n",
    "plt.plot(nn.losses['valid'], label='Valid loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEACAYAAABPiSrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7P8Dvqpio4VHNREAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121245198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn.losses['valid_acc'], label='Valid accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
