{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Linear classifier on sensor data with plot patterns and filters\n",
    "\n",
    "\n",
    "Decoding, a.k.a MVPA or supervised machine learning applied to MEG and EEG\n",
    "data in sensor space. Fit a linear classifier with the LinearModel object\n",
    "providing topographical patterns which are more neurophysiologically\n",
    "interpretable [1]_ than the classifier filters (weight vectors).\n",
    "The patterns explain how the MEG and EEG data were generated from the\n",
    "discriminant neural sources which are extracted by the filters.\n",
    "Note patterns/filters in MEG data are more similar than EEG data\n",
    "because the noise is less spatially correlated in MEG than EEG.\n",
    "\n",
    "References\n",
    "----------\n",
    "\n",
    ".. [1] Haufe, S., Meinecke, F., Görgen, K., Dähne, S., Haynes, J.-D.,\n",
    "       Blankertz, B., & Bießmann, F. (2014). On the interpretation of\n",
    "       weight vectors of linear models in multivariate neuroimaging.\n",
    "       NeuroImage, 87, 96–110. doi:10.1016/j.neuroimage.2013.10.067\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "# Authors: Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>\n",
    "#          Romain Trachel <trachelr@gmail.com>\n",
    "#          Jean-Remi King <jeanremi.king@gmail.com>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "import mne\n",
    "from mne import io, EvokedArray\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import Vectorizer, get_coef\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# import a linear classifier from mne.decoding\n",
    "from mne.decoding import LinearModel\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "data_path = sample.data_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /Users/arasdar/mne_data/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif...\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "        Average EEG reference (1 x 60)  idle\n",
      "    Range : 6450 ... 48149 =     42.956 ...   320.665 secs\n",
      "Ready.\n",
      "Current compensation grade : 0\n",
      "Reading 0 ... 41699  =      0.000 ...   277.709 secs...\n",
      "Setting up band-pass filter from 0.5 - 25 Hz\n",
      "l_trans_bandwidth chosen to be 0.5 Hz\n",
      "h_trans_bandwidth chosen to be 6.2 Hz\n",
      "Filter length of 1982 samples (13.200 sec) selected\n",
      "This filename (/Users/arasdar/mne_data/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif) does not conform to MNE naming conventions. All events files should end with .eve, -eve.fif, -eve.fif.gz, -eve.lst or -eve.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-4f90a440f6aa>:9: RuntimeWarning: This filename (/Users/arasdar/mne_data/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif) does not conform to MNE naming conventions. All events files should end with .eve, -eve.fif, -eve.fif.gz, -eve.lst or -eve.txt\n",
      "  events = mne.read_events(event_fname)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not find event data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4f90a440f6aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_raw_fif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Read epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/arasdar-DL-env/lib/python3.5/site-packages/mne/event.py\u001b[0m in \u001b[0;36mread_events\u001b[0;34m(filename, include, exclude, mask, mask_type)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiff_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mevent_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_events_fif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/arasdar-DL-env/lib/python3.5/site-packages/mne/event.py\u001b[0m in \u001b[0;36m_read_events_fif\u001b[0;34m(fid, tree)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not find event data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find event data"
     ]
    }
   ],
   "source": [
    "raw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\n",
    "event_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\n",
    "tmin, tmax = -0.1, 0.4\n",
    "event_id = dict(aud_l=1, vis_l=3)\n",
    "\n",
    "# Setup for reading the raw data\n",
    "raw = io.read_raw_fif(raw_fname, preload=True)\n",
    "raw.filter(.5, 25)\n",
    "events = mne.read_events(event_fname)\n",
    "\n",
    "# Read epochs\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True,\n",
    "                    decim=4, baseline=None, preload=True)\n",
    "\n",
    "labels = epochs.events[:, -1]\n",
    "\n",
    "# get MEG and EEG data\n",
    "meg_epochs = epochs.copy().pick_types(meg=True, eeg=False)\n",
    "meg_data = meg_epochs.get_data().reshape(len(labels), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding in sensor space using a LogisticRegression classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# create a linear model with LogisticRegression\n",
    "model = LinearModel(clf)\n",
    "\n",
    "# fit the classifier on MEG data\n",
    "X = scaler.fit_transform(meg_data)\n",
    "model.fit(X, labels)\n",
    "\n",
    "# Extract and plot spatial filters and spatial patterns\n",
    "for name, coef in (('patterns', model.patterns_), ('filters', model.filters_)):\n",
    "    # We fitted the linear model onto Z-scored data. To make the filters\n",
    "    # interpretable, we must reverse this normalization step\n",
    "    coef = scaler.inverse_transform([coef])[0]\n",
    "\n",
    "    # The data was vectorized to fit a single model across all time points and\n",
    "    # all channels. We thus reshape it:\n",
    "    coef = coef.reshape(len(meg_epochs.ch_names), -1)\n",
    "\n",
    "    # Plot\n",
    "    evoked = EvokedArray(coef, meg_epochs.info, tmin=epochs.tmin)\n",
    "    evoked.plot_topomap(title='MEG %s' % name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same on EEG data using a scikit-learn pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epochs.pick_types(meg=False, eeg=True)\n",
    "y = epochs.events[:, 2]\n",
    "\n",
    "# Define a unique pipeline to sequentially:\n",
    "clf = make_pipeline(\n",
    "    Vectorizer(),                       # 1) vectorize across time and channels\n",
    "    StandardScaler(),                   # 2) normalize features across trials\n",
    "    LinearModel(LogisticRegression()))  # 3) fits a logistic regression\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Extract and plot patterns and filters\n",
    "for name in ('patterns_', 'filters_'):\n",
    "    # The `inverse_transform` parameter will call this method on any estimator\n",
    "    # contained in the pipeline, in reverse order.\n",
    "    coef = get_coef(clf, name, inverse_transform=True)\n",
    "    evoked = EvokedArray(coef, epochs.info, tmin=epochs.tmin)\n",
    "    evoked.plot_topomap(title='EEG %s' % name[:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
