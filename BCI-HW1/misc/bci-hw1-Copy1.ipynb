{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCI homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain-Computer Interfaces (Fall 2017, ELE 594)\n",
    "# Instructor: Yalda Shahriari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st homework, 9/23/17 (The homework, is due by Oct 4, 11:55 pm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction: \n",
    "Load the “sampleEEGdata” into your Matlab workspace. \n",
    "This EEG dataset contains 64 channels (EEG.nbchan), 640 time points (EEG.pnts), and 99 trials (EEG.trials). \n",
    "The time points in ms has been saved in EEG.times where you can see each trial has been started \n",
    "from -1000 ms and ends at ~1500 ms. \n",
    "Use the topoplot.m function for plotting the head plots. \n",
    "Save the ‘eloc64C2.txt’ file in the same directory as the topoplot.m function for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here are the functions, \n",
    "# which reconstructs the dictionaries just use this loadmat instead of scipy.io's loadmat:\n",
    "\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    data = spio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], spio.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict        \n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'icasplinefile', 'chanlocs', 'splinefile', 'srate', 'chaninfo', 'spedata', 'data', 'etc', 'xmax', 'group', 'specdata', 'times', 'setname', 'urchanlocs', 'session', 'icawinv', 'saved', 'ref', 'nbchan', 'stats', 'event', 'pnts', 'icaweights', 'icaact', 'history', 'trials', 'icasphere', 'filepath', 'subject', 'specicaact', 'urevent', 'filename', 'comments', 'dipfit', 'epochdescription', 'reject', 'xmin', 'icachansind', 'eventdescription', 'condition'])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the “sampleEEGdata” into your Matlab workspace. \n",
    "data = loadmat(filename='sampleEEGdata')\n",
    "data['EEG'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 640, 99)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This EEG dataset contains 64 channels (EEG.nbchan), 640 time points (EEG.pnts), and 99 trials (EEG.trials). \n",
    "eeg = data['EEG']\n",
    "eeg['nbchan'], eeg['pnts'], eeg['trials']\n",
    "# _todict(eeg['chanlocs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256.0, 256)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The time points in ms has been saved in EEG.times where you can see each trial has been started \n",
    "# from -1000 ms and ends at ~1500 ms.\n",
    "eeg['times'].shape\n",
    "t_start = -1000 # ms: milisecond\n",
    "t_end = 1500 # ms\n",
    "t_duration = t_end - t_start\n",
    "sfreq = (eeg['times'].shape[0]/t_duration) * 1000\n",
    "sfreq, eeg['srate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 matching events found\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# Use the topoplot.m function for plotting the head plots.\n",
    "# Creating mne Objects from numpy arrays\n",
    "import mne as mne\n",
    "\n",
    "labels = []\n",
    "XYZs = []\n",
    "for each in eeg['chanlocs']:\n",
    "    label = _todict(matobj=each)['labels']\n",
    "    labels.append(label)\n",
    "    X = _todict(matobj=each)['X']\n",
    "    Y = _todict(matobj=each)['Y']\n",
    "    Z = _todict(matobj=each)['Z']\n",
    "    XYZs.append(np.array([X, Y, Z], dtype=float))\n",
    "    \n",
    "# len(labels)\n",
    "XYZs = np.array(XYZs, dtype=float)\n",
    "XYZs\n",
    "ch_names = labels #mat['ch_names'].tolist()\n",
    "elec = XYZs #mat['elec']\n",
    "dig_ch_pos = dict(zip(ch_names, elec))\n",
    "mon = mne.channels.DigMontage(dig_ch_pos=dig_ch_pos)\n",
    "\n",
    "# It is also possible to use info from another raw object.\n",
    "info = mne.create_info(ch_names=ch_names, ch_types='eeg', montage=mon, sfreq=eeg['srate'])\n",
    "\n",
    "data = eeg['data'].transpose(2, 0, 1)\n",
    "data.shape  # data : array, shape (n_epochs, n_channels, n_times)\n",
    "\n",
    "epochs = mne.EpochsArray(data=data, info=info) #, tmin=eeg['xmin']\n",
    "# epochs.plo\n",
    "picks = mne.pick_types(info=info, meg=False, eeg=True, misc=False)\n",
    "evoked = epochs.average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # epochs.plot\n",
    "# epochs.plot(picks=picks, scalings='auto', show=True, block=True)\n",
    "# # epochs.plot_drop_log()\n",
    "# epochs.plot_image(picks=picks)\n",
    "# # epochs.plot_projs_topomap()\n",
    "# epochs.plot_psd(picks=picks, tmin=eeg['xmin'], tmax=eeg['xmax'], show=True)\n",
    "# epochs.plot_psd_topomap()\n",
    "# epochs.plot_sensors()\n",
    "# epochs.plot_topo_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evoked.plot(picks=picks)\n",
    "# # evoked.plot_field()\n",
    "# evoked.plot_image(picks=picks, show='True')\n",
    "\n",
    "# ts_args = dict(gfp=True)\n",
    "# topomap_args = dict(sensors=False)\n",
    "# # evoked_r_aud.plot_joint(title='right auditory', times=[.07, .105],\n",
    "# #                         ts_args=ts_args, topomap_args=topomap_args)\n",
    "# evoked.plot_joint(exclude=(), picks=picks, show='True', topomap_args=topomap_args, ts_args=ts_args)\n",
    "# # evoked.plot_joint()\n",
    "\n",
    "# evoked.plot_topomap()\n",
    "# # evoked.animate_topomap()\n",
    "# # evoked.plot_projs_topomap()\n",
    "# evoked.plot_sensors()\n",
    "# evoked.plot_topo()\n",
    "# evoked.plot_topomap()\n",
    "# # evoked.plot_white()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bci-hw1-Copy1.ipynb  \u001b[0m\u001b[01;32mChannel Description.txt\u001b[0m*  \u001b[01;34mmne_examples\u001b[0m/       \u001b[01;32mtopoplot.m\u001b[0m*\r\n",
      "bci-hw1-Copy2.ipynb  \u001b[01;32meloc64C2.txt\u001b[0m*             README\r\n",
      "bci-hw1.ipynb        HW1.pdf                   \u001b[01;32msampleEEGdata.mat\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "# Save the ‘eloc64C2.txt’ file in the same directory as the topoplot.m function for further analysis.\n",
    "% ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a) Extract epochs from 0 to 800 ms.\n",
    "\n",
    "# Compute the ERPs at each electrode. \n",
    "\n",
    "# Get the average over all the trials. \n",
    "\n",
    "# Select nine time points at which to show topographical plots (e.g., 0 to 800 ms in 100- ms steps). \n",
    "\n",
    "# In one figure, make a series of topographical plots at these time points. \n",
    "\n",
    "# To increase the signal-to-noise ratio (SNR), make each plot show the average of activity from 20 ms before \n",
    "# until 20 ms after each time point. \n",
    "\n",
    "# For example, the topographical plot from 200 ms should show average activity from 180 ms until 220 ms. \n",
    "\n",
    "# Indicate the center time point in a title on each subplot., tmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99, 64, 640), (99, 64, 204))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data[0, 0, 20]\n",
    "# data.shape\n",
    "# 640 points\n",
    "# 1/ eeg['srate'] is time distance or period between each point\n",
    "# eeg['xmin'], eeg['xmax']\n",
    "# 1 * eeg['srate'], 0.8 * eeg['srate'], 1.5 * eeg['srate']\n",
    "# the window limit, lower limit and the upper limit for extracting the pochs\n",
    "roi_low, roi_length = 1 * eeg['srate'], 0.8 * eeg['srate']\n",
    "roi_low, roi_length = int(roi_low), int(roi_length)\n",
    "roi_low, roi_length, data.shape, (roi_low + roi_length)\n",
    "# data_extracted using the lower limit and upper limit of the region of interest (ROI) or window of interest\n",
    "data_roi = data[:, :, roi_low: (roi_low + roi_length)]\n",
    "data.shape, data_roi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# idx = _todict(eeg['epoch'][0])['eventlatency'] >= 0\n",
    "# idx *= _todict(eeg['epoch'][0])['eventlatency'] <= 800\n",
    "# # idx, idx2, idx * idx2\n",
    "# _todict(eeg['epoch'][0])['eventlatency'], _todict(eeg['epoch'][0])['eventlatency'][idx]\n",
    "# # idx = if _todict(eeg['epoch'][0])['eventlatency'][idx] >= 0 and _todict(eeg['epoch'][0])['eventlatency'][idx] <= 800\n",
    "# # _todict(eeg['epoch'][0])['eventlatency'][idx] >= 0 : _todict(eeg['epoch'][0])['eventlatency'][idx] <= 800\n",
    "# # if _todict(eeg['epoch'][0])['eventlatency'] >= 0 and _todict(eeg['epoch'][0])['eventlatency'] <= 800:\n",
    "# #     idx = _todict(eeg['epoch'][0])['eventlatency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  1,   0,   1],\n",
       "        [709,   0,   1],\n",
       "        [353,   0,   1],\n",
       "        [441,   0,   1],\n",
       "        [479,   0,   1],\n",
       "        [534,   0,   1],\n",
       "        [417,   0,   1],\n",
       "        [746,   0,   1],\n",
       "        [603,   0,   1],\n",
       "        [437,   0,   1],\n",
       "        [677,   0,   1],\n",
       "        [732,   0,   1],\n",
       "        [416,   0,   1],\n",
       "        [633,   0,   1],\n",
       "        [573,   0,   1],\n",
       "        [762,   0,   1],\n",
       "        [604,   0,   1],\n",
       "        [512,   0,   1],\n",
       "        [541,   0,   1],\n",
       "        [559,   0,   1],\n",
       "        [683,   0,   1],\n",
       "        [463,   0,   1],\n",
       "        [477,   0,   1],\n",
       "        [498,   0,   1],\n",
       "        [577,   0,   1],\n",
       "        [703,   0,   1],\n",
       "        [543,   0,   1],\n",
       "        [402,   0,   1],\n",
       "        [370,   0,   1],\n",
       "        [664,   0,   1],\n",
       "        [556,   0,   1],\n",
       "        [589,   0,   1],\n",
       "        [636,   0,   1],\n",
       "        [760,   0,   1],\n",
       "        [754,   0,   1],\n",
       "        [449,   0,   1],\n",
       "        [462,   0,   1],\n",
       "        [494,   0,   1],\n",
       "        [425,   0,   1],\n",
       "        [316,   0,   1],\n",
       "        [587,   0,   1],\n",
       "        [520,   0,   1],\n",
       "        [500,   0,   1],\n",
       "        [447,   0,   1],\n",
       "        [556,   0,   1],\n",
       "        [409,   0,   1],\n",
       "        [458,   0,   1],\n",
       "        [578,   0,   1],\n",
       "        [639,   0,   1],\n",
       "        [468,   0,   1],\n",
       "        [491,   0,   1],\n",
       "        [416,   0,   1],\n",
       "        [474,   0,   1],\n",
       "        [468,   0,   1],\n",
       "        [665,   0,   1],\n",
       "        [610,   0,   1],\n",
       "        [397,   0,   1],\n",
       "        [495,   0,   1],\n",
       "        [474,   0,   1],\n",
       "        [389,   0,   1],\n",
       "        [549,   0,   1],\n",
       "        [437,   0,   1],\n",
       "        [498,   0,   1],\n",
       "        [506,   0,   1],\n",
       "        [606,   0,   1],\n",
       "        [430,   0,   1],\n",
       "        [367,   0,   1],\n",
       "        [515,   0,   1],\n",
       "        [472,   0,   1],\n",
       "        [327,   0,   1],\n",
       "        [483,   0,   1],\n",
       "        [346,   0,   1],\n",
       "        [458,   0,   1],\n",
       "        [393,   0,   1],\n",
       "        [394,   0,   1],\n",
       "        [554,   0,   1],\n",
       "        [373,   0,   1],\n",
       "        [528,   0,   1],\n",
       "        [495,   0,   1],\n",
       "        [452,   0,   1],\n",
       "        [513,   0,   1],\n",
       "        [505,   0,   1],\n",
       "        [770,   0,   1],\n",
       "        [475,   0,   1],\n",
       "        [518,   0,   1],\n",
       "        [428,   0,   1],\n",
       "        [715,   0,   1],\n",
       "        [574,   0,   1],\n",
       "        [477,   0,   1],\n",
       "        [609,   0,   1],\n",
       "        [412,   0,   1],\n",
       "        [476,   0,   1],\n",
       "        [488,   0,   1],\n",
       "        [490,   0,   1],\n",
       "        [464,   0,   1],\n",
       "        [494,   0,   1],\n",
       "        [575,   0,   1],\n",
       "        [636,   0,   1],\n",
       "        [574,   0,   1]]),)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events, event_id = [], []\n",
    "for epoch in eeg['epoch']:\n",
    "    epoch = _todict(epoch)\n",
    "    idx = epoch['eventlatency'] > 0.0\n",
    "    idx *= epoch['eventlatency'] < 800.0\n",
    "#     print(epoch['eventlatency'], idx, epoch['eventlatency'][idx], epoch['eventtype'][idx], idx.argmax())\n",
    "#     if epoch['eventlatency'][idx] != 1: \n",
    "#         epoch['eventlatency'][idx] = 1\n",
    "#         epoch['eventtype'][idx] = 0\n",
    "#     t = np.array(epoch['eventlatency'][idx], dtype=int)\n",
    "#     A = np.array(epoch['eventtype'][idx], dtype=int)\n",
    "#     idx = idx['True']\n",
    "    t = epoch['eventlatency'][idx].all() # or.any() to get the all/any content of the array\n",
    "    A = epoch['eventtype'][idx].all()\n",
    "#     print(t.dtype, t, A.all(), A.dtype)\n",
    "#     print(t.all(), A.all())\n",
    "#     print(t, A)\n",
    "    event = np.array([t, 0, A])\n",
    "#     print(event)\n",
    "    events.append(event) # list of events/ stimuli/ pulses/ spikes\n",
    "    event_id.append(A) # list of event amplitude\n",
    "\n",
    "# events\n",
    "events = np.array(events, dtype=int)\n",
    "events, \n",
    "# # events.dtype\n",
    "# # event_id[0] = 1\n",
    "# event_id = np.array(event_id, dtype=int)\n",
    "\n",
    "# from collections import Counter\n",
    "# # Count the freq of words in the text/collection of words\n",
    "# counts = Counter(event_id)\n",
    "# counts\n",
    "# event_id = sorted(counts)\n",
    "# event_id[0]\n",
    "\n",
    "# # # if len(np.unique(events[:, 0])) != len(events):\n",
    "# # #     print('wrong')\n",
    "# # np.unique(events[:, 0]), len(np.unique(events[:, 0])), len(events)\n",
    "\n",
    "# epochs = mne.EpochsArray(data=data, events=events, event_id=event_id, info=info, tmin=eeg['xmin'])\n",
    "# # picks = mne.pick_types(info=info, meg=False, eeg=True, misc=False)\n",
    "# # # evoked = epochs.average()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# b) Loop through each electrode and find the peak time of the ERP between 100 and 800 ms.\n",
    "\n",
    "# Store these peak times in a separate variable and then make a topographical plot of the peak times\n",
    "# (that is, the topographical map will illustrate times in milliseconds, not activity at peak times).\n",
    "\n",
    "# Include a color bar in the figure and make sure to show times in milliseconds from time 0 (not, for\n",
    "# example, time indices instead of milliseconds).\n",
    "\n",
    "# What areas of the scalp show the earliest and the latest peak responses to the stimulus within this window?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# c) Repeat step (a) by applying large Laplacian filter.\n",
    "\n",
    "# Compare step (c) with step (a) and clearly explain your observations and comments (hint: To obtain the distance\n",
    "# and the surrounding electrodes, transfer the polar coordinates in eloc64C2.txt file into Cartesian.\n",
    "                                                                                   \n",
    "# Then for each electrode of interest keep those electrodes that are in radius [0.18 0.28], \n",
    "# remove the rest, continue obtaining your weights, and then the Laplacian filtered signal). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (Note: Make the colormaps in ‘jet’ format and keep the color limit for all the topoplots and for\n",
    "# each section the same)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a) Create a family of complex Morlet wavelets, ranging in frequencies from 2 Hz to 30 Hz in five steps. \n",
    "# Consider cycle as a fix number of 4 cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# b) Convolve each wavelet with EEG data from all electrodes and from only first trial \n",
    "# (hint: you can get the fft of both data and wavelet; multiply in the frequency domain, \n",
    "#  get ifft to return it back to the time domain, \n",
    "#  and then in order to make the convolved data the same length as the original data cut out the begging \n",
    "#  and the end of the convolved data with the cutting length equivalent to half of the wavelet length). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# c) Extract power and phase from the result of the complex wavelet convolution and store in a\n",
    "# time x frequency x electrodes x power/phase matrix (thus, a 640 x 5 x 64 x 2 matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# d) Make topographical plots of power and phase at 180 ms at all frequencies (hint: you may need\n",
    "# to use the squeeze function to remove singleton dimensions).\n",
    "\n",
    "# Arrange the plots in one figure with five columns for frequency and two rows for power/phase. \n",
    "\n",
    "# Put labels in the plot so it is clear which topographical maps correspond to which frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# e) Repeat step (d) for activity at 360 ms, and 650 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f) Are there any prominent topographical features in power or in phase? \n",
    "\n",
    "# Do these differ for different frequencies? \n",
    "\n",
    "# Do power and phase have similar topographical distributions? \n",
    "\n",
    "# Is there any reason to suspect that they might have similar or different topographies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g) (Optional) Now consider the frequency range varies between 2Hz to 30Hz in two steps.\n",
    "\n",
    "# Instead of constant cycle equivalent to 4 (what we had before), \n",
    "# consider variable cycles ranging between [3 10] cycle. \n",
    "\n",
    "# Based on your total number of frequencies, \n",
    "# you can define constant steps for your cycles where it starts from 3 cycles and ends at 10 cycles. \n",
    "\n",
    "# 3 would correspond to the minimum frequency (i.e. 2 Hz) and 10 would correspond to the maximum frequency (i.e. 30 Hz).\n",
    "\n",
    "# Considering only channel ‘FCz’, for each frequency, obtain the power for all the trials (i.e. 99).\n",
    "\n",
    "# Get the average of the powers over all the trials. \n",
    "\n",
    "# Apply baseline correction by dividing the obtained results to the average baseline power (i.e. [-500 -200 ms]). \n",
    "\n",
    "# The resulting matrix size would be 20 x 640. \n",
    "\n",
    "# Plot the time-frequency map where the x-axis is the time [-200 1000 ms], \n",
    "# y-axis is the frequency [2 30 Hz], and color corresponds to 10log10 (power). \n",
    "\n",
    "# Make the colormaps in ‘jet’ format and the color-limit to [-3 3]. \n",
    "\n",
    "# Repeat the same process with fixed cycle 4 for all the frequencies.\n",
    "\n",
    "# Compare your results between two conditions of fixed and variable cycles and explain your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
